{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from Common import NeuralNet, MultiVariatePoly\n",
    "import time\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "torch.manual_seed(128)\n",
    "# torch.manual_seed\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNO\n",
    "\n",
    "The Temperature evolution of the solid and fluid phases $T_S$a nd $T_f$ is described by a sdystem of two linear reaction-convection diffusion equation $$\\begin{aligned} \\varepsilon \\rho_{f} C_{f} \\frac{\\partial T_{f}}{\\partial t}+\\varepsilon \\rho_{f} C_{f} u_{f}(t) \\frac{\\partial T_{f}}{\\partial x}=\\lambda_{f} \\frac{\\partial^{2} T_{f}}{\\partial x^{2}}-h_{v}\\left(T_{f}-T_{s}\\right) & x \\in[0, L], t \\in[0, T] \\\\ (1-\\varepsilon) \\rho_{s} C_{s} \\frac{\\partial T_{s}}{\\partial t}=\\lambda_{s} \\frac{\\partial^{2} T_{s}}{\\partial x^{2}}+h_{v}\\left(T_{f}-T_{s}\\right) & x \\in[0, L], t \\in[0, T]\\end{aligned}$$\n",
    "\n",
    "\n",
    "### Learning Operators\n",
    "\n",
    "Mapping between two infinite dimensional spaces from a finite collection of observed input-output pairs (i.e $(t, T_s)$ and $(t, T_f)$)\n",
    "\n",
    "We want to find a solution operator (map) $G^\\dagger$ of the parametric PDE above by constructing a parametric map $$ G_\\theta: \\mathcal{A} \\rightarrow \\mathcal{U}$$ for some parameter $\\theta^\\dagger \\in \\Theta$ (where $\\Theta$ is some finite dimensional parameter space), such that this approximation map $$G(\\cdot, \\theta^\\dagger) = G_{\\theta^\\dagger} \\simeq G^\\dagger$$\n",
    "\n",
    "Approximating this solution operator $G^\\dagger$ is different than finding the solution $u \\in \\mathcal{U}$ of a PDE for a single instance of the parameter $a \\in \\mathcal{A}$\n",
    "\n",
    "## Operator Learning\n",
    "\n",
    "- The spatial domain for the PDE $D \\subset \\mathbb{R}^d$ (in our case simply $t \\in \\mathbb{R}$, where $t$ correspond to the points in the spatial domain)\n",
    "- $a \\in \\mathcal{A} = (D; \\mathbb{R}^{d_a})$ are the **input coefficient functions**\n",
    "- $u \\in \\mathcal{U} = (D; \\mathbb{R}^{d_u})$ are the **target solution functions**\n",
    "\n",
    "Given a set of observations s $\\{a_j, u_j\\}_{j =1}^N$, the function $D_j$ describes the discretization of $(a_j, u_j)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>tf0</th>\n",
       "      <th>ts0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>873.000000</td>\n",
       "      <td>293.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2478.06</td>\n",
       "      <td>873.000000</td>\n",
       "      <td>655.920736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4956.12</td>\n",
       "      <td>873.000000</td>\n",
       "      <td>792.106226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7434.18</td>\n",
       "      <td>873.000000</td>\n",
       "      <td>842.176577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9912.24</td>\n",
       "      <td>873.000000</td>\n",
       "      <td>861.040655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>508002.30</td>\n",
       "      <td>730.794575</td>\n",
       "      <td>730.514961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>510480.36</td>\n",
       "      <td>730.053663</td>\n",
       "      <td>729.797475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>512958.42</td>\n",
       "      <td>729.371039</td>\n",
       "      <td>729.133162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>515436.48</td>\n",
       "      <td>728.734400</td>\n",
       "      <td>728.511278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>517914.54</td>\n",
       "      <td>728.135229</td>\n",
       "      <td>727.924326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             t         tf0         ts0\n",
       "0         0.00  873.000000  293.000000\n",
       "1      2478.06  873.000000  655.920736\n",
       "2      4956.12  873.000000  792.106226\n",
       "3      7434.18  873.000000  842.176577\n",
       "4      9912.24  873.000000  861.040655\n",
       "..         ...         ...         ...\n",
       "205  508002.30  730.794575  730.514961\n",
       "206  510480.36  730.053663  729.797475\n",
       "207  512958.42  729.371039  729.133162\n",
       "208  515436.48  728.734400  728.511278\n",
       "209  517914.54  728.135229  727.924326\n",
       "\n",
       "[210 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"Task3/TrainingData.txt\")\n",
    "test_data = pd.read_csv(\"Task3/TestingData.txt\")\n",
    "display(train_data)\n",
    "\n",
    "t_train_import = torch.from_numpy(train_data['t'].to_numpy()).type(torch.float32)\n",
    "t_pred = torch.from_numpy(test_data['t'].to_numpy()).type(torch.float32)\n",
    "\n",
    "Tf0 = torch.from_numpy(train_data['tf0'].to_numpy()).type(torch.float32)\n",
    "Ts0 = torch.from_numpy(train_data['ts0'].to_numpy()).type(torch.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# load data\n",
    "# create scaler\n",
    "scaler_t = MinMaxScaler()\n",
    "scaler_Tf = MinMaxScaler()\n",
    "scaler_Ts = MinMaxScaler()\n",
    "# # inverse transform\n",
    "# inverse = scaler.inverse_transform(normalized)\n",
    "\n",
    "t_train_norm = scaler_t.fit_transform(train_data['t'].to_numpy().reshape(-1, 1))\n",
    "t_test_norm = scaler_t.fit_transform(test_data['t'].to_numpy().reshape(-1, 1))\n",
    "Tf0_norm = scaler_Tf.fit_transform(train_data['tf0'].to_numpy().reshape(-1, 1))\n",
    "Ts0_norm = scaler_Ts.fit_transform(train_data['ts0'].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Normalized data')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (12, 8))\n",
    "\n",
    "ax[0].plot(t_train_import, Tf0, label = \"tf\")\n",
    "ax[0].plot(t_train_import, Ts0, label = 'ts')\n",
    "ax[0].legend()\n",
    "ax[0].set_title(\"Unnormalized data\")\n",
    "\n",
    "ax[1].plot(t_train_norm, Tf0_norm, label = 'tf_norm')\n",
    "ax[1].plot(t_train_norm, Ts0_norm, label = 'ts_norm')\n",
    "ax[1].set_title(\"Normalized data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain $\\Delta t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00478469]\n"
     ]
    }
   ],
   "source": [
    "delta_t = t_pred[1] - t_pred[0]\n",
    "delta_t_norm = t_train_norm[1] - t_train_norm[0]\n",
    "print(delta_t_norm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the a(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last element\n"
     ]
    }
   ],
   "source": [
    "a_t = []\n",
    "for idx, t in enumerate(t_train_import):\n",
    "    # print(idx)\n",
    "    if idx == (len(t_train_import)-1):\n",
    "        print(\"last element\")\n",
    "    else:\n",
    "        a_idx = (Tf0[idx+1] - Tf0[idx])/(delta_t*(Tf0[idx] - Ts0[idx]))\n",
    "        # print(a_idx)\n",
    "        a_t.append(a_idx)\n",
    "\n",
    "a_t = torch.tensor(a_t)\n",
    "# a_t = a_t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -7.3596e-05, -2.7060e-04,\n",
      "        -6.0869e-04, -1.0089e-03, -1.0901e-03, -1.1138e-03, -1.1234e-03,\n",
      "        -1.1084e-03, -1.1192e-03, -9.3048e-02,  3.5746e-03,  1.4307e-03,\n",
      "         9.8085e-04,  7.8270e-04,  6.6903e-04,  5.9409e-04,  5.4034e-04,\n",
      "         4.9955e-04, -1.0547e-04, -4.5424e-05, -2.1249e-03, -1.0942e-03,\n",
      "        -1.0651e-03, -1.0701e-03, -1.0758e-03, -1.0801e-03,  3.4913e-01,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0339e-04, -2.9171e-04,\n",
      "        -6.8553e-04, -1.0352e-03, -1.0886e-03, -1.1220e-03, -1.1049e-03,\n",
      "        -1.1049e-03, -1.1145e-03, -1.3911e-01,  3.0455e-03,  1.4085e-03,\n",
      "         9.9744e-04,  8.0841e-04,  6.9829e-04,  6.2545e-04,  5.7336e-04,\n",
      "         5.3411e-04, -1.7552e-04,  3.2822e-05, -1.6156e-03, -1.0837e-03,\n",
      "        -1.0660e-03, -1.0715e-03, -1.0769e-03, -1.0811e-03,  3.0282e-01,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.3362e-04, -3.1924e-04,\n",
      "        -7.5572e-04, -1.0563e-03, -1.0761e-03, -1.1097e-03, -1.1097e-03,\n",
      "        -1.1097e-03, -1.1223e-03, -2.0255e-01,  2.6164e-03,  1.3445e-03,\n",
      "         9.7913e-04,  8.0442e-04,  7.0098e-04,  6.3218e-04,  5.8303e-04,\n",
      "         4.2790e-04, -1.8129e-04,  1.6223e-04, -1.3912e-03, -1.0766e-03,\n",
      "        -1.0669e-03, -1.0726e-03, -1.0779e-03, -1.0819e-03,  2.8906e-01,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.6559e-04, -3.5310e-04,\n",
      "        -8.1692e-04, -1.0809e-03, -1.1060e-03, -1.0911e-03, -1.1060e-03,\n",
      "        -1.1060e-03, -1.1209e-03, -2.7427e-01,  2.3002e-03,  1.2817e-03,\n",
      "         9.5600e-04,  7.9463e-04,  6.9762e-04,  6.3272e-04,  5.8635e-04,\n",
      "         3.0901e-04, -1.7153e-04,  4.0166e-04, -1.2701e-03, -1.0720e-03,\n",
      "        -1.0675e-03, -1.0735e-03, -1.0787e-03, -1.0826e-03,  2.8280e-01,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.9969e-04, -3.9698e-04,\n",
      "        -8.6822e-04, -1.0653e-03, -1.0929e-03, -1.0929e-03, -1.1404e-03,\n",
      "        -1.0929e-03, -6.3894e-03,  3.1025e-02,  2.0605e-03,  1.2247e-03,\n",
      "         9.3284e-04,  7.8355e-04,  6.9247e-04,  6.3118e-04,  5.8738e-04,\n",
      "         2.0321e-04, -1.5793e-04,  9.4803e-04, -1.1978e-03, -1.0691e-03,\n",
      "        -1.0685e-03, -1.0744e-03, -1.0794e-03, -1.0833e-03,  2.7933e-01,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -2.3665e-04, -4.4529e-04,\n",
      "        -9.2238e-04, -1.0822e-03, -1.0822e-03, -1.0822e-03, -1.0822e-03,\n",
      "        -1.1006e-03, -2.0947e-02,  1.0148e-02,  1.8730e-03,  1.1738e-03,\n",
      "         9.1084e-04,  7.7236e-04,  6.8673e-04,  6.2878e-04,  5.8732e-04,\n",
      "         1.0787e-04, -1.3870e-04,  3.1347e-03, -1.1520e-03, -1.0676e-03,\n",
      "        -1.0693e-03, -1.0753e-03, -1.0801e-03, -1.0838e-03])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15d7fb760>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(a_t)\n",
    "plt.plot(t_train_import[:-1], a_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last element\n"
     ]
    }
   ],
   "source": [
    "a_t_norm = []\n",
    "for idx, t in enumerate(t_train_norm):\n",
    "    if idx == (len(t_train_norm) - 1):\n",
    "        print(\"Last element\")\n",
    "    else:\n",
    "        a_idx = (Tf0_norm[idx+1] - Tf0_norm[idx])/(delta_t*(Tf0_norm[idx] - Ts0_norm[idx]))\n",
    "        a_t_norm.append(a_idx)\n",
    "a_t_norm = torch.tensor(a_t_norm)\n",
    "# a_t_norm = a_t_norm.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([178, 2])\n",
      "torch.Size([31, 2])\n",
      "torch.Size([178, 1])\n",
      "torch.Size([31, 1])\n"
     ]
    }
   ],
   "source": [
    "n_train = 178\n",
    "batch_size = 178\n",
    "\n",
    "t_train = t_train_norm[:n_train].reshape(-1,1)\n",
    "t_test =  t_train_norm[n_train:-1].reshape(-1,1)\n",
    "\n",
    "t_train = torch.from_numpy(t_train).type(torch.float32)\n",
    "t_test = torch.from_numpy(t_test).type(torch.float32)\n",
    "\n",
    "Tf0_norm_torch = torch.from_numpy(Tf0_norm).type(torch.float32)\n",
    "Ts0_norm_torch = torch.from_numpy(Ts0_norm).type(torch.float32)\n",
    "\n",
    "# Output Set\n",
    "Tf0_train = Tf0_norm_torch[:n_train]\n",
    "Ts0_train = Ts0_norm_torch[:n_train]\n",
    "\n",
    "Tf0_test = Tf0_norm_torch[n_train:-1]\n",
    "Ts0_test = Ts0_norm_torch[n_train:-1]\n",
    "\n",
    "at_train = a_t_norm[:n_train].reshape(-1,1)\n",
    "at_test = a_t_norm[n_train:].reshape(-1,1)\n",
    "\n",
    "input_train_tf0 = torch.cat((t_train, at_train), 1).type(torch.float32)\n",
    "input_test_tf0 = torch.cat((t_test, at_test), 1).type(torch.float32)\n",
    "\n",
    "torch.unsqueeze(input_train_tf0, dim=0)\n",
    "torch.unsqueeze(input_test_tf0, dim=0)\n",
    "\n",
    "print(input_train_tf0.shape)\n",
    "print(input_test_tf0.shape)\n",
    "print(Tf0_train.shape)\n",
    "print(Tf0_test.shape)\n",
    "\n",
    "training_set_tf0 = DataLoader(TensorDataset(input_train_tf0, Tf0_train), batch_size=batch_size, shuffle=True)\n",
    "testing_set_tf0 =  DataLoader(TensorDataset(input_test_tf0, Tf0_test), batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Training and Testing Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1772e6220>]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(t_train, Ts0_train, label=\"Ts0\")\n",
    "plt.plot(t_train, Tf0_train, label=\"Tf0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x15ff80e80>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(t_test, Ts0_test, label=\"Ts0\")\n",
    "plt.scatter(t_test, Tf0_test, label=\"Tf0\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNO1D Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(name):\n",
    "    if name in ['tanh', 'Tanh']:\n",
    "        return nn.Tanh()\n",
    "    elif name in ['relu', 'ReLU']:\n",
    "        return nn.ReLU(inplace=True)\n",
    "    elif name in ['lrelu', 'LReLU']:\n",
    "        return nn.LeakyReLU(inplace=True)\n",
    "    elif name in ['sigmoid', 'Sigmoid']:\n",
    "        return nn.Sigmoid()\n",
    "    elif name in ['softplus', 'Softplus']:\n",
    "        return nn.Softplus(beta=4)\n",
    "    elif name in ['celu', 'CeLU']:\n",
    "        return nn.CELU()\n",
    "    elif name in ['elu']:\n",
    "        return nn.ELU()\n",
    "    elif name in ['mish']:\n",
    "        return nn.Mish()\n",
    "    else:\n",
    "        raise ValueError('Unknown activation function')\n",
    "\n",
    "\n",
    "################################################################\n",
    "#  1d fourier layer\n",
    "################################################################\n",
    "class SpectralConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1):\n",
    "        super(SpectralConv1d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        1D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul1d(self, input, weights):\n",
    "        # (batch, in_channel, x ), (in_channel, out_channel, x) -> (batch, out_channel, x)\n",
    "        return torch.einsum(\"bix,iox->box\", input, weights)\n",
    "\n",
    "\n",
    "######################### TO DO ####################################\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        # x.shape == [batch_size, in_channels, number of grid points]\n",
    "        # hint: use torch.fft library torch.fft.rfft\n",
    "        # use DFT to approximate the fourier transform\n",
    "        \n",
    "        # Compute Fourier coefficients\n",
    "        x_ft = torch.fft.rfft(x)\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-1) // 2 + 1, device=x.device, dtype=torch.cfloat)\n",
    "        out_ft[:, :, :self.modes1] = self.compl_mul1d(x_ft[:, :, :self.modes1], self.weights1)\n",
    "\n",
    "        # Return to physical space\n",
    "        x = torch.fft.irfft(out_ft, n=x.size(-1))\n",
    "        return x\n",
    "\n",
    "\n",
    "####################################################################\n",
    "\n",
    "\n",
    "class FNO1d(nn.Module):\n",
    "    def __init__(self, modes, width):\n",
    "        super(FNO1d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "\n",
    "        input: the solution of the initial condition and location (a(x), x)\n",
    "        input shape: (batchsize, x=s, c=2)\n",
    "        output: the solution of a later timestep\n",
    "        output shape: (batchsize, x=s, c=1)\n",
    "        \"\"\"\n",
    "\n",
    "        self.modes1 = modes\n",
    "        self.width = width\n",
    "        self.padding = 1  # pad the domain if input is non-periodic\n",
    "        self.linear_p = nn.Linear(2, self.width)  # input channel is 2: (u0(x), x)\n",
    "\n",
    "        self.spect1 = SpectralConv1d(self.width, self.width, self.modes1)\n",
    "        self.spect2 = SpectralConv1d(self.width, self.width, self.modes1)\n",
    "        self.spect3 = SpectralConv1d(self.width, self.width, self.modes1)\n",
    "        self.lin0 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.lin1 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.lin2 = nn.Conv1d(self.width, self.width, 1)\n",
    "\n",
    "        self.linear_q = nn.Linear(self.width, 32)\n",
    "        self.output_layer = nn.Linear(32, 1)\n",
    "\n",
    "        self.activation = torch.nn.Tanh()\n",
    "\n",
    "    def fourier_layer(self, x, spectral_layer, conv_layer):\n",
    "        return self.activation(spectral_layer(x) + conv_layer(x))\n",
    "\n",
    "    def linear_layer(self, x, linear_transformation):\n",
    "        return self.activation(linear_transformation(x))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # grid = self.get_grid(x.shape, x.device)\n",
    "        # x = torch.cat((x, grid), dim=-1)\n",
    "        x = self.linear_p(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # x = F.pad(x, [0, self.padding])  # pad the domain if input is non-periodic\n",
    "\n",
    "        x = self.fourier_layer(x, self.spect1, self.lin0)\n",
    "        x = self.fourier_layer(x, self.spect2, self.lin1)\n",
    "        x = self.fourier_layer(x, self.spect3, self.lin2)\n",
    "\n",
    "        # x = x[..., :-self.padding]  # pad the domain if input is non-periodic\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.linear_layer(x, self.linear_q)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "# epochs = 250\n",
    "epochs = 250\n",
    "step_size = 50\n",
    "gamma = 0.5\n",
    "\n",
    "modes = 16\n",
    "width = 64\n",
    "\n",
    "# model\n",
    "\n",
    "fno = FNO1d(modes, width)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 0  ######### Train Loss: 0.5939539074897766  ######### Relative L2 Test Norm: 77.57982635498047\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 1  ######### Train Loss: 0.4518243372440338  ######### Relative L2 Test Norm: 64.47579193115234\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 2  ######### Train Loss: 0.3281303942203522  ######### Relative L2 Test Norm: 50.32514190673828\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 3  ######### Train Loss: 0.21996447443962097  ######### Relative L2 Test Norm: 35.588523864746094\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 4  ######### Train Loss: 0.13688650727272034  ######### Relative L2 Test Norm: 24.510618209838867\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabianjaeger/miniconda/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([178, 1])) that is different to the input size (torch.Size([1, 178])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### Epoch: 5  ######### Train Loss: 0.096783347427845  ######### Relative L2 Test Norm: 25.868057250976562\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 6  ######### Train Loss: 0.10972552001476288  ######### Relative L2 Test Norm: 33.11991882324219\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 7  ######### Train Loss: 0.14737196266651154  ######### Relative L2 Test Norm: 35.89610290527344\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 8  ######### Train Loss: 0.16459082067012787  ######### Relative L2 Test Norm: 33.88306427001953\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 9  ######### Train Loss: 0.1541016399860382  ######### Relative L2 Test Norm: 29.29616928100586\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 10  ######### Train Loss: 0.12994375824928284  ######### Relative L2 Test Norm: 24.849409103393555\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 11  ######### Train Loss: 0.10735321789979935  ######### Relative L2 Test Norm: 23.402456283569336\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 12  ######### Train Loss: 0.09594883769750595  ######### Relative L2 Test Norm: 25.76563262939453\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 13  ######### Train Loss: 0.09771354496479034  ######### Relative L2 Test Norm: 29.673818588256836\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 14  ######### Train Loss: 0.10758177936077118  ######### Relative L2 Test Norm: 32.67475128173828\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 15  ######### Train Loss: 0.1172892227768898  ######### Relative L2 Test Norm: 33.7242546081543\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 16  ######### Train Loss: 0.1210147961974144  ######### Relative L2 Test Norm: 32.87327575683594\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 17  ######### Train Loss: 0.11790691316127777  ######### Relative L2 Test Norm: 30.695173263549805\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 18  ######### Train Loss: 0.11056356132030487  ######### Relative L2 Test Norm: 27.96402359008789\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 19  ######### Train Loss: 0.10262046009302139  ######### Relative L2 Test Norm: 25.48554801940918\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 20  ######### Train Loss: 0.09704186022281647  ######### Relative L2 Test Norm: 23.888893127441406\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 21  ######### Train Loss: 0.09518873691558838  ######### Relative L2 Test Norm: 23.357641220092773\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 22  ######### Train Loss: 0.09669926762580872  ######### Relative L2 Test Norm: 23.559518814086914\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 23  ######### Train Loss: 0.09992260485887527  ######### Relative L2 Test Norm: 23.944087982177734\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 24  ######### Train Loss: 0.10282158106565475  ######### Relative L2 Test Norm: 24.10997772216797\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 25  ######### Train Loss: 0.10395297408103943  ######### Relative L2 Test Norm: 23.952545166015625\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 26  ######### Train Loss: 0.10299588739871979  ######### Relative L2 Test Norm: 23.618024826049805\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 27  ######### Train Loss: 0.10060247033834457  ######### Relative L2 Test Norm: 23.372291564941406\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 28  ######### Train Loss: 0.09790997207164764  ######### Relative L2 Test Norm: 23.445287704467773\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 29  ######### Train Loss: 0.09592962265014648  ######### Relative L2 Test Norm: 23.90824317932129\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 30  ######### Train Loss: 0.09518170356750488  ######### Relative L2 Test Norm: 24.649030685424805\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 31  ######### Train Loss: 0.09559819847345352  ######### Relative L2 Test Norm: 25.448381423950195\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 32  ######### Train Loss: 0.09668950736522675  ######### Relative L2 Test Norm: 26.08687973022461\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 33  ######### Train Loss: 0.09781111031770706  ######### Relative L2 Test Norm: 26.41780662536621\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 34  ######### Train Loss: 0.09845220297574997  ######### Relative L2 Test Norm: 26.391475677490234\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 35  ######### Train Loss: 0.0983862578868866  ######### Relative L2 Test Norm: 26.048425674438477\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 36  ######### Train Loss: 0.09770210087299347  ######### Relative L2 Test Norm: 25.494396209716797\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 37  ######### Train Loss: 0.09671781212091446  ######### Relative L2 Test Norm: 24.866235733032227\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 38  ######### Train Loss: 0.09580609202384949  ######### Relative L2 Test Norm: 24.292316436767578\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 39  ######### Train Loss: 0.09526773542165756  ######### Relative L2 Test Norm: 23.857839584350586\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 40  ######### Train Loss: 0.09520325064659119  ######### Relative L2 Test Norm: 23.58681297302246\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 41  ######### Train Loss: 0.09551946073770523  ######### Relative L2 Test Norm: 23.450864791870117\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 42  ######### Train Loss: 0.09598593413829803  ######### Relative L2 Test Norm: 23.398853302001953\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 43  ######### Train Loss: 0.09634707123041153  ######### Relative L2 Test Norm: 23.390207290649414\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 44  ######### Train Loss: 0.09643619507551193  ######### Relative L2 Test Norm: 23.412813186645508\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 45  ######### Train Loss: 0.09623883664608002  ######### Relative L2 Test Norm: 23.48035430908203\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 46  ######### Train Loss: 0.09586241096258163  ######### Relative L2 Test Norm: 23.61406135559082\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 47  ######### Train Loss: 0.09547578543424606  ######### Relative L2 Test Norm: 23.821548461914062\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 48  ######### Train Loss: 0.09522668272256851  ######### Relative L2 Test Norm: 24.084428787231445\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 49  ######### Train Loss: 0.09517450630664825  ######### Relative L2 Test Norm: 24.36046600341797\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 50  ######### Train Loss: 0.09529072046279907  ######### Relative L2 Test Norm: 24.476306915283203\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 51  ######### Train Loss: 0.0953734815120697  ######### Relative L2 Test Norm: 24.555511474609375\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 52  ######### Train Loss: 0.09543940424919128  ######### Relative L2 Test Norm: 24.593355178833008\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 53  ######### Train Loss: 0.09547156095504761  ######### Relative L2 Test Norm: 24.589487075805664\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 54  ######### Train Loss: 0.09546632319688797  ######### Relative L2 Test Norm: 24.547977447509766\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 55  ######### Train Loss: 0.09542852640151978  ######### Relative L2 Test Norm: 24.476179122924805\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 56  ######### Train Loss: 0.09536867588758469  ######### Relative L2 Test Norm: 24.383262634277344\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 57  ######### Train Loss: 0.09529939293861389  ######### Relative L2 Test Norm: 24.279264450073242\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 58  ######### Train Loss: 0.09523794800043106  ######### Relative L2 Test Norm: 24.17357635498047\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 59  ######### Train Loss: 0.09519276767969131  ######### Relative L2 Test Norm: 24.07402992248535\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 60  ######### Train Loss: 0.09517179429531097  ######### Relative L2 Test Norm: 23.98625946044922\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 61  ######### Train Loss: 0.09517082571983337  ######### Relative L2 Test Norm: 23.913951873779297\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 62  ######### Train Loss: 0.09518709778785706  ######### Relative L2 Test Norm: 23.858808517456055\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 63  ######### Train Loss: 0.09521014988422394  ######### Relative L2 Test Norm: 23.821182250976562\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 64  ######### Train Loss: 0.09523358941078186  ######### Relative L2 Test Norm: 23.800477981567383\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 65  ######### Train Loss: 0.0952497199177742  ######### Relative L2 Test Norm: 23.795747756958008\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 66  ######### Train Loss: 0.09525378048419952  ######### Relative L2 Test Norm: 23.805683135986328\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 67  ######### Train Loss: 0.09524673968553543  ######### Relative L2 Test Norm: 23.828855514526367\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 68  ######### Train Loss: 0.09523091465234756  ######### Relative L2 Test Norm: 23.8634033203125\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 69  ######### Train Loss: 0.09521038085222244  ######### Relative L2 Test Norm: 23.90702247619629\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 70  ######### Train Loss: 0.0951913371682167  ######### Relative L2 Test Norm: 23.95682716369629\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 71  ######### Train Loss: 0.09517622739076614  ######### Relative L2 Test Norm: 24.009389877319336\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 72  ######### Train Loss: 0.09516848623752594  ######### Relative L2 Test Norm: 24.06099510192871\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 73  ######### Train Loss: 0.09516800194978714  ######### Relative L2 Test Norm: 24.107927322387695\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 74  ######### Train Loss: 0.09517206251621246  ######### Relative L2 Test Norm: 24.14686393737793\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 75  ######### Train Loss: 0.09518006443977356  ######### Relative L2 Test Norm: 24.175254821777344\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 76  ######### Train Loss: 0.09518749266862869  ######### Relative L2 Test Norm: 24.191694259643555\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 77  ######### Train Loss: 0.09519180655479431  ######### Relative L2 Test Norm: 24.195749282836914\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 78  ######### Train Loss: 0.09519249945878983  ######### Relative L2 Test Norm: 24.18831443786621\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 79  ######### Train Loss: 0.09518980234861374  ######### Relative L2 Test Norm: 24.171009063720703\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 80  ######### Train Loss: 0.09518392384052277  ######### Relative L2 Test Norm: 24.146371841430664\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 81  ######### Train Loss: 0.09517794102430344  ######### Relative L2 Test Norm: 24.11713409423828\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 82  ######### Train Loss: 0.09517159312963486  ######### Relative L2 Test Norm: 24.0861759185791\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 83  ######### Train Loss: 0.09516866505146027  ######### Relative L2 Test Norm: 24.056015014648438\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 84  ######### Train Loss: 0.09516634792089462  ######### Relative L2 Test Norm: 24.028913497924805\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 85  ######### Train Loss: 0.09516756236553192  ######### Relative L2 Test Norm: 24.006479263305664\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 86  ######### Train Loss: 0.09516901522874832  ######### Relative L2 Test Norm: 23.989904403686523\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 87  ######### Train Loss: 0.09517102688550949  ######### Relative L2 Test Norm: 23.97980308532715\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 88  ######### Train Loss: 0.09517354518175125  ######### Relative L2 Test Norm: 23.97628402709961\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 89  ######### Train Loss: 0.0951739102602005  ######### Relative L2 Test Norm: 23.97903823852539\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 90  ######### Train Loss: 0.09517316520214081  ######### Relative L2 Test Norm: 23.987442016601562\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 91  ######### Train Loss: 0.09517192840576172  ######### Relative L2 Test Norm: 24.000476837158203\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 92  ######### Train Loss: 0.0951700210571289  ######### Relative L2 Test Norm: 24.016942977905273\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 93  ######### Train Loss: 0.09516816586256027  ######### Relative L2 Test Norm: 24.035356521606445\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 94  ######### Train Loss: 0.09516606479883194  ######### Relative L2 Test Norm: 24.054250717163086\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 95  ######### Train Loss: 0.09516578912734985  ######### Relative L2 Test Norm: 24.072187423706055\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 96  ######### Train Loss: 0.09516600519418716  ######### Relative L2 Test Norm: 24.08786392211914\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 97  ######### Train Loss: 0.09516660124063492  ######### Relative L2 Test Norm: 24.100265502929688\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 98  ######### Train Loss: 0.09516684710979462  ######### Relative L2 Test Norm: 24.108705520629883\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 99  ######### Train Loss: 0.09516774117946625  ######### Relative L2 Test Norm: 24.11285972595215\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 100  ######### Train Loss: 0.0951676219701767  ######### Relative L2 Test Norm: 24.11286163330078\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 101  ######### Train Loss: 0.09516763687133789  ######### Relative L2 Test Norm: 24.110980987548828\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 102  ######### Train Loss: 0.09516720473766327  ######### Relative L2 Test Norm: 24.10749626159668\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 103  ######### Train Loss: 0.09516697376966476  ######### Relative L2 Test Norm: 24.102750778198242\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 104  ######### Train Loss: 0.09516669064760208  ######### Relative L2 Test Norm: 24.09705352783203\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 105  ######### Train Loss: 0.09516572207212448  ######### Relative L2 Test Norm: 24.09077262878418\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 106  ######### Train Loss: 0.09516541659832001  ######### Relative L2 Test Norm: 24.084238052368164\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 107  ######### Train Loss: 0.09516497701406479  ######### Relative L2 Test Norm: 24.07777214050293\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 108  ######### Train Loss: 0.09516505897045135  ######### Relative L2 Test Norm: 24.071664810180664\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 109  ######### Train Loss: 0.09516481310129166  ######### Relative L2 Test Norm: 24.066158294677734\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 110  ######### Train Loss: 0.095164455473423  ######### Relative L2 Test Norm: 24.061450958251953\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 111  ######### Train Loss: 0.09516464918851852  ######### Relative L2 Test Norm: 24.05767059326172\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 112  ######### Train Loss: 0.09516496956348419  ######### Relative L2 Test Norm: 24.0549259185791\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 113  ######### Train Loss: 0.09516438096761703  ######### Relative L2 Test Norm: 24.0532169342041\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 114  ######### Train Loss: 0.09516516327857971  ######### Relative L2 Test Norm: 24.052555084228516\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 115  ######### Train Loss: 0.09516516327857971  ######### Relative L2 Test Norm: 24.052921295166016\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 116  ######### Train Loss: 0.0951654240489006  ######### Relative L2 Test Norm: 24.05421257019043\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 117  ######### Train Loss: 0.09516523778438568  ######### Relative L2 Test Norm: 24.05628776550293\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 118  ######### Train Loss: 0.0951651781797409  ######### Relative L2 Test Norm: 24.05904197692871\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 119  ######### Train Loss: 0.0951651930809021  ######### Relative L2 Test Norm: 24.062274932861328\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 120  ######### Train Loss: 0.09516476839780807  ######### Relative L2 Test Norm: 24.06587028503418\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 121  ######### Train Loss: 0.09516468644142151  ######### Relative L2 Test Norm: 24.069658279418945\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 122  ######### Train Loss: 0.09516474604606628  ######### Relative L2 Test Norm: 24.073453903198242\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 123  ######### Train Loss: 0.09516466408967972  ######### Relative L2 Test Norm: 24.077102661132812\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 124  ######### Train Loss: 0.095163993537426  ######### Relative L2 Test Norm: 24.08051109313965\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 125  ######### Train Loss: 0.09516452252864838  ######### Relative L2 Test Norm: 24.083541870117188\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 126  ######### Train Loss: 0.09516435861587524  ######### Relative L2 Test Norm: 24.086124420166016\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 127  ######### Train Loss: 0.0951644629240036  ######### Relative L2 Test Norm: 24.08819007873535\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 128  ######### Train Loss: 0.09516477584838867  ######### Relative L2 Test Norm: 24.08971405029297\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 129  ######### Train Loss: 0.09516444802284241  ######### Relative L2 Test Norm: 24.090709686279297\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 130  ######### Train Loss: 0.09516386687755585  ######### Relative L2 Test Norm: 24.09121322631836\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 131  ######### Train Loss: 0.09516443312168121  ######### Relative L2 Test Norm: 24.09126091003418\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 132  ######### Train Loss: 0.0951642096042633  ######### Relative L2 Test Norm: 24.090927124023438\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 133  ######### Train Loss: 0.09516454488039017  ######### Relative L2 Test Norm: 24.09025001525879\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 134  ######### Train Loss: 0.09516404569149017  ######### Relative L2 Test Norm: 24.089372634887695\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 135  ######### Train Loss: 0.09516378492116928  ######### Relative L2 Test Norm: 24.088354110717773\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 136  ######### Train Loss: 0.09516432881355286  ######### Relative L2 Test Norm: 24.087247848510742\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 137  ######### Train Loss: 0.09516391158103943  ######### Relative L2 Test Norm: 24.08620834350586\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 138  ######### Train Loss: 0.09516370296478271  ######### Relative L2 Test Norm: 24.08526039123535\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 139  ######### Train Loss: 0.0951637551188469  ######### Relative L2 Test Norm: 24.08447265625\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 140  ######### Train Loss: 0.09516424685716629  ######### Relative L2 Test Norm: 24.083892822265625\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 141  ######### Train Loss: 0.09516359865665436  ######### Relative L2 Test Norm: 24.08357048034668\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 142  ######### Train Loss: 0.09516371041536331  ######### Relative L2 Test Norm: 24.0835018157959\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 143  ######### Train Loss: 0.09516403079032898  ######### Relative L2 Test Norm: 24.083707809448242\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 144  ######### Train Loss: 0.09516340494155884  ######### Relative L2 Test Norm: 24.084152221679688\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 145  ######### Train Loss: 0.09516409039497375  ######### Relative L2 Test Norm: 24.08483123779297\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 146  ######### Train Loss: 0.0951637327671051  ######### Relative L2 Test Norm: 24.085742950439453\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 147  ######### Train Loss: 0.09516391903162003  ######### Relative L2 Test Norm: 24.086780548095703\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 148  ######### Train Loss: 0.09516365081071854  ######### Relative L2 Test Norm: 24.087974548339844\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 149  ######### Train Loss: 0.0951635017991066  ######### Relative L2 Test Norm: 24.089262008666992\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 150  ######### Train Loss: 0.0951630100607872  ######### Relative L2 Test Norm: 24.089916229248047\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 151  ######### Train Loss: 0.0951632633805275  ######### Relative L2 Test Norm: 24.090600967407227\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 152  ######### Train Loss: 0.0951632484793663  ######### Relative L2 Test Norm: 24.09125518798828\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 153  ######### Train Loss: 0.0951634868979454  ######### Relative L2 Test Norm: 24.091917037963867\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 154  ######### Train Loss: 0.09516299515962601  ######### Relative L2 Test Norm: 24.092557907104492\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 155  ######### Train Loss: 0.09516347199678421  ######### Relative L2 Test Norm: 24.093154907226562\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 156  ######### Train Loss: 0.09516379982233047  ######### Relative L2 Test Norm: 24.093719482421875\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 157  ######### Train Loss: 0.09516327828168869  ######### Relative L2 Test Norm: 24.09426498413086\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 158  ######### Train Loss: 0.0951635017991066  ######### Relative L2 Test Norm: 24.09475326538086\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 159  ######### Train Loss: 0.0951632559299469  ######### Relative L2 Test Norm: 24.095197677612305\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 160  ######### Train Loss: 0.09516312927007675  ######### Relative L2 Test Norm: 24.09560203552246\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 161  ######### Train Loss: 0.09516339749097824  ######### Relative L2 Test Norm: 24.095962524414062\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 162  ######### Train Loss: 0.09516341239213943  ######### Relative L2 Test Norm: 24.096267700195312\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 163  ######### Train Loss: 0.09516309201717377  ######### Relative L2 Test Norm: 24.096561431884766\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 164  ######### Train Loss: 0.09516332298517227  ######### Relative L2 Test Norm: 24.096799850463867\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 165  ######### Train Loss: 0.09516298770904541  ######### Relative L2 Test Norm: 24.097000122070312\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 166  ######### Train Loss: 0.09516297280788422  ######### Relative L2 Test Norm: 24.09720230102539\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 167  ######### Train Loss: 0.09516332298517227  ######### Relative L2 Test Norm: 24.09735870361328\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 168  ######### Train Loss: 0.09516285359859467  ######### Relative L2 Test Norm: 24.097511291503906\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 169  ######### Train Loss: 0.09516306221485138  ######### Relative L2 Test Norm: 24.0976505279541\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 170  ######### Train Loss: 0.09516308456659317  ######### Relative L2 Test Norm: 24.0977725982666\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 171  ######### Train Loss: 0.09516295790672302  ######### Relative L2 Test Norm: 24.097896575927734\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 172  ######### Train Loss: 0.09516343474388123  ######### Relative L2 Test Norm: 24.0980167388916\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 173  ######### Train Loss: 0.09516332298517227  ######### Relative L2 Test Norm: 24.098127365112305\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 174  ######### Train Loss: 0.09516303241252899  ######### Relative L2 Test Norm: 24.098270416259766\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 175  ######### Train Loss: 0.09516280144453049  ######### Relative L2 Test Norm: 24.098417282104492\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 176  ######### Train Loss: 0.09516267478466034  ######### Relative L2 Test Norm: 24.098560333251953\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 177  ######### Train Loss: 0.09516243636608124  ######### Relative L2 Test Norm: 24.098752975463867\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 178  ######### Train Loss: 0.09516306221485138  ######### Relative L2 Test Norm: 24.09894561767578\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 179  ######### Train Loss: 0.0951632410287857  ######### Relative L2 Test Norm: 24.099145889282227\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 180  ######### Train Loss: 0.09516267478466034  ######### Relative L2 Test Norm: 24.09937286376953\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 181  ######### Train Loss: 0.0951627865433693  ######### Relative L2 Test Norm: 24.099618911743164\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 182  ######### Train Loss: 0.09516347944736481  ######### Relative L2 Test Norm: 24.09986114501953\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 183  ######### Train Loss: 0.09516319632530212  ######### Relative L2 Test Norm: 24.10012435913086\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 184  ######### Train Loss: 0.09516280144453049  ######### Relative L2 Test Norm: 24.100421905517578\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 185  ######### Train Loss: 0.09516289830207825  ######### Relative L2 Test Norm: 24.10069465637207\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 186  ######### Train Loss: 0.09516269713640213  ######### Relative L2 Test Norm: 24.100997924804688\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 187  ######### Train Loss: 0.0951630249619484  ######### Relative L2 Test Norm: 24.101306915283203\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 188  ######### Train Loss: 0.09516281634569168  ######### Relative L2 Test Norm: 24.10162925720215\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 189  ######### Train Loss: 0.09516249597072601  ######### Relative L2 Test Norm: 24.101961135864258\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n",
      "######### Epoch: 190  ######### Train Loss: 0.0951627716422081  ######### Relative L2 Test Norm: 24.10228729248047\n",
      "torch.Size([178, 2])\n",
      "torch.Size([178, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     12\u001b[0m \u001b[39m# print(input_batch.shape)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# print(fno(input_batch).shape)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m output_pred_batch \u001b[39m=\u001b[39m fno(input_batch)\u001b[39m.\u001b[39msqueeze(\u001b[39m2\u001b[39m) \u001b[39m# gives you the prediction of T_s or T_f\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m# print(output_pred_batch)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m# print(output_batch)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m loss_f \u001b[39m=\u001b[39m l(output_pred_batch, output_batch)\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1482\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1480\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1481\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1482\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1483\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[106], line 128\u001b[0m, in \u001b[0;36mFNO1d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    123\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfourier_layer(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspect3, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin2)\n\u001b[1;32m    125\u001b[0m \u001b[39m# x = x[..., :-self.padding]  # pad the domain if input is non-periodic\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39m# x = x.permute(1,0)\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mpermute(\u001b[39m0\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    130\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear_layer(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear_q)\n\u001b[1;32m    131\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_layer(x)\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch/lib/python3.8/site-packages/torch/fx/traceback.py:58\u001b[0m, in \u001b[0;36mformat_stack\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m current_stack\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m     56\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[39m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m     \u001b[39mreturn\u001b[39;00m traceback\u001b[39m.\u001b[39mformat_list(traceback\u001b[39m.\u001b[39;49mextract_stack()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch/lib/python3.8/traceback.py:211\u001b[0m, in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     f \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39m_getframe()\u001b[39m.\u001b[39mf_back\n\u001b[0;32m--> 211\u001b[0m stack \u001b[39m=\u001b[39m StackSummary\u001b[39m.\u001b[39;49mextract(walk_stack(f), limit\u001b[39m=\u001b[39;49mlimit)\n\u001b[1;32m    212\u001b[0m stack\u001b[39m.\u001b[39mreverse()\n\u001b[1;32m    213\u001b[0m \u001b[39mreturn\u001b[39;00m stack\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch/lib/python3.8/traceback.py:362\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    359\u001b[0m     result\u001b[39m.\u001b[39mappend(FrameSummary(\n\u001b[1;32m    360\u001b[0m         filename, lineno, name, lookup_line\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39mlocals\u001b[39m\u001b[39m=\u001b[39mf_locals))\n\u001b[1;32m    361\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m fnames:\n\u001b[0;32m--> 362\u001b[0m     linecache\u001b[39m.\u001b[39;49mcheckcache(filename)\n\u001b[1;32m    363\u001b[0m \u001b[39m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[39mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch/lib/python3.8/linecache.py:74\u001b[0m, in \u001b[0;36mcheckcache\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[39mcontinue\u001b[39;00m   \u001b[39m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 74\u001b[0m     stat \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mstat(fullname)\n\u001b[1;32m     75\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     cache\u001b[39m.\u001b[39mpop(filename, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = Adam(fno.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "l = torch.nn.MSELoss()\n",
    "freq_print = 1\n",
    "for epoch in range(epochs):\n",
    "    train_mse = 0.0\n",
    "    for step, (input_batch, output_batch) in enumerate(training_set_tf0):\n",
    "        print(input_batch.shape)\n",
    "        print(output_batch.shape)\n",
    "        optimizer.zero_grad()\n",
    "        # print(input_batch.shape)\n",
    "        # print(fno(input_batch).shape)\n",
    "        output_pred_batch = fno(input_batch).squeeze(2) # gives you the prediction of T_s or T_f\n",
    "        # print(output_pred_batch)\n",
    "        # print(output_batch)\n",
    "        loss_f = l(output_pred_batch, output_batch)\n",
    "        loss_f.backward()\n",
    "        optimizer.step()\n",
    "        train_mse += loss_f.item()\n",
    "    train_mse /= len(training_set_tf0)\n",
    "    # print(train_mse)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # print(\"=========\")\n",
    "        # print(\"Testing Set\")\n",
    "        fno.eval()\n",
    "        test_relative_l2 = 0.0\n",
    "        for step, (input_batch, output_batch) in enumerate(testing_set_tf0):\n",
    "            output_pred_batch = fno(input_batch).squeeze(2)\n",
    "            loss_f = (torch.mean((output_pred_batch - output_batch) ** 2) / torch.mean(output_batch ** 2)) ** 0.5 * 100\n",
    "            test_relative_l2 += loss_f.item()\n",
    "        test_relative_l2 /= len(testing_set_tf0)\n",
    "\n",
    "    if epoch % freq_print == 0: print(\"######### Epoch:\", epoch, \" ######### Train Loss:\", train_mse, \" ######### Relative L2 Test Norm:\", test_relative_l2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_data_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# idx_data = 4\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m input_function_train_n \u001b[39m=\u001b[39m input_data_train\n\u001b[1;32m      3\u001b[0m output_function_train_tf \u001b[39m=\u001b[39m Tf0_train\n\u001b[1;32m      5\u001b[0m plt\u001b[39m.\u001b[39mplot(input_function_train_n, output_function_train_tf, label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTrue Solution\u001b[39m\u001b[39m\"\u001b[39m, c\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC0\u001b[39m\u001b[39m\"\u001b[39m, lw\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_data_train' is not defined"
     ]
    }
   ],
   "source": [
    "# idx_data = 4\n",
    "input_function_train_n = input_data_train\n",
    "output_function_train_tf = Tf0_train\n",
    "\n",
    "plt.plot(input_function_train_n, output_function_train_tf, label=\"True Solution\", c=\"C0\", lw=2)\n",
    "output_function_train_pred_n = fno(input_function_train_n)\n",
    "# print(output_function_test_pred_n.shape)\n",
    "output_function_train_pred_n = output_function_train_pred_n.detach()[0,:,0]\n",
    "print(output_function_train_pred_n.shape)\n",
    "print(input_function_train_n[:,0].shape)\n",
    "# print(input_function_test_n[0,:,1])\n",
    "plt.figure(dpi=250)\n",
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.scatter(input_function_train_n[:,0], output_function_train_pred_n, label=\"Approximate Solution\", s=8, c=\"C0\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get prediction with 2D Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_data = 4\n",
    "input_function_train_n = input_train\n",
    "output_function_train_tf = Tf0_train\n",
    "\n",
    "\n",
    "output_function_train_pred_n = fno(input_function_train_n)\n",
    "# print(output_function_test_pred_n.shape)\n",
    "output_function_train_pred_n = output_function_train_pred_n.detach()[0,:,0]\n",
    "print(output_function_train_pred_n.shape)\n",
    "print(input_function_train_n[:,0].shape)\n",
    "# print(input_function_test_n[0,:,1])\n",
    "plt.figure(dpi=250)\n",
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.scatter(input_function_train_n[:,0], output_function_train_pred_n, label=\"Approximate Solution\", s=2, c=\"red\")\n",
    "plt.plot(input_function_train_n, output_function_train_tf, label=\"True Solution\", c=\"C0\", lw=2)\n",
    "p = 2\n",
    "err = (torch.mean(abs(output_function_train_tf.detach().reshape(-1, ) - output_function_train_pred_n.detach().reshape(-1, )) ** p) / torch.mean(abs(output_function_train_tf.detach()) ** p)) ** (1 / p) * 100\n",
    "print(\"Relative L2 error: \", err.item())\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_function_test_n = input_test\n",
    "# print(len(input_function_test_n))\n",
    "output_function_test_tf = Tf0_test\n",
    "\n",
    "\n",
    "output_function_test_pred_n = fno(input_function_test_n)\n",
    "# print(output_function_test_pred_n.shape)\n",
    "output_function_test_pred_n = output_function_test_pred_n.detach()[0,:,0]\n",
    "print(output_function_test_pred_n.shape)\n",
    "print(input_function_test_n[:,0].shape)\n",
    "# print(input_function_test_n[0,:,1])\n",
    "plt.figure(dpi=250)\n",
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.scatter(input_function_test_n[:,0], output_function_test_pred_n, label=\"Approximate Solution\", s=8, c=\"C0\")\n",
    "plt.plot(input_function_test_n, output_function_test_tf, label=\"True Solution\", c=\"C0\", lw=2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer with (t, T_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 178 # 85 percent\n",
    "# Input set\n",
    "t_train = t_train_norm[:n_train].reshape(-1,1)\n",
    "t_test =  t_train_norm[n_train:].reshape(-1,1)\n",
    "\n",
    "t_train = torch.from_numpy(t_train).type(torch.float32)\n",
    "t_test = torch.from_numpy(t_test).type(torch.float32)\n",
    "\n",
    "\n",
    "Tf0_norm_torch = torch.from_numpy(Tf0_norm).type(torch.float32)\n",
    "Ts0_norm_torch = torch.from_numpy(Ts0_norm).type(torch.float32)\n",
    "\n",
    "# Output Set\n",
    "Tf0_train = Tf0_norm_torch[:n_train]\n",
    "Ts0_train = Ts0_norm_torch[:n_train]\n",
    "\n",
    "Tf0_test = Tf0_norm_torch[n_train:]\n",
    "Ts0_test = Ts0_norm_torch[n_train:]\n",
    "\n",
    "\n",
    "input_train_tf0 = torch.cat((t_train, Tf0_train), 1)\n",
    "input_test_tf0 = torch.cat((t_test, Tf0_test), 1)\n",
    "\n",
    "\n",
    "print(input_train_tf0.shape)\n",
    "\n",
    "training_set_tf0 = DataLoader(TensorDataset(input_train_tf0, Tf0_train), batch_size=batch_size, shuffle=True)\n",
    "testing_set_tf0 =  DataLoader(TensorDataset(input_test_tf0, Ts0_test), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "batch_size = 178\n",
    "\n",
    "# training_set_tf0 = DataLoader(TensorDataset(t_train, Tf0_train), batch_size=batch_size, shuffle=True)\n",
    "# training_set_ts0 = DataLoader(TensorDataset(t_train, Ts0_train), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# testing_set_tf0 = DataLoader(TensorDataset(t_test, Tf0_test), batch_size=batch_size, shuffle=True)\n",
    "# testing_set_ts0 = DataLoader(TensorDataset(t_test, Ts0_test), batch_size=batch_size, shuffle=True)\n",
    "# batch_size = 178\n",
    "\n",
    "# training_set_tf0_2d = DataLoader(TensorDataset(input_train, Tf0_train), batch_size=batch_size, shuffle=True)\n",
    "# training_set_ts0_2d = DataLoader(TensorDataset(input_train, Ts0_train), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# testing_set_tf0_2d = DataLoader(TensorDataset(input_test, Tf0_test), batch_size=batch_size, shuffle=True)\n",
    "# testing_set_ts0_2d = DataLoader(TensorDataset(input_test, Ts0_test), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output batch pred: tensor([[[0.3863],\n",
      "         [0.7175],\n",
      "         [0.9902],\n",
      "         [0.9276],\n",
      "         [0.9932],\n",
      "         [0.5004],\n",
      "         [0.0226],\n",
      "         [0.9939],\n",
      "         [0.9962],\n",
      "         [0.9946],\n",
      "         [0.9851],\n",
      "         [0.9977],\n",
      "         [0.9970],\n",
      "         [0.9968],\n",
      "         [0.2532],\n",
      "         [0.9980],\n",
      "         [0.9825],\n",
      "         [0.9959],\n",
      "         [0.9945],\n",
      "         [0.9932],\n",
      "         [0.9899],\n",
      "         [0.9905],\n",
      "         [0.9932],\n",
      "         [0.9941],\n",
      "         [0.9961],\n",
      "         [0.5064],\n",
      "         [0.9986],\n",
      "         [0.9983],\n",
      "         [1.0013],\n",
      "         [1.0013],\n",
      "         [0.9996],\n",
      "         [0.9990],\n",
      "         [0.4468],\n",
      "         [0.4495],\n",
      "         [0.9949],\n",
      "         [0.9962],\n",
      "         [0.9598],\n",
      "         [0.8452],\n",
      "         [0.9980],\n",
      "         [0.0400],\n",
      "         [0.9856],\n",
      "         [0.0603],\n",
      "         [0.6574],\n",
      "         [0.9953],\n",
      "         [0.9939],\n",
      "         [0.4651],\n",
      "         [0.9937],\n",
      "         [0.9179],\n",
      "         [0.3422],\n",
      "         [0.4632],\n",
      "         [0.9974],\n",
      "         [0.9997],\n",
      "         [0.9191],\n",
      "         [1.0017],\n",
      "         [1.0004],\n",
      "         [0.9977],\n",
      "         [0.3615],\n",
      "         [0.9954],\n",
      "         [0.9934],\n",
      "         [0.4533],\n",
      "         [0.9912],\n",
      "         [0.9908],\n",
      "         [0.9919],\n",
      "         [0.5294],\n",
      "         [0.1995],\n",
      "         [0.9949],\n",
      "         [0.9978],\n",
      "         [0.9964],\n",
      "         [0.9989],\n",
      "         [0.9978],\n",
      "         [0.3715],\n",
      "         [0.9799],\n",
      "         [0.3633],\n",
      "         [0.5027],\n",
      "         [0.9897],\n",
      "         [0.9880],\n",
      "         [0.9895],\n",
      "         [0.1586],\n",
      "         [0.9954],\n",
      "         [0.9759],\n",
      "         [0.9983],\n",
      "         [0.9955],\n",
      "         [0.9995],\n",
      "         [0.9992],\n",
      "         [0.9993],\n",
      "         [0.2424],\n",
      "         [0.9950],\n",
      "         [0.8601],\n",
      "         [0.9925],\n",
      "         [0.3739],\n",
      "         [0.9157],\n",
      "         [0.3777],\n",
      "         [0.6096],\n",
      "         [0.4531],\n",
      "         [0.9968],\n",
      "         [0.9957],\n",
      "         [0.9981],\n",
      "         [0.9969],\n",
      "         [0.8159],\n",
      "         [0.7700],\n",
      "         [0.9970],\n",
      "         [0.5185],\n",
      "         [0.9966],\n",
      "         [0.9965],\n",
      "         [0.9960],\n",
      "         [0.2540],\n",
      "         [0.9978],\n",
      "         [0.6922],\n",
      "         [0.9978],\n",
      "         [1.0005],\n",
      "         [0.5127],\n",
      "         [0.5539],\n",
      "         [0.9960],\n",
      "         [0.2589],\n",
      "         [0.8485],\n",
      "         [0.9935],\n",
      "         [0.6735],\n",
      "         [0.9920],\n",
      "         [0.5023],\n",
      "         [0.0545],\n",
      "         [0.0291],\n",
      "         [0.8997],\n",
      "         [0.9963],\n",
      "         [0.9958],\n",
      "         [0.4618],\n",
      "         [0.9946],\n",
      "         [0.9941],\n",
      "         [0.9897],\n",
      "         [0.0450],\n",
      "         [0.3657],\n",
      "         [0.9945],\n",
      "         [0.9966],\n",
      "         [0.2385],\n",
      "         [0.9992],\n",
      "         [0.9996],\n",
      "         [0.9979],\n",
      "         [0.9970],\n",
      "         [0.5150],\n",
      "         [0.9930],\n",
      "         [0.0409],\n",
      "         [0.9897],\n",
      "         [0.4478],\n",
      "         [0.7718],\n",
      "         [0.4939],\n",
      "         [0.4390],\n",
      "         [0.5167],\n",
      "         [0.9555],\n",
      "         [0.5466],\n",
      "         [0.3840],\n",
      "         [0.9928],\n",
      "         [0.7423],\n",
      "         [0.5037],\n",
      "         [0.9926],\n",
      "         [0.9927],\n",
      "         [0.3611],\n",
      "         [0.9954],\n",
      "         [0.9970],\n",
      "         [0.9971],\n",
      "         [0.9987],\n",
      "         [0.9558],\n",
      "         [0.9988],\n",
      "         [0.9973],\n",
      "         [0.3588],\n",
      "         [0.2573],\n",
      "         [0.2534],\n",
      "         [0.0601],\n",
      "         [0.2740],\n",
      "         [0.0642],\n",
      "         [0.9884],\n",
      "         [0.4464],\n",
      "         [0.9943],\n",
      "         [0.9948],\n",
      "         [0.9616],\n",
      "         [0.8586],\n",
      "         [0.9976],\n",
      "         [0.9966],\n",
      "         [0.9958],\n",
      "         [0.9937]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.3930],\n",
      "        [0.6920],\n",
      "        [0.9998],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [0.5030],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9819],\n",
      "        [0.0383],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.3573],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.2208],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.9804],\n",
      "        [0.3753],\n",
      "        [0.5054],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.1762],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.9044],\n",
      "        [0.3875],\n",
      "        [0.5945],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [0.5151],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.9997],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5108],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.0288],\n",
      "        [0.0000],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.4645],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.0368],\n",
      "        [0.3780],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.9995],\n",
      "        [0.5139],\n",
      "        [0.9996],\n",
      "        [0.0247],\n",
      "        [0.9997],\n",
      "        [0.4552],\n",
      "        [0.7540],\n",
      "        [0.4988],\n",
      "        [0.4454],\n",
      "        [0.5165],\n",
      "        [0.9520],\n",
      "        [0.5334],\n",
      "        [0.3912],\n",
      "        [0.9997],\n",
      "        [0.7129],\n",
      "        [0.5038],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9420],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.3575],\n",
      "        [0.2577],\n",
      "        [0.2518],\n",
      "        [0.0209],\n",
      "        [0.2735],\n",
      "        [0.0335],\n",
      "        [0.9997],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [0.9999]])\n",
      "######### Epoch: 0  ######### Train Loss: 0.00012840265117119998  ######### Relative L2 Test Norm: 28.201135635375977\n",
      "Output batch pred: tensor([[[ 0.8912],\n",
      "         [ 0.8861],\n",
      "         [-0.2456],\n",
      "         [ 0.8728],\n",
      "         [ 0.8800],\n",
      "         [ 0.8820],\n",
      "         [-0.0218],\n",
      "         [ 0.8949],\n",
      "         [ 0.9002],\n",
      "         [ 0.9145],\n",
      "         [ 0.0298],\n",
      "         [ 0.9189],\n",
      "         [ 0.0102],\n",
      "         [ 0.9204],\n",
      "         [ 0.9168],\n",
      "         [ 0.9129],\n",
      "         [ 0.6108],\n",
      "         [ 0.9004],\n",
      "         [ 0.9078],\n",
      "         [-0.0053],\n",
      "         [ 0.9108],\n",
      "         [ 0.3387],\n",
      "         [ 0.9102],\n",
      "         [ 0.7206],\n",
      "         [ 0.9111],\n",
      "         [ 0.0237],\n",
      "         [ 0.5104],\n",
      "         [ 0.7868],\n",
      "         [ 0.2995],\n",
      "         [ 0.9201],\n",
      "         [ 0.9226],\n",
      "         [ 0.9237],\n",
      "         [ 0.9190],\n",
      "         [ 0.1623],\n",
      "         [ 0.9133],\n",
      "         [ 0.9071],\n",
      "         [ 0.1270],\n",
      "         [ 0.1023],\n",
      "         [ 0.7833],\n",
      "         [ 0.8911],\n",
      "         [ 0.2220],\n",
      "         [ 0.8896],\n",
      "         [ 0.2851],\n",
      "         [ 0.9055],\n",
      "         [ 0.9064],\n",
      "         [ 0.1571],\n",
      "         [ 0.9120],\n",
      "         [ 0.3511],\n",
      "         [ 0.9012],\n",
      "         [ 0.8928],\n",
      "         [ 0.8881],\n",
      "         [ 0.8844],\n",
      "         [ 0.1827],\n",
      "         [ 0.5145],\n",
      "         [ 0.8896],\n",
      "         [ 0.8044],\n",
      "         [ 0.8855],\n",
      "         [ 0.9049],\n",
      "         [-0.2325],\n",
      "         [ 0.9135],\n",
      "         [ 0.8656],\n",
      "         [ 0.9056],\n",
      "         [ 0.9068],\n",
      "         [ 0.8960],\n",
      "         [ 0.9013],\n",
      "         [ 0.4030],\n",
      "         [ 0.1260],\n",
      "         [ 0.8854],\n",
      "         [ 0.9038],\n",
      "         [ 0.8064],\n",
      "         [ 0.3069],\n",
      "         [ 0.9049],\n",
      "         [ 0.9012],\n",
      "         [-0.1070],\n",
      "         [ 0.8884],\n",
      "         [ 0.8857],\n",
      "         [ 0.8790],\n",
      "         [ 0.8801],\n",
      "         [-0.0749],\n",
      "         [ 0.6958],\n",
      "         [ 0.8873],\n",
      "         [-0.0049],\n",
      "         [ 0.8836],\n",
      "         [ 0.3077],\n",
      "         [ 0.2328],\n",
      "         [ 0.2277],\n",
      "         [ 0.7894],\n",
      "         [ 0.8661],\n",
      "         [-0.2274],\n",
      "         [ 0.8843],\n",
      "         [ 0.1304],\n",
      "         [ 0.8997],\n",
      "         [ 0.1255],\n",
      "         [ 0.9012],\n",
      "         [ 0.9094],\n",
      "         [ 0.9023],\n",
      "         [ 0.9083],\n",
      "         [ 0.3136],\n",
      "         [ 0.9113],\n",
      "         [ 0.8785],\n",
      "         [-0.0054],\n",
      "         [ 0.9050],\n",
      "         [-0.2336],\n",
      "         [ 0.9087],\n",
      "         [ 0.9126],\n",
      "         [ 0.9151],\n",
      "         [ 0.9146],\n",
      "         [ 0.9111],\n",
      "         [ 0.9067],\n",
      "         [-0.2345],\n",
      "         [ 0.6467],\n",
      "         [ 0.8828],\n",
      "         [ 0.2130],\n",
      "         [ 0.8843],\n",
      "         [ 0.8845],\n",
      "         [ 0.2614],\n",
      "         [ 0.6791],\n",
      "         [-0.2131],\n",
      "         [ 0.8358],\n",
      "         [ 0.2835],\n",
      "         [ 0.1248],\n",
      "         [-0.2253],\n",
      "         [ 0.2794],\n",
      "         [ 0.1194],\n",
      "         [ 0.8890],\n",
      "         [ 0.8882],\n",
      "         [ 0.8922],\n",
      "         [ 0.6209],\n",
      "         [ 0.2234],\n",
      "         [ 0.1137],\n",
      "         [ 0.8998],\n",
      "         [-0.2013],\n",
      "         [ 0.2964],\n",
      "         [ 0.8953],\n",
      "         [ 0.8921],\n",
      "         [ 0.2099],\n",
      "         [ 0.8876],\n",
      "         [ 0.8865],\n",
      "         [ 0.4824],\n",
      "         [ 0.8847],\n",
      "         [ 0.8823],\n",
      "         [ 0.2023],\n",
      "         [ 0.8908],\n",
      "         [ 0.8931],\n",
      "         [ 0.2941],\n",
      "         [ 0.8987],\n",
      "         [ 0.9035],\n",
      "         [ 0.9080],\n",
      "         [ 0.9137],\n",
      "         [ 0.9105],\n",
      "         [ 0.9166],\n",
      "         [ 0.9086],\n",
      "         [-0.0151],\n",
      "         [ 0.9038],\n",
      "         [ 0.8919],\n",
      "         [ 0.8815],\n",
      "         [ 0.0969],\n",
      "         [ 0.8176],\n",
      "         [ 0.8726],\n",
      "         [ 0.2590],\n",
      "         [ 0.7143],\n",
      "         [ 0.8945],\n",
      "         [ 0.8991],\n",
      "         [ 0.5786],\n",
      "         [ 0.2350],\n",
      "         [ 0.8640],\n",
      "         [ 0.9056],\n",
      "         [ 0.8959],\n",
      "         [ 0.8716],\n",
      "         [ 0.4304],\n",
      "         [ 0.8777],\n",
      "         [ 0.8739],\n",
      "         [ 0.8774],\n",
      "         [ 0.1832],\n",
      "         [ 0.8881],\n",
      "         [ 0.8913],\n",
      "         [ 0.8889],\n",
      "         [-0.2423]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.9999],\n",
      "        [0.8223],\n",
      "        [0.9956],\n",
      "        [0.2735],\n",
      "        [0.6555],\n",
      "        [0.8761],\n",
      "        [0.5009],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.3573],\n",
      "        [0.8933],\n",
      "        [0.9999],\n",
      "        [0.4611],\n",
      "        [0.9995],\n",
      "        [0.5030],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9997],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.4454],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.9820],\n",
      "        [0.9997],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9966],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.5945],\n",
      "        [0.3840],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.4668],\n",
      "        [0.4642],\n",
      "        [0.9044],\n",
      "        [0.9804],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.9999],\n",
      "        [0.3747],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.9999],\n",
      "        [0.9724],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0288],\n",
      "        [0.7820],\n",
      "        [0.9995],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.8139],\n",
      "        [0.0368],\n",
      "        [0.9490],\n",
      "        [0.5080],\n",
      "        [0.3808],\n",
      "        [0.0247],\n",
      "        [0.5054],\n",
      "        [0.3780],\n",
      "        [0.9996],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.4503],\n",
      "        [0.3575],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.7129],\n",
      "        [0.4580],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0000]])\n",
      "######### Epoch: 1  ######### Train Loss: 0.026137156412005424  ######### Relative L2 Test Norm: 13.871691703796387\n",
      "Output batch pred: tensor([[[ 1.0356],\n",
      "         [ 1.0336],\n",
      "         [ 1.0275],\n",
      "         [ 1.0274],\n",
      "         [ 0.4017],\n",
      "         [ 0.3135],\n",
      "         [ 1.0230],\n",
      "         [ 0.1870],\n",
      "         [ 1.0394],\n",
      "         [ 0.4974],\n",
      "         [ 0.8487],\n",
      "         [ 1.0489],\n",
      "         [ 1.0536],\n",
      "         [ 1.0567],\n",
      "         [ 0.3713],\n",
      "         [ 0.3554],\n",
      "         [-0.0281],\n",
      "         [ 1.0381],\n",
      "         [-0.0246],\n",
      "         [ 1.0389],\n",
      "         [ 1.0348],\n",
      "         [ 0.5591],\n",
      "         [ 0.2067],\n",
      "         [ 0.5179],\n",
      "         [ 0.8380],\n",
      "         [ 1.0618],\n",
      "         [ 1.0639],\n",
      "         [ 0.7276],\n",
      "         [ 1.0405],\n",
      "         [ 1.0428],\n",
      "         [ 0.2037],\n",
      "         [-0.0300],\n",
      "         [ 1.0209],\n",
      "         [ 1.0192],\n",
      "         [ 0.3239],\n",
      "         [ 0.1281],\n",
      "         [ 1.0228],\n",
      "         [ 0.4239],\n",
      "         [ 0.7411],\n",
      "         [ 1.0249],\n",
      "         [ 1.0246],\n",
      "         [ 0.9792],\n",
      "         [ 1.0035],\n",
      "         [ 1.0274],\n",
      "         [ 1.0370],\n",
      "         [ 1.0448],\n",
      "         [ 1.0488],\n",
      "         [ 1.0446],\n",
      "         [ 1.0628],\n",
      "         [ 1.0645],\n",
      "         [ 1.0640],\n",
      "         [ 1.0574],\n",
      "         [-0.0468],\n",
      "         [ 0.4810],\n",
      "         [ 1.0208],\n",
      "         [ 0.4550],\n",
      "         [-0.0716],\n",
      "         [ 0.4701],\n",
      "         [ 0.9953],\n",
      "         [ 1.0075],\n",
      "         [ 1.0170],\n",
      "         [ 1.0258],\n",
      "         [ 1.0339],\n",
      "         [ 0.4972],\n",
      "         [-0.0610],\n",
      "         [ 1.0351],\n",
      "         [ 0.4364],\n",
      "         [ 1.0270],\n",
      "         [ 1.0050],\n",
      "         [ 1.0174],\n",
      "         [ 0.9190],\n",
      "         [ 0.9711],\n",
      "         [ 1.0144],\n",
      "         [ 1.0206],\n",
      "         [ 1.0306],\n",
      "         [ 0.7806],\n",
      "         [ 0.1691],\n",
      "         [ 0.8970],\n",
      "         [ 1.0355],\n",
      "         [ 1.0319],\n",
      "         [ 1.0293],\n",
      "         [ 1.0212],\n",
      "         [ 1.0134],\n",
      "         [ 0.1483],\n",
      "         [ 1.0144],\n",
      "         [ 1.0090],\n",
      "         [ 0.1722],\n",
      "         [ 1.0181],\n",
      "         [ 1.0258],\n",
      "         [ 1.0300],\n",
      "         [ 0.2976],\n",
      "         [ 0.4238],\n",
      "         [ 1.0374],\n",
      "         [ 1.0452],\n",
      "         [ 1.0459],\n",
      "         [ 1.0456],\n",
      "         [ 1.0430],\n",
      "         [ 1.0421],\n",
      "         [ 1.0386],\n",
      "         [ 0.9595],\n",
      "         [ 1.0391],\n",
      "         [ 1.0398],\n",
      "         [ 0.5147],\n",
      "         [ 0.4313],\n",
      "         [ 0.3383],\n",
      "         [ 1.0333],\n",
      "         [ 0.3304],\n",
      "         [ 0.1076],\n",
      "         [ 0.1985],\n",
      "         [ 1.0304],\n",
      "         [ 1.0227],\n",
      "         [ 1.0148],\n",
      "         [ 0.2675],\n",
      "         [ 1.0144],\n",
      "         [ 1.0166],\n",
      "         [ 1.0198],\n",
      "         [ 0.8538],\n",
      "         [ 0.5041],\n",
      "         [ 0.4547],\n",
      "         [ 0.3576],\n",
      "         [ 0.0053],\n",
      "         [ 1.0554],\n",
      "         [ 0.6394],\n",
      "         [ 0.9040],\n",
      "         [ 0.5154],\n",
      "         [ 1.0376],\n",
      "         [ 1.0248],\n",
      "         [ 1.0254],\n",
      "         [ 1.0175],\n",
      "         [ 1.0251],\n",
      "         [ 1.0307],\n",
      "         [ 1.0380],\n",
      "         [ 1.0322],\n",
      "         [ 1.0485],\n",
      "         [ 0.2319],\n",
      "         [ 0.4617],\n",
      "         [ 1.0633],\n",
      "         [ 1.0605],\n",
      "         [ 1.0545],\n",
      "         [ 1.0500],\n",
      "         [ 1.0442],\n",
      "         [ 0.8708],\n",
      "         [ 1.0353],\n",
      "         [ 0.9468],\n",
      "         [ 0.4136],\n",
      "         [ 0.3948],\n",
      "         [ 1.0235],\n",
      "         [ 1.0296],\n",
      "         [ 0.3116],\n",
      "         [ 1.0288],\n",
      "         [ 1.0286],\n",
      "         [ 0.9895],\n",
      "         [ 0.6410],\n",
      "         [ 1.0288],\n",
      "         [ 1.0283],\n",
      "         [ 1.0336],\n",
      "         [ 0.4207],\n",
      "         [ 0.5057],\n",
      "         [ 0.7303],\n",
      "         [ 1.0313],\n",
      "         [ 1.0309],\n",
      "         [-0.0633],\n",
      "         [ 1.0239],\n",
      "         [ 1.0152],\n",
      "         [ 1.0131],\n",
      "         [ 0.9687],\n",
      "         [ 0.8934],\n",
      "         [ 0.4343],\n",
      "         [ 0.4523],\n",
      "         [ 1.0147],\n",
      "         [-0.0675],\n",
      "         [ 1.0226],\n",
      "         [ 1.0304],\n",
      "         [ 0.3364],\n",
      "         [ 1.0388],\n",
      "         [ 0.9667],\n",
      "         [ 0.6853],\n",
      "         [ 1.0396]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.7820],\n",
      "        [0.9995],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.3840],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.2577],\n",
      "        [0.5009],\n",
      "        [0.7540],\n",
      "        [0.9962],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.7129],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.0383],\n",
      "        [0.5334],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.9997],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.7391],\n",
      "        [0.2518],\n",
      "        [0.8379],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.2547],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.4580],\n",
      "        [0.3808],\n",
      "        [0.9995],\n",
      "        [0.3728],\n",
      "        [0.1762],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.9996],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.8139],\n",
      "        [0.5151],\n",
      "        [0.4645],\n",
      "        [0.3753],\n",
      "        [0.0288],\n",
      "        [0.9999],\n",
      "        [0.5945],\n",
      "        [0.8296],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [0.9967],\n",
      "        [0.2729],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.4611],\n",
      "        [0.4454],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [0.3780],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9520],\n",
      "        [0.6327],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.4503],\n",
      "        [0.5139],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.8761],\n",
      "        [0.4988],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [0.0174],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.6555],\n",
      "        [1.0000]])\n",
      "######### Epoch: 2  ######### Train Loss: 0.001981517765671015  ######### Relative L2 Test Norm: 9.930020332336426\n",
      "Output batch pred: tensor([[[1.1198],\n",
      "         [0.6130],\n",
      "         [1.1255],\n",
      "         [1.1258],\n",
      "         [1.1241],\n",
      "         [1.1203],\n",
      "         [0.4850],\n",
      "         [0.9024],\n",
      "         [0.9843],\n",
      "         [1.1111],\n",
      "         [0.7842],\n",
      "         [1.1026],\n",
      "         [1.1180],\n",
      "         [1.0878],\n",
      "         [1.1202],\n",
      "         [0.3274],\n",
      "         [1.1296],\n",
      "         [0.9941],\n",
      "         [0.6758],\n",
      "         [0.8723],\n",
      "         [1.1249],\n",
      "         [1.1221],\n",
      "         [1.1186],\n",
      "         [0.4809],\n",
      "         [0.9737],\n",
      "         [1.1060],\n",
      "         [1.0985],\n",
      "         [1.0977],\n",
      "         [1.0859],\n",
      "         [1.0960],\n",
      "         [1.0905],\n",
      "         [1.0962],\n",
      "         [1.0976],\n",
      "         [1.0955],\n",
      "         [1.1018],\n",
      "         [1.0996],\n",
      "         [1.0902],\n",
      "         [1.0710],\n",
      "         [0.7912],\n",
      "         [1.0956],\n",
      "         [1.0886],\n",
      "         [1.0881],\n",
      "         [1.0837],\n",
      "         [1.0799],\n",
      "         [1.0773],\n",
      "         [1.0823],\n",
      "         [1.0854],\n",
      "         [0.0856],\n",
      "         [1.0934],\n",
      "         [0.6575],\n",
      "         [1.0961],\n",
      "         [1.0998],\n",
      "         [1.0987],\n",
      "         [0.6136],\n",
      "         [0.9801],\n",
      "         [0.6127],\n",
      "         [1.1083],\n",
      "         [0.5801],\n",
      "         [1.1141],\n",
      "         [1.1163],\n",
      "         [0.3532],\n",
      "         [1.1231],\n",
      "         [1.1219],\n",
      "         [1.0886],\n",
      "         [1.1156],\n",
      "         [0.1118],\n",
      "         [1.0808],\n",
      "         [1.0946],\n",
      "         [1.0914],\n",
      "         [1.0858],\n",
      "         [1.0917],\n",
      "         [1.0015],\n",
      "         [1.0991],\n",
      "         [0.4812],\n",
      "         [1.1080],\n",
      "         [0.3745],\n",
      "         [1.1184],\n",
      "         [0.6598],\n",
      "         [0.1338],\n",
      "         [0.1052],\n",
      "         [1.1151],\n",
      "         [0.8698],\n",
      "         [1.1071],\n",
      "         [1.1049],\n",
      "         [1.1011],\n",
      "         [0.6563],\n",
      "         [0.3552],\n",
      "         [1.1118],\n",
      "         [1.1117],\n",
      "         [1.0522],\n",
      "         [0.5229],\n",
      "         [0.5215],\n",
      "         [0.6870],\n",
      "         [1.1271],\n",
      "         [0.5070],\n",
      "         [1.1158],\n",
      "         [0.4960],\n",
      "         [0.6388],\n",
      "         [1.0605],\n",
      "         [0.4710],\n",
      "         [1.0953],\n",
      "         [1.0953],\n",
      "         [1.0977],\n",
      "         [1.0901],\n",
      "         [1.1089],\n",
      "         [0.6332],\n",
      "         [1.1178],\n",
      "         [1.1218],\n",
      "         [0.1263],\n",
      "         [1.1229],\n",
      "         [0.6598],\n",
      "         [0.8189],\n",
      "         [0.5524],\n",
      "         [0.3232],\n",
      "         [1.0931],\n",
      "         [1.0913],\n",
      "         [0.6039],\n",
      "         [1.0941],\n",
      "         [0.6247],\n",
      "         [1.0450],\n",
      "         [1.1106],\n",
      "         [0.3578],\n",
      "         [0.1355],\n",
      "         [0.3586],\n",
      "         [1.1014],\n",
      "         [1.0924],\n",
      "         [0.5300],\n",
      "         [1.0795],\n",
      "         [1.0707],\n",
      "         [1.0727],\n",
      "         [1.0773],\n",
      "         [1.0845],\n",
      "         [1.0228],\n",
      "         [0.5570],\n",
      "         [1.1100],\n",
      "         [0.5643],\n",
      "         [1.1184],\n",
      "         [1.1175],\n",
      "         [1.1134],\n",
      "         [1.1114],\n",
      "         [1.1065],\n",
      "         [1.1021],\n",
      "         [0.7178],\n",
      "         [1.0970],\n",
      "         [0.4368],\n",
      "         [1.0979],\n",
      "         [1.0230],\n",
      "         [0.1098],\n",
      "         [0.6215],\n",
      "         [0.9067],\n",
      "         [0.1214],\n",
      "         [1.1048],\n",
      "         [1.1022],\n",
      "         [0.5823],\n",
      "         [0.5658],\n",
      "         [0.3549],\n",
      "         [1.1035],\n",
      "         [1.1049],\n",
      "         [1.1055],\n",
      "         [0.4608],\n",
      "         [1.1168],\n",
      "         [0.5822],\n",
      "         [1.1202],\n",
      "         [1.1196],\n",
      "         [1.1209],\n",
      "         [1.1239],\n",
      "         [0.4934],\n",
      "         [0.2678],\n",
      "         [0.1244],\n",
      "         [1.1062],\n",
      "         [1.1032],\n",
      "         [1.0959],\n",
      "         [1.0903],\n",
      "         [1.0935],\n",
      "         [0.9171],\n",
      "         [0.5558],\n",
      "         [0.3365],\n",
      "         [1.1026]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.4668],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [0.7391],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.9996],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.5151],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9999],\n",
      "        [0.9820],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9804],\n",
      "        [0.9515],\n",
      "        [0.6555],\n",
      "        [0.9996],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0383],\n",
      "        [0.9997],\n",
      "        [0.5463],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.8379],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.9724],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.8761],\n",
      "        [0.9997],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [0.0247],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.5334],\n",
      "        [0.2735],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9009],\n",
      "        [0.3930],\n",
      "        [0.3875],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.9967],\n",
      "        [0.3840],\n",
      "        [0.5139],\n",
      "        [0.9420],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9819],\n",
      "        [0.9998],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0174],\n",
      "        [0.9999],\n",
      "        [0.5165],\n",
      "        [0.6628],\n",
      "        [0.4454],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [0.5080],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [0.2547],\n",
      "        [0.0288],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.5945],\n",
      "        [0.9998],\n",
      "        [0.3575],\n",
      "        [0.9999],\n",
      "        [0.8933],\n",
      "        [0.0142],\n",
      "        [0.4988],\n",
      "        [0.7540],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.4645],\n",
      "        [0.4527],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.1762],\n",
      "        [0.0368],\n",
      "        [0.9962],\n",
      "        [0.9999],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.4580],\n",
      "        [0.2610],\n",
      "        [0.9959]])\n",
      "######### Epoch: 3  ######### Train Loss: 0.012664025649428368  ######### Relative L2 Test Norm: 7.447413444519043\n",
      "Output batch pred: tensor([[[0.5957],\n",
      "         [1.0842],\n",
      "         [0.6380],\n",
      "         [0.5583],\n",
      "         [0.5789],\n",
      "         [1.0768],\n",
      "         [1.0134],\n",
      "         [0.5823],\n",
      "         [1.0866],\n",
      "         [1.0884],\n",
      "         [1.0877],\n",
      "         [1.0860],\n",
      "         [1.0826],\n",
      "         [1.0774],\n",
      "         [1.0753],\n",
      "         [1.0737],\n",
      "         [0.1243],\n",
      "         [1.0764],\n",
      "         [1.0775],\n",
      "         [1.0834],\n",
      "         [0.6503],\n",
      "         [1.0902],\n",
      "         [1.0906],\n",
      "         [1.0904],\n",
      "         [0.3635],\n",
      "         [1.0852],\n",
      "         [1.0509],\n",
      "         [1.0820],\n",
      "         [1.0815],\n",
      "         [1.0812],\n",
      "         [1.0868],\n",
      "         [0.5148],\n",
      "         [1.0175],\n",
      "         [0.9720],\n",
      "         [1.0826],\n",
      "         [0.3129],\n",
      "         [1.0725],\n",
      "         [1.0653],\n",
      "         [1.0594],\n",
      "         [1.0612],\n",
      "         [1.0655],\n",
      "         [0.6101],\n",
      "         [1.0813],\n",
      "         [1.0878],\n",
      "         [0.6637],\n",
      "         [0.6103],\n",
      "         [1.1046],\n",
      "         [0.5336],\n",
      "         [0.6559],\n",
      "         [0.8199],\n",
      "         [1.0801],\n",
      "         [1.0766],\n",
      "         [0.5707],\n",
      "         [0.9422],\n",
      "         [1.0018],\n",
      "         [1.0710],\n",
      "         [1.0762],\n",
      "         [0.9962],\n",
      "         [1.0846],\n",
      "         [1.0896],\n",
      "         [0.1829],\n",
      "         [0.1740],\n",
      "         [0.9444],\n",
      "         [1.1026],\n",
      "         [0.8314],\n",
      "         [1.0762],\n",
      "         [0.1913],\n",
      "         [1.1077],\n",
      "         [1.1075],\n",
      "         [1.1063],\n",
      "         [1.0953],\n",
      "         [0.4083],\n",
      "         [1.1054],\n",
      "         [0.5426],\n",
      "         [1.1031],\n",
      "         [1.0928],\n",
      "         [1.1045],\n",
      "         [1.1051],\n",
      "         [0.5118],\n",
      "         [1.0957],\n",
      "         [0.3271],\n",
      "         [1.1033],\n",
      "         [0.4031],\n",
      "         [1.0987],\n",
      "         [1.0953],\n",
      "         [0.1555],\n",
      "         [1.0924],\n",
      "         [1.0945],\n",
      "         [1.0933],\n",
      "         [1.0994],\n",
      "         [1.1019],\n",
      "         [0.6622],\n",
      "         [0.1565],\n",
      "         [1.1007],\n",
      "         [1.0663],\n",
      "         [0.7452],\n",
      "         [1.0841],\n",
      "         [1.0784],\n",
      "         [1.0764],\n",
      "         [1.0716],\n",
      "         [1.0798],\n",
      "         [1.0828],\n",
      "         [0.6694],\n",
      "         [1.0944],\n",
      "         [0.6599],\n",
      "         [0.8032],\n",
      "         [1.0999],\n",
      "         [1.0937],\n",
      "         [1.0856],\n",
      "         [0.4996],\n",
      "         [1.0730],\n",
      "         [1.0728],\n",
      "         [1.0708],\n",
      "         [0.3594],\n",
      "         [1.0761],\n",
      "         [1.0600],\n",
      "         [0.5956],\n",
      "         [1.0893],\n",
      "         [1.0916],\n",
      "         [1.0866],\n",
      "         [0.4943],\n",
      "         [1.0778],\n",
      "         [1.0836],\n",
      "         [1.0281],\n",
      "         [1.0838],\n",
      "         [0.6800],\n",
      "         [1.0860],\n",
      "         [1.0855],\n",
      "         [0.1643],\n",
      "         [1.0903],\n",
      "         [1.0860],\n",
      "         [0.5030],\n",
      "         [0.6760],\n",
      "         [1.0815],\n",
      "         [1.0801],\n",
      "         [1.0806],\n",
      "         [0.6433],\n",
      "         [0.3785],\n",
      "         [0.8913],\n",
      "         [0.8707],\n",
      "         [0.4064],\n",
      "         [0.8539],\n",
      "         [0.5125],\n",
      "         [1.0954],\n",
      "         [1.0924],\n",
      "         [1.0869],\n",
      "         [1.0858],\n",
      "         [1.0834],\n",
      "         [0.6444],\n",
      "         [1.0823],\n",
      "         [0.5665],\n",
      "         [1.0778],\n",
      "         [1.0740],\n",
      "         [1.0747],\n",
      "         [0.9346],\n",
      "         [1.0701],\n",
      "         [0.9396],\n",
      "         [1.0744],\n",
      "         [0.4731],\n",
      "         [0.3958],\n",
      "         [0.1901],\n",
      "         [0.2017],\n",
      "         [1.1029],\n",
      "         [1.0693],\n",
      "         [0.4043],\n",
      "         [0.6681],\n",
      "         [1.0943],\n",
      "         [1.0895],\n",
      "         [0.4931],\n",
      "         [0.8814],\n",
      "         [1.0694],\n",
      "         [1.0711],\n",
      "         [1.0746],\n",
      "         [0.4882],\n",
      "         [0.5826],\n",
      "         [1.0897],\n",
      "         [0.5891],\n",
      "         [1.0888]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.4611],\n",
      "        [0.9998],\n",
      "        [0.5139],\n",
      "        [0.4454],\n",
      "        [0.4642],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [0.4580],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.8933],\n",
      "        [0.8379],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [0.3808],\n",
      "        [0.5009],\n",
      "        [0.6628],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.4645],\n",
      "        [0.8296],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.8761],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.0335],\n",
      "        [0.0174],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.9520],\n",
      "        [0.0247],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.2646],\n",
      "        [0.9999],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [0.9820],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.0000],\n",
      "        [0.9998],\n",
      "        [0.9515],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5245],\n",
      "        [0.9998],\n",
      "        [0.5038],\n",
      "        [0.6327],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.3875],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.3728],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.9966],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.5334],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.2547],\n",
      "        [0.7391],\n",
      "        [0.7129],\n",
      "        [0.2729],\n",
      "        [0.6920],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.9996],\n",
      "        [0.9997],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.8139],\n",
      "        [0.9995],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.2735],\n",
      "        [0.0368],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.2518],\n",
      "        [0.5054],\n",
      "        [0.9956],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.3780],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [1.0000]])\n",
      "######### Epoch: 4  ######### Train Loss: 0.012143086642026901  ######### Relative L2 Test Norm: 7.770647048950195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabianjaeger/miniconda/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([178, 1])) that is different to the input size (torch.Size([1, 178, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output batch pred: tensor([[[1.0265],\n",
      "         [0.6272],\n",
      "         [0.3549],\n",
      "         [0.3140],\n",
      "         [1.0247],\n",
      "         [0.8705],\n",
      "         [1.0311],\n",
      "         [1.0301],\n",
      "         [0.5422],\n",
      "         [0.4806],\n",
      "         [0.9545],\n",
      "         [1.0228],\n",
      "         [1.0192],\n",
      "         [1.0157],\n",
      "         [1.0149],\n",
      "         [0.3490],\n",
      "         [0.7352],\n",
      "         [0.5920],\n",
      "         [1.0273],\n",
      "         [0.6023],\n",
      "         [0.4778],\n",
      "         [0.7411],\n",
      "         [0.6073],\n",
      "         [1.0328],\n",
      "         [0.4686],\n",
      "         [1.0208],\n",
      "         [1.0152],\n",
      "         [1.0125],\n",
      "         [0.4147],\n",
      "         [1.0121],\n",
      "         [1.0164],\n",
      "         [1.0216],\n",
      "         [1.0277],\n",
      "         [1.0322],\n",
      "         [0.5490],\n",
      "         [0.5494],\n",
      "         [1.0362],\n",
      "         [1.0348],\n",
      "         [0.5408],\n",
      "         [1.0310],\n",
      "         [0.9982],\n",
      "         [0.1599],\n",
      "         [0.5929],\n",
      "         [1.0284],\n",
      "         [1.0279],\n",
      "         [0.9980],\n",
      "         [0.1439],\n",
      "         [0.6097],\n",
      "         [1.0260],\n",
      "         [1.0223],\n",
      "         [1.0187],\n",
      "         [1.0173],\n",
      "         [1.0096],\n",
      "         [0.7532],\n",
      "         [0.6086],\n",
      "         [0.4737],\n",
      "         [0.1629],\n",
      "         [0.3628],\n",
      "         [0.8550],\n",
      "         [1.0326],\n",
      "         [0.8359],\n",
      "         [0.9705],\n",
      "         [1.0228],\n",
      "         [1.0184],\n",
      "         [0.1040],\n",
      "         [1.0159],\n",
      "         [0.8827],\n",
      "         [1.0224],\n",
      "         [1.0104],\n",
      "         [0.7035],\n",
      "         [0.4934],\n",
      "         [1.0419],\n",
      "         [0.5841],\n",
      "         [1.0301],\n",
      "         [0.1754],\n",
      "         [1.0344],\n",
      "         [0.3750],\n",
      "         [1.0330],\n",
      "         [1.0308],\n",
      "         [1.0380],\n",
      "         [0.5778],\n",
      "         [1.0493],\n",
      "         [1.0550],\n",
      "         [0.1991],\n",
      "         [0.4986],\n",
      "         [1.0546],\n",
      "         [1.0525],\n",
      "         [1.0454],\n",
      "         [1.0364],\n",
      "         [1.0281],\n",
      "         [1.0178],\n",
      "         [1.0038],\n",
      "         [1.0138],\n",
      "         [1.0130],\n",
      "         [1.0170],\n",
      "         [0.5888],\n",
      "         [0.4654],\n",
      "         [1.0219],\n",
      "         [1.0271],\n",
      "         [1.0260],\n",
      "         [0.4551],\n",
      "         [0.5244],\n",
      "         [1.0154],\n",
      "         [0.8975],\n",
      "         [1.0099],\n",
      "         [1.0128],\n",
      "         [0.9493],\n",
      "         [0.9891],\n",
      "         [1.0249],\n",
      "         [1.0289],\n",
      "         [1.0328],\n",
      "         [1.0345],\n",
      "         [1.0311],\n",
      "         [1.0236],\n",
      "         [1.0322],\n",
      "         [1.0294],\n",
      "         [1.0267],\n",
      "         [1.0237],\n",
      "         [1.0206],\n",
      "         [1.0222],\n",
      "         [1.0213],\n",
      "         [1.0207],\n",
      "         [0.5431],\n",
      "         [0.3508],\n",
      "         [0.9106],\n",
      "         [1.0332],\n",
      "         [1.0358],\n",
      "         [0.1603],\n",
      "         [1.0397],\n",
      "         [0.9583],\n",
      "         [0.6103],\n",
      "         [1.0395],\n",
      "         [0.3655],\n",
      "         [1.0350],\n",
      "         [0.9944],\n",
      "         [0.2787],\n",
      "         [1.0238],\n",
      "         [1.0223],\n",
      "         [1.0213],\n",
      "         [1.0175],\n",
      "         [1.0188],\n",
      "         [0.4614],\n",
      "         [1.0288],\n",
      "         [1.0305],\n",
      "         [1.0368],\n",
      "         [1.0378],\n",
      "         [0.3640],\n",
      "         [1.0427],\n",
      "         [0.4965],\n",
      "         [1.0323],\n",
      "         [0.9656],\n",
      "         [1.0214],\n",
      "         [1.0152],\n",
      "         [1.0107],\n",
      "         [1.0072],\n",
      "         [1.0119],\n",
      "         [0.7710],\n",
      "         [0.3556],\n",
      "         [1.0337],\n",
      "         [1.0420],\n",
      "         [1.0492],\n",
      "         [0.6368],\n",
      "         [0.2056],\n",
      "         [0.2128],\n",
      "         [0.6785],\n",
      "         [1.0408],\n",
      "         [0.6353],\n",
      "         [1.0230],\n",
      "         [0.5907],\n",
      "         [0.5350],\n",
      "         [1.0091],\n",
      "         [1.0079],\n",
      "         [0.5303],\n",
      "         [1.0093],\n",
      "         [1.0176],\n",
      "         [0.7948],\n",
      "         [1.0187],\n",
      "         [0.8960]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.5334],\n",
      "        [0.2646],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.3930],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.6555],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.3753],\n",
      "        [0.6327],\n",
      "        [0.5054],\n",
      "        [0.9997],\n",
      "        [0.3840],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.0383],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.0142],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.6628],\n",
      "        [0.5165],\n",
      "        [0.3747],\n",
      "        [0.0174],\n",
      "        [0.2547],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.9164],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.5945],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.9804],\n",
      "        [0.0288],\n",
      "        [0.9966],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.0335],\n",
      "        [0.3573],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [0.9814],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.3728],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9009],\n",
      "        [0.9515],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.4580],\n",
      "        [0.2610],\n",
      "        [0.8296],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.1762],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9998],\n",
      "        [0.3912],\n",
      "        [0.9995],\n",
      "        [0.9044],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.6920],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.0247],\n",
      "        [0.0368],\n",
      "        [0.5463],\n",
      "        [0.9967],\n",
      "        [0.5245],\n",
      "        [0.9996],\n",
      "        [0.5108],\n",
      "        [0.4642],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7129],\n",
      "        [0.9959],\n",
      "        [0.8223]])\n",
      "######### Epoch: 5  ######### Train Loss: 0.004650959279388189  ######### Relative L2 Test Norm: 12.456080436706543\n",
      "Output batch pred: tensor([[[0.0936],\n",
      "         [0.9471],\n",
      "         [0.9486],\n",
      "         [0.9475],\n",
      "         [0.3043],\n",
      "         [0.9452],\n",
      "         [0.9419],\n",
      "         [0.9399],\n",
      "         [0.2918],\n",
      "         [0.9398],\n",
      "         [0.2859],\n",
      "         [0.9415],\n",
      "         [0.9439],\n",
      "         [0.9481],\n",
      "         [0.9530],\n",
      "         [0.9562],\n",
      "         [0.1067],\n",
      "         [0.9503],\n",
      "         [0.9611],\n",
      "         [0.9625],\n",
      "         [0.9606],\n",
      "         [0.9579],\n",
      "         [0.9548],\n",
      "         [0.6816],\n",
      "         [0.9558],\n",
      "         [0.9563],\n",
      "         [0.9621],\n",
      "         [0.5021],\n",
      "         [0.9317],\n",
      "         [0.4978],\n",
      "         [0.4382],\n",
      "         [0.5521],\n",
      "         [0.4339],\n",
      "         [0.9551],\n",
      "         [0.8744],\n",
      "         [0.5276],\n",
      "         [0.9522],\n",
      "         [0.5320],\n",
      "         [0.9511],\n",
      "         [0.7265],\n",
      "         [0.4051],\n",
      "         [0.9595],\n",
      "         [0.5672],\n",
      "         [0.9621],\n",
      "         [0.9654],\n",
      "         [0.9656],\n",
      "         [0.9641],\n",
      "         [0.9582],\n",
      "         [0.9577],\n",
      "         [0.3819],\n",
      "         [0.9557],\n",
      "         [0.7917],\n",
      "         [0.9350],\n",
      "         [0.9559],\n",
      "         [0.9531],\n",
      "         [0.5244],\n",
      "         [0.9559],\n",
      "         [0.9534],\n",
      "         [0.9531],\n",
      "         [0.4743],\n",
      "         [0.9476],\n",
      "         [0.9470],\n",
      "         [0.9489],\n",
      "         [0.1148],\n",
      "         [0.4762],\n",
      "         [0.9509],\n",
      "         [0.4799],\n",
      "         [0.9577],\n",
      "         [0.2703],\n",
      "         [0.9611],\n",
      "         [0.9569],\n",
      "         [0.1170],\n",
      "         [0.9554],\n",
      "         [0.9487],\n",
      "         [0.8935],\n",
      "         [0.4132],\n",
      "         [0.9544],\n",
      "         [0.8216],\n",
      "         [0.4986],\n",
      "         [0.9670],\n",
      "         [0.4403],\n",
      "         [0.9739],\n",
      "         [0.5183],\n",
      "         [0.7058],\n",
      "         [0.9766],\n",
      "         [0.1437],\n",
      "         [0.5917],\n",
      "         [0.9372],\n",
      "         [0.9655],\n",
      "         [0.9603],\n",
      "         [0.9627],\n",
      "         [0.5466],\n",
      "         [0.5026],\n",
      "         [0.4309],\n",
      "         [0.9685],\n",
      "         [0.9704],\n",
      "         [0.9706],\n",
      "         [0.9698],\n",
      "         [0.9692],\n",
      "         [0.9642],\n",
      "         [0.5447],\n",
      "         [0.9598],\n",
      "         [0.9582],\n",
      "         [0.7536],\n",
      "         [0.4663],\n",
      "         [0.9532],\n",
      "         [0.7613],\n",
      "         [0.9529],\n",
      "         [0.9517],\n",
      "         [0.9528],\n",
      "         [0.9525],\n",
      "         [0.8843],\n",
      "         [0.9407],\n",
      "         [0.2168],\n",
      "         [0.9437],\n",
      "         [0.5484],\n",
      "         [0.9612],\n",
      "         [0.9316],\n",
      "         [0.6344],\n",
      "         [0.8443],\n",
      "         [0.9705],\n",
      "         [0.7385],\n",
      "         [0.9716],\n",
      "         [0.1334],\n",
      "         [0.1413],\n",
      "         [0.9717],\n",
      "         [0.9682],\n",
      "         [0.5030],\n",
      "         [0.9715],\n",
      "         [0.9443],\n",
      "         [0.4377],\n",
      "         [0.9791],\n",
      "         [0.1581],\n",
      "         [0.3493],\n",
      "         [0.3394],\n",
      "         [0.3449],\n",
      "         [0.9684],\n",
      "         [0.5510],\n",
      "         [0.5291],\n",
      "         [0.8804],\n",
      "         [0.9518],\n",
      "         [0.5159],\n",
      "         [0.9498],\n",
      "         [0.9563],\n",
      "         [0.3029],\n",
      "         [0.3121],\n",
      "         [0.9656],\n",
      "         [0.9664],\n",
      "         [0.8441],\n",
      "         [0.4163],\n",
      "         [0.9592],\n",
      "         [0.9578],\n",
      "         [0.9557],\n",
      "         [0.9576],\n",
      "         [0.9613],\n",
      "         [0.9635],\n",
      "         [0.9719],\n",
      "         [0.9767],\n",
      "         [0.4445],\n",
      "         [0.9887],\n",
      "         [0.9878],\n",
      "         [0.9864],\n",
      "         [0.9820],\n",
      "         [0.9744],\n",
      "         [0.9722],\n",
      "         [0.3959],\n",
      "         [0.8980],\n",
      "         [0.9576],\n",
      "         [0.9610],\n",
      "         [0.9623],\n",
      "         [0.6660],\n",
      "         [0.1357],\n",
      "         [0.8514],\n",
      "         [0.9670],\n",
      "         [0.9623],\n",
      "         [0.5463],\n",
      "         [0.9599],\n",
      "         [0.9565]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.0000],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.9997],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.0142],\n",
      "        [0.9804],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.9420],\n",
      "        [0.4454],\n",
      "        [0.3808],\n",
      "        [0.5038],\n",
      "        [0.3840],\n",
      "        [0.9820],\n",
      "        [0.8761],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.7129],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.9997],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.5030],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.4580],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.4527],\n",
      "        [0.9995],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.0368],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [0.9164],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.4668],\n",
      "        [0.9997],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.6555],\n",
      "        [0.9997],\n",
      "        [0.0288],\n",
      "        [0.5463],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.4642],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9967],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.9814],\n",
      "        [0.1762],\n",
      "        [0.9819],\n",
      "        [0.5245],\n",
      "        [0.9998],\n",
      "        [0.9490],\n",
      "        [0.5945],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.3728],\n",
      "        [0.9999],\n",
      "        [0.0174],\n",
      "        [0.2610],\n",
      "        [0.2518],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.4988],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.2547],\n",
      "        [0.2577],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.3747],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.6327],\n",
      "        [0.0383],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [1.0000]])\n",
      "######### Epoch: 6  ######### Train Loss: 0.0020430777221918106  ######### Relative L2 Test Norm: 17.44108009338379\n",
      "Output batch pred: tensor([[[0.9115],\n",
      "         [0.9181],\n",
      "         [0.2221],\n",
      "         [0.9329],\n",
      "         [0.9350],\n",
      "         [0.1226],\n",
      "         [0.9283],\n",
      "         [0.2929],\n",
      "         [0.8940],\n",
      "         [0.8909],\n",
      "         [0.8746],\n",
      "         [0.8659],\n",
      "         [0.6559],\n",
      "         [0.8642],\n",
      "         [0.4221],\n",
      "         [0.8831],\n",
      "         [0.8840],\n",
      "         [0.7865],\n",
      "         [0.4966],\n",
      "         [0.9193],\n",
      "         [0.9068],\n",
      "         [0.4878],\n",
      "         [0.9082],\n",
      "         [0.8668],\n",
      "         [0.4225],\n",
      "         [0.8946],\n",
      "         [0.8954],\n",
      "         [0.0972],\n",
      "         [0.2841],\n",
      "         [0.9218],\n",
      "         [0.9304],\n",
      "         [0.3028],\n",
      "         [0.9442],\n",
      "         [0.9430],\n",
      "         [0.9428],\n",
      "         [0.4150],\n",
      "         [0.9347],\n",
      "         [0.9266],\n",
      "         [0.7310],\n",
      "         [0.5193],\n",
      "         [0.9266],\n",
      "         [0.9243],\n",
      "         [0.1142],\n",
      "         [0.9297],\n",
      "         [0.1207],\n",
      "         [0.4561],\n",
      "         [0.3833],\n",
      "         [0.9135],\n",
      "         [0.9109],\n",
      "         [0.9097],\n",
      "         [0.5741],\n",
      "         [0.3543],\n",
      "         [0.0973],\n",
      "         [0.4524],\n",
      "         [0.9082],\n",
      "         [0.9065],\n",
      "         [0.9053],\n",
      "         [0.9023],\n",
      "         [0.9018],\n",
      "         [0.8970],\n",
      "         [0.8948],\n",
      "         [0.8948],\n",
      "         [0.8980],\n",
      "         [0.4250],\n",
      "         [0.9039],\n",
      "         [0.2639],\n",
      "         [0.9166],\n",
      "         [0.9178],\n",
      "         [0.9192],\n",
      "         [0.6703],\n",
      "         [0.9083],\n",
      "         [0.9054],\n",
      "         [0.8982],\n",
      "         [0.8964],\n",
      "         [0.9012],\n",
      "         [0.8396],\n",
      "         [0.9153],\n",
      "         [0.9252],\n",
      "         [0.9344],\n",
      "         [0.9419],\n",
      "         [0.9453],\n",
      "         [0.3113],\n",
      "         [0.8142],\n",
      "         [0.9301],\n",
      "         [0.4962],\n",
      "         [0.0958],\n",
      "         [0.9040],\n",
      "         [0.8971],\n",
      "         [0.3467],\n",
      "         [0.8970],\n",
      "         [0.4170],\n",
      "         [0.9039],\n",
      "         [0.9085],\n",
      "         [0.9076],\n",
      "         [0.9089],\n",
      "         [0.3586],\n",
      "         [0.8983],\n",
      "         [0.8884],\n",
      "         [0.7125],\n",
      "         [0.8777],\n",
      "         [0.8763],\n",
      "         [0.3921],\n",
      "         [0.8810],\n",
      "         [0.8858],\n",
      "         [0.0526],\n",
      "         [0.8990],\n",
      "         [0.9017],\n",
      "         [0.2584],\n",
      "         [0.9061],\n",
      "         [0.9050],\n",
      "         [0.7746],\n",
      "         [0.4673],\n",
      "         [0.8969],\n",
      "         [0.8969],\n",
      "         [0.8997],\n",
      "         [0.5163],\n",
      "         [0.4405],\n",
      "         [0.4893],\n",
      "         [0.7802],\n",
      "         [0.9186],\n",
      "         [0.9192],\n",
      "         [0.9197],\n",
      "         [0.9189],\n",
      "         [0.4557],\n",
      "         [0.9135],\n",
      "         [0.2406],\n",
      "         [0.3864],\n",
      "         [0.9097],\n",
      "         [0.3570],\n",
      "         [0.4569],\n",
      "         [0.3853],\n",
      "         [0.6457],\n",
      "         [0.4915],\n",
      "         [0.4976],\n",
      "         [0.9105],\n",
      "         [0.9096],\n",
      "         [0.8958],\n",
      "         [0.5088],\n",
      "         [0.8254],\n",
      "         [0.6923],\n",
      "         [0.2724],\n",
      "         [0.3831],\n",
      "         [0.4537],\n",
      "         [0.9194],\n",
      "         [0.9128],\n",
      "         [0.8379],\n",
      "         [0.3605],\n",
      "         [0.8849],\n",
      "         [0.8803],\n",
      "         [0.8751],\n",
      "         [0.8744],\n",
      "         [0.8784],\n",
      "         [0.8525],\n",
      "         [0.8980],\n",
      "         [0.8716],\n",
      "         [0.9236],\n",
      "         [0.9328],\n",
      "         [0.9353],\n",
      "         [0.1063],\n",
      "         [0.9330],\n",
      "         [0.8577],\n",
      "         [0.5052],\n",
      "         [0.9091],\n",
      "         [0.9026],\n",
      "         [0.8640],\n",
      "         [0.8969],\n",
      "         [0.8978],\n",
      "         [0.9064],\n",
      "         [0.8557],\n",
      "         [0.5325],\n",
      "         [0.6525],\n",
      "         [0.1325],\n",
      "         [0.3986],\n",
      "         [0.2865],\n",
      "         [0.6205],\n",
      "         [0.9110],\n",
      "         [0.9041],\n",
      "         [0.8846]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.9997],\n",
      "        [0.1762],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9997],\n",
      "        [0.2735],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.9998],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [0.9819],\n",
      "        [0.8379],\n",
      "        [0.5108],\n",
      "        [0.9997],\n",
      "        [0.9814],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.2729],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.9998],\n",
      "        [0.3930],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9999],\n",
      "        [0.0335],\n",
      "        [0.4480],\n",
      "        [0.3753],\n",
      "        [0.9959],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.3575],\n",
      "        [0.0247],\n",
      "        [0.4668],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [0.8223],\n",
      "        [0.9995],\n",
      "        [0.5009],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.9998],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5463],\n",
      "        [0.4611],\n",
      "        [0.5080],\n",
      "        [0.8139],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.3912],\n",
      "        [0.9994],\n",
      "        [0.3573],\n",
      "        [0.4642],\n",
      "        [0.3875],\n",
      "        [0.6628],\n",
      "        [0.5054],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9804],\n",
      "        [0.5245],\n",
      "        [0.8761],\n",
      "        [0.7129],\n",
      "        [0.2518],\n",
      "        [0.3747],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9009],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.0209],\n",
      "        [0.9956],\n",
      "        [0.8933],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9164],\n",
      "        [0.5334],\n",
      "        [0.6555],\n",
      "        [0.0368],\n",
      "        [0.3780],\n",
      "        [0.2547],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9724]])\n",
      "######### Epoch: 7  ######### Train Loss: 0.005908578168600798  ######### Relative L2 Test Norm: 19.78685760498047\n",
      "Output batch pred: tensor([[[0.8878],\n",
      "         [0.8265],\n",
      "         [0.8844],\n",
      "         [0.8835],\n",
      "         [0.6309],\n",
      "         [0.8814],\n",
      "         [0.8809],\n",
      "         [0.8845],\n",
      "         [0.8891],\n",
      "         [0.8908],\n",
      "         [0.3404],\n",
      "         [0.2307],\n",
      "         [0.5709],\n",
      "         [0.8979],\n",
      "         [0.4296],\n",
      "         [0.9076],\n",
      "         [0.4943],\n",
      "         [0.8233],\n",
      "         [0.8936],\n",
      "         [0.8889],\n",
      "         [0.8856],\n",
      "         [0.8847],\n",
      "         [0.8867],\n",
      "         [0.3447],\n",
      "         [0.8921],\n",
      "         [0.8811],\n",
      "         [0.8948],\n",
      "         [0.8931],\n",
      "         [0.8563],\n",
      "         [0.8870],\n",
      "         [0.8816],\n",
      "         [0.2108],\n",
      "         [0.8697],\n",
      "         [0.8640],\n",
      "         [0.8643],\n",
      "         [0.2128],\n",
      "         [0.8643],\n",
      "         [0.2180],\n",
      "         [0.0663],\n",
      "         [0.6698],\n",
      "         [0.8676],\n",
      "         [0.8686],\n",
      "         [0.0724],\n",
      "         [0.8728],\n",
      "         [0.0676],\n",
      "         [0.3398],\n",
      "         [0.0527],\n",
      "         [0.8213],\n",
      "         [0.8937],\n",
      "         [0.8961],\n",
      "         [0.9006],\n",
      "         [0.9002],\n",
      "         [0.8978],\n",
      "         [0.8934],\n",
      "         [0.8877],\n",
      "         [0.7441],\n",
      "         [0.8717],\n",
      "         [0.8669],\n",
      "         [0.3834],\n",
      "         [0.4223],\n",
      "         [0.4188],\n",
      "         [0.8641],\n",
      "         [0.8571],\n",
      "         [0.4353],\n",
      "         [0.7493],\n",
      "         [0.2402],\n",
      "         [0.2503],\n",
      "         [0.4708],\n",
      "         [0.8934],\n",
      "         [0.8080],\n",
      "         [0.8937],\n",
      "         [0.5067],\n",
      "         [0.8933],\n",
      "         [0.8929],\n",
      "         [0.8909],\n",
      "         [0.2459],\n",
      "         [0.8892],\n",
      "         [0.7664],\n",
      "         [0.3495],\n",
      "         [0.8864],\n",
      "         [0.8886],\n",
      "         [0.8904],\n",
      "         [0.0781],\n",
      "         [0.8886],\n",
      "         [0.4103],\n",
      "         [0.8911],\n",
      "         [0.8892],\n",
      "         [0.4120],\n",
      "         [0.8882],\n",
      "         [0.8871],\n",
      "         [0.5950],\n",
      "         [0.6051],\n",
      "         [0.4539],\n",
      "         [0.8837],\n",
      "         [0.4501],\n",
      "         [0.8769],\n",
      "         [0.8049],\n",
      "         [0.0435],\n",
      "         [0.8351],\n",
      "         [0.8660],\n",
      "         [0.4565],\n",
      "         [0.3695],\n",
      "         [0.3092],\n",
      "         [0.8664],\n",
      "         [0.6638],\n",
      "         [0.4596],\n",
      "         [0.8867],\n",
      "         [0.7545],\n",
      "         [0.6735],\n",
      "         [0.9034],\n",
      "         [0.4315],\n",
      "         [0.9072],\n",
      "         [0.3671],\n",
      "         [0.4504],\n",
      "         [0.4505],\n",
      "         [0.0928],\n",
      "         [0.2711],\n",
      "         [0.9025],\n",
      "         [0.9027],\n",
      "         [0.3640],\n",
      "         [0.9098],\n",
      "         [0.8752],\n",
      "         [0.9159],\n",
      "         [0.9187],\n",
      "         [0.9214],\n",
      "         [0.9233],\n",
      "         [0.9203],\n",
      "         [0.9212],\n",
      "         [0.9198],\n",
      "         [0.9126],\n",
      "         [0.0826],\n",
      "         [0.9042],\n",
      "         [0.8977],\n",
      "         [0.8920],\n",
      "         [0.8853],\n",
      "         [0.8810],\n",
      "         [0.8857],\n",
      "         [0.8673],\n",
      "         [0.2352],\n",
      "         [0.4240],\n",
      "         [0.8882],\n",
      "         [0.6053],\n",
      "         [0.9069],\n",
      "         [0.9049],\n",
      "         [0.9046],\n",
      "         [0.8989],\n",
      "         [0.8905],\n",
      "         [0.3281],\n",
      "         [0.8749],\n",
      "         [0.8745],\n",
      "         [0.8737],\n",
      "         [0.8748],\n",
      "         [0.8834],\n",
      "         [0.8914],\n",
      "         [0.1860],\n",
      "         [0.3476],\n",
      "         [0.4830],\n",
      "         [0.9146],\n",
      "         [0.3717],\n",
      "         [0.9077],\n",
      "         [0.9021],\n",
      "         [0.8936],\n",
      "         [0.8848],\n",
      "         [0.0688],\n",
      "         [0.8781],\n",
      "         [0.4577],\n",
      "         [0.8786],\n",
      "         [0.8825],\n",
      "         [0.8864],\n",
      "         [0.8576],\n",
      "         [0.8929],\n",
      "         [0.4619],\n",
      "         [0.3612],\n",
      "         [0.4172],\n",
      "         [0.8930],\n",
      "         [0.8936],\n",
      "         [0.8926],\n",
      "         [0.7243]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.9164],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.6920],\n",
      "        [0.9996],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.2208],\n",
      "        [0.5945],\n",
      "        [0.9819],\n",
      "        [0.4503],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.0383],\n",
      "        [0.7540],\n",
      "        [0.9995],\n",
      "        [0.9996],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.3808],\n",
      "        [0.0000],\n",
      "        [0.9044],\n",
      "        [0.9997],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.5038],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.5054],\n",
      "        [0.8296],\n",
      "        [0.2686],\n",
      "        [0.2729],\n",
      "        [0.5139],\n",
      "        [0.9995],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.3875],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [0.6628],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.0209],\n",
      "        [0.9520],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [0.4454],\n",
      "        [0.3753],\n",
      "        [0.9966],\n",
      "        [0.7391],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.7129],\n",
      "        [0.9999],\n",
      "        [0.4480],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.4645],\n",
      "        [0.4642],\n",
      "        [0.0174],\n",
      "        [0.2646],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.2610],\n",
      "        [0.4611],\n",
      "        [0.9804],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.3575],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9515],\n",
      "        [0.9999],\n",
      "        [0.5030],\n",
      "        [0.3930],\n",
      "        [0.4527],\n",
      "        [0.9967],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7820]])\n",
      "######### Epoch: 8  ######### Train Loss: 0.00824643298983574  ######### Relative L2 Test Norm: 20.51417350769043\n",
      "Output batch pred: tensor([[[0.2411],\n",
      "         [0.6868],\n",
      "         [0.8949],\n",
      "         [0.8954],\n",
      "         [0.1998],\n",
      "         [0.6499],\n",
      "         [0.9046],\n",
      "         [0.9092],\n",
      "         [0.9132],\n",
      "         [0.9159],\n",
      "         [0.9210],\n",
      "         [0.4390],\n",
      "         [0.9245],\n",
      "         [0.9208],\n",
      "         [0.9212],\n",
      "         [0.9153],\n",
      "         [0.9117],\n",
      "         [0.9105],\n",
      "         [0.9063],\n",
      "         [0.9019],\n",
      "         [0.8996],\n",
      "         [0.4113],\n",
      "         [0.8988],\n",
      "         [0.8963],\n",
      "         [0.0407],\n",
      "         [0.3472],\n",
      "         [0.8911],\n",
      "         [0.8887],\n",
      "         [0.8887],\n",
      "         [0.4434],\n",
      "         [0.7613],\n",
      "         [0.6122],\n",
      "         [0.8391],\n",
      "         [0.9021],\n",
      "         [0.0621],\n",
      "         [0.9094],\n",
      "         [0.9120],\n",
      "         [0.2495],\n",
      "         [0.9074],\n",
      "         [0.8902],\n",
      "         [0.4524],\n",
      "         [0.4551],\n",
      "         [0.0507],\n",
      "         [0.7356],\n",
      "         [0.8739],\n",
      "         [0.8756],\n",
      "         [0.7339],\n",
      "         [0.8843],\n",
      "         [0.7237],\n",
      "         [0.9021],\n",
      "         [0.4149],\n",
      "         [0.8228],\n",
      "         [0.5158],\n",
      "         [0.9093],\n",
      "         [0.9059],\n",
      "         [0.8996],\n",
      "         [0.6574],\n",
      "         [0.8843],\n",
      "         [0.2232],\n",
      "         [0.8447],\n",
      "         [0.8799],\n",
      "         [0.2242],\n",
      "         [0.8827],\n",
      "         [0.8878],\n",
      "         [0.4412],\n",
      "         [0.0468],\n",
      "         [0.4813],\n",
      "         [0.8913],\n",
      "         [0.3391],\n",
      "         [0.8914],\n",
      "         [0.8800],\n",
      "         [0.7722],\n",
      "         [0.8987],\n",
      "         [0.9014],\n",
      "         [0.3458],\n",
      "         [0.9028],\n",
      "         [0.4730],\n",
      "         [0.4638],\n",
      "         [0.8829],\n",
      "         [0.8970],\n",
      "         [0.8958],\n",
      "         [0.8918],\n",
      "         [0.5365],\n",
      "         [0.8934],\n",
      "         [0.8943],\n",
      "         [0.4029],\n",
      "         [0.4813],\n",
      "         [0.9138],\n",
      "         [0.6316],\n",
      "         [0.9177],\n",
      "         [0.9159],\n",
      "         [0.8355],\n",
      "         [0.7056],\n",
      "         [0.8937],\n",
      "         [0.8849],\n",
      "         [0.8789],\n",
      "         [0.8743],\n",
      "         [0.8725],\n",
      "         [0.5539],\n",
      "         [0.3927],\n",
      "         [0.0482],\n",
      "         [0.8859],\n",
      "         [0.8899],\n",
      "         [0.4472],\n",
      "         [0.8823],\n",
      "         [0.0547],\n",
      "         [0.8923],\n",
      "         [0.8924],\n",
      "         [0.8917],\n",
      "         [0.8898],\n",
      "         [0.3293],\n",
      "         [0.0529],\n",
      "         [0.9015],\n",
      "         [0.9050],\n",
      "         [0.9109],\n",
      "         [0.9153],\n",
      "         [0.9177],\n",
      "         [0.8784],\n",
      "         [0.3383],\n",
      "         [0.3595],\n",
      "         [0.9110],\n",
      "         [0.3610],\n",
      "         [0.9034],\n",
      "         [0.8699],\n",
      "         [0.8319],\n",
      "         [0.8977],\n",
      "         [0.2459],\n",
      "         [0.8979],\n",
      "         [0.9007],\n",
      "         [0.4266],\n",
      "         [0.9045],\n",
      "         [0.9071],\n",
      "         [0.3384],\n",
      "         [0.9088],\n",
      "         [0.4326],\n",
      "         [0.9123],\n",
      "         [0.9109],\n",
      "         [0.2618],\n",
      "         [0.9041],\n",
      "         [0.4226],\n",
      "         [0.8980],\n",
      "         [0.8953],\n",
      "         [0.4701],\n",
      "         [0.8916],\n",
      "         [0.8914],\n",
      "         [0.8928],\n",
      "         [0.8954],\n",
      "         [0.8983],\n",
      "         [0.8878],\n",
      "         [0.4080],\n",
      "         [0.9027],\n",
      "         [0.8344],\n",
      "         [0.4709],\n",
      "         [0.9020],\n",
      "         [0.8964],\n",
      "         [0.3263],\n",
      "         [0.4520],\n",
      "         [0.8941],\n",
      "         [0.8934],\n",
      "         [0.8934],\n",
      "         [0.8957],\n",
      "         [0.8969],\n",
      "         [0.0472],\n",
      "         [0.8973],\n",
      "         [0.8641],\n",
      "         [0.2427],\n",
      "         [0.3510],\n",
      "         [0.1766],\n",
      "         [0.8959],\n",
      "         [0.3440],\n",
      "         [0.8973],\n",
      "         [0.2399],\n",
      "         [0.9001],\n",
      "         [0.9023],\n",
      "         [0.9028],\n",
      "         [0.0856],\n",
      "         [0.9022],\n",
      "         [0.4325]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2547],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.0000],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.5038],\n",
      "        [0.8296],\n",
      "        [0.6628],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.2518],\n",
      "        [0.9998],\n",
      "        [0.9819],\n",
      "        [0.5030],\n",
      "        [0.5165],\n",
      "        [0.0368],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [0.9995],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [0.8761],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.9967],\n",
      "        [0.2686],\n",
      "        [0.9490],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.0209],\n",
      "        [0.5334],\n",
      "        [0.9997],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.8379],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.3747],\n",
      "        [0.9959],\n",
      "        [0.5108],\n",
      "        [0.5054],\n",
      "        [0.9724],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.6327],\n",
      "        [0.4645],\n",
      "        [0.0288],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9820],\n",
      "        [0.0247],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.3753],\n",
      "        [0.0335],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.3573],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [0.3875],\n",
      "        [0.9966],\n",
      "        [0.9515],\n",
      "        [0.9044],\n",
      "        [0.9994],\n",
      "        [0.2735],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5245],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.4503],\n",
      "        [0.9994],\n",
      "        [0.9009],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [0.3728],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.2610],\n",
      "        [0.3840],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0383],\n",
      "        [0.9999],\n",
      "        [0.4642]])\n",
      "######### Epoch: 9  ######### Train Loss: 0.006860088557004929  ######### Relative L2 Test Norm: 18.182964324951172\n",
      "Output batch pred: tensor([[[0.9159],\n",
      "         [0.9222],\n",
      "         [0.9299],\n",
      "         [0.9376],\n",
      "         [0.9439],\n",
      "         [0.9377],\n",
      "         [0.5038],\n",
      "         [0.9438],\n",
      "         [0.5129],\n",
      "         [0.4685],\n",
      "         [0.9142],\n",
      "         [0.6410],\n",
      "         [0.2122],\n",
      "         [0.4761],\n",
      "         [0.2201],\n",
      "         [0.2175],\n",
      "         [0.6578],\n",
      "         [0.9075],\n",
      "         [0.9156],\n",
      "         [0.9228],\n",
      "         [0.2542],\n",
      "         [0.9305],\n",
      "         [0.0854],\n",
      "         [0.3584],\n",
      "         [0.5112],\n",
      "         [0.8457],\n",
      "         [0.6288],\n",
      "         [0.9118],\n",
      "         [0.9160],\n",
      "         [0.9193],\n",
      "         [0.9268],\n",
      "         [0.9220],\n",
      "         [0.4274],\n",
      "         [0.9434],\n",
      "         [0.9461],\n",
      "         [0.9409],\n",
      "         [0.9348],\n",
      "         [0.7978],\n",
      "         [0.7151],\n",
      "         [0.8286],\n",
      "         [0.3924],\n",
      "         [0.0151],\n",
      "         [0.8949],\n",
      "         [0.7483],\n",
      "         [0.9043],\n",
      "         [0.9121],\n",
      "         [0.9188],\n",
      "         [0.3462],\n",
      "         [0.9312],\n",
      "         [0.9323],\n",
      "         [0.9304],\n",
      "         [0.9256],\n",
      "         [0.0457],\n",
      "         [0.9123],\n",
      "         [0.3272],\n",
      "         [0.3879],\n",
      "         [0.9030],\n",
      "         [0.9042],\n",
      "         [0.4465],\n",
      "         [0.9194],\n",
      "         [0.9275],\n",
      "         [0.2048],\n",
      "         [0.9380],\n",
      "         [0.9473],\n",
      "         [0.9494],\n",
      "         [0.9494],\n",
      "         [0.9466],\n",
      "         [0.4507],\n",
      "         [0.4862],\n",
      "         [0.9348],\n",
      "         [0.9313],\n",
      "         [0.9283],\n",
      "         [0.9275],\n",
      "         [0.9253],\n",
      "         [0.4307],\n",
      "         [0.9261],\n",
      "         [0.2543],\n",
      "         [0.9248],\n",
      "         [0.9236],\n",
      "         [0.3576],\n",
      "         [0.9190],\n",
      "         [0.9178],\n",
      "         [0.8278],\n",
      "         [0.4776],\n",
      "         [0.9200],\n",
      "         [0.4803],\n",
      "         [0.9304],\n",
      "         [0.9348],\n",
      "         [0.9393],\n",
      "         [0.9301],\n",
      "         [0.9311],\n",
      "         [0.3487],\n",
      "         [0.9376],\n",
      "         [0.7195],\n",
      "         [0.9234],\n",
      "         [0.9125],\n",
      "         [0.4419],\n",
      "         [0.3101],\n",
      "         [0.4428],\n",
      "         [0.9031],\n",
      "         [0.8747],\n",
      "         [0.9183],\n",
      "         [0.4789],\n",
      "         [0.9376],\n",
      "         [0.4507],\n",
      "         [0.4731],\n",
      "         [0.9473],\n",
      "         [0.3923],\n",
      "         [0.2638],\n",
      "         [0.9327],\n",
      "         [0.9272],\n",
      "         [0.1775],\n",
      "         [0.9179],\n",
      "         [0.9204],\n",
      "         [0.8901],\n",
      "         [0.6153],\n",
      "         [0.8994],\n",
      "         [0.2734],\n",
      "         [0.3589],\n",
      "         [0.9394],\n",
      "         [0.9346],\n",
      "         [0.5886],\n",
      "         [0.9269],\n",
      "         [0.0721],\n",
      "         [0.9232],\n",
      "         [0.2430],\n",
      "         [0.9222],\n",
      "         [0.9246],\n",
      "         [0.3654],\n",
      "         [0.9289],\n",
      "         [0.9290],\n",
      "         [0.3647],\n",
      "         [0.9226],\n",
      "         [0.4075],\n",
      "         [0.6149],\n",
      "         [0.9101],\n",
      "         [0.9099],\n",
      "         [0.3302],\n",
      "         [0.4766],\n",
      "         [0.9268],\n",
      "         [0.9356],\n",
      "         [0.9462],\n",
      "         [0.9524],\n",
      "         [0.9415],\n",
      "         [0.9629],\n",
      "         [0.9627],\n",
      "         [0.9596],\n",
      "         [0.9552],\n",
      "         [0.9512],\n",
      "         [0.9462],\n",
      "         [0.0752],\n",
      "         [0.9506],\n",
      "         [0.8367],\n",
      "         [0.9597],\n",
      "         [0.9615],\n",
      "         [0.9657],\n",
      "         [0.9655],\n",
      "         [0.0970],\n",
      "         [0.0779],\n",
      "         [0.7834],\n",
      "         [0.9370],\n",
      "         [0.9290],\n",
      "         [0.8525],\n",
      "         [0.9199],\n",
      "         [0.4204],\n",
      "         [0.0602],\n",
      "         [0.9310],\n",
      "         [0.9024],\n",
      "         [0.8190],\n",
      "         [0.9534],\n",
      "         [0.9010],\n",
      "         [0.0969],\n",
      "         [0.9513],\n",
      "         [0.9422],\n",
      "         [0.4472],\n",
      "         [0.9266],\n",
      "         [0.9193],\n",
      "         [0.9129]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9820],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.2547],\n",
      "        [0.5463],\n",
      "        [0.2686],\n",
      "        [0.2610],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.9998],\n",
      "        [0.0368],\n",
      "        [0.3753],\n",
      "        [0.5334],\n",
      "        [0.9009],\n",
      "        [0.6628],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9995],\n",
      "        [0.8296],\n",
      "        [0.7540],\n",
      "        [0.8933],\n",
      "        [0.4580],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.4645],\n",
      "        [0.9997],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.9804],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.5009],\n",
      "        [0.3728],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.4668],\n",
      "        [0.9999],\n",
      "        [0.3840],\n",
      "        [0.2518],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9520],\n",
      "        [0.6327],\n",
      "        [0.9490],\n",
      "        [0.2729],\n",
      "        [0.3575],\n",
      "        [0.9998],\n",
      "        [0.9967],\n",
      "        [0.5945],\n",
      "        [0.9962],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.3912],\n",
      "        [0.9997],\n",
      "        [0.4454],\n",
      "        [0.6555],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3747],\n",
      "        [0.5151],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9724],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [0.0335],\n",
      "        [0.9999],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0209],\n",
      "        [0.0000],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.8223],\n",
      "        [0.9998],\n",
      "        [0.9164],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000]])\n",
      "######### Epoch: 10  ######### Train Loss: 0.0034920175094157457  ######### Relative L2 Test Norm: 15.954229354858398\n",
      "Output batch pred: tensor([[[0.9395],\n",
      "         [0.2209],\n",
      "         [0.9471],\n",
      "         [0.9545],\n",
      "         [0.5382],\n",
      "         [0.9716],\n",
      "         [0.8400],\n",
      "         [0.9853],\n",
      "         [0.9872],\n",
      "         [0.9900],\n",
      "         [0.5539],\n",
      "         [0.9862],\n",
      "         [0.9852],\n",
      "         [0.9159],\n",
      "         [0.9781],\n",
      "         [0.9784],\n",
      "         [0.9764],\n",
      "         [0.0783],\n",
      "         [0.9757],\n",
      "         [0.9730],\n",
      "         [0.6877],\n",
      "         [0.9727],\n",
      "         [0.5409],\n",
      "         [0.9736],\n",
      "         [0.3685],\n",
      "         [0.9792],\n",
      "         [0.9855],\n",
      "         [0.9903],\n",
      "         [0.8337],\n",
      "         [0.9980],\n",
      "         [0.9862],\n",
      "         [0.9939],\n",
      "         [0.9901],\n",
      "         [0.9482],\n",
      "         [0.9700],\n",
      "         [0.9375],\n",
      "         [0.0596],\n",
      "         [0.9388],\n",
      "         [0.3394],\n",
      "         [0.9332],\n",
      "         [0.0407],\n",
      "         [0.2538],\n",
      "         [0.4996],\n",
      "         [0.9613],\n",
      "         [0.9704],\n",
      "         [0.8405],\n",
      "         [0.9739],\n",
      "         [0.2657],\n",
      "         [0.9708],\n",
      "         [0.9665],\n",
      "         [0.9625],\n",
      "         [0.9589],\n",
      "         [0.8971],\n",
      "         [0.5085],\n",
      "         [0.3644],\n",
      "         [0.9617],\n",
      "         [0.9638],\n",
      "         [0.5023],\n",
      "         [0.4358],\n",
      "         [0.9616],\n",
      "         [0.4932],\n",
      "         [0.4460],\n",
      "         [0.9548],\n",
      "         [0.9514],\n",
      "         [0.9568],\n",
      "         [0.4998],\n",
      "         [0.2691],\n",
      "         [0.9698],\n",
      "         [0.9747],\n",
      "         [0.9788],\n",
      "         [0.5216],\n",
      "         [0.9803],\n",
      "         [0.9782],\n",
      "         [0.0917],\n",
      "         [0.9727],\n",
      "         [0.6490],\n",
      "         [0.9660],\n",
      "         [0.9303],\n",
      "         [0.2624],\n",
      "         [0.2543],\n",
      "         [0.9597],\n",
      "         [0.9628],\n",
      "         [0.2593],\n",
      "         [0.9659],\n",
      "         [0.2777],\n",
      "         [0.9691],\n",
      "         [0.9650],\n",
      "         [0.9803],\n",
      "         [0.9857],\n",
      "         [0.9883],\n",
      "         [0.0815],\n",
      "         [0.2505],\n",
      "         [0.9903],\n",
      "         [0.9855],\n",
      "         [0.9790],\n",
      "         [0.9707],\n",
      "         [0.9645],\n",
      "         [0.3431],\n",
      "         [0.6485],\n",
      "         [0.4802],\n",
      "         [0.9460],\n",
      "         [0.9460],\n",
      "         [0.9463],\n",
      "         [0.4348],\n",
      "         [0.8742],\n",
      "         [0.9090],\n",
      "         [0.4374],\n",
      "         [0.5035],\n",
      "         [0.8403],\n",
      "         [0.7171],\n",
      "         [0.7862],\n",
      "         [0.9880],\n",
      "         [0.8746],\n",
      "         [0.0971],\n",
      "         [0.9993],\n",
      "         [0.9967],\n",
      "         [0.9896],\n",
      "         [0.9820],\n",
      "         [0.9695],\n",
      "         [0.9543],\n",
      "         [0.3628],\n",
      "         [0.0308],\n",
      "         [0.9355],\n",
      "         [0.4262],\n",
      "         [0.1755],\n",
      "         [0.3677],\n",
      "         [0.9700],\n",
      "         [0.9829],\n",
      "         [0.9914],\n",
      "         [0.9969],\n",
      "         [0.5131],\n",
      "         [0.9921],\n",
      "         [0.4131],\n",
      "         [0.4683],\n",
      "         [0.9736],\n",
      "         [0.9665],\n",
      "         [0.9627],\n",
      "         [0.9249],\n",
      "         [0.4373],\n",
      "         [0.9591],\n",
      "         [0.9573],\n",
      "         [0.5957],\n",
      "         [0.4523],\n",
      "         [0.9591],\n",
      "         [0.9604],\n",
      "         [0.8853],\n",
      "         [0.5473],\n",
      "         [0.9709],\n",
      "         [0.9673],\n",
      "         [0.9867],\n",
      "         [0.9940],\n",
      "         [0.7724],\n",
      "         [1.0017],\n",
      "         [1.0005],\n",
      "         [0.9838],\n",
      "         [0.4034],\n",
      "         [0.9730],\n",
      "         [0.4992],\n",
      "         [0.0612],\n",
      "         [0.9363],\n",
      "         [0.0494],\n",
      "         [0.9291],\n",
      "         [0.4136],\n",
      "         [0.9447],\n",
      "         [0.3740],\n",
      "         [0.9670],\n",
      "         [0.9787],\n",
      "         [0.9879],\n",
      "         [0.9951],\n",
      "         [0.9966],\n",
      "         [0.9979],\n",
      "         [0.7922],\n",
      "         [0.4077],\n",
      "         [0.8917],\n",
      "         [0.9698],\n",
      "         [0.9593],\n",
      "         [0.3680],\n",
      "         [0.9424]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.9962],\n",
      "        [0.9998],\n",
      "        [0.9044],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.9996],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.9520],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.9999],\n",
      "        [0.0142],\n",
      "        [0.2735],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.5165],\n",
      "        [0.3753],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.4611],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.2686],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [0.6327],\n",
      "        [0.9997],\n",
      "        [0.9515],\n",
      "        [0.2646],\n",
      "        [0.2577],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.2610],\n",
      "        [0.9999],\n",
      "        [0.2729],\n",
      "        [0.9959],\n",
      "        [0.9804],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.6555],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [0.9009],\n",
      "        [0.9420],\n",
      "        [0.4580],\n",
      "        [0.5139],\n",
      "        [0.8379],\n",
      "        [0.6920],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.3875],\n",
      "        [0.0000],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.1762],\n",
      "        [0.3728],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9819],\n",
      "        [0.3747],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.3780],\n",
      "        [0.8761],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.3912],\n",
      "        [1.0000]])\n",
      "######### Epoch: 11  ######### Train Loss: 0.0009110596147365868  ######### Relative L2 Test Norm: 14.444889068603516\n",
      "Output batch pred: tensor([[[0.9347],\n",
      "         [0.9925],\n",
      "         [0.4535],\n",
      "         [0.4630],\n",
      "         [0.0602],\n",
      "         [0.4639],\n",
      "         [0.9851],\n",
      "         [0.8554],\n",
      "         [1.0006],\n",
      "         [1.0045],\n",
      "         [0.0672],\n",
      "         [1.0103],\n",
      "         [1.0084],\n",
      "         [1.0056],\n",
      "         [1.0013],\n",
      "         [0.5492],\n",
      "         [0.9984],\n",
      "         [0.0916],\n",
      "         [0.2934],\n",
      "         [1.0112],\n",
      "         [1.0157],\n",
      "         [0.8982],\n",
      "         [1.0198],\n",
      "         [0.2580],\n",
      "         [0.7314],\n",
      "         [0.3085],\n",
      "         [0.9779],\n",
      "         [0.4347],\n",
      "         [0.5166],\n",
      "         [1.0155],\n",
      "         [0.8991],\n",
      "         [1.0234],\n",
      "         [1.0228],\n",
      "         [0.9877],\n",
      "         [1.0208],\n",
      "         [0.2931],\n",
      "         [1.0089],\n",
      "         [0.9950],\n",
      "         [1.0089],\n",
      "         [0.3900],\n",
      "         [1.0243],\n",
      "         [1.0343],\n",
      "         [1.0459],\n",
      "         [1.0548],\n",
      "         [1.0603],\n",
      "         [1.0586],\n",
      "         [1.0490],\n",
      "         [0.5158],\n",
      "         [1.0143],\n",
      "         [0.9919],\n",
      "         [0.5017],\n",
      "         [0.9658],\n",
      "         [0.0275],\n",
      "         [0.9663],\n",
      "         [0.0630],\n",
      "         [0.5273],\n",
      "         [0.3912],\n",
      "         [1.0133],\n",
      "         [1.0182],\n",
      "         [1.0183],\n",
      "         [0.2835],\n",
      "         [0.5886],\n",
      "         [0.4001],\n",
      "         [0.6320],\n",
      "         [0.9955],\n",
      "         [0.2767],\n",
      "         [1.0026],\n",
      "         [0.4187],\n",
      "         [1.0082],\n",
      "         [1.0091],\n",
      "         [1.0030],\n",
      "         [0.5166],\n",
      "         [0.9826],\n",
      "         [0.3608],\n",
      "         [0.1604],\n",
      "         [0.4251],\n",
      "         [0.7262],\n",
      "         [0.9840],\n",
      "         [1.0018],\n",
      "         [1.0142],\n",
      "         [1.0261],\n",
      "         [1.0326],\n",
      "         [0.3036],\n",
      "         [0.6023],\n",
      "         [1.0075],\n",
      "         [0.9889],\n",
      "         [0.9661],\n",
      "         [0.2405],\n",
      "         [0.9391],\n",
      "         [0.0223],\n",
      "         [0.0174],\n",
      "         [0.3110],\n",
      "         [0.9669],\n",
      "         [0.5265],\n",
      "         [0.9923],\n",
      "         [1.0006],\n",
      "         [1.0061],\n",
      "         [0.5383],\n",
      "         [1.0115],\n",
      "         [1.0141],\n",
      "         [1.0183],\n",
      "         [1.0220],\n",
      "         [1.0293],\n",
      "         [1.0332],\n",
      "         [1.0364],\n",
      "         [1.0360],\n",
      "         [1.0325],\n",
      "         [1.0258],\n",
      "         [0.6973],\n",
      "         [1.0118],\n",
      "         [0.4938],\n",
      "         [0.5457],\n",
      "         [0.8110],\n",
      "         [1.0142],\n",
      "         [0.5572],\n",
      "         [0.5772],\n",
      "         [1.0363],\n",
      "         [1.0252],\n",
      "         [0.9691],\n",
      "         [1.0242],\n",
      "         [0.9972],\n",
      "         [0.9166],\n",
      "         [0.9944],\n",
      "         [0.9886],\n",
      "         [0.0709],\n",
      "         [0.9897],\n",
      "         [0.9626],\n",
      "         [1.0050],\n",
      "         [0.9378],\n",
      "         [0.0800],\n",
      "         [0.8808],\n",
      "         [1.0170],\n",
      "         [0.4060],\n",
      "         [1.0063],\n",
      "         [1.0033],\n",
      "         [0.7033],\n",
      "         [1.0064],\n",
      "         [1.0102],\n",
      "         [1.0155],\n",
      "         [1.0185],\n",
      "         [1.0230],\n",
      "         [0.5592],\n",
      "         [1.0193],\n",
      "         [0.8434],\n",
      "         [1.0046],\n",
      "         [0.9970],\n",
      "         [0.9621],\n",
      "         [0.9965],\n",
      "         [1.0019],\n",
      "         [0.8023],\n",
      "         [0.5062],\n",
      "         [0.5321],\n",
      "         [1.0323],\n",
      "         [1.0445],\n",
      "         [0.9906],\n",
      "         [1.0270],\n",
      "         [0.5263],\n",
      "         [1.0157],\n",
      "         [1.0075],\n",
      "         [1.0011],\n",
      "         [0.2861],\n",
      "         [0.5416],\n",
      "         [0.4240],\n",
      "         [1.0227],\n",
      "         [1.0303],\n",
      "         [1.0359],\n",
      "         [1.0371],\n",
      "         [1.0366],\n",
      "         [0.4327],\n",
      "         [1.0257],\n",
      "         [0.4301],\n",
      "         [1.0161],\n",
      "         [1.0141],\n",
      "         [1.0147],\n",
      "         [1.0160],\n",
      "         [0.7628],\n",
      "         [1.0185],\n",
      "         [1.0174]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9044],\n",
      "        [0.9997],\n",
      "        [0.4454],\n",
      "        [0.4611],\n",
      "        [0.0209],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [0.0335],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.6628],\n",
      "        [0.2729],\n",
      "        [0.9490],\n",
      "        [0.3930],\n",
      "        [0.4642],\n",
      "        [0.9967],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.9420],\n",
      "        [0.9997],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [0.3575],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.5151],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.5463],\n",
      "        [0.3780],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.5030],\n",
      "        [0.9997],\n",
      "        [0.3808],\n",
      "        [0.1762],\n",
      "        [0.4480],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.2547],\n",
      "        [0.5334],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.0142],\n",
      "        [0.3573],\n",
      "        [0.9997],\n",
      "        [0.5245],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.5139],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.5054],\n",
      "        [0.9997],\n",
      "        [0.9814],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.8761],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.9997],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.0247],\n",
      "        [0.8139],\n",
      "        [0.9999],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [0.9515],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.4503],\n",
      "        [0.4580],\n",
      "        [0.9819],\n",
      "        [0.9995],\n",
      "        [0.9164],\n",
      "        [0.9820],\n",
      "        [0.4552],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.2610],\n",
      "        [0.5038],\n",
      "        [0.3875],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000]])\n",
      "######### Epoch: 12  ######### Train Loss: 0.0011462982511147857  ######### Relative L2 Test Norm: 12.827704429626465\n",
      "Output batch pred: tensor([[[0.2596],\n",
      "         [0.4496],\n",
      "         [0.9962],\n",
      "         [0.3580],\n",
      "         [0.3282],\n",
      "         [0.9889],\n",
      "         [0.9936],\n",
      "         [1.0004],\n",
      "         [0.2482],\n",
      "         [0.4668],\n",
      "         [1.0244],\n",
      "         [1.0265],\n",
      "         [0.5655],\n",
      "         [1.0275],\n",
      "         [0.0895],\n",
      "         [0.8479],\n",
      "         [1.0182],\n",
      "         [0.0655],\n",
      "         [1.0147],\n",
      "         [1.0194],\n",
      "         [0.4009],\n",
      "         [1.0308],\n",
      "         [0.5123],\n",
      "         [1.0426],\n",
      "         [1.0502],\n",
      "         [0.5969],\n",
      "         [1.0551],\n",
      "         [1.0547],\n",
      "         [1.0534],\n",
      "         [0.7549],\n",
      "         [1.0445],\n",
      "         [1.0383],\n",
      "         [0.4935],\n",
      "         [1.0328],\n",
      "         [1.0332],\n",
      "         [1.0353],\n",
      "         [0.2469],\n",
      "         [1.0475],\n",
      "         [1.0451],\n",
      "         [1.0632],\n",
      "         [1.0702],\n",
      "         [1.0752],\n",
      "         [1.0770],\n",
      "         [0.9622],\n",
      "         [1.0678],\n",
      "         [1.0583],\n",
      "         [0.9136],\n",
      "         [1.0342],\n",
      "         [0.5770],\n",
      "         [0.9844],\n",
      "         [0.2731],\n",
      "         [0.9641],\n",
      "         [1.0349],\n",
      "         [0.5117],\n",
      "         [1.0575],\n",
      "         [0.5610],\n",
      "         [1.0723],\n",
      "         [1.0710],\n",
      "         [1.0666],\n",
      "         [1.0565],\n",
      "         [0.3125],\n",
      "         [1.0334],\n",
      "         [0.0458],\n",
      "         [0.5428],\n",
      "         [1.0277],\n",
      "         [0.7767],\n",
      "         [0.9211],\n",
      "         [1.0569],\n",
      "         [1.0635],\n",
      "         [0.5986],\n",
      "         [1.0574],\n",
      "         [1.0475],\n",
      "         [0.4196],\n",
      "         [1.0088],\n",
      "         [0.0363],\n",
      "         [0.9756],\n",
      "         [0.3330],\n",
      "         [0.4374],\n",
      "         [0.4950],\n",
      "         [1.0119],\n",
      "         [0.2973],\n",
      "         [1.0545],\n",
      "         [1.0687],\n",
      "         [1.0756],\n",
      "         [1.0748],\n",
      "         [1.0522],\n",
      "         [1.0557],\n",
      "         [1.0420],\n",
      "         [1.0277],\n",
      "         [0.4071],\n",
      "         [0.1781],\n",
      "         [1.0145],\n",
      "         [0.6873],\n",
      "         [1.0329],\n",
      "         [1.0436],\n",
      "         [1.0557],\n",
      "         [1.0636],\n",
      "         [0.6557],\n",
      "         [1.0533],\n",
      "         [1.0594],\n",
      "         [0.5767],\n",
      "         [1.0413],\n",
      "         [0.3003],\n",
      "         [0.4186],\n",
      "         [1.0275],\n",
      "         [0.9949],\n",
      "         [0.5644],\n",
      "         [0.0771],\n",
      "         [0.7479],\n",
      "         [1.0371],\n",
      "         [0.4398],\n",
      "         [1.0380],\n",
      "         [0.5080],\n",
      "         [0.5625],\n",
      "         [1.0310],\n",
      "         [0.9605],\n",
      "         [0.0755],\n",
      "         [0.5088],\n",
      "         [0.8929],\n",
      "         [1.0346],\n",
      "         [1.0270],\n",
      "         [1.0410],\n",
      "         [1.0420],\n",
      "         [1.0433],\n",
      "         [0.8323],\n",
      "         [0.5166],\n",
      "         [0.3978],\n",
      "         [1.0362],\n",
      "         [1.0335],\n",
      "         [0.0699],\n",
      "         [1.0282],\n",
      "         [0.7881],\n",
      "         [1.0234],\n",
      "         [1.0233],\n",
      "         [0.6545],\n",
      "         [0.0581],\n",
      "         [1.0186],\n",
      "         [1.0164],\n",
      "         [1.0121],\n",
      "         [0.2504],\n",
      "         [0.9727],\n",
      "         [1.0132],\n",
      "         [1.0135],\n",
      "         [0.0544],\n",
      "         [1.0177],\n",
      "         [0.9905],\n",
      "         [0.2807],\n",
      "         [1.0375],\n",
      "         [0.9607],\n",
      "         [0.6176],\n",
      "         [1.0554],\n",
      "         [1.0614],\n",
      "         [0.8749],\n",
      "         [1.0659],\n",
      "         [1.0647],\n",
      "         [0.4560],\n",
      "         [0.6137],\n",
      "         [1.0599],\n",
      "         [1.0616],\n",
      "         [1.0647],\n",
      "         [1.0695],\n",
      "         [1.0741],\n",
      "         [1.0807],\n",
      "         [1.0856],\n",
      "         [1.0862],\n",
      "         [1.0266],\n",
      "         [1.0744],\n",
      "         [1.0792],\n",
      "         [1.0697],\n",
      "         [1.0642],\n",
      "         [0.5942],\n",
      "         [1.0487],\n",
      "         [0.4310],\n",
      "         [1.0425],\n",
      "         [1.0390],\n",
      "         [1.0364],\n",
      "         [0.9598],\n",
      "         [1.0293]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2577],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.4503],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.5165],\n",
      "        [0.9996],\n",
      "        [0.0383],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.9997],\n",
      "        [0.4552],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9998],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.9490],\n",
      "        [0.2729],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.9994],\n",
      "        [0.0000],\n",
      "        [0.5038],\n",
      "        [0.9999],\n",
      "        [0.6920],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.4668],\n",
      "        [0.5030],\n",
      "        [0.9997],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.3840],\n",
      "        [0.9999],\n",
      "        [0.9515],\n",
      "        [0.5139],\n",
      "        [0.0209],\n",
      "        [0.6628],\n",
      "        [0.9994],\n",
      "        [0.3912],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.9044],\n",
      "        [0.0288],\n",
      "        [0.4645],\n",
      "        [0.8139],\n",
      "        [0.9995],\n",
      "        [0.9814],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.4611],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.9995],\n",
      "        [0.9996],\n",
      "        [0.5945],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [0.2518],\n",
      "        [0.9420],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.2547],\n",
      "        [0.9999],\n",
      "        [0.8761],\n",
      "        [0.5245],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.3780],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [0.9009],\n",
      "        [0.9820],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [1.0000]])\n",
      "######### Epoch: 13  ######### Train Loss: 0.0030587040819227695  ######### Relative L2 Test Norm: 13.042001724243164\n",
      "Output batch pred: tensor([[[1.0251],\n",
      "         [0.7368],\n",
      "         [1.0466],\n",
      "         [1.0566],\n",
      "         [1.0618],\n",
      "         [1.0649],\n",
      "         [1.0625],\n",
      "         [0.9888],\n",
      "         [1.0466],\n",
      "         [0.4937],\n",
      "         [1.0298],\n",
      "         [0.0499],\n",
      "         [1.0276],\n",
      "         [0.8871],\n",
      "         [1.0373],\n",
      "         [0.9214],\n",
      "         [1.0500],\n",
      "         [0.6020],\n",
      "         [0.5752],\n",
      "         [1.0541],\n",
      "         [1.0530],\n",
      "         [1.0517],\n",
      "         [0.2944],\n",
      "         [1.0486],\n",
      "         [0.6151],\n",
      "         [1.0514],\n",
      "         [1.0528],\n",
      "         [0.0762],\n",
      "         [0.9298],\n",
      "         [1.0532],\n",
      "         [1.0542],\n",
      "         [1.0548],\n",
      "         [1.0556],\n",
      "         [0.0881],\n",
      "         [1.0660],\n",
      "         [1.0725],\n",
      "         [1.0673],\n",
      "         [1.0792],\n",
      "         [1.0818],\n",
      "         [1.0676],\n",
      "         [1.0691],\n",
      "         [1.0592],\n",
      "         [0.3863],\n",
      "         [0.8582],\n",
      "         [1.0251],\n",
      "         [0.4618],\n",
      "         [1.0244],\n",
      "         [1.0319],\n",
      "         [1.0468],\n",
      "         [1.0596],\n",
      "         [1.0739],\n",
      "         [1.0712],\n",
      "         [1.0865],\n",
      "         [1.0879],\n",
      "         [1.0826],\n",
      "         [1.0714],\n",
      "         [1.0602],\n",
      "         [0.5633],\n",
      "         [1.0421],\n",
      "         [0.9604],\n",
      "         [0.5009],\n",
      "         [1.0398],\n",
      "         [0.2360],\n",
      "         [1.0517],\n",
      "         [1.0572],\n",
      "         [1.0617],\n",
      "         [1.0625],\n",
      "         [0.0760],\n",
      "         [1.0625],\n",
      "         [0.5272],\n",
      "         [1.0676],\n",
      "         [1.0711],\n",
      "         [1.0749],\n",
      "         [1.0791],\n",
      "         [1.0839],\n",
      "         [1.0868],\n",
      "         [1.0903],\n",
      "         [1.0902],\n",
      "         [1.0871],\n",
      "         [0.9607],\n",
      "         [0.6250],\n",
      "         [1.0810],\n",
      "         [1.0792],\n",
      "         [0.3460],\n",
      "         [1.0761],\n",
      "         [1.0748],\n",
      "         [1.0668],\n",
      "         [0.4330],\n",
      "         [1.0558],\n",
      "         [0.6674],\n",
      "         [0.4137],\n",
      "         [0.9679],\n",
      "         [0.4659],\n",
      "         [0.3868],\n",
      "         [1.0337],\n",
      "         [1.0428],\n",
      "         [1.0525],\n",
      "         [1.0414],\n",
      "         [1.0646],\n",
      "         [1.0622],\n",
      "         [0.5237],\n",
      "         [0.2027],\n",
      "         [1.0371],\n",
      "         [0.0427],\n",
      "         [0.0423],\n",
      "         [1.0134],\n",
      "         [1.0170],\n",
      "         [1.0274],\n",
      "         [1.0389],\n",
      "         [0.2827],\n",
      "         [0.5147],\n",
      "         [1.0665],\n",
      "         [0.0898],\n",
      "         [1.0551],\n",
      "         [0.5663],\n",
      "         [0.9861],\n",
      "         [1.0114],\n",
      "         [0.4523],\n",
      "         [0.0332],\n",
      "         [0.3547],\n",
      "         [0.4727],\n",
      "         [0.9914],\n",
      "         [0.7346],\n",
      "         [0.3113],\n",
      "         [1.0646],\n",
      "         [1.0731],\n",
      "         [0.4709],\n",
      "         [1.0677],\n",
      "         [1.0599],\n",
      "         [1.0488],\n",
      "         [1.0417],\n",
      "         [0.5407],\n",
      "         [0.2583],\n",
      "         [0.5429],\n",
      "         [0.4008],\n",
      "         [1.0386],\n",
      "         [1.0584],\n",
      "         [1.0649],\n",
      "         [1.0691],\n",
      "         [1.0714],\n",
      "         [1.0755],\n",
      "         [1.0762],\n",
      "         [1.0442],\n",
      "         [1.0431],\n",
      "         [0.9856],\n",
      "         [1.0660],\n",
      "         [0.2941],\n",
      "         [0.5189],\n",
      "         [1.0451],\n",
      "         [1.0406],\n",
      "         [0.8264],\n",
      "         [0.5872],\n",
      "         [0.2785],\n",
      "         [0.9651],\n",
      "         [0.4173],\n",
      "         [0.5754],\n",
      "         [1.0525],\n",
      "         [0.4070],\n",
      "         [0.4338],\n",
      "         [1.0535],\n",
      "         [1.0461],\n",
      "         [0.4056],\n",
      "         [1.0303],\n",
      "         [0.2571],\n",
      "         [0.7524],\n",
      "         [0.6890],\n",
      "         [0.5511],\n",
      "         [0.5621],\n",
      "         [0.8221],\n",
      "         [1.0696],\n",
      "         [1.0750],\n",
      "         [1.0730],\n",
      "         [0.6077],\n",
      "         [1.0587],\n",
      "         [0.8292],\n",
      "         [1.0323],\n",
      "         [1.0217],\n",
      "         [0.0187]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.6628],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [0.9996],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.9997],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9997],\n",
      "        [0.5245],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.0368],\n",
      "        [0.8296],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9820],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.3573],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0142],\n",
      "        [0.9967],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.8223],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.3753],\n",
      "        [0.9997],\n",
      "        [0.5945],\n",
      "        [0.3930],\n",
      "        [0.9164],\n",
      "        [0.4503],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.0247],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2547],\n",
      "        [0.4480],\n",
      "        [0.9999],\n",
      "        [0.0335],\n",
      "        [0.9997],\n",
      "        [0.5139],\n",
      "        [0.9420],\n",
      "        [0.9999],\n",
      "        [0.4611],\n",
      "        [0.0209],\n",
      "        [0.3728],\n",
      "        [0.4668],\n",
      "        [0.9490],\n",
      "        [0.6555],\n",
      "        [0.2686],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.2518],\n",
      "        [0.5030],\n",
      "        [0.3747],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9520],\n",
      "        [0.9515],\n",
      "        [0.8761],\n",
      "        [0.9997],\n",
      "        [0.2646],\n",
      "        [0.4645],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.5463],\n",
      "        [0.2729],\n",
      "        [0.9044],\n",
      "        [0.3875],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.6920],\n",
      "        [0.6327],\n",
      "        [0.5080],\n",
      "        [0.5038],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.0000]])\n",
      "######### Epoch: 14  ######### Train Loss: 0.0037140846252441406  ######### Relative L2 Test Norm: 14.390786170959473\n",
      "Output batch pred: tensor([[[0.2445],\n",
      "         [1.0381],\n",
      "         [1.0510],\n",
      "         [1.0620],\n",
      "         [1.0697],\n",
      "         [1.0639],\n",
      "         [1.0752],\n",
      "         [0.7898],\n",
      "         [1.0662],\n",
      "         [1.0216],\n",
      "         [0.4288],\n",
      "         [0.9714],\n",
      "         [1.0377],\n",
      "         [0.0214],\n",
      "         [0.8096],\n",
      "         [1.0372],\n",
      "         [0.5435],\n",
      "         [1.0460],\n",
      "         [0.4018],\n",
      "         [1.0583],\n",
      "         [1.0601],\n",
      "         [1.0636],\n",
      "         [0.5738],\n",
      "         [1.0626],\n",
      "         [1.0638],\n",
      "         [1.0627],\n",
      "         [1.0618],\n",
      "         [1.0610],\n",
      "         [1.0622],\n",
      "         [1.0619],\n",
      "         [1.0629],\n",
      "         [1.0628],\n",
      "         [0.3051],\n",
      "         [1.0576],\n",
      "         [0.9194],\n",
      "         [1.0492],\n",
      "         [0.9661],\n",
      "         [0.0446],\n",
      "         [0.4822],\n",
      "         [0.0145],\n",
      "         [1.0210],\n",
      "         [0.9494],\n",
      "         [0.0148],\n",
      "         [1.0265],\n",
      "         [1.0316],\n",
      "         [0.8640],\n",
      "         [0.2212],\n",
      "         [1.0545],\n",
      "         [1.0589],\n",
      "         [1.0653],\n",
      "         [1.0660],\n",
      "         [1.0718],\n",
      "         [1.0724],\n",
      "         [1.0390],\n",
      "         [1.0693],\n",
      "         [0.5137],\n",
      "         [0.8205],\n",
      "         [0.4295],\n",
      "         [1.0528],\n",
      "         [1.0482],\n",
      "         [0.2895],\n",
      "         [0.7338],\n",
      "         [1.0506],\n",
      "         [0.1923],\n",
      "         [1.0545],\n",
      "         [1.0581],\n",
      "         [0.5077],\n",
      "         [0.7977],\n",
      "         [1.0455],\n",
      "         [1.0534],\n",
      "         [1.0474],\n",
      "         [0.6564],\n",
      "         [1.0358],\n",
      "         [1.0312],\n",
      "         [0.2341],\n",
      "         [1.0176],\n",
      "         [0.4603],\n",
      "         [1.0396],\n",
      "         [0.9129],\n",
      "         [1.0501],\n",
      "         [0.5807],\n",
      "         [1.0566],\n",
      "         [0.4009],\n",
      "         [0.5724],\n",
      "         [1.0470],\n",
      "         [0.4955],\n",
      "         [1.0357],\n",
      "         [0.0427],\n",
      "         [1.0272],\n",
      "         [0.4640],\n",
      "         [0.4628],\n",
      "         [1.0324],\n",
      "         [1.0370],\n",
      "         [0.3918],\n",
      "         [1.0464],\n",
      "         [0.4141],\n",
      "         [0.4097],\n",
      "         [1.0482],\n",
      "         [0.4924],\n",
      "         [1.0446],\n",
      "         [0.5426],\n",
      "         [0.8301],\n",
      "         [0.8901],\n",
      "         [1.0367],\n",
      "         [1.0384],\n",
      "         [0.0617],\n",
      "         [0.5521],\n",
      "         [0.4098],\n",
      "         [0.5751],\n",
      "         [1.0528],\n",
      "         [1.0542],\n",
      "         [1.0554],\n",
      "         [1.0523],\n",
      "         [1.0522],\n",
      "         [1.0515],\n",
      "         [0.2602],\n",
      "         [0.5526],\n",
      "         [0.4178],\n",
      "         [1.0485],\n",
      "         [1.0494],\n",
      "         [1.0522],\n",
      "         [1.0565],\n",
      "         [1.0601],\n",
      "         [1.0666],\n",
      "         [0.6276],\n",
      "         [1.0572],\n",
      "         [0.9597],\n",
      "         [1.0734],\n",
      "         [1.0676],\n",
      "         [1.0596],\n",
      "         [1.0475],\n",
      "         [1.0344],\n",
      "         [1.0180],\n",
      "         [0.5098],\n",
      "         [0.2141],\n",
      "         [0.3139],\n",
      "         [0.5340],\n",
      "         [0.0262],\n",
      "         [0.4698],\n",
      "         [1.0333],\n",
      "         [0.9604],\n",
      "         [1.0282],\n",
      "         [1.0684],\n",
      "         [1.0737],\n",
      "         [0.0730],\n",
      "         [1.0745],\n",
      "         [1.0705],\n",
      "         [1.0649],\n",
      "         [1.0618],\n",
      "         [0.2929],\n",
      "         [1.0253],\n",
      "         [1.0573],\n",
      "         [1.0572],\n",
      "         [1.0600],\n",
      "         [1.0603],\n",
      "         [0.7272],\n",
      "         [1.0544],\n",
      "         [1.0489],\n",
      "         [0.5039],\n",
      "         [0.5822],\n",
      "         [0.0297],\n",
      "         [1.0280],\n",
      "         [1.0295],\n",
      "         [1.0324],\n",
      "         [0.4118],\n",
      "         [1.0568],\n",
      "         [1.0650],\n",
      "         [1.0726],\n",
      "         [1.0768],\n",
      "         [1.0682],\n",
      "         [1.0730],\n",
      "         [1.0102],\n",
      "         [1.0512],\n",
      "         [0.2553],\n",
      "         [1.0250],\n",
      "         [0.5053],\n",
      "         [1.0090],\n",
      "         [1.0081]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2686],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.3912],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9997],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.9999],\n",
      "        [0.8933],\n",
      "        [0.0335],\n",
      "        [0.4645],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.0247],\n",
      "        [0.9999],\n",
      "        [0.9967],\n",
      "        [0.7820],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.7129],\n",
      "        [0.3875],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [0.2735],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.6920],\n",
      "        [0.9820],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.9997],\n",
      "        [0.9995],\n",
      "        [0.2518],\n",
      "        [0.9814],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9997],\n",
      "        [0.3575],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.9999],\n",
      "        [0.4580],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3747],\n",
      "        [0.9997],\n",
      "        [0.3840],\n",
      "        [0.3780],\n",
      "        [0.9995],\n",
      "        [0.4503],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [0.7540],\n",
      "        [0.8139],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0288],\n",
      "        [0.5030],\n",
      "        [0.3753],\n",
      "        [0.5139],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.5038],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.9724],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.5151],\n",
      "        [0.2577],\n",
      "        [0.3573],\n",
      "        [0.5463],\n",
      "        [0.0383],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.9520],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.5334],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.9996],\n",
      "        [0.9164],\n",
      "        [0.9962],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [1.0000]])\n",
      "######### Epoch: 15  ######### Train Loss: 0.003137006890028715  ######### Relative L2 Test Norm: 15.042296409606934\n",
      "Output batch pred: tensor([[[ 1.0220],\n",
      "         [ 0.8962],\n",
      "         [ 1.0219],\n",
      "         [ 1.0416],\n",
      "         [ 1.0468],\n",
      "         [ 1.0491],\n",
      "         [ 1.0474],\n",
      "         [ 1.0461],\n",
      "         [ 1.0408],\n",
      "         [ 1.0344],\n",
      "         [ 1.0229],\n",
      "         [ 0.5126],\n",
      "         [ 0.1880],\n",
      "         [ 0.6873],\n",
      "         [ 0.7837],\n",
      "         [ 0.9796],\n",
      "         [ 0.0051],\n",
      "         [ 1.0184],\n",
      "         [ 0.0241],\n",
      "         [ 0.9502],\n",
      "         [ 1.0252],\n",
      "         [ 0.5198],\n",
      "         [ 0.3846],\n",
      "         [ 1.0347],\n",
      "         [ 1.0410],\n",
      "         [ 0.7824],\n",
      "         [ 1.0163],\n",
      "         [ 1.0503],\n",
      "         [ 1.0516],\n",
      "         [ 1.0487],\n",
      "         [ 0.5692],\n",
      "         [ 1.0395],\n",
      "         [ 0.7871],\n",
      "         [ 0.5252],\n",
      "         [ 1.0253],\n",
      "         [ 0.3742],\n",
      "         [ 0.4638],\n",
      "         [ 1.0089],\n",
      "         [ 1.0316],\n",
      "         [ 1.0359],\n",
      "         [ 1.0388],\n",
      "         [ 1.0393],\n",
      "         [ 1.0409],\n",
      "         [ 0.0302],\n",
      "         [ 1.0369],\n",
      "         [ 1.0329],\n",
      "         [ 1.0270],\n",
      "         [ 1.0242],\n",
      "         [ 1.0209],\n",
      "         [ 0.8866],\n",
      "         [ 0.0247],\n",
      "         [ 0.2463],\n",
      "         [ 0.5235],\n",
      "         [ 1.0235],\n",
      "         [ 0.3576],\n",
      "         [ 1.0328],\n",
      "         [ 1.0364],\n",
      "         [ 1.0423],\n",
      "         [ 0.4926],\n",
      "         [ 1.0518],\n",
      "         [ 1.0561],\n",
      "         [ 1.0580],\n",
      "         [ 1.0600],\n",
      "         [ 0.9303],\n",
      "         [ 1.0603],\n",
      "         [ 1.0539],\n",
      "         [ 1.0501],\n",
      "         [ 0.3968],\n",
      "         [ 0.3633],\n",
      "         [ 1.0293],\n",
      "         [ 1.0253],\n",
      "         [ 0.2434],\n",
      "         [ 1.0156],\n",
      "         [ 0.0027],\n",
      "         [ 0.2272],\n",
      "         [ 1.0226],\n",
      "         [ 0.9932],\n",
      "         [ 1.0208],\n",
      "         [ 1.0379],\n",
      "         [ 0.9735],\n",
      "         [ 0.2689],\n",
      "         [ 1.0473],\n",
      "         [ 1.0509],\n",
      "         [ 1.0498],\n",
      "         [ 0.9720],\n",
      "         [ 0.8677],\n",
      "         [ 1.0357],\n",
      "         [ 0.2295],\n",
      "         [ 1.0199],\n",
      "         [ 0.6559],\n",
      "         [ 0.3345],\n",
      "         [ 0.3517],\n",
      "         [ 1.0027],\n",
      "         [-0.0153],\n",
      "         [ 1.0095],\n",
      "         [ 0.5396],\n",
      "         [ 0.6345],\n",
      "         [ 0.5194],\n",
      "         [ 1.0311],\n",
      "         [ 0.2491],\n",
      "         [ 1.0311],\n",
      "         [ 1.0308],\n",
      "         [ 1.0269],\n",
      "         [ 0.0288],\n",
      "         [ 1.0187],\n",
      "         [ 0.2477],\n",
      "         [ 1.0112],\n",
      "         [ 1.0148],\n",
      "         [ 0.1541],\n",
      "         [ 0.3612],\n",
      "         [ 1.0237],\n",
      "         [ 0.4797],\n",
      "         [ 0.8842],\n",
      "         [ 0.4010],\n",
      "         [ 1.0384],\n",
      "         [ 1.0404],\n",
      "         [ 1.0441],\n",
      "         [ 1.0496],\n",
      "         [ 1.0525],\n",
      "         [ 0.5168],\n",
      "         [ 0.7660],\n",
      "         [ 1.0544],\n",
      "         [ 1.0529],\n",
      "         [ 1.0510],\n",
      "         [ 1.0456],\n",
      "         [ 1.0430],\n",
      "         [ 1.0370],\n",
      "         [ 1.0369],\n",
      "         [ 1.0335],\n",
      "         [ 1.0334],\n",
      "         [ 0.9965],\n",
      "         [ 0.4864],\n",
      "         [ 1.0376],\n",
      "         [ 0.9805],\n",
      "         [ 0.4683],\n",
      "         [ 1.0350],\n",
      "         [ 1.0334],\n",
      "         [ 1.0177],\n",
      "         [ 0.4711],\n",
      "         [ 1.0228],\n",
      "         [ 0.2224],\n",
      "         [ 0.4395],\n",
      "         [ 1.0217],\n",
      "         [ 0.5113],\n",
      "         [ 0.5606],\n",
      "         [ 1.0130],\n",
      "         [ 1.0245],\n",
      "         [ 1.0230],\n",
      "         [ 0.9300],\n",
      "         [-0.0086],\n",
      "         [ 0.5161],\n",
      "         [ 0.4518],\n",
      "         [ 0.5283],\n",
      "         [ 1.0252],\n",
      "         [ 1.0304],\n",
      "         [ 1.0347],\n",
      "         [ 1.0373],\n",
      "         [ 0.5550],\n",
      "         [ 0.3882],\n",
      "         [ 0.5820],\n",
      "         [ 1.0250],\n",
      "         [ 0.4541],\n",
      "         [ 1.0112],\n",
      "         [ 0.3646],\n",
      "         [ 1.0102],\n",
      "         [ 0.0252],\n",
      "         [ 1.0225],\n",
      "         [ 1.0316],\n",
      "         [ 1.0417],\n",
      "         [ 1.0501],\n",
      "         [ 1.0542],\n",
      "         [ 1.0568],\n",
      "         [ 1.0545],\n",
      "         [ 0.8483],\n",
      "         [ 1.0423],\n",
      "         [ 1.0329],\n",
      "         [ 1.0269],\n",
      "         [ 1.0219]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9997],\n",
      "        [0.8296],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.5054],\n",
      "        [0.2208],\n",
      "        [0.6555],\n",
      "        [0.7391],\n",
      "        [0.9515],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.6920],\n",
      "        [0.9520],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.4580],\n",
      "        [0.9724],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.0288],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.8379],\n",
      "        [0.0383],\n",
      "        [0.2735],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.3575],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.8223],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.3573],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.8933],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.3753],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [0.5945],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [0.3728],\n",
      "        [0.9999],\n",
      "        [0.4642],\n",
      "        [0.8139],\n",
      "        [0.3912],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9420],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.4480],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.4645],\n",
      "        [0.9997],\n",
      "        [0.2547],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.5334],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.8761],\n",
      "        [0.0000],\n",
      "        [0.5080],\n",
      "        [0.4527],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.3780],\n",
      "        [0.5463],\n",
      "        [0.9997],\n",
      "        [0.4552],\n",
      "        [0.9997],\n",
      "        [0.3875],\n",
      "        [0.9997],\n",
      "        [0.0368],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998]])\n",
      "######### Epoch: 16  ######### Train Loss: 0.001559231779538095  ######### Relative L2 Test Norm: 15.79310131072998\n",
      "Output batch pred: tensor([[[ 0.9593],\n",
      "         [ 0.9977],\n",
      "         [ 0.7711],\n",
      "         [ 1.0035],\n",
      "         [ 0.4341],\n",
      "         [ 1.0061],\n",
      "         [ 1.0074],\n",
      "         [ 1.0081],\n",
      "         [ 0.0101],\n",
      "         [ 0.9344],\n",
      "         [ 1.0048],\n",
      "         [ 0.9713],\n",
      "         [ 0.4545],\n",
      "         [ 0.5535],\n",
      "         [ 1.0100],\n",
      "         [ 0.6936],\n",
      "         [ 1.0146],\n",
      "         [ 0.7159],\n",
      "         [ 1.0158],\n",
      "         [ 0.5191],\n",
      "         [ 1.0180],\n",
      "         [ 1.0191],\n",
      "         [ 0.8797],\n",
      "         [ 1.0163],\n",
      "         [ 1.0151],\n",
      "         [ 0.3756],\n",
      "         [ 1.0123],\n",
      "         [ 1.0167],\n",
      "         [ 1.0207],\n",
      "         [ 1.0243],\n",
      "         [ 1.0286],\n",
      "         [ 0.2509],\n",
      "         [ 0.9015],\n",
      "         [ 1.0276],\n",
      "         [ 1.0240],\n",
      "         [ 1.0171],\n",
      "         [ 0.4413],\n",
      "         [ 1.0005],\n",
      "         [ 0.9963],\n",
      "         [ 0.1555],\n",
      "         [ 0.9933],\n",
      "         [ 0.5131],\n",
      "         [-0.0131],\n",
      "         [ 1.0052],\n",
      "         [ 1.0103],\n",
      "         [ 1.0125],\n",
      "         [ 1.0132],\n",
      "         [ 1.0124],\n",
      "         [ 1.0090],\n",
      "         [ 0.4313],\n",
      "         [ 1.0007],\n",
      "         [ 0.9972],\n",
      "         [ 0.3357],\n",
      "         [ 1.0010],\n",
      "         [ 0.4859],\n",
      "         [ 0.5071],\n",
      "         [ 1.0117],\n",
      "         [ 1.0150],\n",
      "         [ 0.5197],\n",
      "         [ 1.0144],\n",
      "         [ 0.6626],\n",
      "         [ 1.0097],\n",
      "         [ 1.0062],\n",
      "         [ 0.8251],\n",
      "         [ 1.0088],\n",
      "         [ 0.2140],\n",
      "         [ 1.0152],\n",
      "         [ 1.0194],\n",
      "         [ 0.4687],\n",
      "         [ 1.0275],\n",
      "         [ 1.0258],\n",
      "         [ 1.0219],\n",
      "         [ 1.0167],\n",
      "         [ 0.8630],\n",
      "         [-0.0039],\n",
      "         [ 0.2085],\n",
      "         [ 0.9977],\n",
      "         [ 0.9977],\n",
      "         [ 1.0026],\n",
      "         [ 0.2328],\n",
      "         [ 1.0104],\n",
      "         [ 0.9386],\n",
      "         [ 1.0117],\n",
      "         [ 0.0083],\n",
      "         [ 0.2353],\n",
      "         [ 0.9377],\n",
      "         [ 0.5003],\n",
      "         [ 0.2083],\n",
      "         [ 0.4377],\n",
      "         [ 0.9077],\n",
      "         [ 1.0087],\n",
      "         [ 1.0165],\n",
      "         [ 1.0257],\n",
      "         [ 1.0303],\n",
      "         [ 0.8288],\n",
      "         [ 1.0309],\n",
      "         [ 1.0252],\n",
      "         [ 0.4635],\n",
      "         [ 0.1314],\n",
      "         [ 1.0052],\n",
      "         [ 1.0006],\n",
      "         [ 0.9983],\n",
      "         [ 1.0017],\n",
      "         [ 1.0055],\n",
      "         [ 0.3239],\n",
      "         [ 1.0125],\n",
      "         [ 0.9998],\n",
      "         [ 0.9716],\n",
      "         [-0.0214],\n",
      "         [ 0.9989],\n",
      "         [-0.0041],\n",
      "         [ 0.9831],\n",
      "         [ 0.3275],\n",
      "         [ 0.4512],\n",
      "         [ 0.9825],\n",
      "         [ 0.9767],\n",
      "         [ 0.9960],\n",
      "         [ 0.7267],\n",
      "         [ 0.9334],\n",
      "         [ 0.7651],\n",
      "         [ 0.2409],\n",
      "         [ 1.0163],\n",
      "         [ 0.6276],\n",
      "         [ 1.0130],\n",
      "         [ 0.3339],\n",
      "         [ 1.0117],\n",
      "         [ 1.0156],\n",
      "         [ 1.0192],\n",
      "         [ 0.4470],\n",
      "         [ 0.9923],\n",
      "         [ 1.0273],\n",
      "         [ 1.0264],\n",
      "         [ 0.5258],\n",
      "         [ 1.0211],\n",
      "         [ 0.4660],\n",
      "         [ 1.0113],\n",
      "         [ 1.0082],\n",
      "         [ 0.4325],\n",
      "         [ 1.0113],\n",
      "         [ 0.3548],\n",
      "         [ 1.0205],\n",
      "         [ 1.0252],\n",
      "         [ 1.0266],\n",
      "         [ 1.0263],\n",
      "         [ 1.0232],\n",
      "         [ 0.2246],\n",
      "         [ 0.3560],\n",
      "         [ 0.9781],\n",
      "         [-0.0130],\n",
      "         [ 0.9733],\n",
      "         [ 0.9881],\n",
      "         [-0.0026],\n",
      "         [ 0.4851],\n",
      "         [ 0.3508],\n",
      "         [ 1.0161],\n",
      "         [ 1.0191],\n",
      "         [ 1.0213],\n",
      "         [ 1.0082],\n",
      "         [ 1.0165],\n",
      "         [ 1.0079],\n",
      "         [ 1.0005],\n",
      "         [ 0.8583],\n",
      "         [-0.0260],\n",
      "         [ 0.4786],\n",
      "         [ 0.4624],\n",
      "         [ 0.9897],\n",
      "         [ 0.9946],\n",
      "         [ 0.9983],\n",
      "         [ 0.3402],\n",
      "         [ 1.0048],\n",
      "         [ 0.5446],\n",
      "         [ 1.0055],\n",
      "         [ 0.3555],\n",
      "         [ 1.0008],\n",
      "         [ 0.9919],\n",
      "         [ 0.3257],\n",
      "         [ 0.9903],\n",
      "         [ 0.9915]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9515],\n",
      "        [0.9997],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.9044],\n",
      "        [0.9967],\n",
      "        [0.9520],\n",
      "        [0.4668],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.9959],\n",
      "        [0.5054],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2646],\n",
      "        [0.8296],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.5108],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.8139],\n",
      "        [0.0142],\n",
      "        [0.2547],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.2729],\n",
      "        [0.9164],\n",
      "        [0.5165],\n",
      "        [0.2610],\n",
      "        [0.4645],\n",
      "        [0.8761],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.7540],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.1762],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.9420],\n",
      "        [0.0000],\n",
      "        [0.9998],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [0.3912],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.9999],\n",
      "        [0.6920],\n",
      "        [0.8933],\n",
      "        [0.7129],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.9997],\n",
      "        [0.3573],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.3840],\n",
      "        [0.9724],\n",
      "        [0.0174],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.5030],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.8379],\n",
      "        [0.0209],\n",
      "        [0.5151],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [0.3753],\n",
      "        [0.9998],\n",
      "        [0.9999]])\n",
      "######### Epoch: 17  ######### Train Loss: 0.0006447633495554328  ######### Relative L2 Test Norm: 17.535913467407227\n",
      "Output batch pred: tensor([[[ 0.8490],\n",
      "         [ 0.9118],\n",
      "         [ 0.9878],\n",
      "         [ 0.3303],\n",
      "         [ 0.4884],\n",
      "         [ 0.9985],\n",
      "         [ 1.0011],\n",
      "         [ 1.0039],\n",
      "         [ 1.0060],\n",
      "         [ 1.0032],\n",
      "         [ 0.9732],\n",
      "         [ 0.7027],\n",
      "         [ 1.0034],\n",
      "         [ 0.2149],\n",
      "         [ 0.9994],\n",
      "         [ 0.7257],\n",
      "         [ 0.9923],\n",
      "         [ 0.9939],\n",
      "         [ 0.9903],\n",
      "         [ 0.9902],\n",
      "         [ 0.9751],\n",
      "         [ 0.9827],\n",
      "         [ 0.9798],\n",
      "         [ 0.4108],\n",
      "         [ 0.4613],\n",
      "         [ 0.3177],\n",
      "         [ 0.1925],\n",
      "         [ 0.3068],\n",
      "         [ 0.9572],\n",
      "         [-0.0082],\n",
      "         [ 0.4548],\n",
      "         [ 0.6304],\n",
      "         [ 0.9855],\n",
      "         [ 0.9871],\n",
      "         [ 0.2156],\n",
      "         [ 0.3501],\n",
      "         [ 0.9943],\n",
      "         [ 0.5358],\n",
      "         [ 0.9874],\n",
      "         [ 0.9809],\n",
      "         [ 0.9822],\n",
      "         [ 0.9830],\n",
      "         [ 0.9651],\n",
      "         [ 0.8052],\n",
      "         [ 0.8382],\n",
      "         [ 0.9904],\n",
      "         [ 0.9895],\n",
      "         [ 0.9881],\n",
      "         [ 0.4054],\n",
      "         [ 0.9787],\n",
      "         [ 0.8930],\n",
      "         [ 0.4660],\n",
      "         [ 0.1673],\n",
      "         [ 0.9667],\n",
      "         [ 0.9681],\n",
      "         [ 0.9732],\n",
      "         [ 0.9759],\n",
      "         [ 0.9791],\n",
      "         [-0.0366],\n",
      "         [ 0.9832],\n",
      "         [ 0.9822],\n",
      "         [ 0.9789],\n",
      "         [ 0.9769],\n",
      "         [ 0.9601],\n",
      "         [ 0.9709],\n",
      "         [ 0.4062],\n",
      "         [ 0.9340],\n",
      "         [ 0.2845],\n",
      "         [ 0.8997],\n",
      "         [ 0.4927],\n",
      "         [ 0.9785],\n",
      "         [ 0.9817],\n",
      "         [ 0.9811],\n",
      "         [-0.0281],\n",
      "         [ 0.9784],\n",
      "         [ 0.9767],\n",
      "         [ 0.9761],\n",
      "         [ 0.9749],\n",
      "         [ 0.1793],\n",
      "         [ 0.9776],\n",
      "         [ 0.9829],\n",
      "         [ 0.9838],\n",
      "         [ 0.4161],\n",
      "         [ 0.9896],\n",
      "         [ 0.9906],\n",
      "         [ 0.9875],\n",
      "         [ 0.6009],\n",
      "         [ 0.4949],\n",
      "         [ 0.9928],\n",
      "         [ 0.9982],\n",
      "         [ 0.4568],\n",
      "         [ 1.0052],\n",
      "         [ 1.0097],\n",
      "         [ 1.0117],\n",
      "         [ 1.0142],\n",
      "         [ 1.0138],\n",
      "         [ 0.3728],\n",
      "         [ 1.0101],\n",
      "         [ 1.0095],\n",
      "         [ 1.0069],\n",
      "         [ 1.0073],\n",
      "         [ 1.0075],\n",
      "         [ 1.0075],\n",
      "         [ 0.9175],\n",
      "         [ 1.0058],\n",
      "         [ 1.0029],\n",
      "         [ 1.0009],\n",
      "         [ 0.9977],\n",
      "         [ 0.9929],\n",
      "         [ 0.9877],\n",
      "         [-0.0160],\n",
      "         [ 0.9776],\n",
      "         [ 0.3260],\n",
      "         [ 0.4610],\n",
      "         [ 0.4202],\n",
      "         [ 0.2213],\n",
      "         [ 0.9969],\n",
      "         [ 0.9948],\n",
      "         [ 1.0101],\n",
      "         [ 1.0100],\n",
      "         [ 0.0063],\n",
      "         [ 1.0042],\n",
      "         [ 0.9957],\n",
      "         [ 0.9910],\n",
      "         [ 0.7252],\n",
      "         [ 0.4143],\n",
      "         [ 0.9127],\n",
      "         [-0.0260],\n",
      "         [ 0.9772],\n",
      "         [ 0.9782],\n",
      "         [ 0.7566],\n",
      "         [-0.0319],\n",
      "         [ 0.9798],\n",
      "         [ 0.9798],\n",
      "         [ 0.2885],\n",
      "         [ 0.3223],\n",
      "         [ 0.9708],\n",
      "         [ 0.1647],\n",
      "         [ 0.2875],\n",
      "         [ 0.9266],\n",
      "         [ 0.9645],\n",
      "         [ 0.0844],\n",
      "         [ 0.3799],\n",
      "         [ 0.9650],\n",
      "         [ 0.9663],\n",
      "         [ 0.6299],\n",
      "         [ 0.9639],\n",
      "         [-0.0225],\n",
      "         [ 0.9622],\n",
      "         [ 0.9485],\n",
      "         [-0.0263],\n",
      "         [ 0.3868],\n",
      "         [ 0.7289],\n",
      "         [ 0.9688],\n",
      "         [ 0.9701],\n",
      "         [ 0.4562],\n",
      "         [ 0.1431],\n",
      "         [ 0.4600],\n",
      "         [ 0.4656],\n",
      "         [ 0.9818],\n",
      "         [ 0.9455],\n",
      "         [ 0.3268],\n",
      "         [ 0.8605],\n",
      "         [ 0.9966],\n",
      "         [ 1.0009],\n",
      "         [ 1.0004],\n",
      "         [ 0.9993],\n",
      "         [ 0.9977],\n",
      "         [ 0.9930],\n",
      "         [ 0.9882],\n",
      "         [ 0.1927],\n",
      "         [ 0.9778],\n",
      "         [ 0.3866],\n",
      "         [ 0.4689],\n",
      "         [ 0.9739],\n",
      "         [ 0.5039],\n",
      "         [ 0.8290],\n",
      "         [ 0.9789]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.8379],\n",
      "        [0.9044],\n",
      "        [0.9999],\n",
      "        [0.3747],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.6628],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.5165],\n",
      "        [0.3930],\n",
      "        [0.2735],\n",
      "        [0.3840],\n",
      "        [0.9999],\n",
      "        [0.0288],\n",
      "        [0.4988],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.2577],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.7820],\n",
      "        [0.8139],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.5139],\n",
      "        [0.2518],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.9996],\n",
      "        [0.4645],\n",
      "        [0.9490],\n",
      "        [0.3575],\n",
      "        [0.9009],\n",
      "        [0.5245],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.5945],\n",
      "        [0.5108],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.4668],\n",
      "        [0.9995],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.8761],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.5009],\n",
      "        [0.4580],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.9997],\n",
      "        [0.9995],\n",
      "        [0.0247],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.7129],\n",
      "        [0.4611],\n",
      "        [0.9164],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7540],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.3728],\n",
      "        [0.9520],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.9994],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [0.0174],\n",
      "        [0.4527],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.2208],\n",
      "        [0.5030],\n",
      "        [0.5038],\n",
      "        [0.9999],\n",
      "        [0.9420],\n",
      "        [0.3753],\n",
      "        [0.8296],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9999],\n",
      "        [0.4454],\n",
      "        [0.5151],\n",
      "        [0.9999],\n",
      "        [0.5463],\n",
      "        [0.8223],\n",
      "        [0.9998]])\n",
      "######### Epoch: 18  ######### Train Loss: 0.0011588691268116236  ######### Relative L2 Test Norm: 17.90843391418457\n",
      "Output batch pred: tensor([[[ 0.1575],\n",
      "         [-0.0026],\n",
      "         [ 0.3209],\n",
      "         [ 0.9680],\n",
      "         [ 0.9707],\n",
      "         [ 0.9718],\n",
      "         [ 0.9735],\n",
      "         [ 0.9741],\n",
      "         [-0.0249],\n",
      "         [-0.0060],\n",
      "         [ 0.9707],\n",
      "         [ 0.9668],\n",
      "         [ 0.9672],\n",
      "         [ 0.9676],\n",
      "         [ 0.9329],\n",
      "         [-0.0251],\n",
      "         [ 0.9606],\n",
      "         [ 0.9757],\n",
      "         [ 0.3957],\n",
      "         [ 0.9786],\n",
      "         [ 0.9790],\n",
      "         [ 0.9745],\n",
      "         [ 0.9741],\n",
      "         [-0.0459],\n",
      "         [ 0.7857],\n",
      "         [ 0.9659],\n",
      "         [ 0.9614],\n",
      "         [ 0.2828],\n",
      "         [ 0.8709],\n",
      "         [ 0.9685],\n",
      "         [ 0.9711],\n",
      "         [ 0.9739],\n",
      "         [ 0.9753],\n",
      "         [ 0.8351],\n",
      "         [ 0.2068],\n",
      "         [ 0.9678],\n",
      "         [ 0.3190],\n",
      "         [ 0.1769],\n",
      "         [ 0.9524],\n",
      "         [ 0.3841],\n",
      "         [ 0.9437],\n",
      "         [ 0.3784],\n",
      "         [ 0.9425],\n",
      "         [ 0.1591],\n",
      "         [ 0.4507],\n",
      "         [ 0.9616],\n",
      "         [ 0.3989],\n",
      "         [ 0.4679],\n",
      "         [ 0.9761],\n",
      "         [ 0.9754],\n",
      "         [ 0.9753],\n",
      "         [ 0.9716],\n",
      "         [ 0.9256],\n",
      "         [ 0.9607],\n",
      "         [ 0.4432],\n",
      "         [ 0.9534],\n",
      "         [ 0.4859],\n",
      "         [ 0.1759],\n",
      "         [ 0.6032],\n",
      "         [ 0.9634],\n",
      "         [ 0.4188],\n",
      "         [ 0.9734],\n",
      "         [ 0.9775],\n",
      "         [ 0.9620],\n",
      "         [ 0.4733],\n",
      "         [ 0.9801],\n",
      "         [ 0.9782],\n",
      "         [ 0.9751],\n",
      "         [ 0.9725],\n",
      "         [ 0.0961],\n",
      "         [ 0.4927],\n",
      "         [ 0.9674],\n",
      "         [ 0.9309],\n",
      "         [ 0.9649],\n",
      "         [ 0.9655],\n",
      "         [ 0.4691],\n",
      "         [-0.0416],\n",
      "         [ 0.9650],\n",
      "         [ 0.9488],\n",
      "         [ 0.9650],\n",
      "         [ 0.9642],\n",
      "         [ 0.9682],\n",
      "         [ 0.9686],\n",
      "         [ 0.9733],\n",
      "         [ 0.4778],\n",
      "         [ 0.9767],\n",
      "         [ 0.1906],\n",
      "         [ 0.4718],\n",
      "         [ 0.9762],\n",
      "         [ 0.9619],\n",
      "         [ 0.2008],\n",
      "         [ 0.4042],\n",
      "         [ 0.9698],\n",
      "         [ 0.9697],\n",
      "         [ 0.9697],\n",
      "         [ 0.9718],\n",
      "         [ 0.9738],\n",
      "         [ 0.9766],\n",
      "         [ 0.9770],\n",
      "         [ 0.9782],\n",
      "         [ 0.9731],\n",
      "         [ 0.9754],\n",
      "         [ 0.9713],\n",
      "         [ 0.9692],\n",
      "         [ 0.8910],\n",
      "         [ 0.5659],\n",
      "         [ 0.9021],\n",
      "         [ 0.1837],\n",
      "         [ 0.9688],\n",
      "         [ 0.9702],\n",
      "         [ 0.9708],\n",
      "         [ 0.3286],\n",
      "         [ 0.9756],\n",
      "         [ 0.7198],\n",
      "         [ 0.6653],\n",
      "         [ 0.5124],\n",
      "         [ 0.9388],\n",
      "         [-0.0091],\n",
      "         [ 0.9037],\n",
      "         [ 0.9770],\n",
      "         [ 0.9787],\n",
      "         [ 0.9791],\n",
      "         [ 0.7687],\n",
      "         [ 0.9797],\n",
      "         [-0.0271],\n",
      "         [ 0.3260],\n",
      "         [ 0.9636],\n",
      "         [ 0.8772],\n",
      "         [ 0.2816],\n",
      "         [ 0.9496],\n",
      "         [ 0.2993],\n",
      "         [ 0.3013],\n",
      "         [ 0.2005],\n",
      "         [ 0.9593],\n",
      "         [ 0.4654],\n",
      "         [ 0.3411],\n",
      "         [ 0.9715],\n",
      "         [ 0.9723],\n",
      "         [ 0.9692],\n",
      "         [ 0.3973],\n",
      "         [ 0.7285],\n",
      "         [ 0.3032],\n",
      "         [ 0.9551],\n",
      "         [ 0.7976],\n",
      "         [ 0.9545],\n",
      "         [ 0.3765],\n",
      "         [-0.0381],\n",
      "         [ 0.9574],\n",
      "         [ 0.9603],\n",
      "         [ 0.9593],\n",
      "         [ 0.3796],\n",
      "         [ 0.9552],\n",
      "         [ 0.9519],\n",
      "         [ 0.9513],\n",
      "         [ 0.6651],\n",
      "         [ 0.9501],\n",
      "         [ 0.4345],\n",
      "         [ 0.2963],\n",
      "         [ 0.9549],\n",
      "         [ 0.9715],\n",
      "         [ 0.9754],\n",
      "         [ 0.9763],\n",
      "         [ 0.9752],\n",
      "         [ 0.9727],\n",
      "         [ 0.4708],\n",
      "         [ 0.9683],\n",
      "         [ 0.3973],\n",
      "         [ 0.9655],\n",
      "         [ 0.9646],\n",
      "         [ 0.8356],\n",
      "         [ 0.9705],\n",
      "         [ 0.9737],\n",
      "         [ 0.8449],\n",
      "         [ 0.6619],\n",
      "         [ 0.9841],\n",
      "         [ 0.9836],\n",
      "         [ 0.9815],\n",
      "         [ 0.9741]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2208],\n",
      "        [0.0335],\n",
      "        [0.3840],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9515],\n",
      "        [0.0209],\n",
      "        [0.9804],\n",
      "        [0.9995],\n",
      "        [0.4454],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [0.2646],\n",
      "        [0.9998],\n",
      "        [0.3808],\n",
      "        [0.2547],\n",
      "        [0.9998],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.9999],\n",
      "        [0.2577],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.5030],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9994],\n",
      "        [0.5463],\n",
      "        [0.2686],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9724],\n",
      "        [0.5009],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.5151],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.5038],\n",
      "        [0.9999],\n",
      "        [0.9819],\n",
      "        [0.2729],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9044],\n",
      "        [0.5945],\n",
      "        [0.9164],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9997],\n",
      "        [0.7129],\n",
      "        [0.6628],\n",
      "        [0.5334],\n",
      "        [0.9520],\n",
      "        [0.0368],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.3875],\n",
      "        [0.9999],\n",
      "        [0.8933],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.3753],\n",
      "        [0.2735],\n",
      "        [0.9956],\n",
      "        [0.5054],\n",
      "        [0.3930],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.7391],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.9997],\n",
      "        [0.4480],\n",
      "        [0.0247],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.3728],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8296],\n",
      "        [0.6555],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9962]])\n",
      "######### Epoch: 19  ######### Train Loss: 0.0017350227572023869  ######### Relative L2 Test Norm: 17.419876098632812\n",
      "Output batch pred: tensor([[[ 0.7139],\n",
      "         [ 0.9628],\n",
      "         [ 0.9627],\n",
      "         [ 0.8830],\n",
      "         [ 0.9565],\n",
      "         [ 0.9554],\n",
      "         [ 0.4700],\n",
      "         [ 0.9575],\n",
      "         [ 0.9581],\n",
      "         [ 0.9631],\n",
      "         [ 0.8344],\n",
      "         [ 0.9315],\n",
      "         [ 0.9640],\n",
      "         [ 0.9644],\n",
      "         [ 0.9618],\n",
      "         [ 0.3148],\n",
      "         [ 0.9471],\n",
      "         [-0.0227],\n",
      "         [ 0.4382],\n",
      "         [ 0.8656],\n",
      "         [ 0.3787],\n",
      "         [ 0.9555],\n",
      "         [ 0.9600],\n",
      "         [ 0.9690],\n",
      "         [ 0.9751],\n",
      "         [ 0.9660],\n",
      "         [ 0.9765],\n",
      "         [ 0.9761],\n",
      "         [ 0.9117],\n",
      "         [ 0.9641],\n",
      "         [ 0.9552],\n",
      "         [ 0.9504],\n",
      "         [ 0.2876],\n",
      "         [ 0.9467],\n",
      "         [ 0.9485],\n",
      "         [ 0.1910],\n",
      "         [ 0.9624],\n",
      "         [ 0.7892],\n",
      "         [ 0.9697],\n",
      "         [ 0.9545],\n",
      "         [ 0.4076],\n",
      "         [ 0.9663],\n",
      "         [ 0.2054],\n",
      "         [ 0.7348],\n",
      "         [ 0.9507],\n",
      "         [ 0.9494],\n",
      "         [ 0.3940],\n",
      "         [ 0.2974],\n",
      "         [ 0.3162],\n",
      "         [ 0.8279],\n",
      "         [ 0.9754],\n",
      "         [ 0.9807],\n",
      "         [-0.0027],\n",
      "         [ 0.7626],\n",
      "         [ 0.6413],\n",
      "         [ 0.9733],\n",
      "         [ 0.4788],\n",
      "         [ 0.9439],\n",
      "         [ 0.4023],\n",
      "         [ 0.9493],\n",
      "         [ 0.9463],\n",
      "         [ 0.9457],\n",
      "         [ 0.9471],\n",
      "         [ 0.6687],\n",
      "         [ 0.9489],\n",
      "         [ 0.4581],\n",
      "         [ 0.3283],\n",
      "         [ 0.4158],\n",
      "         [ 0.0340],\n",
      "         [ 0.1783],\n",
      "         [ 0.8900],\n",
      "         [ 0.0101],\n",
      "         [ 0.9731],\n",
      "         [ 0.3137],\n",
      "         [ 0.9738],\n",
      "         [ 0.9722],\n",
      "         [ 0.9670],\n",
      "         [ 0.9623],\n",
      "         [ 0.9545],\n",
      "         [ 0.9501],\n",
      "         [ 0.9452],\n",
      "         [ 0.8456],\n",
      "         [ 0.9416],\n",
      "         [ 0.9431],\n",
      "         [ 0.9492],\n",
      "         [ 0.9560],\n",
      "         [ 0.9630],\n",
      "         [ 0.9291],\n",
      "         [ 0.4209],\n",
      "         [ 0.9735],\n",
      "         [ 0.0029],\n",
      "         [ 0.3296],\n",
      "         [ 0.3388],\n",
      "         [ 0.3879],\n",
      "         [ 0.9492],\n",
      "         [ 0.4645],\n",
      "         [ 0.4254],\n",
      "         [ 0.1692],\n",
      "         [ 0.9426],\n",
      "         [ 0.9474],\n",
      "         [ 0.9537],\n",
      "         [-0.0166],\n",
      "         [ 0.9324],\n",
      "         [ 0.9688],\n",
      "         [ 0.9714],\n",
      "         [ 0.2002],\n",
      "         [ 0.9748],\n",
      "         [ 0.9726],\n",
      "         [ 0.6635],\n",
      "         [ 0.9647],\n",
      "         [ 0.4597],\n",
      "         [ 0.9519],\n",
      "         [ 0.9640],\n",
      "         [ 0.9645],\n",
      "         [ 0.9680],\n",
      "         [-0.0124],\n",
      "         [ 0.5281],\n",
      "         [ 0.9774],\n",
      "         [ 0.9784],\n",
      "         [ 0.9779],\n",
      "         [ 0.9781],\n",
      "         [ 0.9764],\n",
      "         [ 0.9733],\n",
      "         [ 0.9690],\n",
      "         [ 0.5763],\n",
      "         [ 0.9619],\n",
      "         [-0.0442],\n",
      "         [ 0.4442],\n",
      "         [ 0.9504],\n",
      "         [ 0.9543],\n",
      "         [ 0.6265],\n",
      "         [ 0.9570],\n",
      "         [ 0.1010],\n",
      "         [ 0.9626],\n",
      "         [ 0.4018],\n",
      "         [ 0.9675],\n",
      "         [ 0.8241],\n",
      "         [ 0.9722],\n",
      "         [ 0.9607],\n",
      "         [ 0.9726],\n",
      "         [ 0.9704],\n",
      "         [ 0.9663],\n",
      "         [ 0.9599],\n",
      "         [ 0.8161],\n",
      "         [ 0.9517],\n",
      "         [ 0.1617],\n",
      "         [ 0.9448],\n",
      "         [ 0.3853],\n",
      "         [ 0.9459],\n",
      "         [ 0.9498],\n",
      "         [ 0.4400],\n",
      "         [ 0.1766],\n",
      "         [ 0.9658],\n",
      "         [ 0.9699],\n",
      "         [ 0.9753],\n",
      "         [ 0.9760],\n",
      "         [ 0.5262],\n",
      "         [ 0.9725],\n",
      "         [ 0.4132],\n",
      "         [ 0.2995],\n",
      "         [ 0.9561],\n",
      "         [ 0.3126],\n",
      "         [ 0.4504],\n",
      "         [ 0.9188],\n",
      "         [ 0.9545],\n",
      "         [ 0.9536],\n",
      "         [ 0.9528],\n",
      "         [ 0.9544],\n",
      "         [ 0.9530],\n",
      "         [-0.0176],\n",
      "         [ 0.9491],\n",
      "         [ 0.1806],\n",
      "         [ 0.9460],\n",
      "         [ 0.9463],\n",
      "         [ 0.1788],\n",
      "         [ 0.4618],\n",
      "         [ 0.3238],\n",
      "         [ 0.9612]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.7129],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.8933],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [0.5165],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9490],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.9998],\n",
      "        [0.0247],\n",
      "        [0.5108],\n",
      "        [0.9044],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9966],\n",
      "        [0.9724],\n",
      "        [0.4454],\n",
      "        [0.9996],\n",
      "        [0.2686],\n",
      "        [0.7540],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.3780],\n",
      "        [0.3875],\n",
      "        [0.8223],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.7391],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.9814],\n",
      "        [0.4645],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.3808],\n",
      "        [0.4611],\n",
      "        [0.0368],\n",
      "        [0.2208],\n",
      "        [0.9009],\n",
      "        [0.0288],\n",
      "        [0.9994],\n",
      "        [0.3575],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [0.0174],\n",
      "        [0.3747],\n",
      "        [0.3930],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.5038],\n",
      "        [0.2729],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.9515],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.9998],\n",
      "        [0.5054],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0142],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.5463],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.3573],\n",
      "        [0.9956],\n",
      "        [0.3728],\n",
      "        [0.4988],\n",
      "        [0.9520],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.9996],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.5151],\n",
      "        [0.3912],\n",
      "        [0.9999]])\n",
      "######### Epoch: 20  ######### Train Loss: 0.002004764275625348  ######### Relative L2 Test Norm: 16.984609603881836\n",
      "Output batch pred: tensor([[[ 9.5641e-01],\n",
      "         [ 6.5634e-01],\n",
      "         [ 9.6414e-01],\n",
      "         [ 9.6800e-01],\n",
      "         [ 9.7341e-01],\n",
      "         [ 9.7718e-01],\n",
      "         [ 9.8073e-01],\n",
      "         [ 9.7983e-01],\n",
      "         [ 4.8977e-01],\n",
      "         [ 9.7338e-01],\n",
      "         [ 4.8381e-01],\n",
      "         [ 8.1610e-01],\n",
      "         [ 9.5657e-01],\n",
      "         [ 9.4855e-01],\n",
      "         [ 4.5577e-01],\n",
      "         [ 9.4424e-01],\n",
      "         [ 9.4698e-01],\n",
      "         [ 9.5251e-01],\n",
      "         [ 8.5068e-04],\n",
      "         [ 9.6598e-01],\n",
      "         [ 9.7302e-01],\n",
      "         [ 9.7682e-01],\n",
      "         [ 9.7930e-01],\n",
      "         [ 9.7891e-01],\n",
      "         [ 9.3733e-01],\n",
      "         [ 4.1673e-01],\n",
      "         [ 9.6536e-01],\n",
      "         [ 9.5963e-01],\n",
      "         [ 4.5547e-01],\n",
      "         [ 8.6390e-01],\n",
      "         [ 3.1331e-01],\n",
      "         [ 5.0479e-01],\n",
      "         [ 9.6364e-01],\n",
      "         [ 4.1473e-01],\n",
      "         [ 9.6902e-01],\n",
      "         [ 6.5569e-01],\n",
      "         [ 9.7049e-01],\n",
      "         [ 8.9901e-01],\n",
      "         [ 9.6745e-01],\n",
      "         [ 9.6712e-01],\n",
      "         [ 8.3098e-01],\n",
      "         [ 8.3445e-01],\n",
      "         [ 2.0040e-02],\n",
      "         [ 2.3771e-01],\n",
      "         [ 8.9284e-01],\n",
      "         [ 5.3437e-01],\n",
      "         [ 9.7271e-01],\n",
      "         [ 4.3447e-01],\n",
      "         [ 6.3499e-01],\n",
      "         [ 2.0838e-02],\n",
      "         [ 9.6560e-01],\n",
      "         [ 3.3856e-01],\n",
      "         [ 9.6345e-01],\n",
      "         [ 4.6337e-01],\n",
      "         [ 9.6097e-01],\n",
      "         [ 4.2497e-01],\n",
      "         [ 9.5930e-01],\n",
      "         [ 9.5615e-01],\n",
      "         [ 9.5669e-01],\n",
      "         [ 9.5268e-01],\n",
      "         [ 9.5277e-01],\n",
      "         [ 4.1074e-01],\n",
      "         [ 9.5435e-01],\n",
      "         [ 1.9295e-01],\n",
      "         [ 9.5661e-01],\n",
      "         [ 4.2095e-01],\n",
      "         [ 9.5988e-01],\n",
      "         [ 4.3019e-01],\n",
      "         [ 4.9346e-01],\n",
      "         [ 9.7009e-01],\n",
      "         [ 9.7157e-01],\n",
      "         [ 9.6991e-01],\n",
      "         [ 4.8390e-01],\n",
      "         [ 9.6357e-01],\n",
      "         [ 9.5951e-01],\n",
      "         [ 9.5439e-01],\n",
      "         [ 9.5360e-01],\n",
      "         [ 9.3772e-01],\n",
      "         [ 3.1063e-01],\n",
      "         [ 9.5220e-01],\n",
      "         [ 9.5486e-01],\n",
      "         [ 9.5699e-01],\n",
      "         [ 1.9359e-01],\n",
      "         [ 9.6191e-01],\n",
      "         [ 9.4759e-01],\n",
      "         [ 3.2054e-01],\n",
      "         [ 9.6835e-01],\n",
      "         [ 9.6371e-01],\n",
      "         [ 9.5092e-01],\n",
      "         [ 9.6238e-01],\n",
      "         [ 3.3697e-01],\n",
      "         [ 7.8950e-03],\n",
      "         [ 9.5758e-01],\n",
      "         [ 9.5614e-01],\n",
      "         [ 9.5127e-01],\n",
      "         [ 9.5653e-01],\n",
      "         [ 9.6118e-01],\n",
      "         [-8.8909e-03],\n",
      "         [ 9.6897e-01],\n",
      "         [ 8.4396e-01],\n",
      "         [ 9.4342e-01],\n",
      "         [ 9.8185e-01],\n",
      "         [ 2.3093e-02],\n",
      "         [ 5.3095e-01],\n",
      "         [ 9.8184e-01],\n",
      "         [ 1.0333e-02],\n",
      "         [ 9.6249e-01],\n",
      "         [ 9.6721e-01],\n",
      "         [ 9.5948e-01],\n",
      "         [ 9.5270e-01],\n",
      "         [ 9.5002e-01],\n",
      "         [ 9.4898e-01],\n",
      "         [ 7.3143e-01],\n",
      "         [ 9.5317e-01],\n",
      "         [ 9.5743e-01],\n",
      "         [ 1.3425e-01],\n",
      "         [ 2.3734e-01],\n",
      "         [ 9.7630e-01],\n",
      "         [ 9.8137e-01],\n",
      "         [ 5.2278e-01],\n",
      "         [ 9.8467e-01],\n",
      "         [ 9.8320e-01],\n",
      "         [ 2.3486e-01],\n",
      "         [ 3.2942e-01],\n",
      "         [ 9.3316e-01],\n",
      "         [ 9.6311e-01],\n",
      "         [ 9.5669e-01],\n",
      "         [ 3.3712e-03],\n",
      "         [ 9.4753e-01],\n",
      "         [ 3.9138e-01],\n",
      "         [ 1.9521e-01],\n",
      "         [ 9.5349e-01],\n",
      "         [ 9.6127e-01],\n",
      "         [ 4.8071e-01],\n",
      "         [ 2.1428e-01],\n",
      "         [ 9.7489e-01],\n",
      "         [ 9.7681e-01],\n",
      "         [ 9.7542e-01],\n",
      "         [ 9.6998e-01],\n",
      "         [ 3.2500e-01],\n",
      "         [ 9.5964e-01],\n",
      "         [ 9.5540e-01],\n",
      "         [ 6.9752e-01],\n",
      "         [ 8.7390e-01],\n",
      "         [ 4.4531e-01],\n",
      "         [ 9.5083e-01],\n",
      "         [ 9.2006e-01],\n",
      "         [ 9.6090e-01],\n",
      "         [ 9.6592e-01],\n",
      "         [ 9.7008e-01],\n",
      "         [ 9.1488e-01],\n",
      "         [ 9.7446e-01],\n",
      "         [ 9.7354e-01],\n",
      "         [ 3.1185e-01],\n",
      "         [ 7.4027e-01],\n",
      "         [ 9.6218e-01],\n",
      "         [ 3.9072e-01],\n",
      "         [-3.2266e-02],\n",
      "         [ 9.5785e-01],\n",
      "         [ 6.8907e-01],\n",
      "         [ 1.5959e-01],\n",
      "         [ 3.3064e-01],\n",
      "         [ 9.6879e-01],\n",
      "         [ 9.6906e-01],\n",
      "         [ 4.2362e-01],\n",
      "         [ 9.6740e-01],\n",
      "         [ 9.6572e-01],\n",
      "         [ 9.6267e-01],\n",
      "         [ 3.2891e-01],\n",
      "         [ 9.5717e-01],\n",
      "         [ 9.5586e-01],\n",
      "         [ 9.5493e-01],\n",
      "         [ 9.4301e-01],\n",
      "         [ 5.6828e-01],\n",
      "         [ 3.3549e-01],\n",
      "         [ 9.5775e-01],\n",
      "         [ 7.7784e-01],\n",
      "         [ 2.0877e-01]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9962],\n",
      "        [0.6628],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.0335],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9420],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.5038],\n",
      "        [0.8761],\n",
      "        [0.3780],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.9999],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [0.8296],\n",
      "        [0.0247],\n",
      "        [0.2729],\n",
      "        [0.8933],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.6327],\n",
      "        [0.0368],\n",
      "        [0.9999],\n",
      "        [0.3840],\n",
      "        [0.9994],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9996],\n",
      "        [0.4645],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [0.5139],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.2577],\n",
      "        [0.9966],\n",
      "        [0.9724],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.8379],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.1762],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.5151],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.2646],\n",
      "        [0.3575],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.2547],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.9009],\n",
      "        [0.5030],\n",
      "        [0.9998],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [0.4454],\n",
      "        [0.0000],\n",
      "        [0.9996],\n",
      "        [0.6920],\n",
      "        [0.2208],\n",
      "        [0.3747],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.5945],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.2686]])\n",
      "######### Epoch: 21  ######### Train Loss: 0.0013441063929349184  ######### Relative L2 Test Norm: 14.811101913452148\n",
      "Output batch pred: tensor([[[0.9921],\n",
      "         [0.9697],\n",
      "         [0.9773],\n",
      "         [0.9722],\n",
      "         [0.2085],\n",
      "         [0.9687],\n",
      "         [0.7599],\n",
      "         [0.9414],\n",
      "         [0.0402],\n",
      "         [0.9882],\n",
      "         [0.0770],\n",
      "         [0.4707],\n",
      "         [0.9936],\n",
      "         [0.2279],\n",
      "         [0.0543],\n",
      "         [0.9782],\n",
      "         [0.2321],\n",
      "         [0.9666],\n",
      "         [0.9086],\n",
      "         [0.9695],\n",
      "         [0.9727],\n",
      "         [0.9781],\n",
      "         [0.3388],\n",
      "         [0.9836],\n",
      "         [0.0329],\n",
      "         [0.9823],\n",
      "         [0.9802],\n",
      "         [0.9716],\n",
      "         [0.9623],\n",
      "         [0.3982],\n",
      "         [0.9521],\n",
      "         [0.9497],\n",
      "         [0.9185],\n",
      "         [0.5188],\n",
      "         [0.7284],\n",
      "         [0.9825],\n",
      "         [0.9892],\n",
      "         [0.9947],\n",
      "         [0.9969],\n",
      "         [0.4842],\n",
      "         [0.4750],\n",
      "         [0.9782],\n",
      "         [0.4789],\n",
      "         [0.9553],\n",
      "         [0.9514],\n",
      "         [0.6240],\n",
      "         [0.9490],\n",
      "         [0.8212],\n",
      "         [0.9589],\n",
      "         [0.9647],\n",
      "         [0.9734],\n",
      "         [0.5287],\n",
      "         [0.9803],\n",
      "         [0.3592],\n",
      "         [0.9781],\n",
      "         [0.9761],\n",
      "         [0.4475],\n",
      "         [0.9687],\n",
      "         [0.3548],\n",
      "         [0.9667],\n",
      "         [0.9716],\n",
      "         [0.5013],\n",
      "         [0.9759],\n",
      "         [0.8880],\n",
      "         [0.0449],\n",
      "         [0.8430],\n",
      "         [0.3647],\n",
      "         [0.9743],\n",
      "         [0.4834],\n",
      "         [0.9728],\n",
      "         [0.9716],\n",
      "         [0.5041],\n",
      "         [0.9698],\n",
      "         [0.9708],\n",
      "         [0.9546],\n",
      "         [0.5995],\n",
      "         [0.8387],\n",
      "         [0.9659],\n",
      "         [0.9659],\n",
      "         [0.9626],\n",
      "         [0.9489],\n",
      "         [0.3523],\n",
      "         [0.9622],\n",
      "         [0.9641],\n",
      "         [0.9543],\n",
      "         [0.9693],\n",
      "         [0.9700],\n",
      "         [0.9599],\n",
      "         [0.9654],\n",
      "         [0.9698],\n",
      "         [0.2368],\n",
      "         [0.9627],\n",
      "         [0.9600],\n",
      "         [0.9568],\n",
      "         [0.0222],\n",
      "         [0.4147],\n",
      "         [0.7812],\n",
      "         [0.9623],\n",
      "         [0.9653],\n",
      "         [0.9698],\n",
      "         [0.9719],\n",
      "         [0.3482],\n",
      "         [0.9751],\n",
      "         [0.9738],\n",
      "         [0.4868],\n",
      "         [0.9650],\n",
      "         [0.9619],\n",
      "         [0.9562],\n",
      "         [0.9537],\n",
      "         [0.9519],\n",
      "         [0.9523],\n",
      "         [0.8799],\n",
      "         [0.9600],\n",
      "         [0.9671],\n",
      "         [0.0133],\n",
      "         [0.9865],\n",
      "         [0.9957],\n",
      "         [1.0026],\n",
      "         [0.2718],\n",
      "         [0.9377],\n",
      "         [1.0033],\n",
      "         [0.4879],\n",
      "         [0.3649],\n",
      "         [0.5039],\n",
      "         [0.8345],\n",
      "         [0.7509],\n",
      "         [0.9660],\n",
      "         [0.9664],\n",
      "         [0.9689],\n",
      "         [0.9731],\n",
      "         [0.0541],\n",
      "         [0.3842],\n",
      "         [0.5697],\n",
      "         [0.2881],\n",
      "         [0.5308],\n",
      "         [0.9954],\n",
      "         [0.9552],\n",
      "         [0.9793],\n",
      "         [0.9687],\n",
      "         [0.6901],\n",
      "         [0.2023],\n",
      "         [0.9506],\n",
      "         [0.9479],\n",
      "         [0.4134],\n",
      "         [0.8908],\n",
      "         [0.2398],\n",
      "         [0.9816],\n",
      "         [0.9872],\n",
      "         [0.6650],\n",
      "         [0.9915],\n",
      "         [0.9885],\n",
      "         [0.9821],\n",
      "         [0.3387],\n",
      "         [0.9702],\n",
      "         [0.9246],\n",
      "         [0.9618],\n",
      "         [0.9602],\n",
      "         [0.9624],\n",
      "         [0.2224],\n",
      "         [0.5051],\n",
      "         [0.1651],\n",
      "         [0.6962],\n",
      "         [0.9887],\n",
      "         [0.9885],\n",
      "         [0.9870],\n",
      "         [0.9803],\n",
      "         [0.9777],\n",
      "         [0.4851],\n",
      "         [0.9689],\n",
      "         [0.3479],\n",
      "         [0.9667],\n",
      "         [0.4214],\n",
      "         [0.3493],\n",
      "         [0.4348],\n",
      "         [0.5195],\n",
      "         [0.9971],\n",
      "         [0.9985],\n",
      "         [0.0275]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.9490],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9997],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.9998],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [0.4480],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9520],\n",
      "        [0.5463],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4645],\n",
      "        [0.4642],\n",
      "        [0.9995],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.4668],\n",
      "        [0.9998],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.0368],\n",
      "        [0.8223],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.5945],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9820],\n",
      "        [0.3930],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9819],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.0288],\n",
      "        [0.4552],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.8933],\n",
      "        [0.9962],\n",
      "        [0.4611],\n",
      "        [0.3575],\n",
      "        [0.5009],\n",
      "        [0.8139],\n",
      "        [0.7391],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.3808],\n",
      "        [0.5334],\n",
      "        [0.2735],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [0.9515],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.9044],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.6327],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.5165],\n",
      "        [0.1762],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.5080],\n",
      "        [0.9999],\n",
      "        [0.3912],\n",
      "        [0.9995],\n",
      "        [0.4527],\n",
      "        [0.3780],\n",
      "        [0.4454],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.9967],\n",
      "        [0.0000]])\n",
      "######### Epoch: 22  ######### Train Loss: 0.0007770885131321847  ######### Relative L2 Test Norm: 12.15826416015625\n",
      "Output batch pred: tensor([[[0.9962],\n",
      "         [0.7434],\n",
      "         [0.9981],\n",
      "         [0.9952],\n",
      "         [0.0452],\n",
      "         [0.5257],\n",
      "         [0.9986],\n",
      "         [0.4049],\n",
      "         [0.9880],\n",
      "         [0.9986],\n",
      "         [0.9964],\n",
      "         [0.9915],\n",
      "         [0.9866],\n",
      "         [0.4500],\n",
      "         [0.9730],\n",
      "         [0.9686],\n",
      "         [0.9650],\n",
      "         [0.8338],\n",
      "         [0.9672],\n",
      "         [0.2425],\n",
      "         [0.9830],\n",
      "         [0.9922],\n",
      "         [0.9998],\n",
      "         [1.0046],\n",
      "         [0.5344],\n",
      "         [0.4803],\n",
      "         [0.8402],\n",
      "         [0.9982],\n",
      "         [0.9885],\n",
      "         [0.9865],\n",
      "         [0.9087],\n",
      "         [0.8530],\n",
      "         [0.5021],\n",
      "         [0.9889],\n",
      "         [0.3749],\n",
      "         [0.9962],\n",
      "         [0.9971],\n",
      "         [0.9999],\n",
      "         [0.9972],\n",
      "         [0.9829],\n",
      "         [0.0521],\n",
      "         [0.5058],\n",
      "         [0.9846],\n",
      "         [0.9822],\n",
      "         [0.9136],\n",
      "         [0.3839],\n",
      "         [0.3960],\n",
      "         [0.0634],\n",
      "         [0.8720],\n",
      "         [0.2816],\n",
      "         [0.9180],\n",
      "         [0.9968],\n",
      "         [0.9938],\n",
      "         [0.2585],\n",
      "         [0.9841],\n",
      "         [0.9805],\n",
      "         [0.9780],\n",
      "         [0.9781],\n",
      "         [0.9805],\n",
      "         [0.0516],\n",
      "         [0.9818],\n",
      "         [0.9864],\n",
      "         [0.9892],\n",
      "         [0.9893],\n",
      "         [0.9873],\n",
      "         [0.0477],\n",
      "         [0.9862],\n",
      "         [0.4533],\n",
      "         [0.9752],\n",
      "         [0.4613],\n",
      "         [0.9936],\n",
      "         [0.9928],\n",
      "         [0.9987],\n",
      "         [0.3766],\n",
      "         [0.5814],\n",
      "         [0.9950],\n",
      "         [0.9884],\n",
      "         [0.3753],\n",
      "         [0.9786],\n",
      "         [0.9753],\n",
      "         [0.4926],\n",
      "         [0.9708],\n",
      "         [0.9602],\n",
      "         [0.9733],\n",
      "         [0.8334],\n",
      "         [0.9775],\n",
      "         [0.5360],\n",
      "         [0.9454],\n",
      "         [0.9850],\n",
      "         [0.9863],\n",
      "         [0.9867],\n",
      "         [0.9858],\n",
      "         [0.9868],\n",
      "         [0.9831],\n",
      "         [0.2554],\n",
      "         [0.9841],\n",
      "         [0.5475],\n",
      "         [0.6880],\n",
      "         [0.9776],\n",
      "         [0.9764],\n",
      "         [0.9736],\n",
      "         [0.9763],\n",
      "         [0.9775],\n",
      "         [0.5156],\n",
      "         [0.9848],\n",
      "         [0.9871],\n",
      "         [0.9893],\n",
      "         [0.6275],\n",
      "         [0.9885],\n",
      "         [0.5226],\n",
      "         [0.9829],\n",
      "         [0.4536],\n",
      "         [0.9852],\n",
      "         [0.9491],\n",
      "         [0.9857],\n",
      "         [0.9869],\n",
      "         [0.3580],\n",
      "         [0.9933],\n",
      "         [0.4841],\n",
      "         [0.7972],\n",
      "         [0.9946],\n",
      "         [0.9910],\n",
      "         [0.9873],\n",
      "         [0.9817],\n",
      "         [0.9761],\n",
      "         [0.9724],\n",
      "         [0.4995],\n",
      "         [0.9109],\n",
      "         [0.9708],\n",
      "         [0.5083],\n",
      "         [0.9817],\n",
      "         [0.2720],\n",
      "         [0.2674],\n",
      "         [0.9969],\n",
      "         [0.3986],\n",
      "         [1.0015],\n",
      "         [0.0731],\n",
      "         [0.9981],\n",
      "         [0.9619],\n",
      "         [0.9918],\n",
      "         [0.9860],\n",
      "         [0.2086],\n",
      "         [0.9829],\n",
      "         [0.3803],\n",
      "         [0.9798],\n",
      "         [0.4434],\n",
      "         [0.7582],\n",
      "         [0.9756],\n",
      "         [0.9752],\n",
      "         [0.9794],\n",
      "         [0.3678],\n",
      "         [0.3845],\n",
      "         [0.4669],\n",
      "         [0.9977],\n",
      "         [0.0902],\n",
      "         [0.6895],\n",
      "         [0.7178],\n",
      "         [1.0139],\n",
      "         [0.2253],\n",
      "         [0.5621],\n",
      "         [0.0901],\n",
      "         [0.5080],\n",
      "         [1.0031],\n",
      "         [0.9682],\n",
      "         [0.0672],\n",
      "         [0.9745],\n",
      "         [0.9881],\n",
      "         [0.9843],\n",
      "         [0.9813],\n",
      "         [0.9805],\n",
      "         [0.2370],\n",
      "         [0.9801],\n",
      "         [0.9786],\n",
      "         [0.2596],\n",
      "         [0.9858],\n",
      "         [0.7490],\n",
      "         [0.4778],\n",
      "         [0.9242]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0142],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.4503],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.8296],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [0.0209],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.3808],\n",
      "        [0.3840],\n",
      "        [0.0000],\n",
      "        [0.8223],\n",
      "        [0.2547],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9995],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0174],\n",
      "        [0.9999],\n",
      "        [0.4454],\n",
      "        [0.9814],\n",
      "        [0.4480],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [0.9819],\n",
      "        [0.9997],\n",
      "        [0.8139],\n",
      "        [0.9995],\n",
      "        [0.5245],\n",
      "        [0.9420],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9967],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [0.9956],\n",
      "        [0.4552],\n",
      "        [0.9996],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.7540],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5151],\n",
      "        [0.9164],\n",
      "        [0.9959],\n",
      "        [0.5139],\n",
      "        [0.9966],\n",
      "        [0.2646],\n",
      "        [0.2518],\n",
      "        [0.9999],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9994],\n",
      "        [0.3912],\n",
      "        [0.9998],\n",
      "        [0.4527],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.3875],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [0.0335],\n",
      "        [0.6327],\n",
      "        [0.6555],\n",
      "        [0.9997],\n",
      "        [0.1762],\n",
      "        [0.5080],\n",
      "        [0.0247],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.0368],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.4642],\n",
      "        [0.9009]])\n",
      "######### Epoch: 23  ######### Train Loss: 0.0004802202747669071  ######### Relative L2 Test Norm: 11.258111000061035\n",
      "Output batch pred: tensor([[[0.9967],\n",
      "         [0.1084],\n",
      "         [0.5602],\n",
      "         [1.0120],\n",
      "         [1.0097],\n",
      "         [1.0058],\n",
      "         [0.9997],\n",
      "         [0.9947],\n",
      "         [0.3748],\n",
      "         [0.8177],\n",
      "         [0.9844],\n",
      "         [0.9820],\n",
      "         [0.9852],\n",
      "         [0.9869],\n",
      "         [0.6653],\n",
      "         [0.8529],\n",
      "         [0.5185],\n",
      "         [0.5593],\n",
      "         [0.9974],\n",
      "         [0.9979],\n",
      "         [0.9979],\n",
      "         [0.9978],\n",
      "         [0.9983],\n",
      "         [0.9980],\n",
      "         [0.5787],\n",
      "         [1.0015],\n",
      "         [1.0056],\n",
      "         [1.0065],\n",
      "         [1.0063],\n",
      "         [0.0700],\n",
      "         [0.2944],\n",
      "         [1.0029],\n",
      "         [1.0017],\n",
      "         [1.0011],\n",
      "         [0.9988],\n",
      "         [0.5356],\n",
      "         [0.4809],\n",
      "         [0.8057],\n",
      "         [1.0028],\n",
      "         [0.8808],\n",
      "         [1.0023],\n",
      "         [0.8683],\n",
      "         [0.9962],\n",
      "         [0.9556],\n",
      "         [0.4488],\n",
      "         [0.4602],\n",
      "         [0.9856],\n",
      "         [0.9832],\n",
      "         [0.9835],\n",
      "         [0.9854],\n",
      "         [0.9172],\n",
      "         [0.9898],\n",
      "         [0.9929],\n",
      "         [0.5311],\n",
      "         [1.0022],\n",
      "         [0.9520],\n",
      "         [1.0122],\n",
      "         [0.4113],\n",
      "         [1.0191],\n",
      "         [1.0085],\n",
      "         [0.6674],\n",
      "         [0.5548],\n",
      "         [0.2976],\n",
      "         [0.0930],\n",
      "         [0.5883],\n",
      "         [0.9986],\n",
      "         [0.0931],\n",
      "         [0.9932],\n",
      "         [0.4700],\n",
      "         [0.9924],\n",
      "         [0.9956],\n",
      "         [0.9954],\n",
      "         [0.0777],\n",
      "         [1.0055],\n",
      "         [0.9353],\n",
      "         [0.4141],\n",
      "         [1.0093],\n",
      "         [0.4881],\n",
      "         [0.9885],\n",
      "         [0.7505],\n",
      "         [0.3928],\n",
      "         [0.9691],\n",
      "         [0.5352],\n",
      "         [0.9957],\n",
      "         [0.5423],\n",
      "         [0.5081],\n",
      "         [1.0154],\n",
      "         [1.0187],\n",
      "         [0.3078],\n",
      "         [1.0150],\n",
      "         [1.0127],\n",
      "         [0.0897],\n",
      "         [1.0074],\n",
      "         [0.5543],\n",
      "         [1.0005],\n",
      "         [1.0002],\n",
      "         [0.4983],\n",
      "         [0.3850],\n",
      "         [0.4813],\n",
      "         [0.2975],\n",
      "         [1.0100],\n",
      "         [0.5640],\n",
      "         [0.2220],\n",
      "         [1.0123],\n",
      "         [0.2494],\n",
      "         [1.0067],\n",
      "         [1.0037],\n",
      "         [1.0008],\n",
      "         [0.9957],\n",
      "         [0.9966],\n",
      "         [0.9956],\n",
      "         [0.9952],\n",
      "         [0.4658],\n",
      "         [0.0634],\n",
      "         [1.0048],\n",
      "         [1.0068],\n",
      "         [0.4146],\n",
      "         [1.0040],\n",
      "         [1.0169],\n",
      "         [0.5192],\n",
      "         [1.0155],\n",
      "         [1.0156],\n",
      "         [0.8899],\n",
      "         [1.0075],\n",
      "         [0.2690],\n",
      "         [0.0771],\n",
      "         [1.0019],\n",
      "         [0.9150],\n",
      "         [0.9995],\n",
      "         [0.9967],\n",
      "         [0.4127],\n",
      "         [0.5483],\n",
      "         [0.9964],\n",
      "         [0.9976],\n",
      "         [0.9965],\n",
      "         [0.9959],\n",
      "         [0.9955],\n",
      "         [0.9959],\n",
      "         [0.9926],\n",
      "         [0.9925],\n",
      "         [0.9991],\n",
      "         [0.9966],\n",
      "         [0.3937],\n",
      "         [0.4013],\n",
      "         [0.9922],\n",
      "         [0.9900],\n",
      "         [0.2615],\n",
      "         [0.7746],\n",
      "         [0.9549],\n",
      "         [0.9857],\n",
      "         [0.9938],\n",
      "         [0.9984],\n",
      "         [1.0057],\n",
      "         [1.0104],\n",
      "         [0.7258],\n",
      "         [0.4090],\n",
      "         [0.0729],\n",
      "         [1.0144],\n",
      "         [1.0063],\n",
      "         [0.9976],\n",
      "         [0.9882],\n",
      "         [0.9786],\n",
      "         [0.9716],\n",
      "         [0.9650],\n",
      "         [0.9677],\n",
      "         [0.9715],\n",
      "         [0.9793],\n",
      "         [0.2705],\n",
      "         [0.9965],\n",
      "         [1.0065],\n",
      "         [1.0124],\n",
      "         [1.0124],\n",
      "         [0.9860],\n",
      "         [0.7411],\n",
      "         [0.4350],\n",
      "         [0.7847],\n",
      "         [0.9439],\n",
      "         [0.3056]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9814],\n",
      "        [0.0335],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.7820],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.6327],\n",
      "        [0.8139],\n",
      "        [0.4988],\n",
      "        [0.5245],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5334],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0174],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5038],\n",
      "        [0.4527],\n",
      "        [0.7540],\n",
      "        [0.9994],\n",
      "        [0.8379],\n",
      "        [0.9997],\n",
      "        [0.8223],\n",
      "        [0.9998],\n",
      "        [0.9420],\n",
      "        [0.4480],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [0.9995],\n",
      "        [0.9164],\n",
      "        [0.9999],\n",
      "        [0.3747],\n",
      "        [0.9996],\n",
      "        [0.9820],\n",
      "        [0.5945],\n",
      "        [0.5009],\n",
      "        [0.2547],\n",
      "        [0.0142],\n",
      "        [0.5463],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.0288],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.9724],\n",
      "        [0.6920],\n",
      "        [0.3753],\n",
      "        [0.9520],\n",
      "        [0.5054],\n",
      "        [0.9804],\n",
      "        [0.5030],\n",
      "        [0.4645],\n",
      "        [0.9967],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.3573],\n",
      "        [0.4454],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.1762],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [0.2518],\n",
      "        [0.0368],\n",
      "        [0.9997],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.3808],\n",
      "        [0.3875],\n",
      "        [0.9997],\n",
      "        [0.9959],\n",
      "        [0.2577],\n",
      "        [0.7391],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [0.3575],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.6628],\n",
      "        [0.3912],\n",
      "        [0.7129],\n",
      "        [0.9009],\n",
      "        [0.2686]])\n",
      "######### Epoch: 24  ######### Train Loss: 0.0008157201809808612  ######### Relative L2 Test Norm: 10.106735229492188\n",
      "Output batch pred: tensor([[[1.0101],\n",
      "         [1.0095],\n",
      "         [0.4823],\n",
      "         [1.0074],\n",
      "         [0.4285],\n",
      "         [0.9502],\n",
      "         [1.0190],\n",
      "         [1.0225],\n",
      "         [0.1150],\n",
      "         [0.3258],\n",
      "         [0.3123],\n",
      "         [1.0169],\n",
      "         [1.0161],\n",
      "         [1.0154],\n",
      "         [0.5677],\n",
      "         [0.9428],\n",
      "         [0.4164],\n",
      "         [0.5113],\n",
      "         [0.5503],\n",
      "         [0.5627],\n",
      "         [1.0083],\n",
      "         [1.0022],\n",
      "         [1.0010],\n",
      "         [0.9977],\n",
      "         [0.9959],\n",
      "         [0.9978],\n",
      "         [1.0006],\n",
      "         [0.9686],\n",
      "         [0.5530],\n",
      "         [0.4027],\n",
      "         [0.7757],\n",
      "         [0.3115],\n",
      "         [1.0242],\n",
      "         [1.0229],\n",
      "         [1.0208],\n",
      "         [0.9853],\n",
      "         [1.0116],\n",
      "         [1.0102],\n",
      "         [1.0088],\n",
      "         [0.0632],\n",
      "         [0.3977],\n",
      "         [1.0090],\n",
      "         [1.0071],\n",
      "         [1.0100],\n",
      "         [0.9424],\n",
      "         [1.0091],\n",
      "         [1.0075],\n",
      "         [1.0034],\n",
      "         [1.0042],\n",
      "         [1.0037],\n",
      "         [0.3682],\n",
      "         [1.0011],\n",
      "         [1.0058],\n",
      "         [1.0008],\n",
      "         [1.0071],\n",
      "         [1.0053],\n",
      "         [0.4039],\n",
      "         [0.9969],\n",
      "         [0.8003],\n",
      "         [1.0106],\n",
      "         [0.3060],\n",
      "         [1.0179],\n",
      "         [1.0197],\n",
      "         [0.0927],\n",
      "         [1.0227],\n",
      "         [0.3039],\n",
      "         [1.0142],\n",
      "         [1.0108],\n",
      "         [0.7118],\n",
      "         [0.4812],\n",
      "         [0.9963],\n",
      "         [0.9955],\n",
      "         [0.9945],\n",
      "         [0.9981],\n",
      "         [1.0003],\n",
      "         [0.5912],\n",
      "         [1.0137],\n",
      "         [0.6656],\n",
      "         [0.7079],\n",
      "         [1.0186],\n",
      "         [1.0201],\n",
      "         [1.0185],\n",
      "         [0.5680],\n",
      "         [0.5574],\n",
      "         [0.5087],\n",
      "         [0.5552],\n",
      "         [1.0099],\n",
      "         [1.0243],\n",
      "         [1.0258],\n",
      "         [0.2479],\n",
      "         [1.0280],\n",
      "         [1.0255],\n",
      "         [0.1086],\n",
      "         [1.0191],\n",
      "         [0.3043],\n",
      "         [1.0102],\n",
      "         [0.4843],\n",
      "         [0.9716],\n",
      "         [0.9918],\n",
      "         [1.0034],\n",
      "         [1.0026],\n",
      "         [0.7250],\n",
      "         [1.0052],\n",
      "         [0.9186],\n",
      "         [0.4776],\n",
      "         [0.2393],\n",
      "         [0.9976],\n",
      "         [0.9984],\n",
      "         [0.9996],\n",
      "         [1.0024],\n",
      "         [0.5383],\n",
      "         [0.8860],\n",
      "         [1.0101],\n",
      "         [0.0989],\n",
      "         [0.5814],\n",
      "         [1.0120],\n",
      "         [1.0108],\n",
      "         [1.0083],\n",
      "         [0.4085],\n",
      "         [0.8406],\n",
      "         [1.0028],\n",
      "         [0.4886],\n",
      "         [1.0051],\n",
      "         [1.0038],\n",
      "         [1.0023],\n",
      "         [1.0001],\n",
      "         [0.9976],\n",
      "         [0.9785],\n",
      "         [0.9908],\n",
      "         [0.4697],\n",
      "         [0.9900],\n",
      "         [0.9949],\n",
      "         [1.0008],\n",
      "         [0.3945],\n",
      "         [1.0165],\n",
      "         [0.1027],\n",
      "         [1.0258],\n",
      "         [1.0264],\n",
      "         [0.9001],\n",
      "         [0.4942],\n",
      "         [1.0098],\n",
      "         [1.0015],\n",
      "         [0.9922],\n",
      "         [0.9903],\n",
      "         [0.8608],\n",
      "         [0.9605],\n",
      "         [0.8616],\n",
      "         [0.4082],\n",
      "         [1.0172],\n",
      "         [0.6072],\n",
      "         [1.0229],\n",
      "         [0.8329],\n",
      "         [0.0915],\n",
      "         [1.0169],\n",
      "         [0.2891],\n",
      "         [0.2785],\n",
      "         [1.0050],\n",
      "         [1.0005],\n",
      "         [0.9500],\n",
      "         [1.0057],\n",
      "         [1.0117],\n",
      "         [0.0861],\n",
      "         [0.1045],\n",
      "         [1.0118],\n",
      "         [1.0123],\n",
      "         [0.9924],\n",
      "         [1.0076],\n",
      "         [0.5324],\n",
      "         [1.0071],\n",
      "         [1.0097],\n",
      "         [0.5072],\n",
      "         [0.5544],\n",
      "         [0.4409],\n",
      "         [1.0264],\n",
      "         [0.8024],\n",
      "         [1.0263],\n",
      "         [1.0236],\n",
      "         [0.4389]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.2735],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.8933],\n",
      "        [0.3747],\n",
      "        [0.4645],\n",
      "        [0.5030],\n",
      "        [0.5165],\n",
      "        [0.9994],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9420],\n",
      "        [0.5108],\n",
      "        [0.3575],\n",
      "        [0.6920],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9967],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.0209],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.9044],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.3573],\n",
      "        [0.9962],\n",
      "        [0.9999],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.9819],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.6555],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.9997],\n",
      "        [0.5945],\n",
      "        [0.6327],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.5139],\n",
      "        [0.5054],\n",
      "        [0.4580],\n",
      "        [0.4988],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0247],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.4527],\n",
      "        [0.9490],\n",
      "        [0.9804],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.4503],\n",
      "        [0.2208],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.3840],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.9994],\n",
      "        [0.4668],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [0.4454],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.8296],\n",
      "        [0.9520],\n",
      "        [0.8139],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.9999],\n",
      "        [0.7540],\n",
      "        [0.0000],\n",
      "        [0.9998],\n",
      "        [0.2547],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.5038],\n",
      "        [0.3912],\n",
      "        [0.9998],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3930]])\n",
      "######### Epoch: 25  ######### Train Loss: 0.0012120034079998732  ######### Relative L2 Test Norm: 9.158943176269531\n",
      "Output batch pred: tensor([[[1.0023],\n",
      "         [0.4213],\n",
      "         [1.0165],\n",
      "         [0.8767],\n",
      "         [1.0096],\n",
      "         [1.0038],\n",
      "         [0.6961],\n",
      "         [0.9986],\n",
      "         [0.0661],\n",
      "         [1.0011],\n",
      "         [0.9981],\n",
      "         [0.4131],\n",
      "         [1.0121],\n",
      "         [0.9837],\n",
      "         [1.0176],\n",
      "         [1.0177],\n",
      "         [0.9356],\n",
      "         [1.0155],\n",
      "         [0.5125],\n",
      "         [1.0096],\n",
      "         [1.0115],\n",
      "         [0.9732],\n",
      "         [0.4986],\n",
      "         [1.0132],\n",
      "         [1.0128],\n",
      "         [1.0169],\n",
      "         [0.4250],\n",
      "         [0.9022],\n",
      "         [1.0188],\n",
      "         [0.2929],\n",
      "         [0.4235],\n",
      "         [1.0159],\n",
      "         [0.7843],\n",
      "         [1.0111],\n",
      "         [1.0051],\n",
      "         [1.0085],\n",
      "         [1.0077],\n",
      "         [1.0091],\n",
      "         [0.9960],\n",
      "         [1.0112],\n",
      "         [0.5526],\n",
      "         [0.6595],\n",
      "         [0.8093],\n",
      "         [1.0156],\n",
      "         [1.0149],\n",
      "         [0.4948],\n",
      "         [0.5630],\n",
      "         [0.1059],\n",
      "         [0.5571],\n",
      "         [0.7351],\n",
      "         [1.0168],\n",
      "         [1.0204],\n",
      "         [0.4164],\n",
      "         [1.0214],\n",
      "         [0.3131],\n",
      "         [1.0198],\n",
      "         [0.5536],\n",
      "         [0.4912],\n",
      "         [1.0105],\n",
      "         [1.0100],\n",
      "         [1.0077],\n",
      "         [1.0085],\n",
      "         [0.9361],\n",
      "         [0.5426],\n",
      "         [0.4238],\n",
      "         [1.0106],\n",
      "         [1.0133],\n",
      "         [0.5388],\n",
      "         [1.0135],\n",
      "         [1.0114],\n",
      "         [1.0103],\n",
      "         [0.2031],\n",
      "         [1.0062],\n",
      "         [1.0060],\n",
      "         [0.9956],\n",
      "         [1.0097],\n",
      "         [0.2754],\n",
      "         [1.0144],\n",
      "         [1.0164],\n",
      "         [1.0150],\n",
      "         [1.0158],\n",
      "         [1.0154],\n",
      "         [0.6932],\n",
      "         [0.9525],\n",
      "         [1.0030],\n",
      "         [0.9969],\n",
      "         [0.2741],\n",
      "         [0.9599],\n",
      "         [0.9959],\n",
      "         [0.9260],\n",
      "         [0.3782],\n",
      "         [0.7481],\n",
      "         [1.0100],\n",
      "         [0.8467],\n",
      "         [0.0912],\n",
      "         [0.1004],\n",
      "         [1.0054],\n",
      "         [1.0150],\n",
      "         [0.5755],\n",
      "         [1.0070],\n",
      "         [1.0023],\n",
      "         [0.9988],\n",
      "         [0.5152],\n",
      "         [0.9933],\n",
      "         [0.9925],\n",
      "         [0.9989],\n",
      "         [1.0019],\n",
      "         [1.0059],\n",
      "         [1.0091],\n",
      "         [0.0889],\n",
      "         [0.2889],\n",
      "         [1.0169],\n",
      "         [1.0181],\n",
      "         [0.6007],\n",
      "         [1.0209],\n",
      "         [1.0219],\n",
      "         [1.0221],\n",
      "         [0.2725],\n",
      "         [0.9104],\n",
      "         [1.0332],\n",
      "         [0.4289],\n",
      "         [0.5447],\n",
      "         [0.4558],\n",
      "         [0.6048],\n",
      "         [0.5862],\n",
      "         [0.4414],\n",
      "         [0.5308],\n",
      "         [1.0164],\n",
      "         [0.4885],\n",
      "         [1.0064],\n",
      "         [1.0054],\n",
      "         [1.0022],\n",
      "         [0.9740],\n",
      "         [0.8827],\n",
      "         [1.0153],\n",
      "         [0.5014],\n",
      "         [0.9588],\n",
      "         [0.4517],\n",
      "         [1.0240],\n",
      "         [0.3145],\n",
      "         [0.8233],\n",
      "         [1.0093],\n",
      "         [1.0040],\n",
      "         [0.9982],\n",
      "         [0.4642],\n",
      "         [0.9828],\n",
      "         [0.9962],\n",
      "         [1.0043],\n",
      "         [1.0104],\n",
      "         [1.0181],\n",
      "         [1.0241],\n",
      "         [0.1070],\n",
      "         [0.3140],\n",
      "         [0.5848],\n",
      "         [1.0246],\n",
      "         [1.0169],\n",
      "         [1.0074],\n",
      "         [0.9992],\n",
      "         [0.9921],\n",
      "         [0.9929],\n",
      "         [0.9913],\n",
      "         [1.0013],\n",
      "         [0.5835],\n",
      "         [1.0176],\n",
      "         [0.0873],\n",
      "         [1.0281],\n",
      "         [1.0328],\n",
      "         [1.0333],\n",
      "         [0.1113],\n",
      "         [0.0778],\n",
      "         [1.0190],\n",
      "         [1.0134],\n",
      "         [1.0074],\n",
      "         [0.4834],\n",
      "         [1.0052],\n",
      "         [1.0069],\n",
      "         [1.0103],\n",
      "         [0.3039]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9724],\n",
      "        [0.3780],\n",
      "        [0.9999],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.9997],\n",
      "        [0.9956],\n",
      "        [0.3875],\n",
      "        [0.9997],\n",
      "        [0.9515],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.8761],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.3808],\n",
      "        [0.9997],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.5945],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.5165],\n",
      "        [0.0368],\n",
      "        [0.5108],\n",
      "        [0.6628],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.3728],\n",
      "        [0.9994],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.5038],\n",
      "        [0.3912],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.6327],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.9520],\n",
      "        [0.9996],\n",
      "        [0.9009],\n",
      "        [0.3575],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.0142],\n",
      "        [0.0288],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.4611],\n",
      "        [0.3747],\n",
      "        [0.5151],\n",
      "        [0.5054],\n",
      "        [0.3753],\n",
      "        [0.4668],\n",
      "        [0.9962],\n",
      "        [0.4480],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9490],\n",
      "        [0.8223],\n",
      "        [0.9999],\n",
      "        [0.4503],\n",
      "        [0.9044],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.7540],\n",
      "        [0.9966],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.4552],\n",
      "        [0.9819],\n",
      "        [0.9967],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0247],\n",
      "        [0.2577],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.9998],\n",
      "        [0.0174],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735]])\n",
      "######### Epoch: 26  ######### Train Loss: 0.0013545131077989936  ######### Relative L2 Test Norm: 9.882901191711426\n",
      "Output batch pred: tensor([[[0.7210],\n",
      "         [0.1074],\n",
      "         [1.0152],\n",
      "         [0.1002],\n",
      "         [1.0087],\n",
      "         [1.0086],\n",
      "         [1.0060],\n",
      "         [1.0036],\n",
      "         [1.0029],\n",
      "         [1.0056],\n",
      "         [0.0591],\n",
      "         [1.0103],\n",
      "         [1.0148],\n",
      "         [0.5832],\n",
      "         [1.0209],\n",
      "         [0.0887],\n",
      "         [0.5505],\n",
      "         [1.0134],\n",
      "         [1.0093],\n",
      "         [1.0039],\n",
      "         [1.0056],\n",
      "         [0.8740],\n",
      "         [0.1993],\n",
      "         [1.0120],\n",
      "         [0.0881],\n",
      "         [1.0230],\n",
      "         [0.5289],\n",
      "         [0.5286],\n",
      "         [0.6759],\n",
      "         [1.0105],\n",
      "         [1.0206],\n",
      "         [0.5480],\n",
      "         [1.0121],\n",
      "         [0.4773],\n",
      "         [0.4895],\n",
      "         [0.4643],\n",
      "         [0.9304],\n",
      "         [1.0042],\n",
      "         [1.0034],\n",
      "         [1.0007],\n",
      "         [0.8728],\n",
      "         [0.4570],\n",
      "         [0.7765],\n",
      "         [0.9939],\n",
      "         [0.9956],\n",
      "         [0.5290],\n",
      "         [0.9993],\n",
      "         [1.0065],\n",
      "         [0.9932],\n",
      "         [0.4217],\n",
      "         [1.0033],\n",
      "         [0.2895],\n",
      "         [1.0171],\n",
      "         [1.0160],\n",
      "         [1.0152],\n",
      "         [0.2486],\n",
      "         [0.5534],\n",
      "         [0.5440],\n",
      "         [0.3976],\n",
      "         [1.0206],\n",
      "         [0.7734],\n",
      "         [0.2907],\n",
      "         [1.0193],\n",
      "         [1.0150],\n",
      "         [0.4056],\n",
      "         [1.0066],\n",
      "         [1.0048],\n",
      "         [1.0036],\n",
      "         [0.5279],\n",
      "         [1.0078],\n",
      "         [1.0117],\n",
      "         [0.7873],\n",
      "         [1.0177],\n",
      "         [0.9931],\n",
      "         [0.9594],\n",
      "         [0.1086],\n",
      "         [1.0211],\n",
      "         [0.5951],\n",
      "         [1.0122],\n",
      "         [0.5527],\n",
      "         [0.4879],\n",
      "         [1.0056],\n",
      "         [1.0071],\n",
      "         [0.2926],\n",
      "         [1.0105],\n",
      "         [0.3116],\n",
      "         [0.3146],\n",
      "         [1.0185],\n",
      "         [1.0062],\n",
      "         [1.0147],\n",
      "         [0.5424],\n",
      "         [1.0072],\n",
      "         [1.0035],\n",
      "         [0.9989],\n",
      "         [0.9990],\n",
      "         [0.9970],\n",
      "         [0.9663],\n",
      "         [1.0000],\n",
      "         [1.0044],\n",
      "         [1.0069],\n",
      "         [1.0054],\n",
      "         [1.0124],\n",
      "         [1.0037],\n",
      "         [1.0189],\n",
      "         [0.4347],\n",
      "         [0.4353],\n",
      "         [1.0275],\n",
      "         [0.4297],\n",
      "         [1.0302],\n",
      "         [0.8405],\n",
      "         [1.0265],\n",
      "         [1.0220],\n",
      "         [0.3023],\n",
      "         [0.9779],\n",
      "         [0.5561],\n",
      "         [1.0060],\n",
      "         [1.0037],\n",
      "         [1.0016],\n",
      "         [1.0022],\n",
      "         [1.0027],\n",
      "         [1.0025],\n",
      "         [1.0026],\n",
      "         [0.9997],\n",
      "         [0.9976],\n",
      "         [0.3854],\n",
      "         [0.9970],\n",
      "         [0.9993],\n",
      "         [1.0024],\n",
      "         [0.2655],\n",
      "         [1.0094],\n",
      "         [1.0104],\n",
      "         [1.0161],\n",
      "         [0.2853],\n",
      "         [1.0161],\n",
      "         [1.0103],\n",
      "         [0.9237],\n",
      "         [0.0648],\n",
      "         [0.9974],\n",
      "         [0.9902],\n",
      "         [0.9918],\n",
      "         [0.9911],\n",
      "         [0.9945],\n",
      "         [0.9413],\n",
      "         [1.0002],\n",
      "         [0.3920],\n",
      "         [1.0044],\n",
      "         [1.0041],\n",
      "         [0.9324],\n",
      "         [0.6939],\n",
      "         [0.9982],\n",
      "         [0.8237],\n",
      "         [0.9607],\n",
      "         [0.9927],\n",
      "         [0.6650],\n",
      "         [0.9975],\n",
      "         [0.9995],\n",
      "         [0.9997],\n",
      "         [0.5198],\n",
      "         [1.0029],\n",
      "         [0.8755],\n",
      "         [1.0020],\n",
      "         [1.0049],\n",
      "         [1.0074],\n",
      "         [0.4795],\n",
      "         [0.0764],\n",
      "         [1.0154],\n",
      "         [0.6053],\n",
      "         [0.4980],\n",
      "         [1.0213],\n",
      "         [1.0194],\n",
      "         [0.0773],\n",
      "         [0.3819],\n",
      "         [0.4785],\n",
      "         [0.8527],\n",
      "         [0.3747],\n",
      "         [0.9937],\n",
      "         [0.3867],\n",
      "         [0.9987]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.6628],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.5245],\n",
      "        [0.9998],\n",
      "        [0.0288],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.4645],\n",
      "        [0.5945],\n",
      "        [0.9814],\n",
      "        [0.9998],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.4668],\n",
      "        [0.4480],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.4552],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5165],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.3930],\n",
      "        [0.9820],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.5108],\n",
      "        [0.5009],\n",
      "        [0.3575],\n",
      "        [0.9997],\n",
      "        [0.6920],\n",
      "        [0.2577],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.3840],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.9044],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [0.5151],\n",
      "        [0.4611],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9520],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.3875],\n",
      "        [0.9996],\n",
      "        [0.3753],\n",
      "        [0.9997],\n",
      "        [0.7540],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.2686],\n",
      "        [0.9420],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.9999],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.8761],\n",
      "        [0.0247],\n",
      "        [0.9966],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [0.3747],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.9009],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.0142],\n",
      "        [0.9962],\n",
      "        [0.5463],\n",
      "        [0.4454],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.0000],\n",
      "        [0.3573],\n",
      "        [0.4580],\n",
      "        [0.8139],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.9997]])\n",
      "######### Epoch: 27  ######### Train Loss: 0.0009289705194532871  ######### Relative L2 Test Norm: 12.019472122192383\n",
      "Output batch pred: tensor([[[0.3954],\n",
      "         [1.0084],\n",
      "         [0.9712],\n",
      "         [1.0004],\n",
      "         [0.0453],\n",
      "         [0.9564],\n",
      "         [0.9886],\n",
      "         [0.2656],\n",
      "         [0.9944],\n",
      "         [1.0006],\n",
      "         [1.0018],\n",
      "         [0.3830],\n",
      "         [1.0128],\n",
      "         [0.5522],\n",
      "         [0.8820],\n",
      "         [0.5341],\n",
      "         [1.0059],\n",
      "         [0.4620],\n",
      "         [0.4727],\n",
      "         [0.9928],\n",
      "         [0.9919],\n",
      "         [0.9903],\n",
      "         [0.9923],\n",
      "         [0.9948],\n",
      "         [0.4559],\n",
      "         [0.9944],\n",
      "         [0.4652],\n",
      "         [0.3907],\n",
      "         [0.9953],\n",
      "         [0.9976],\n",
      "         [0.9974],\n",
      "         [0.9980],\n",
      "         [0.3875],\n",
      "         [1.0018],\n",
      "         [0.5433],\n",
      "         [0.4033],\n",
      "         [0.1935],\n",
      "         [1.0052],\n",
      "         [1.0037],\n",
      "         [1.0035],\n",
      "         [1.0025],\n",
      "         [1.0030],\n",
      "         [1.0026],\n",
      "         [0.2783],\n",
      "         [0.2779],\n",
      "         [0.0742],\n",
      "         [0.5337],\n",
      "         [0.2390],\n",
      "         [0.7037],\n",
      "         [1.0042],\n",
      "         [0.9962],\n",
      "         [0.4386],\n",
      "         [0.9851],\n",
      "         [0.9808],\n",
      "         [0.9772],\n",
      "         [0.9805],\n",
      "         [0.9821],\n",
      "         [0.2348],\n",
      "         [1.0013],\n",
      "         [0.5377],\n",
      "         [1.0132],\n",
      "         [1.0149],\n",
      "         [1.0128],\n",
      "         [1.0101],\n",
      "         [0.2687],\n",
      "         [0.5737],\n",
      "         [0.3783],\n",
      "         [0.9126],\n",
      "         [0.9987],\n",
      "         [0.9915],\n",
      "         [1.0065],\n",
      "         [0.0520],\n",
      "         [1.0135],\n",
      "         [0.4041],\n",
      "         [0.4914],\n",
      "         [0.4200],\n",
      "         [1.0094],\n",
      "         [1.0062],\n",
      "         [0.7883],\n",
      "         [1.0018],\n",
      "         [0.4587],\n",
      "         [1.0042],\n",
      "         [0.4826],\n",
      "         [0.2802],\n",
      "         [1.0105],\n",
      "         [0.9547],\n",
      "         [0.3965],\n",
      "         [0.0746],\n",
      "         [0.9974],\n",
      "         [0.9906],\n",
      "         [0.9832],\n",
      "         [0.9775],\n",
      "         [0.9740],\n",
      "         [0.9760],\n",
      "         [0.9410],\n",
      "         [0.9850],\n",
      "         [0.9971],\n",
      "         [0.4828],\n",
      "         [0.9437],\n",
      "         [1.0172],\n",
      "         [0.5435],\n",
      "         [0.5406],\n",
      "         [1.0155],\n",
      "         [0.2671],\n",
      "         [1.0043],\n",
      "         [0.9973],\n",
      "         [0.9923],\n",
      "         [0.9887],\n",
      "         [0.9809],\n",
      "         [0.9874],\n",
      "         [0.3727],\n",
      "         [0.7535],\n",
      "         [0.8731],\n",
      "         [0.9410],\n",
      "         [0.5955],\n",
      "         [0.7474],\n",
      "         [0.5774],\n",
      "         [0.1004],\n",
      "         [0.3108],\n",
      "         [0.5752],\n",
      "         [1.0268],\n",
      "         [1.0193],\n",
      "         [1.0100],\n",
      "         [0.9997],\n",
      "         [0.8254],\n",
      "         [0.9859],\n",
      "         [0.9842],\n",
      "         [0.6032],\n",
      "         [0.9794],\n",
      "         [0.9838],\n",
      "         [0.9860],\n",
      "         [0.9916],\n",
      "         [0.9917],\n",
      "         [1.0011],\n",
      "         [0.8820],\n",
      "         [0.0774],\n",
      "         [1.0139],\n",
      "         [0.0905],\n",
      "         [1.0196],\n",
      "         [1.0041],\n",
      "         [1.0178],\n",
      "         [0.7716],\n",
      "         [0.0703],\n",
      "         [0.9781],\n",
      "         [1.0046],\n",
      "         [0.6721],\n",
      "         [0.9910],\n",
      "         [0.9742],\n",
      "         [0.9798],\n",
      "         [0.9802],\n",
      "         [0.9848],\n",
      "         [0.9760],\n",
      "         [0.9935],\n",
      "         [0.4707],\n",
      "         [1.0041],\n",
      "         [1.0060],\n",
      "         [1.0074],\n",
      "         [0.9924],\n",
      "         [1.0023],\n",
      "         [0.9996],\n",
      "         [0.3503],\n",
      "         [0.7877],\n",
      "         [0.9873],\n",
      "         [0.9860],\n",
      "         [0.9854],\n",
      "         [0.9876],\n",
      "         [0.9892],\n",
      "         [0.9902],\n",
      "         [0.9916],\n",
      "         [0.5219],\n",
      "         [0.9923],\n",
      "         [0.5434],\n",
      "         [0.9959],\n",
      "         [0.0608],\n",
      "         [0.9270],\n",
      "         [0.8646],\n",
      "         [1.0084],\n",
      "         [1.0093]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.3728],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9520],\n",
      "        [0.9999],\n",
      "        [0.2729],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9962],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.8223],\n",
      "        [0.5054],\n",
      "        [0.9997],\n",
      "        [0.4527],\n",
      "        [0.4642],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.9997],\n",
      "        [0.4580],\n",
      "        [0.3912],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.3875],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2735],\n",
      "        [0.2686],\n",
      "        [0.0247],\n",
      "        [0.5038],\n",
      "        [0.2208],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9997],\n",
      "        [0.5108],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.2610],\n",
      "        [0.5463],\n",
      "        [0.3747],\n",
      "        [0.8761],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [0.9998],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.4552],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.9996],\n",
      "        [0.4611],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.3780],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.7129],\n",
      "        [0.8296],\n",
      "        [0.9009],\n",
      "        [0.5334],\n",
      "        [0.6628],\n",
      "        [0.5080],\n",
      "        [0.0174],\n",
      "        [0.2547],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.9966],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.8379],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.0209],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.9994],\n",
      "        [0.9819],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.9994],\n",
      "        [0.4645],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.7540],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.9994],\n",
      "        [0.0335],\n",
      "        [0.8933],\n",
      "        [0.8139],\n",
      "        [0.9995],\n",
      "        [1.0000]])\n",
      "######### Epoch: 28  ######### Train Loss: 0.0006397697143256664  ######### Relative L2 Test Norm: 13.737318992614746\n",
      "Output batch pred: tensor([[[0.7821],\n",
      "         [1.0003],\n",
      "         [0.9976],\n",
      "         [0.9991],\n",
      "         [0.2667],\n",
      "         [0.7357],\n",
      "         [0.0534],\n",
      "         [0.3992],\n",
      "         [1.0054],\n",
      "         [0.4820],\n",
      "         [0.3998],\n",
      "         [1.0115],\n",
      "         [1.0109],\n",
      "         [0.5238],\n",
      "         [1.0055],\n",
      "         [0.2585],\n",
      "         [1.0000],\n",
      "         [0.8655],\n",
      "         [1.0004],\n",
      "         [1.0011],\n",
      "         [1.0012],\n",
      "         [0.0402],\n",
      "         [1.0122],\n",
      "         [1.0124],\n",
      "         [1.0081],\n",
      "         [0.6801],\n",
      "         [0.9943],\n",
      "         [0.9915],\n",
      "         [0.9829],\n",
      "         [0.9764],\n",
      "         [0.4277],\n",
      "         [0.9702],\n",
      "         [0.9734],\n",
      "         [0.9799],\n",
      "         [0.5047],\n",
      "         [0.3637],\n",
      "         [0.4661],\n",
      "         [0.2516],\n",
      "         [0.9899],\n",
      "         [0.9879],\n",
      "         [0.9826],\n",
      "         [0.9771],\n",
      "         [0.9732],\n",
      "         [0.9696],\n",
      "         [0.9685],\n",
      "         [0.4254],\n",
      "         [0.9748],\n",
      "         [0.9663],\n",
      "         [0.9864],\n",
      "         [0.9870],\n",
      "         [0.9889],\n",
      "         [0.8981],\n",
      "         [0.0246],\n",
      "         [0.9838],\n",
      "         [0.9803],\n",
      "         [0.9757],\n",
      "         [0.9781],\n",
      "         [0.9427],\n",
      "         [0.9817],\n",
      "         [0.9864],\n",
      "         [0.6909],\n",
      "         [0.9906],\n",
      "         [0.3696],\n",
      "         [0.0494],\n",
      "         [1.0051],\n",
      "         [0.3675],\n",
      "         [1.0073],\n",
      "         [1.0039],\n",
      "         [0.5742],\n",
      "         [0.5285],\n",
      "         [0.3866],\n",
      "         [0.4502],\n",
      "         [0.9806],\n",
      "         [0.9882],\n",
      "         [0.7736],\n",
      "         [0.3548],\n",
      "         [0.9813],\n",
      "         [0.0430],\n",
      "         [0.9739],\n",
      "         [0.9904],\n",
      "         [0.9953],\n",
      "         [0.0859],\n",
      "         [1.0100],\n",
      "         [0.0783],\n",
      "         [1.0023],\n",
      "         [0.0910],\n",
      "         [0.4762],\n",
      "         [1.0023],\n",
      "         [0.2456],\n",
      "         [0.9478],\n",
      "         [0.9800],\n",
      "         [0.9717],\n",
      "         [0.9718],\n",
      "         [0.9711],\n",
      "         [0.7937],\n",
      "         [0.8974],\n",
      "         [0.8339],\n",
      "         [0.9874],\n",
      "         [0.9928],\n",
      "         [0.9963],\n",
      "         [1.0030],\n",
      "         [1.0023],\n",
      "         [1.0063],\n",
      "         [1.0073],\n",
      "         [0.5280],\n",
      "         [1.0043],\n",
      "         [0.3843],\n",
      "         [0.9989],\n",
      "         [0.9599],\n",
      "         [0.9898],\n",
      "         [0.9861],\n",
      "         [0.8495],\n",
      "         [0.9838],\n",
      "         [0.9857],\n",
      "         [0.9884],\n",
      "         [0.0111],\n",
      "         [0.9999],\n",
      "         [1.0048],\n",
      "         [0.5743],\n",
      "         [0.5254],\n",
      "         [1.0108],\n",
      "         [0.5277],\n",
      "         [0.5569],\n",
      "         [0.4543],\n",
      "         [0.2562],\n",
      "         [0.3795],\n",
      "         [0.4953],\n",
      "         [0.9824],\n",
      "         [0.9750],\n",
      "         [0.9736],\n",
      "         [0.9693],\n",
      "         [0.9628],\n",
      "         [0.1981],\n",
      "         [0.8847],\n",
      "         [0.9639],\n",
      "         [0.9650],\n",
      "         [0.9746],\n",
      "         [0.9835],\n",
      "         [0.9936],\n",
      "         [0.7614],\n",
      "         [0.5484],\n",
      "         [0.2659],\n",
      "         [0.9657],\n",
      "         [0.2743],\n",
      "         [1.0120],\n",
      "         [1.0029],\n",
      "         [0.9899],\n",
      "         [0.9795],\n",
      "         [0.9665],\n",
      "         [0.9623],\n",
      "         [0.9599],\n",
      "         [0.9428],\n",
      "         [0.9679],\n",
      "         [0.9755],\n",
      "         [0.9858],\n",
      "         [0.3683],\n",
      "         [0.1922],\n",
      "         [0.8855],\n",
      "         [1.0113],\n",
      "         [0.2425],\n",
      "         [0.7123],\n",
      "         [0.4937],\n",
      "         [0.9724],\n",
      "         [0.4615],\n",
      "         [0.9935],\n",
      "         [0.4293],\n",
      "         [0.9800],\n",
      "         [0.9757],\n",
      "         [0.4728],\n",
      "         [0.5772],\n",
      "         [0.9681],\n",
      "         [0.9671],\n",
      "         [0.9707],\n",
      "         [0.4887],\n",
      "         [0.9809],\n",
      "         [0.3298],\n",
      "         [0.9914],\n",
      "         [0.9244]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.7391],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.6920],\n",
      "        [0.0209],\n",
      "        [0.3912],\n",
      "        [0.9996],\n",
      "        [0.4580],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9997],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.3747],\n",
      "        [0.4642],\n",
      "        [0.2646],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.9520],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.0288],\n",
      "        [0.9997],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5463],\n",
      "        [0.5108],\n",
      "        [0.3875],\n",
      "        [0.4503],\n",
      "        [0.9819],\n",
      "        [0.9998],\n",
      "        [0.7540],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.9820],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9804],\n",
      "        [0.0368],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [0.2547],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.8933],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.8296],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.5245],\n",
      "        [0.4480],\n",
      "        [0.2686],\n",
      "        [0.3930],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.2577],\n",
      "        [0.9044],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.9994],\n",
      "        [0.7129],\n",
      "        [0.5151],\n",
      "        [0.2518],\n",
      "        [0.9164],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.1762],\n",
      "        [0.8379],\n",
      "        [0.9999],\n",
      "        [0.2208],\n",
      "        [0.6555],\n",
      "        [0.4668],\n",
      "        [0.9515],\n",
      "        [0.4552],\n",
      "        [0.9997],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.5080],\n",
      "        [0.5945],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.5165],\n",
      "        [0.9999],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.9009]])\n",
      "######### Epoch: 29  ######### Train Loss: 0.000515059451572597  ######### Relative L2 Test Norm: 15.511462211608887\n",
      "Output batch pred: tensor([[[ 0.4199],\n",
      "         [ 0.6308],\n",
      "         [ 0.9779],\n",
      "         [ 0.1974],\n",
      "         [ 0.9740],\n",
      "         [ 0.9749],\n",
      "         [ 0.9757],\n",
      "         [ 0.9789],\n",
      "         [ 0.9807],\n",
      "         [ 0.9098],\n",
      "         [ 0.9868],\n",
      "         [ 0.0249],\n",
      "         [ 0.9023],\n",
      "         [ 0.9546],\n",
      "         [ 0.9843],\n",
      "         [ 0.2201],\n",
      "         [ 0.9823],\n",
      "         [ 0.0087],\n",
      "         [ 0.9778],\n",
      "         [ 0.4857],\n",
      "         [ 0.9764],\n",
      "         [ 0.9720],\n",
      "         [ 0.9719],\n",
      "         [ 0.3292],\n",
      "         [ 0.9776],\n",
      "         [ 0.9778],\n",
      "         [ 0.9824],\n",
      "         [ 0.9848],\n",
      "         [ 0.9906],\n",
      "         [ 0.9941],\n",
      "         [ 0.5239],\n",
      "         [ 0.3763],\n",
      "         [ 0.4703],\n",
      "         [ 1.0005],\n",
      "         [ 0.7582],\n",
      "         [ 0.9966],\n",
      "         [ 0.5327],\n",
      "         [ 0.9860],\n",
      "         [ 0.3356],\n",
      "         [ 0.9763],\n",
      "         [ 0.3475],\n",
      "         [ 0.7902],\n",
      "         [ 0.9721],\n",
      "         [ 0.9745],\n",
      "         [ 0.9757],\n",
      "         [ 0.5262],\n",
      "         [ 0.9776],\n",
      "         [ 0.3221],\n",
      "         [ 0.8432],\n",
      "         [ 0.9837],\n",
      "         [ 0.9866],\n",
      "         [ 0.9900],\n",
      "         [ 0.9933],\n",
      "         [ 0.9835],\n",
      "         [ 0.3410],\n",
      "         [ 0.9944],\n",
      "         [ 0.9937],\n",
      "         [ 0.9860],\n",
      "         [ 0.9189],\n",
      "         [ 0.9531],\n",
      "         [ 0.9617],\n",
      "         [ 0.9565],\n",
      "         [ 0.9515],\n",
      "         [ 0.3098],\n",
      "         [ 0.9636],\n",
      "         [ 0.9737],\n",
      "         [ 0.2404],\n",
      "         [ 0.4671],\n",
      "         [ 0.4702],\n",
      "         [ 1.0100],\n",
      "         [ 0.8885],\n",
      "         [ 1.0072],\n",
      "         [ 0.9994],\n",
      "         [ 0.5510],\n",
      "         [ 0.4263],\n",
      "         [ 0.8383],\n",
      "         [ 0.9809],\n",
      "         [ 0.9822],\n",
      "         [ 0.4445],\n",
      "         [ 0.9773],\n",
      "         [ 0.9180],\n",
      "         [ 0.9796],\n",
      "         [ 0.9910],\n",
      "         [ 0.2333],\n",
      "         [ 0.9872],\n",
      "         [ 0.9857],\n",
      "         [ 0.0082],\n",
      "         [ 0.6058],\n",
      "         [ 0.3707],\n",
      "         [ 0.9623],\n",
      "         [ 1.0075],\n",
      "         [ 0.7569],\n",
      "         [ 0.2703],\n",
      "         [ 0.8127],\n",
      "         [ 1.0067],\n",
      "         [ 0.1616],\n",
      "         [ 0.9796],\n",
      "         [ 0.9730],\n",
      "         [ 0.9643],\n",
      "         [ 0.9555],\n",
      "         [ 0.9607],\n",
      "         [ 0.9670],\n",
      "         [ 0.9727],\n",
      "         [ 0.9834],\n",
      "         [ 0.0465],\n",
      "         [ 0.0380],\n",
      "         [ 1.0000],\n",
      "         [ 1.0003],\n",
      "         [ 0.9953],\n",
      "         [ 0.9536],\n",
      "         [ 0.9824],\n",
      "         [ 0.9772],\n",
      "         [ 0.6513],\n",
      "         [ 0.9773],\n",
      "         [ 0.9786],\n",
      "         [ 0.4903],\n",
      "         [ 0.9888],\n",
      "         [ 0.9904],\n",
      "         [ 0.9884],\n",
      "         [ 0.4983],\n",
      "         [ 0.4729],\n",
      "         [ 0.9724],\n",
      "         [ 0.9643],\n",
      "         [ 0.9607],\n",
      "         [ 0.9640],\n",
      "         [-0.0315],\n",
      "         [ 0.9771],\n",
      "         [ 0.9850],\n",
      "         [ 0.5001],\n",
      "         [ 0.8637],\n",
      "         [ 0.2355],\n",
      "         [ 0.2002],\n",
      "         [ 0.4307],\n",
      "         [ 0.9817],\n",
      "         [ 0.9686],\n",
      "         [ 0.9659],\n",
      "         [ 0.9633],\n",
      "         [ 0.9642],\n",
      "         [ 0.4527],\n",
      "         [ 0.7446],\n",
      "         [ 0.4836],\n",
      "         [ 0.9899],\n",
      "         [ 0.0581],\n",
      "         [ 0.0612],\n",
      "         [ 0.9999],\n",
      "         [ 0.2553],\n",
      "         [ 0.9893],\n",
      "         [ 0.9520],\n",
      "         [ 0.9818],\n",
      "         [ 0.2199],\n",
      "         [ 0.4117],\n",
      "         [ 0.9771],\n",
      "         [ 0.6675],\n",
      "         [ 0.3529],\n",
      "         [ 0.3355],\n",
      "         [ 0.3370],\n",
      "         [ 0.9741],\n",
      "         [ 0.8993],\n",
      "         [ 0.9740],\n",
      "         [ 0.9720],\n",
      "         [ 0.9771],\n",
      "         [ 0.9621],\n",
      "         [ 0.4301],\n",
      "         [ 0.9909],\n",
      "         [ 0.5087],\n",
      "         [ 0.0354],\n",
      "         [ 0.9969],\n",
      "         [ 0.9934],\n",
      "         [ 0.9902],\n",
      "         [ 0.9824],\n",
      "         [ 0.9792],\n",
      "         [ 0.9752],\n",
      "         [ 0.4210],\n",
      "         [ 0.4542],\n",
      "         [ 0.9696],\n",
      "         [ 0.9758],\n",
      "         [ 0.9788],\n",
      "         [ 0.9803]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.4527],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [0.8933],\n",
      "        [0.9962],\n",
      "        [0.0247],\n",
      "        [0.8761],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9997],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5165],\n",
      "        [0.3808],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.5463],\n",
      "        [0.9999],\n",
      "        [0.3575],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [0.3573],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9164],\n",
      "        [0.9814],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.9959],\n",
      "        [0.9999],\n",
      "        [0.2735],\n",
      "        [0.4642],\n",
      "        [0.4580],\n",
      "        [0.9995],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.4454],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.4645],\n",
      "        [0.9819],\n",
      "        [0.9009],\n",
      "        [0.9804],\n",
      "        [0.9994],\n",
      "        [0.2646],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.0174],\n",
      "        [0.5945],\n",
      "        [0.3875],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.2577],\n",
      "        [0.7540],\n",
      "        [0.9997],\n",
      "        [0.1762],\n",
      "        [0.9956],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.0335],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5139],\n",
      "        [0.5030],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5080],\n",
      "        [0.8296],\n",
      "        [0.2518],\n",
      "        [0.2208],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.7391],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [0.9998],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.3912],\n",
      "        [0.3753],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.4988],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]])\n",
      "######### Epoch: 30  ######### Train Loss: 0.0006325332797132432  ######### Relative L2 Test Norm: 16.531713485717773\n",
      "Output batch pred: tensor([[[ 0.9740],\n",
      "         [ 0.2045],\n",
      "         [ 0.5015],\n",
      "         [ 0.9680],\n",
      "         [ 0.9639],\n",
      "         [ 0.3279],\n",
      "         [ 0.4025],\n",
      "         [ 0.9811],\n",
      "         [ 0.9816],\n",
      "         [ 0.5283],\n",
      "         [ 0.4794],\n",
      "         [ 0.4159],\n",
      "         [ 0.9753],\n",
      "         [ 0.9725],\n",
      "         [-0.0137],\n",
      "         [ 0.9733],\n",
      "         [ 0.9740],\n",
      "         [ 0.9732],\n",
      "         [ 0.9768],\n",
      "         [ 0.9828],\n",
      "         [ 0.9817],\n",
      "         [ 0.9849],\n",
      "         [ 0.3329],\n",
      "         [ 0.4848],\n",
      "         [ 0.9761],\n",
      "         [ 0.2972],\n",
      "         [ 0.9754],\n",
      "         [ 0.9138],\n",
      "         [ 0.9757],\n",
      "         [ 0.9777],\n",
      "         [ 0.4931],\n",
      "         [ 0.2278],\n",
      "         [ 0.9662],\n",
      "         [ 0.9844],\n",
      "         [ 0.4351],\n",
      "         [ 0.8395],\n",
      "         [ 0.9784],\n",
      "         [ 0.9768],\n",
      "         [ 0.4592],\n",
      "         [ 0.9753],\n",
      "         [-0.0156],\n",
      "         [ 0.9796],\n",
      "         [ 0.9852],\n",
      "         [ 0.3247],\n",
      "         [ 0.7352],\n",
      "         [ 0.9797],\n",
      "         [ 0.9817],\n",
      "         [ 0.9436],\n",
      "         [ 0.9773],\n",
      "         [ 0.9770],\n",
      "         [ 0.9756],\n",
      "         [ 0.9023],\n",
      "         [ 0.9859],\n",
      "         [ 0.9903],\n",
      "         [ 0.9933],\n",
      "         [ 0.0179],\n",
      "         [ 0.9904],\n",
      "         [ 0.9890],\n",
      "         [ 0.9832],\n",
      "         [ 0.4767],\n",
      "         [ 0.9781],\n",
      "         [ 0.9737],\n",
      "         [ 0.9776],\n",
      "         [ 0.0076],\n",
      "         [ 0.9100],\n",
      "         [ 0.9490],\n",
      "         [ 0.3679],\n",
      "         [ 0.9937],\n",
      "         [ 0.9906],\n",
      "         [ 0.4522],\n",
      "         [ 0.9860],\n",
      "         [ 0.9818],\n",
      "         [ 0.9816],\n",
      "         [ 0.9443],\n",
      "         [-0.0073],\n",
      "         [ 0.9903],\n",
      "         [ 0.9964],\n",
      "         [ 1.0017],\n",
      "         [ 0.9911],\n",
      "         [ 0.4598],\n",
      "         [ 0.9972],\n",
      "         [ 0.3519],\n",
      "         [ 0.9791],\n",
      "         [ 0.9720],\n",
      "         [ 0.9628],\n",
      "         [ 0.9610],\n",
      "         [ 0.9623],\n",
      "         [ 0.9683],\n",
      "         [ 0.9764],\n",
      "         [ 0.4423],\n",
      "         [ 0.9925],\n",
      "         [ 0.5351],\n",
      "         [ 0.4352],\n",
      "         [ 0.4876],\n",
      "         [ 0.9816],\n",
      "         [ 0.9714],\n",
      "         [ 0.9600],\n",
      "         [ 0.9555],\n",
      "         [ 0.9540],\n",
      "         [ 0.9584],\n",
      "         [ 0.9654],\n",
      "         [ 0.3233],\n",
      "         [ 0.9870],\n",
      "         [ 0.9948],\n",
      "         [ 0.0434],\n",
      "         [ 0.5050],\n",
      "         [ 0.6538],\n",
      "         [ 0.9888],\n",
      "         [ 0.9818],\n",
      "         [ 0.9746],\n",
      "         [ 0.9691],\n",
      "         [ 0.9683],\n",
      "         [ 0.6589],\n",
      "         [ 0.9626],\n",
      "         [ 0.3469],\n",
      "         [ 0.6704],\n",
      "         [ 0.9939],\n",
      "         [ 0.9927],\n",
      "         [ 0.6026],\n",
      "         [ 0.9841],\n",
      "         [ 0.4743],\n",
      "         [ 0.1877],\n",
      "         [ 0.3950],\n",
      "         [ 0.9668],\n",
      "         [ 0.7826],\n",
      "         [ 0.9749],\n",
      "         [ 0.0149],\n",
      "         [ 0.0179],\n",
      "         [ 0.9169],\n",
      "         [ 0.9919],\n",
      "         [ 0.9800],\n",
      "         [ 0.9876],\n",
      "         [ 0.4854],\n",
      "         [ 0.4149],\n",
      "         [ 0.9813],\n",
      "         [ 0.9800],\n",
      "         [ 0.3482],\n",
      "         [ 0.7112],\n",
      "         [ 0.2251],\n",
      "         [ 0.9774],\n",
      "         [ 0.9895],\n",
      "         [ 0.4390],\n",
      "         [ 0.4938],\n",
      "         [ 0.8434],\n",
      "         [ 0.9743],\n",
      "         [ 0.8258],\n",
      "         [ 0.9681],\n",
      "         [ 0.9676],\n",
      "         [ 0.9712],\n",
      "         [ 0.0023],\n",
      "         [ 0.1650],\n",
      "         [ 0.9804],\n",
      "         [ 0.2212],\n",
      "         [ 0.3310],\n",
      "         [ 0.9797],\n",
      "         [ 0.7566],\n",
      "         [ 0.9709],\n",
      "         [ 0.9669],\n",
      "         [ 0.2960],\n",
      "         [ 0.8738],\n",
      "         [ 0.9717],\n",
      "         [ 0.9774],\n",
      "         [ 0.9761],\n",
      "         [ 0.9839],\n",
      "         [ 0.8345],\n",
      "         [ 0.2085],\n",
      "         [ 0.9818],\n",
      "         [ 0.7447],\n",
      "         [ 0.9703],\n",
      "         [ 0.9690],\n",
      "         [ 0.1804],\n",
      "         [ 0.1070],\n",
      "         [ 0.9764],\n",
      "         [ 0.9792],\n",
      "         [ 0.9463],\n",
      "         [ 0.9810],\n",
      "         [ 0.2032],\n",
      "         [ 0.9811]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.2735],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.3875],\n",
      "        [0.4480],\n",
      "        [0.9996],\n",
      "        [0.9966],\n",
      "        [0.5334],\n",
      "        [0.5030],\n",
      "        [0.4503],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.5139],\n",
      "        [0.9959],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5151],\n",
      "        [0.2729],\n",
      "        [0.9724],\n",
      "        [0.9998],\n",
      "        [0.4645],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.9044],\n",
      "        [0.9420],\n",
      "        [0.3912],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9520],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.4454],\n",
      "        [0.5009],\n",
      "        [0.9996],\n",
      "        [0.9994],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.0383],\n",
      "        [0.5054],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.6628],\n",
      "        [0.9814],\n",
      "        [0.3840],\n",
      "        [0.6555],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.5945],\n",
      "        [0.9997],\n",
      "        [0.5108],\n",
      "        [0.2547],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.0174],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [0.5080],\n",
      "        [0.4527],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.3930],\n",
      "        [0.6920],\n",
      "        [0.2646],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.5165],\n",
      "        [0.8379],\n",
      "        [0.9997],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.3753],\n",
      "        [0.9994],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.8761],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2577],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9490],\n",
      "        [0.9999],\n",
      "        [0.2518],\n",
      "        [0.9998]])\n",
      "######### Epoch: 31  ######### Train Loss: 0.000786172051448375  ######### Relative L2 Test Norm: 16.793785095214844\n",
      "Output batch pred: tensor([[[ 3.3241e-01],\n",
      "         [ 4.9950e-01],\n",
      "         [ 5.8837e-01],\n",
      "         [ 9.8776e-01],\n",
      "         [ 4.7999e-01],\n",
      "         [ 9.9243e-01],\n",
      "         [ 9.9463e-01],\n",
      "         [ 9.9433e-01],\n",
      "         [ 3.4692e-01],\n",
      "         [ 9.9169e-01],\n",
      "         [ 9.9617e-01],\n",
      "         [ 3.4596e-01],\n",
      "         [ 9.9459e-01],\n",
      "         [ 1.3951e-01],\n",
      "         [ 9.9204e-01],\n",
      "         [ 4.3466e-01],\n",
      "         [ 9.8539e-01],\n",
      "         [ 9.8255e-01],\n",
      "         [ 6.5112e-01],\n",
      "         [ 4.5741e-01],\n",
      "         [ 6.1652e-01],\n",
      "         [ 2.9014e-01],\n",
      "         [-1.8871e-03],\n",
      "         [ 9.6305e-01],\n",
      "         [ 9.5774e-01],\n",
      "         [ 9.6069e-01],\n",
      "         [ 9.6091e-01],\n",
      "         [ 9.5888e-01],\n",
      "         [ 9.6348e-01],\n",
      "         [ 9.6856e-01],\n",
      "         [ 9.7391e-01],\n",
      "         [ 4.7477e-01],\n",
      "         [ 9.8429e-01],\n",
      "         [ 9.8917e-01],\n",
      "         [ 9.8862e-01],\n",
      "         [ 9.1805e-01],\n",
      "         [ 9.9123e-01],\n",
      "         [ 4.7376e-01],\n",
      "         [ 9.8473e-01],\n",
      "         [ 8.9772e-01],\n",
      "         [ 7.1126e-01],\n",
      "         [ 9.6712e-01],\n",
      "         [ 4.9055e-01],\n",
      "         [ 9.6238e-01],\n",
      "         [ 9.6160e-01],\n",
      "         [ 9.6597e-01],\n",
      "         [ 9.6865e-01],\n",
      "         [ 9.7562e-01],\n",
      "         [ 9.8286e-01],\n",
      "         [ 3.3388e-01],\n",
      "         [ 4.4336e-01],\n",
      "         [ 2.2449e-01],\n",
      "         [ 9.9801e-01],\n",
      "         [-6.5210e-04],\n",
      "         [ 5.0344e-01],\n",
      "         [ 9.9208e-01],\n",
      "         [ 8.5206e-03],\n",
      "         [ 9.8455e-01],\n",
      "         [ 9.8147e-01],\n",
      "         [ 2.1208e-01],\n",
      "         [ 1.8742e-01],\n",
      "         [ 9.7210e-01],\n",
      "         [ 9.7541e-01],\n",
      "         [ 4.7582e-01],\n",
      "         [ 9.7871e-01],\n",
      "         [-3.7023e-03],\n",
      "         [ 9.8455e-01],\n",
      "         [ 9.8918e-01],\n",
      "         [ 2.1893e-01],\n",
      "         [ 9.9553e-01],\n",
      "         [ 4.4519e-01],\n",
      "         [ 2.5715e-01],\n",
      "         [ 1.0052e+00],\n",
      "         [ 1.0062e+00],\n",
      "         [ 1.0045e+00],\n",
      "         [ 2.3410e-01],\n",
      "         [ 9.6466e-01],\n",
      "         [ 9.8250e-01],\n",
      "         [ 9.8383e-01],\n",
      "         [ 9.7593e-01],\n",
      "         [ 9.0104e-01],\n",
      "         [ 9.7056e-01],\n",
      "         [ 9.7341e-01],\n",
      "         [ 9.7407e-01],\n",
      "         [ 9.7990e-01],\n",
      "         [ 4.8237e-01],\n",
      "         [ 9.9307e-01],\n",
      "         [ 9.9973e-01],\n",
      "         [ 1.3329e-02],\n",
      "         [ 1.0088e+00],\n",
      "         [ 9.5272e-01],\n",
      "         [ 1.0074e+00],\n",
      "         [ 1.0032e+00],\n",
      "         [ 8.6775e-01],\n",
      "         [ 6.8308e-01],\n",
      "         [ 9.7929e-01],\n",
      "         [ 9.7341e-01],\n",
      "         [ 9.7128e-01],\n",
      "         [ 9.6501e-01],\n",
      "         [ 9.6786e-01],\n",
      "         [ 9.6982e-01],\n",
      "         [ 9.7287e-01],\n",
      "         [ 7.5299e-01],\n",
      "         [ 9.7835e-01],\n",
      "         [ 9.7893e-01],\n",
      "         [ 9.8186e-01],\n",
      "         [ 9.8127e-01],\n",
      "         [-1.2185e-02],\n",
      "         [ 9.7786e-01],\n",
      "         [ 4.7132e-01],\n",
      "         [ 8.7889e-01],\n",
      "         [ 9.7077e-01],\n",
      "         [ 9.7377e-01],\n",
      "         [ 9.7420e-01],\n",
      "         [ 3.8731e-01],\n",
      "         [ 9.7170e-01],\n",
      "         [ 7.8790e-01],\n",
      "         [ 9.7161e-01],\n",
      "         [ 9.6747e-01],\n",
      "         [ 3.0865e-01],\n",
      "         [ 4.4737e-01],\n",
      "         [ 3.1823e-01],\n",
      "         [ 9.6673e-01],\n",
      "         [ 8.1789e-01],\n",
      "         [ 3.9117e-01],\n",
      "         [ 9.5262e-01],\n",
      "         [ 9.7540e-01],\n",
      "         [ 9.8128e-01],\n",
      "         [ 3.2505e-01],\n",
      "         [ 4.2821e-01],\n",
      "         [ 4.4385e-01],\n",
      "         [ 4.8992e-01],\n",
      "         [ 9.9106e-01],\n",
      "         [ 9.7958e-01],\n",
      "         [ 9.5447e-01],\n",
      "         [ 4.2407e-01],\n",
      "         [ 9.8318e-01],\n",
      "         [ 7.0261e-01],\n",
      "         [ 9.7381e-01],\n",
      "         [ 9.5909e-01],\n",
      "         [ 8.0201e-03],\n",
      "         [ 9.7580e-01],\n",
      "         [ 7.4255e-01],\n",
      "         [ 9.8048e-01],\n",
      "         [ 9.4017e-01],\n",
      "         [ 2.2668e-01],\n",
      "         [ 9.7108e-01],\n",
      "         [ 3.4858e-01],\n",
      "         [ 2.3290e-02],\n",
      "         [ 3.5474e-01],\n",
      "         [ 1.0635e-02],\n",
      "         [ 8.2682e-01],\n",
      "         [ 9.7377e-01],\n",
      "         [ 8.3178e-01],\n",
      "         [ 9.7137e-01],\n",
      "         [ 9.6919e-01],\n",
      "         [ 2.8658e-01],\n",
      "         [ 9.6784e-01],\n",
      "         [ 9.6733e-01],\n",
      "         [ 9.7155e-01],\n",
      "         [ 9.7385e-01],\n",
      "         [ 1.4854e-01],\n",
      "         [ 9.8283e-01],\n",
      "         [ 9.8745e-01],\n",
      "         [ 9.9031e-01],\n",
      "         [ 9.9156e-01],\n",
      "         [ 2.1736e-01],\n",
      "         [ 4.1904e-01],\n",
      "         [ 5.2975e-01],\n",
      "         [ 9.8763e-01],\n",
      "         [ 9.8700e-01],\n",
      "         [ 9.8334e-01],\n",
      "         [ 9.7981e-01],\n",
      "         [ 9.3954e-01],\n",
      "         [ 4.0834e-01],\n",
      "         [ 9.7266e-01],\n",
      "         [ 9.7351e-01],\n",
      "         [ 9.7423e-01]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.3930],\n",
      "        [0.5245],\n",
      "        [0.5945],\n",
      "        [0.9995],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.4988],\n",
      "        [0.6327],\n",
      "        [0.3573],\n",
      "        [0.0368],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.9996],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.3747],\n",
      "        [0.4645],\n",
      "        [0.2610],\n",
      "        [0.9995],\n",
      "        [0.0000],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [0.2518],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.9520],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.6628],\n",
      "        [0.9999],\n",
      "        [0.9966],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [0.5151],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.5030],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.4527],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.4580],\n",
      "        [0.4642],\n",
      "        [0.5054],\n",
      "        [0.9959],\n",
      "        [0.9804],\n",
      "        [0.9515],\n",
      "        [0.4552],\n",
      "        [0.9997],\n",
      "        [0.6920],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.2686],\n",
      "        [0.9820],\n",
      "        [0.3840],\n",
      "        [0.0288],\n",
      "        [0.3912],\n",
      "        [0.0209],\n",
      "        [0.8139],\n",
      "        [0.9999],\n",
      "        [0.8296],\n",
      "        [0.9994],\n",
      "        [0.9994],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [0.4480],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9490],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]])\n",
      "######### Epoch: 32  ######### Train Loss: 0.0008188996580429375  ######### Relative L2 Test Norm: 15.448026657104492\n",
      "Output batch pred: tensor([[[ 0.9763],\n",
      "         [ 0.9806],\n",
      "         [ 0.3171],\n",
      "         [ 0.9866],\n",
      "         [ 0.1672],\n",
      "         [ 0.9906],\n",
      "         [ 0.9902],\n",
      "         [ 0.3079],\n",
      "         [ 0.9863],\n",
      "         [ 0.4040],\n",
      "         [ 0.9822],\n",
      "         [ 0.9837],\n",
      "         [ 0.9835],\n",
      "         [ 0.9872],\n",
      "         [ 0.9892],\n",
      "         [ 0.9943],\n",
      "         [ 0.9973],\n",
      "         [ 0.9029],\n",
      "         [ 0.6825],\n",
      "         [ 0.9734],\n",
      "         [ 0.4770],\n",
      "         [ 0.2078],\n",
      "         [ 0.4230],\n",
      "         [ 0.3404],\n",
      "         [ 0.9793],\n",
      "         [ 0.9804],\n",
      "         [ 0.5204],\n",
      "         [ 0.9913],\n",
      "         [ 0.9597],\n",
      "         [ 0.5021],\n",
      "         [ 0.2406],\n",
      "         [ 0.3693],\n",
      "         [ 0.0197],\n",
      "         [ 0.9845],\n",
      "         [ 0.0013],\n",
      "         [ 0.5808],\n",
      "         [ 0.9769],\n",
      "         [ 0.8194],\n",
      "         [ 0.9638],\n",
      "         [ 0.4593],\n",
      "         [ 0.9859],\n",
      "         [ 0.3410],\n",
      "         [ 1.0008],\n",
      "         [ 1.0047],\n",
      "         [ 1.0065],\n",
      "         [ 0.4440],\n",
      "         [ 0.9990],\n",
      "         [ 0.9932],\n",
      "         [ 0.4910],\n",
      "         [ 0.9881],\n",
      "         [ 0.4022],\n",
      "         [ 0.3205],\n",
      "         [ 0.7568],\n",
      "         [ 0.5312],\n",
      "         [ 0.9930],\n",
      "         [ 0.9931],\n",
      "         [ 0.8587],\n",
      "         [ 0.9892],\n",
      "         [ 0.9833],\n",
      "         [ 0.9794],\n",
      "         [ 0.1880],\n",
      "         [ 0.9722],\n",
      "         [ 0.9732],\n",
      "         [ 0.9770],\n",
      "         [ 0.9804],\n",
      "         [-0.0175],\n",
      "         [ 0.0113],\n",
      "         [ 1.0048],\n",
      "         [ 0.0396],\n",
      "         [ 1.0104],\n",
      "         [ 1.0045],\n",
      "         [ 1.0002],\n",
      "         [ 0.9936],\n",
      "         [ 0.6537],\n",
      "         [ 0.4572],\n",
      "         [ 0.9740],\n",
      "         [ 0.9723],\n",
      "         [ 0.9730],\n",
      "         [ 0.4865],\n",
      "         [ 0.9806],\n",
      "         [ 0.9813],\n",
      "         [ 0.9897],\n",
      "         [ 0.9878],\n",
      "         [ 0.2227],\n",
      "         [ 0.9909],\n",
      "         [ 0.9751],\n",
      "         [ 0.3253],\n",
      "         [ 0.9832],\n",
      "         [ 0.4154],\n",
      "         [ 0.9765],\n",
      "         [-0.0033],\n",
      "         [ 0.9749],\n",
      "         [ 0.9728],\n",
      "         [ 0.4161],\n",
      "         [ 0.9768],\n",
      "         [ 0.8333],\n",
      "         [ 0.9767],\n",
      "         [ 0.9822],\n",
      "         [ 0.7984],\n",
      "         [ 0.4779],\n",
      "         [ 0.9853],\n",
      "         [ 0.9889],\n",
      "         [ 0.4909],\n",
      "         [ 0.3169],\n",
      "         [ 0.4209],\n",
      "         [ 0.9865],\n",
      "         [ 0.9850],\n",
      "         [ 0.4080],\n",
      "         [ 0.9838],\n",
      "         [ 0.9849],\n",
      "         [ 0.3319],\n",
      "         [ 0.9872],\n",
      "         [ 0.9901],\n",
      "         [ 0.7703],\n",
      "         [ 0.9783],\n",
      "         [ 0.2041],\n",
      "         [ 0.9870],\n",
      "         [ 0.0056],\n",
      "         [ 0.1250],\n",
      "         [ 0.4055],\n",
      "         [ 0.9742],\n",
      "         [ 0.9723],\n",
      "         [ 0.9413],\n",
      "         [ 0.9482],\n",
      "         [ 0.9898],\n",
      "         [ 0.9943],\n",
      "         [ 0.6556],\n",
      "         [ 1.0058],\n",
      "         [ 0.0380],\n",
      "         [ 1.0068],\n",
      "         [ 0.2317],\n",
      "         [ 0.2212],\n",
      "         [ 0.7411],\n",
      "         [ 0.9898],\n",
      "         [ 0.9861],\n",
      "         [ 0.9818],\n",
      "         [ 0.9836],\n",
      "         [ 0.4722],\n",
      "         [ 0.9871],\n",
      "         [ 0.9120],\n",
      "         [ 0.9945],\n",
      "         [ 0.9225],\n",
      "         [ 0.2183],\n",
      "         [ 0.9965],\n",
      "         [ 0.9961],\n",
      "         [ 0.9950],\n",
      "         [ 0.7190],\n",
      "         [ 0.3347],\n",
      "         [ 0.8571],\n",
      "         [ 0.9949],\n",
      "         [ 0.4845],\n",
      "         [ 0.9971],\n",
      "         [ 0.9227],\n",
      "         [ 0.9955],\n",
      "         [ 0.9907],\n",
      "         [ 0.9906],\n",
      "         [ 0.9847],\n",
      "         [ 0.9816],\n",
      "         [ 0.9830],\n",
      "         [ 0.9836],\n",
      "         [ 0.9858],\n",
      "         [ 0.9865],\n",
      "         [-0.0055],\n",
      "         [ 0.9984],\n",
      "         [ 1.0040],\n",
      "         [ 0.4551],\n",
      "         [ 1.0083],\n",
      "         [ 0.9950],\n",
      "         [ 1.0048],\n",
      "         [ 0.9987],\n",
      "         [ 0.9932],\n",
      "         [ 0.3283],\n",
      "         [ 0.9378],\n",
      "         [ 0.9107],\n",
      "         [ 0.9659],\n",
      "         [ 0.9672],\n",
      "         [ 0.4407],\n",
      "         [ 0.9682]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.6628],\n",
      "        [0.9724],\n",
      "        [0.5054],\n",
      "        [0.2610],\n",
      "        [0.4645],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [0.9997],\n",
      "        [0.9490],\n",
      "        [0.5108],\n",
      "        [0.2686],\n",
      "        [0.3912],\n",
      "        [0.0174],\n",
      "        [0.9956],\n",
      "        [0.0142],\n",
      "        [0.5945],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [0.9820],\n",
      "        [0.4988],\n",
      "        [0.9959],\n",
      "        [0.3747],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.3753],\n",
      "        [0.7391],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.0209],\n",
      "        [0.9997],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.5080],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.9999],\n",
      "        [0.9814],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [0.4668],\n",
      "        [0.9999],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [0.9997],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.7820],\n",
      "        [0.5139],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.3575],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.7540],\n",
      "        [0.9819],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.1762],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.2547],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.9967],\n",
      "        [0.8933],\n",
      "        [0.9994],\n",
      "        [0.9044],\n",
      "        [0.2646],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.6920],\n",
      "        [0.3780],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.9420],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.9997]])\n",
      "######### Epoch: 33  ######### Train Loss: 0.0006561555783264339  ######### Relative L2 Test Norm: 15.112585067749023\n",
      "Output batch pred: tensor([[[ 0.7547],\n",
      "         [ 1.0082],\n",
      "         [ 1.0079],\n",
      "         [ 0.4965],\n",
      "         [ 0.1460],\n",
      "         [ 0.4239],\n",
      "         [ 0.9951],\n",
      "         [ 0.9914],\n",
      "         [ 0.9724],\n",
      "         [ 0.4815],\n",
      "         [ 0.9819],\n",
      "         [ 0.3150],\n",
      "         [ 0.1888],\n",
      "         [ 0.9847],\n",
      "         [ 0.9860],\n",
      "         [ 0.9887],\n",
      "         [ 0.8976],\n",
      "         [ 0.9948],\n",
      "         [ 0.9995],\n",
      "         [ 1.0087],\n",
      "         [ 1.0146],\n",
      "         [ 0.0392],\n",
      "         [ 1.0219],\n",
      "         [ 1.0196],\n",
      "         [ 0.4704],\n",
      "         [ 0.5477],\n",
      "         [ 1.0069],\n",
      "         [ 0.7665],\n",
      "         [ 0.9881],\n",
      "         [ 0.9798],\n",
      "         [ 0.9307],\n",
      "         [ 0.9696],\n",
      "         [-0.0178],\n",
      "         [ 0.9770],\n",
      "         [ 0.3437],\n",
      "         [ 0.9760],\n",
      "         [ 0.5456],\n",
      "         [ 0.3686],\n",
      "         [ 1.0156],\n",
      "         [ 0.3837],\n",
      "         [ 0.8080],\n",
      "         [ 0.4413],\n",
      "         [ 1.0054],\n",
      "         [ 0.9875],\n",
      "         [ 0.3447],\n",
      "         [ 0.9902],\n",
      "         [ 0.9883],\n",
      "         [ 0.9853],\n",
      "         [ 0.9891],\n",
      "         [ 0.9950],\n",
      "         [ 0.9968],\n",
      "         [ 1.0040],\n",
      "         [ 1.0058],\n",
      "         [ 0.2348],\n",
      "         [ 1.0023],\n",
      "         [ 1.0013],\n",
      "         [ 1.0013],\n",
      "         [-0.0184],\n",
      "         [ 0.8540],\n",
      "         [ 0.9952],\n",
      "         [ 0.9828],\n",
      "         [ 0.9978],\n",
      "         [ 1.0003],\n",
      "         [ 0.9984],\n",
      "         [ 1.0047],\n",
      "         [ 0.4950],\n",
      "         [ 1.0061],\n",
      "         [ 1.0027],\n",
      "         [ 0.2258],\n",
      "         [ 0.4431],\n",
      "         [ 0.4300],\n",
      "         [ 0.9047],\n",
      "         [ 0.9848],\n",
      "         [ 0.0013],\n",
      "         [ 0.3080],\n",
      "         [ 0.4736],\n",
      "         [ 0.9944],\n",
      "         [ 0.9990],\n",
      "         [ 0.9984],\n",
      "         [ 0.5054],\n",
      "         [ 0.3579],\n",
      "         [ 0.4695],\n",
      "         [ 0.9806],\n",
      "         [ 1.0134],\n",
      "         [ 0.6700],\n",
      "         [ 1.0066],\n",
      "         [ 0.9317],\n",
      "         [ 1.0004],\n",
      "         [ 0.2277],\n",
      "         [ 0.9914],\n",
      "         [ 0.9935],\n",
      "         [ 0.9929],\n",
      "         [ 0.9913],\n",
      "         [ 0.9954],\n",
      "         [ 0.9959],\n",
      "         [ 0.9976],\n",
      "         [ 0.8641],\n",
      "         [ 0.3400],\n",
      "         [ 0.0104],\n",
      "         [ 0.2015],\n",
      "         [ 0.8610],\n",
      "         [ 0.4252],\n",
      "         [ 0.9973],\n",
      "         [ 0.9981],\n",
      "         [ 1.0001],\n",
      "         [ 0.9998],\n",
      "         [ 0.9987],\n",
      "         [ 0.1838],\n",
      "         [ 1.0028],\n",
      "         [ 1.0002],\n",
      "         [ 1.0021],\n",
      "         [ 1.0001],\n",
      "         [ 0.3572],\n",
      "         [ 0.4809],\n",
      "         [ 0.4974],\n",
      "         [ 0.2259],\n",
      "         [ 0.2216],\n",
      "         [ 0.9924],\n",
      "         [ 0.9603],\n",
      "         [ 0.9983],\n",
      "         [ 0.5398],\n",
      "         [-0.0011],\n",
      "         [ 0.9398],\n",
      "         [ 0.9987],\n",
      "         [ 0.9940],\n",
      "         [ 0.9944],\n",
      "         [ 0.9909],\n",
      "         [ 0.4748],\n",
      "         [ 0.9917],\n",
      "         [ 0.9928],\n",
      "         [ 0.9179],\n",
      "         [ 0.9953],\n",
      "         [ 0.9610],\n",
      "         [ 0.9986],\n",
      "         [ 1.0031],\n",
      "         [ 1.0041],\n",
      "         [ 1.0065],\n",
      "         [ 0.6963],\n",
      "         [ 0.4501],\n",
      "         [ 1.0009],\n",
      "         [ 1.0010],\n",
      "         [ 0.3448],\n",
      "         [-0.0114],\n",
      "         [ 0.7131],\n",
      "         [ 0.1990],\n",
      "         [ 0.9878],\n",
      "         [ 0.9744],\n",
      "         [ 0.4723],\n",
      "         [ 0.9851],\n",
      "         [ 0.9838],\n",
      "         [ 0.9864],\n",
      "         [ 0.9886],\n",
      "         [ 0.9894],\n",
      "         [ 0.9903],\n",
      "         [ 0.9979],\n",
      "         [ 1.0015],\n",
      "         [ 0.4363],\n",
      "         [ 0.0306],\n",
      "         [ 0.6166],\n",
      "         [ 0.6811],\n",
      "         [ 1.0044],\n",
      "         [ 1.0007],\n",
      "         [ 0.5000],\n",
      "         [ 0.9922],\n",
      "         [ 0.4148],\n",
      "         [ 0.8278],\n",
      "         [-0.0128],\n",
      "         [ 0.2940],\n",
      "         [ 0.9792],\n",
      "         [ 0.9795],\n",
      "         [ 0.9815],\n",
      "         [ 0.9846],\n",
      "         [ 0.9878],\n",
      "         [ 0.9892],\n",
      "         [ 0.9974],\n",
      "         [ 1.0016],\n",
      "         [ 0.8237],\n",
      "         [ 1.0083]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.7129],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.1762],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9814],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.9967],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9724],\n",
      "        [0.5334],\n",
      "        [0.3780],\n",
      "        [0.9994],\n",
      "        [0.3840],\n",
      "        [0.7540],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9962],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.0142],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.2610],\n",
      "        [0.4642],\n",
      "        [0.4611],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.3575],\n",
      "        [0.5054],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.5080],\n",
      "        [0.3753],\n",
      "        [0.4668],\n",
      "        [0.9490],\n",
      "        [0.9999],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.8379],\n",
      "        [0.3747],\n",
      "        [0.0368],\n",
      "        [0.2518],\n",
      "        [0.8296],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3875],\n",
      "        [0.5009],\n",
      "        [0.5165],\n",
      "        [0.2686],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.0209],\n",
      "        [0.9164],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9009],\n",
      "        [0.9994],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.0000],\n",
      "        [0.6920],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.0288],\n",
      "        [0.5945],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.8139],\n",
      "        [0.0174],\n",
      "        [0.3573],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.7820],\n",
      "        [0.9995]])\n",
      "######### Epoch: 34  ######### Train Loss: 0.0004712696827482432  ######### Relative L2 Test Norm: 14.704902648925781\n",
      "Output batch pred: tensor([[[1.0110],\n",
      "         [1.0087],\n",
      "         [0.9726],\n",
      "         [0.9320],\n",
      "         [0.4930],\n",
      "         [0.9308],\n",
      "         [0.9923],\n",
      "         [0.9900],\n",
      "         [1.0054],\n",
      "         [0.2262],\n",
      "         [0.6928],\n",
      "         [1.0020],\n",
      "         [1.0030],\n",
      "         [0.9831],\n",
      "         [0.3518],\n",
      "         [0.3411],\n",
      "         [0.3556],\n",
      "         [0.7189],\n",
      "         [0.5182],\n",
      "         [0.9973],\n",
      "         [0.9985],\n",
      "         [0.4951],\n",
      "         [0.9962],\n",
      "         [0.9972],\n",
      "         [0.9994],\n",
      "         [0.9989],\n",
      "         [0.9980],\n",
      "         [0.9614],\n",
      "         [0.4233],\n",
      "         [1.0022],\n",
      "         [1.0042],\n",
      "         [1.0096],\n",
      "         [1.0098],\n",
      "         [1.0161],\n",
      "         [0.0410],\n",
      "         [1.0190],\n",
      "         [0.8823],\n",
      "         [1.0132],\n",
      "         [1.0081],\n",
      "         [0.8580],\n",
      "         [0.2023],\n",
      "         [0.9887],\n",
      "         [0.9848],\n",
      "         [0.9823],\n",
      "         [0.7482],\n",
      "         [0.0045],\n",
      "         [0.9957],\n",
      "         [0.1495],\n",
      "         [1.0093],\n",
      "         [0.2410],\n",
      "         [1.0097],\n",
      "         [1.0153],\n",
      "         [1.0128],\n",
      "         [1.0084],\n",
      "         [0.2257],\n",
      "         [0.8446],\n",
      "         [0.3425],\n",
      "         [0.9838],\n",
      "         [0.6745],\n",
      "         [0.0216],\n",
      "         [1.0112],\n",
      "         [1.0211],\n",
      "         [1.0265],\n",
      "         [1.0306],\n",
      "         [0.5540],\n",
      "         [1.0269],\n",
      "         [0.9882],\n",
      "         [1.0120],\n",
      "         [1.0034],\n",
      "         [0.3262],\n",
      "         [0.9964],\n",
      "         [0.8128],\n",
      "         [0.9984],\n",
      "         [0.3503],\n",
      "         [1.0108],\n",
      "         [1.0148],\n",
      "         [1.0236],\n",
      "         [1.0260],\n",
      "         [1.0269],\n",
      "         [1.0233],\n",
      "         [1.0185],\n",
      "         [0.0067],\n",
      "         [1.0032],\n",
      "         [0.4297],\n",
      "         [0.9519],\n",
      "         [0.9910],\n",
      "         [0.9922],\n",
      "         [0.9391],\n",
      "         [1.0044],\n",
      "         [0.5624],\n",
      "         [1.0169],\n",
      "         [0.4654],\n",
      "         [1.0266],\n",
      "         [1.0259],\n",
      "         [1.0238],\n",
      "         [0.5195],\n",
      "         [0.8901],\n",
      "         [0.5077],\n",
      "         [1.0073],\n",
      "         [1.0045],\n",
      "         [1.0021],\n",
      "         [1.0015],\n",
      "         [1.0016],\n",
      "         [1.0032],\n",
      "         [0.3682],\n",
      "         [0.9248],\n",
      "         [1.0027],\n",
      "         [1.0033],\n",
      "         [1.0042],\n",
      "         [0.2133],\n",
      "         [0.2336],\n",
      "         [0.9993],\n",
      "         [0.2266],\n",
      "         [0.1800],\n",
      "         [1.0002],\n",
      "         [1.0034],\n",
      "         [1.0065],\n",
      "         [1.0081],\n",
      "         [1.0150],\n",
      "         [1.0168],\n",
      "         [1.0219],\n",
      "         [1.0245],\n",
      "         [1.0232],\n",
      "         [0.8155],\n",
      "         [1.0187],\n",
      "         [0.5069],\n",
      "         [1.0090],\n",
      "         [0.4383],\n",
      "         [1.0057],\n",
      "         [0.3639],\n",
      "         [0.9108],\n",
      "         [1.0028],\n",
      "         [1.0056],\n",
      "         [1.0075],\n",
      "         [1.0090],\n",
      "         [0.4321],\n",
      "         [0.3589],\n",
      "         [0.5422],\n",
      "         [0.4466],\n",
      "         [0.7410],\n",
      "         [0.4390],\n",
      "         [0.9928],\n",
      "         [0.0226],\n",
      "         [0.9986],\n",
      "         [0.4978],\n",
      "         [1.0005],\n",
      "         [0.4566],\n",
      "         [0.6145],\n",
      "         [1.0087],\n",
      "         [0.0388],\n",
      "         [1.0067],\n",
      "         [1.0041],\n",
      "         [0.3407],\n",
      "         [0.5030],\n",
      "         [0.0098],\n",
      "         [0.9982],\n",
      "         [1.0029],\n",
      "         [1.0053],\n",
      "         [1.0094],\n",
      "         [1.0129],\n",
      "         [1.0016],\n",
      "         [0.0170],\n",
      "         [1.0137],\n",
      "         [1.0115],\n",
      "         [0.4558],\n",
      "         [1.0028],\n",
      "         [0.0180],\n",
      "         [0.9960],\n",
      "         [0.6375],\n",
      "         [0.4305],\n",
      "         [0.9922],\n",
      "         [0.4985],\n",
      "         [1.0030],\n",
      "         [1.0082],\n",
      "         [1.0104],\n",
      "         [0.3413],\n",
      "         [0.5118],\n",
      "         [0.2548]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9009],\n",
      "        [0.5030],\n",
      "        [0.9044],\n",
      "        [0.9804],\n",
      "        [0.9814],\n",
      "        [0.9999],\n",
      "        [0.2547],\n",
      "        [0.6628],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.3840],\n",
      "        [0.3747],\n",
      "        [0.3912],\n",
      "        [0.6920],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.4527],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [0.2646],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7391],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.9956],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.8139],\n",
      "        [0.3780],\n",
      "        [0.9819],\n",
      "        [0.6555],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [0.9490],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.3575],\n",
      "        [0.9997],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.9420],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [0.9164],\n",
      "        [0.9967],\n",
      "        [0.5463],\n",
      "        [0.9997],\n",
      "        [0.4503],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5009],\n",
      "        [0.8379],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.8933],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2518],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.2208],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.9998],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.3808],\n",
      "        [0.5334],\n",
      "        [0.4611],\n",
      "        [0.7129],\n",
      "        [0.4580],\n",
      "        [0.9959],\n",
      "        [0.0209],\n",
      "        [0.9999],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.5945],\n",
      "        [0.9999],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.5151],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.0174],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.4642],\n",
      "        [0.9996],\n",
      "        [0.0368],\n",
      "        [0.9996],\n",
      "        [0.6327],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [0.5054],\n",
      "        [0.2729]])\n",
      "######### Epoch: 35  ######### Train Loss: 0.00039518316043540835  ######### Relative L2 Test Norm: 13.606056213378906\n",
      "Output batch pred: tensor([[[0.9892],\n",
      "         [0.5779],\n",
      "         [0.3911],\n",
      "         [1.0214],\n",
      "         [1.0163],\n",
      "         [1.0146],\n",
      "         [1.0124],\n",
      "         [0.8763],\n",
      "         [1.0062],\n",
      "         [0.2440],\n",
      "         [0.0266],\n",
      "         [0.0378],\n",
      "         [1.0051],\n",
      "         [0.9513],\n",
      "         [0.9791],\n",
      "         [1.0172],\n",
      "         [0.3760],\n",
      "         [0.0611],\n",
      "         [1.0181],\n",
      "         [0.4502],\n",
      "         [1.0115],\n",
      "         [0.3403],\n",
      "         [0.7904],\n",
      "         [1.0027],\n",
      "         [0.4916],\n",
      "         [1.0069],\n",
      "         [0.6889],\n",
      "         [0.4495],\n",
      "         [0.9997],\n",
      "         [1.0190],\n",
      "         [1.0205],\n",
      "         [1.0247],\n",
      "         [1.0251],\n",
      "         [0.5353],\n",
      "         [1.0232],\n",
      "         [1.0228],\n",
      "         [1.0084],\n",
      "         [1.0205],\n",
      "         [1.0176],\n",
      "         [1.0172],\n",
      "         [0.5122],\n",
      "         [0.8328],\n",
      "         [0.0449],\n",
      "         [1.0039],\n",
      "         [0.2223],\n",
      "         [0.9910],\n",
      "         [0.4330],\n",
      "         [0.8578],\n",
      "         [0.4504],\n",
      "         [0.9426],\n",
      "         [0.7204],\n",
      "         [1.0207],\n",
      "         [1.0222],\n",
      "         [0.9954],\n",
      "         [0.6990],\n",
      "         [1.0295],\n",
      "         [1.0249],\n",
      "         [1.0232],\n",
      "         [1.0223],\n",
      "         [1.0191],\n",
      "         [1.0054],\n",
      "         [0.4656],\n",
      "         [0.5163],\n",
      "         [1.0121],\n",
      "         [0.3618],\n",
      "         [1.0102],\n",
      "         [1.0060],\n",
      "         [0.4511],\n",
      "         [1.0073],\n",
      "         [1.0073],\n",
      "         [1.0077],\n",
      "         [1.0096],\n",
      "         [1.0101],\n",
      "         [0.5225],\n",
      "         [1.0104],\n",
      "         [1.0156],\n",
      "         [1.0135],\n",
      "         [1.0128],\n",
      "         [0.2416],\n",
      "         [1.0066],\n",
      "         [0.0281],\n",
      "         [0.4521],\n",
      "         [0.9975],\n",
      "         [0.9985],\n",
      "         [1.0023],\n",
      "         [1.0077],\n",
      "         [0.8752],\n",
      "         [0.5601],\n",
      "         [1.0190],\n",
      "         [0.3856],\n",
      "         [1.0200],\n",
      "         [0.5201],\n",
      "         [0.5178],\n",
      "         [1.0130],\n",
      "         [1.0106],\n",
      "         [1.0089],\n",
      "         [1.0087],\n",
      "         [1.0094],\n",
      "         [0.5398],\n",
      "         [0.0355],\n",
      "         [1.0126],\n",
      "         [1.0131],\n",
      "         [1.0123],\n",
      "         [0.0561],\n",
      "         [1.0073],\n",
      "         [1.0111],\n",
      "         [0.2571],\n",
      "         [1.0118],\n",
      "         [0.8730],\n",
      "         [0.9408],\n",
      "         [1.0168],\n",
      "         [0.0366],\n",
      "         [1.0193],\n",
      "         [0.2528],\n",
      "         [1.0171],\n",
      "         [0.4719],\n",
      "         [0.3576],\n",
      "         [1.0110],\n",
      "         [0.4549],\n",
      "         [0.6287],\n",
      "         [1.0128],\n",
      "         [1.0150],\n",
      "         [1.0165],\n",
      "         [1.0149],\n",
      "         [1.0181],\n",
      "         [1.0173],\n",
      "         [0.5306],\n",
      "         [1.0119],\n",
      "         [0.7808],\n",
      "         [0.4606],\n",
      "         [1.0033],\n",
      "         [0.1935],\n",
      "         [0.0067],\n",
      "         [1.0039],\n",
      "         [0.3585],\n",
      "         [1.0075],\n",
      "         [1.0097],\n",
      "         [1.0085],\n",
      "         [0.2404],\n",
      "         [1.0117],\n",
      "         [1.0099],\n",
      "         [0.9968],\n",
      "         [1.0124],\n",
      "         [1.0097],\n",
      "         [0.7400],\n",
      "         [1.0101],\n",
      "         [1.0134],\n",
      "         [0.3614],\n",
      "         [1.0113],\n",
      "         [0.3603],\n",
      "         [1.0086],\n",
      "         [1.0058],\n",
      "         [0.4881],\n",
      "         [0.2155],\n",
      "         [1.0025],\n",
      "         [1.0046],\n",
      "         [1.0079],\n",
      "         [0.9333],\n",
      "         [1.0160],\n",
      "         [1.0205],\n",
      "         [0.7781],\n",
      "         [0.9364],\n",
      "         [0.4008],\n",
      "         [1.0219],\n",
      "         [1.0185],\n",
      "         [1.0136],\n",
      "         [1.0074],\n",
      "         [1.0073],\n",
      "         [0.2403],\n",
      "         [0.3645],\n",
      "         [1.0036],\n",
      "         [1.0050],\n",
      "         [0.5159],\n",
      "         [1.0098],\n",
      "         [1.0111],\n",
      "         [0.9761],\n",
      "         [0.1689],\n",
      "         [1.0192]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9515],\n",
      "        [0.5463],\n",
      "        [0.3875],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9997],\n",
      "        [0.2686],\n",
      "        [0.0142],\n",
      "        [0.0247],\n",
      "        [0.9999],\n",
      "        [0.9164],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.7540],\n",
      "        [0.9966],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.4503],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.7820],\n",
      "        [0.0383],\n",
      "        [0.9999],\n",
      "        [0.2518],\n",
      "        [0.9804],\n",
      "        [0.4480],\n",
      "        [0.8139],\n",
      "        [0.4552],\n",
      "        [0.9009],\n",
      "        [0.6628],\n",
      "        [0.9962],\n",
      "        [0.9956],\n",
      "        [0.9520],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.4645],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9996],\n",
      "        [0.0209],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5245],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.9044],\n",
      "        [0.9997],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.5945],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.4642],\n",
      "        [0.9994],\n",
      "        [0.2208],\n",
      "        [0.0000],\n",
      "        [0.9999],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6920],\n",
      "        [0.9997],\n",
      "        [0.9995],\n",
      "        [0.3753],\n",
      "        [0.9998],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.5009],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.8761],\n",
      "        [0.3930],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5151],\n",
      "        [0.9997],\n",
      "        [0.9967],\n",
      "        [0.9420],\n",
      "        [0.1762],\n",
      "        [0.9998]])\n",
      "######### Epoch: 36  ######### Train Loss: 0.00046745326835662127  ######### Relative L2 Test Norm: 13.891060829162598\n",
      "Output batch pred: tensor([[[1.0018],\n",
      "         [1.0147],\n",
      "         [0.3697],\n",
      "         [1.0094],\n",
      "         [1.0097],\n",
      "         [0.5230],\n",
      "         [1.0109],\n",
      "         [1.0140],\n",
      "         [0.2406],\n",
      "         [0.4706],\n",
      "         [1.0226],\n",
      "         [1.0276],\n",
      "         [1.0282],\n",
      "         [1.0279],\n",
      "         [1.0248],\n",
      "         [1.0237],\n",
      "         [0.0359],\n",
      "         [0.5645],\n",
      "         [0.9725],\n",
      "         [1.0015],\n",
      "         [0.0488],\n",
      "         [0.0463],\n",
      "         [0.2526],\n",
      "         [1.0034],\n",
      "         [0.5088],\n",
      "         [0.7949],\n",
      "         [1.0078],\n",
      "         [0.2527],\n",
      "         [0.0439],\n",
      "         [0.5625],\n",
      "         [1.0095],\n",
      "         [0.2668],\n",
      "         [0.9738],\n",
      "         [1.0122],\n",
      "         [0.9401],\n",
      "         [1.0187],\n",
      "         [0.3663],\n",
      "         [1.0256],\n",
      "         [0.9550],\n",
      "         [0.4056],\n",
      "         [0.5417],\n",
      "         [1.0207],\n",
      "         [0.7490],\n",
      "         [1.0137],\n",
      "         [0.5276],\n",
      "         [1.0047],\n",
      "         [1.0081],\n",
      "         [1.0081],\n",
      "         [1.0119],\n",
      "         [1.0142],\n",
      "         [1.0157],\n",
      "         [0.0326],\n",
      "         [1.0185],\n",
      "         [1.0197],\n",
      "         [1.0183],\n",
      "         [1.0183],\n",
      "         [0.5157],\n",
      "         [1.0146],\n",
      "         [0.3970],\n",
      "         [0.4603],\n",
      "         [0.2604],\n",
      "         [1.0151],\n",
      "         [0.2451],\n",
      "         [0.5203],\n",
      "         [0.9998],\n",
      "         [1.0121],\n",
      "         [0.4715],\n",
      "         [0.3683],\n",
      "         [1.0157],\n",
      "         [1.0192],\n",
      "         [0.3673],\n",
      "         [1.0230],\n",
      "         [1.0276],\n",
      "         [1.0251],\n",
      "         [0.6531],\n",
      "         [0.4913],\n",
      "         [1.0088],\n",
      "         [0.5181],\n",
      "         [1.0113],\n",
      "         [0.7006],\n",
      "         [0.4591],\n",
      "         [0.9688],\n",
      "         [1.0076],\n",
      "         [1.0116],\n",
      "         [0.3724],\n",
      "         [0.8881],\n",
      "         [1.0228],\n",
      "         [1.0235],\n",
      "         [1.0225],\n",
      "         [0.8813],\n",
      "         [1.0208],\n",
      "         [1.0165],\n",
      "         [1.0128],\n",
      "         [1.0076],\n",
      "         [1.0055],\n",
      "         [0.3564],\n",
      "         [0.0273],\n",
      "         [1.0008],\n",
      "         [1.0049],\n",
      "         [1.0033],\n",
      "         [0.8306],\n",
      "         [0.8798],\n",
      "         [1.0104],\n",
      "         [1.0067],\n",
      "         [0.4618],\n",
      "         [1.0154],\n",
      "         [1.0163],\n",
      "         [1.0161],\n",
      "         [0.5566],\n",
      "         [0.2213],\n",
      "         [0.3941],\n",
      "         [1.0158],\n",
      "         [1.0140],\n",
      "         [1.0154],\n",
      "         [0.0552],\n",
      "         [0.7960],\n",
      "         [1.0152],\n",
      "         [1.0176],\n",
      "         [1.0155],\n",
      "         [0.8852],\n",
      "         [1.0184],\n",
      "         [1.0190],\n",
      "         [1.0174],\n",
      "         [1.0116],\n",
      "         [0.0617],\n",
      "         [0.4443],\n",
      "         [1.0055],\n",
      "         [0.9119],\n",
      "         [1.0049],\n",
      "         [1.0084],\n",
      "         [0.0493],\n",
      "         [1.0152],\n",
      "         [1.0010],\n",
      "         [1.0205],\n",
      "         [0.5303],\n",
      "         [1.0201],\n",
      "         [0.5342],\n",
      "         [0.7714],\n",
      "         [1.0139],\n",
      "         [1.0129],\n",
      "         [0.3774],\n",
      "         [1.0127],\n",
      "         [0.9422],\n",
      "         [0.9822],\n",
      "         [1.0061],\n",
      "         [0.3799],\n",
      "         [1.0172],\n",
      "         [0.9564],\n",
      "         [1.0057],\n",
      "         [1.0043],\n",
      "         [0.1649],\n",
      "         [0.6414],\n",
      "         [0.2299],\n",
      "         [0.4216],\n",
      "         [0.2430],\n",
      "         [0.9988],\n",
      "         [1.0055],\n",
      "         [0.4670],\n",
      "         [1.0175],\n",
      "         [1.0248],\n",
      "         [0.4944],\n",
      "         [1.0293],\n",
      "         [1.0283],\n",
      "         [1.0255],\n",
      "         [1.0217],\n",
      "         [1.0157],\n",
      "         [1.0114],\n",
      "         [1.0119],\n",
      "         [0.6920],\n",
      "         [1.0127],\n",
      "         [1.0145],\n",
      "         [1.0148],\n",
      "         [1.0205],\n",
      "         [1.0223],\n",
      "         [1.0239],\n",
      "         [1.0246],\n",
      "         [0.5239],\n",
      "         [1.0224]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9814],\n",
      "        [0.9998],\n",
      "        [0.3808],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2547],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0000],\n",
      "        [0.5463],\n",
      "        [0.9490],\n",
      "        [0.9998],\n",
      "        [0.0247],\n",
      "        [0.0209],\n",
      "        [0.2686],\n",
      "        [0.9997],\n",
      "        [0.5054],\n",
      "        [0.7540],\n",
      "        [0.9999],\n",
      "        [0.2577],\n",
      "        [0.0142],\n",
      "        [0.5334],\n",
      "        [0.9999],\n",
      "        [0.2729],\n",
      "        [0.9420],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.3912],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.9997],\n",
      "        [0.3930],\n",
      "        [0.4503],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.5080],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [0.4668],\n",
      "        [0.3753],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.5945],\n",
      "        [0.4645],\n",
      "        [0.9820],\n",
      "        [0.5030],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [0.4642],\n",
      "        [0.9520],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.8379],\n",
      "        [0.9999],\n",
      "        [0.9956],\n",
      "        [0.4527],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.2208],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.7391],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.4454],\n",
      "        [0.9996],\n",
      "        [0.8761],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.9998],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.9515],\n",
      "        [0.9819],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [0.6327],\n",
      "        [0.2610],\n",
      "        [0.4480],\n",
      "        [0.2735],\n",
      "        [0.9996],\n",
      "        [0.9994],\n",
      "        [0.4580],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [0.9995]])\n",
      "######### Epoch: 37  ######### Train Loss: 0.0005338542978279293  ######### Relative L2 Test Norm: 13.131793975830078\n",
      "Output batch pred: tensor([[[0.2648],\n",
      "         [1.0081],\n",
      "         [1.0095],\n",
      "         [1.0077],\n",
      "         [0.4729],\n",
      "         [1.0103],\n",
      "         [0.2659],\n",
      "         [0.9314],\n",
      "         [1.0071],\n",
      "         [0.2589],\n",
      "         [0.7616],\n",
      "         [0.3634],\n",
      "         [0.8014],\n",
      "         [1.0084],\n",
      "         [1.0113],\n",
      "         [0.4524],\n",
      "         [1.0105],\n",
      "         [1.0133],\n",
      "         [1.0154],\n",
      "         [1.0160],\n",
      "         [1.0183],\n",
      "         [0.2718],\n",
      "         [0.9493],\n",
      "         [0.5492],\n",
      "         [0.9804],\n",
      "         [1.0167],\n",
      "         [1.0006],\n",
      "         [1.0100],\n",
      "         [0.1676],\n",
      "         [1.0038],\n",
      "         [1.0035],\n",
      "         [0.5116],\n",
      "         [0.4698],\n",
      "         [0.6943],\n",
      "         [0.3894],\n",
      "         [1.0148],\n",
      "         [1.0150],\n",
      "         [1.0185],\n",
      "         [1.0182],\n",
      "         [0.5357],\n",
      "         [1.0156],\n",
      "         [1.0133],\n",
      "         [1.0111],\n",
      "         [0.0434],\n",
      "         [1.0082],\n",
      "         [1.0039],\n",
      "         [0.3976],\n",
      "         [0.5693],\n",
      "         [0.7439],\n",
      "         [0.0696],\n",
      "         [1.0099],\n",
      "         [1.0119],\n",
      "         [0.8854],\n",
      "         [0.5553],\n",
      "         [1.0084],\n",
      "         [1.0073],\n",
      "         [1.0092],\n",
      "         [0.3755],\n",
      "         [0.8640],\n",
      "         [1.0113],\n",
      "         [1.0129],\n",
      "         [0.9252],\n",
      "         [0.6831],\n",
      "         [1.0181],\n",
      "         [1.0168],\n",
      "         [1.0204],\n",
      "         [1.0191],\n",
      "         [1.0193],\n",
      "         [1.0204],\n",
      "         [1.0191],\n",
      "         [1.0183],\n",
      "         [1.0144],\n",
      "         [0.5230],\n",
      "         [1.0109],\n",
      "         [1.0069],\n",
      "         [0.3895],\n",
      "         [1.0037],\n",
      "         [1.0074],\n",
      "         [0.4535],\n",
      "         [0.2485],\n",
      "         [0.9781],\n",
      "         [1.0144],\n",
      "         [1.0152],\n",
      "         [1.0143],\n",
      "         [0.9567],\n",
      "         [0.4604],\n",
      "         [0.3577],\n",
      "         [0.3737],\n",
      "         [1.0072],\n",
      "         [0.2455],\n",
      "         [1.0053],\n",
      "         [1.0101],\n",
      "         [0.4721],\n",
      "         [1.0185],\n",
      "         [1.0216],\n",
      "         [0.8945],\n",
      "         [1.0252],\n",
      "         [0.2393],\n",
      "         [1.0165],\n",
      "         [0.9807],\n",
      "         [0.3809],\n",
      "         [0.5538],\n",
      "         [0.9613],\n",
      "         [0.9965],\n",
      "         [0.9953],\n",
      "         [0.2569],\n",
      "         [1.0010],\n",
      "         [0.7805],\n",
      "         [0.5335],\n",
      "         [0.5329],\n",
      "         [0.4761],\n",
      "         [0.3942],\n",
      "         [1.0075],\n",
      "         [1.0077],\n",
      "         [1.0046],\n",
      "         [1.0038],\n",
      "         [0.9996],\n",
      "         [1.0039],\n",
      "         [0.6233],\n",
      "         [0.0235],\n",
      "         [1.0119],\n",
      "         [0.8408],\n",
      "         [1.0034],\n",
      "         [1.0160],\n",
      "         [1.0138],\n",
      "         [0.4704],\n",
      "         [1.0118],\n",
      "         [1.0093],\n",
      "         [1.0069],\n",
      "         [1.0061],\n",
      "         [1.0034],\n",
      "         [1.0049],\n",
      "         [0.3664],\n",
      "         [1.0086],\n",
      "         [0.0516],\n",
      "         [1.0121],\n",
      "         [1.0130],\n",
      "         [0.0697],\n",
      "         [1.0166],\n",
      "         [0.0517],\n",
      "         [1.0197],\n",
      "         [0.0674],\n",
      "         [1.0212],\n",
      "         [1.0186],\n",
      "         [1.0211],\n",
      "         [1.0198],\n",
      "         [1.0037],\n",
      "         [0.0570],\n",
      "         [0.9434],\n",
      "         [0.7134],\n",
      "         [1.0126],\n",
      "         [0.0649],\n",
      "         [1.0111],\n",
      "         [1.0102],\n",
      "         [1.0106],\n",
      "         [0.5165],\n",
      "         [0.3827],\n",
      "         [0.8772],\n",
      "         [1.0120],\n",
      "         [0.5287],\n",
      "         [1.0131],\n",
      "         [0.5168],\n",
      "         [0.2529],\n",
      "         [0.9977],\n",
      "         [1.0169],\n",
      "         [0.4875],\n",
      "         [1.0052],\n",
      "         [1.0100],\n",
      "         [1.0132],\n",
      "         [0.4587],\n",
      "         [1.0077],\n",
      "         [1.0059],\n",
      "         [0.9998],\n",
      "         [0.9999],\n",
      "         [1.0017],\n",
      "         [1.0005],\n",
      "         [0.5024],\n",
      "         [1.0030]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2686],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.7129],\n",
      "        [0.3575],\n",
      "        [0.7540],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9009],\n",
      "        [0.5165],\n",
      "        [0.9420],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [0.9994],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.4642],\n",
      "        [0.6555],\n",
      "        [0.3840],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.9994],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3930],\n",
      "        [0.5463],\n",
      "        [0.6920],\n",
      "        [0.0247],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.8379],\n",
      "        [0.5245],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.2577],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9164],\n",
      "        [0.4480],\n",
      "        [0.3573],\n",
      "        [0.3753],\n",
      "        [0.9997],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.8223],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.3780],\n",
      "        [0.5334],\n",
      "        [0.9520],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.5151],\n",
      "        [0.5139],\n",
      "        [0.4611],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.9995],\n",
      "        [0.5945],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [0.9967],\n",
      "        [0.4580],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9996],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.0288],\n",
      "        [0.9044],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [0.9997],\n",
      "        [0.5030],\n",
      "        [0.3808],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.2518],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.9819],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9998]])\n",
      "######### Epoch: 38  ######### Train Loss: 0.0004577638756018132  ######### Relative L2 Test Norm: 12.889334678649902\n",
      "Output batch pred: tensor([[[0.9365],\n",
      "         [1.0079],\n",
      "         [1.0078],\n",
      "         [1.0083],\n",
      "         [1.0053],\n",
      "         [0.0550],\n",
      "         [1.0104],\n",
      "         [1.0106],\n",
      "         [0.9403],\n",
      "         [1.0112],\n",
      "         [1.0067],\n",
      "         [0.2716],\n",
      "         [1.0060],\n",
      "         [0.5186],\n",
      "         [0.9255],\n",
      "         [1.0016],\n",
      "         [0.0417],\n",
      "         [1.0032],\n",
      "         [0.4638],\n",
      "         [1.0037],\n",
      "         [1.0059],\n",
      "         [1.0063],\n",
      "         [0.9480],\n",
      "         [1.0036],\n",
      "         [0.5226],\n",
      "         [0.9977],\n",
      "         [0.5032],\n",
      "         [0.9931],\n",
      "         [0.9938],\n",
      "         [0.9952],\n",
      "         [0.9953],\n",
      "         [0.5082],\n",
      "         [0.9114],\n",
      "         [1.0033],\n",
      "         [0.5513],\n",
      "         [0.7416],\n",
      "         [0.9983],\n",
      "         [0.9983],\n",
      "         [0.2663],\n",
      "         [0.9966],\n",
      "         [0.9969],\n",
      "         [0.9972],\n",
      "         [0.9982],\n",
      "         [1.0005],\n",
      "         [1.0037],\n",
      "         [1.0058],\n",
      "         [1.0077],\n",
      "         [0.2845],\n",
      "         [0.5443],\n",
      "         [1.0076],\n",
      "         [1.0068],\n",
      "         [1.0021],\n",
      "         [1.0029],\n",
      "         [0.4555],\n",
      "         [0.9983],\n",
      "         [1.0010],\n",
      "         [1.0009],\n",
      "         [0.0545],\n",
      "         [1.0012],\n",
      "         [0.1845],\n",
      "         [1.0030],\n",
      "         [1.0019],\n",
      "         [0.9863],\n",
      "         [1.0039],\n",
      "         [0.7116],\n",
      "         [1.0034],\n",
      "         [1.0007],\n",
      "         [0.8728],\n",
      "         [1.0004],\n",
      "         [1.0024],\n",
      "         [1.0000],\n",
      "         [1.0006],\n",
      "         [0.7922],\n",
      "         [0.9973],\n",
      "         [0.5602],\n",
      "         [0.9852],\n",
      "         [0.9981],\n",
      "         [0.0533],\n",
      "         [1.0011],\n",
      "         [1.0001],\n",
      "         [1.0034],\n",
      "         [1.0042],\n",
      "         [1.0040],\n",
      "         [0.8758],\n",
      "         [0.9998],\n",
      "         [0.9952],\n",
      "         [0.4673],\n",
      "         [0.2435],\n",
      "         [0.9806],\n",
      "         [0.9566],\n",
      "         [0.4413],\n",
      "         [0.9964],\n",
      "         [0.5233],\n",
      "         [1.0013],\n",
      "         [0.6883],\n",
      "         [0.3583],\n",
      "         [1.0038],\n",
      "         [0.3895],\n",
      "         [1.0066],\n",
      "         [0.9674],\n",
      "         [1.0059],\n",
      "         [1.0056],\n",
      "         [1.0049],\n",
      "         [1.0051],\n",
      "         [0.9703],\n",
      "         [1.0057],\n",
      "         [1.0061],\n",
      "         [1.0032],\n",
      "         [1.0060],\n",
      "         [1.0103],\n",
      "         [0.8676],\n",
      "         [1.0099],\n",
      "         [0.2292],\n",
      "         [1.0140],\n",
      "         [0.5333],\n",
      "         [1.0171],\n",
      "         [1.0156],\n",
      "         [1.0147],\n",
      "         [0.5192],\n",
      "         [0.2565],\n",
      "         [0.3903],\n",
      "         [0.9674],\n",
      "         [0.9984],\n",
      "         [0.2599],\n",
      "         [0.3718],\n",
      "         [0.4729],\n",
      "         [0.3946],\n",
      "         [1.0046],\n",
      "         [0.3856],\n",
      "         [0.3883],\n",
      "         [1.0098],\n",
      "         [0.3715],\n",
      "         [1.0083],\n",
      "         [0.0694],\n",
      "         [0.3854],\n",
      "         [0.8669],\n",
      "         [0.0501],\n",
      "         [0.8312],\n",
      "         [0.9941],\n",
      "         [0.3835],\n",
      "         [0.5353],\n",
      "         [1.0156],\n",
      "         [0.0759],\n",
      "         [1.0161],\n",
      "         [1.0130],\n",
      "         [0.7937],\n",
      "         [1.0051],\n",
      "         [0.6656],\n",
      "         [0.9998],\n",
      "         [0.0377],\n",
      "         [0.9946],\n",
      "         [0.9813],\n",
      "         [0.5059],\n",
      "         [0.9936],\n",
      "         [0.9955],\n",
      "         [0.0537],\n",
      "         [0.5491],\n",
      "         [0.4432],\n",
      "         [0.4524],\n",
      "         [0.9980],\n",
      "         [0.6213],\n",
      "         [0.4698],\n",
      "         [0.4597],\n",
      "         [0.9993],\n",
      "         [1.0018],\n",
      "         [0.2485],\n",
      "         [1.0034],\n",
      "         [0.7585],\n",
      "         [0.3932],\n",
      "         [1.0076],\n",
      "         [1.0090],\n",
      "         [1.0090],\n",
      "         [1.0106],\n",
      "         [1.0093],\n",
      "         [0.2620],\n",
      "         [1.0062],\n",
      "         [0.4765],\n",
      "         [1.0082]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9044],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5030],\n",
      "        [0.8761],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [0.4503],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0247],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.9995],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.4645],\n",
      "        [0.2518],\n",
      "        [0.9804],\n",
      "        [0.9520],\n",
      "        [0.4480],\n",
      "        [0.9997],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.9994],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9998],\n",
      "        [0.5038],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.2547],\n",
      "        [0.3875],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.3753],\n",
      "        [0.4668],\n",
      "        [0.3912],\n",
      "        [0.9999],\n",
      "        [0.3747],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.3575],\n",
      "        [0.9999],\n",
      "        [0.0209],\n",
      "        [0.3808],\n",
      "        [0.8223],\n",
      "        [0.0000],\n",
      "        [0.7820],\n",
      "        [0.9814],\n",
      "        [0.3728],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0288],\n",
      "        [0.5334],\n",
      "        [0.4454],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.4642],\n",
      "        [0.4580],\n",
      "        [0.9967],\n",
      "        [0.9996],\n",
      "        [0.2577],\n",
      "        [0.9997],\n",
      "        [0.7129],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [0.2610],\n",
      "        [0.9956],\n",
      "        [0.4611],\n",
      "        [1.0000]])\n",
      "######### Epoch: 39  ######### Train Loss: 0.00029678019927814603  ######### Relative L2 Test Norm: 13.420642852783203\n",
      "Output batch pred: tensor([[[0.4666],\n",
      "         [0.6729],\n",
      "         [1.0034],\n",
      "         [1.0077],\n",
      "         [1.0038],\n",
      "         [1.0078],\n",
      "         [0.5434],\n",
      "         [1.0054],\n",
      "         [1.0032],\n",
      "         [0.9246],\n",
      "         [0.9947],\n",
      "         [0.9963],\n",
      "         [0.9951],\n",
      "         [0.9593],\n",
      "         [0.4512],\n",
      "         [0.4714],\n",
      "         [0.5227],\n",
      "         [0.4558],\n",
      "         [0.9943],\n",
      "         [0.9917],\n",
      "         [0.9917],\n",
      "         [0.4509],\n",
      "         [0.3451],\n",
      "         [0.0478],\n",
      "         [0.4519],\n",
      "         [0.4899],\n",
      "         [0.9821],\n",
      "         [0.7746],\n",
      "         [0.4404],\n",
      "         [0.9742],\n",
      "         [0.9960],\n",
      "         [0.9998],\n",
      "         [0.3659],\n",
      "         [1.0047],\n",
      "         [0.2872],\n",
      "         [0.9170],\n",
      "         [1.0036],\n",
      "         [1.0021],\n",
      "         [0.3782],\n",
      "         [0.9938],\n",
      "         [0.9947],\n",
      "         [0.0679],\n",
      "         [0.5013],\n",
      "         [0.9943],\n",
      "         [0.4502],\n",
      "         [0.9987],\n",
      "         [1.0005],\n",
      "         [0.5236],\n",
      "         [0.5338],\n",
      "         [1.0011],\n",
      "         [1.0034],\n",
      "         [1.0000],\n",
      "         [0.9936],\n",
      "         [0.9911],\n",
      "         [0.4517],\n",
      "         [0.9861],\n",
      "         [0.4968],\n",
      "         [0.9882],\n",
      "         [0.2480],\n",
      "         [0.9881],\n",
      "         [1.0052],\n",
      "         [1.0085],\n",
      "         [1.0077],\n",
      "         [0.5486],\n",
      "         [0.0424],\n",
      "         [1.0017],\n",
      "         [0.9959],\n",
      "         [0.9158],\n",
      "         [0.9235],\n",
      "         [0.9790],\n",
      "         [0.9795],\n",
      "         [0.5186],\n",
      "         [0.9824],\n",
      "         [0.2555],\n",
      "         [0.2579],\n",
      "         [0.9970],\n",
      "         [1.0001],\n",
      "         [0.9997],\n",
      "         [0.3864],\n",
      "         [0.9934],\n",
      "         [0.5030],\n",
      "         [0.8125],\n",
      "         [0.9902],\n",
      "         [0.0459],\n",
      "         [0.0456],\n",
      "         [0.7526],\n",
      "         [1.0018],\n",
      "         [1.0043],\n",
      "         [1.0047],\n",
      "         [0.2750],\n",
      "         [1.0065],\n",
      "         [1.0005],\n",
      "         [0.7352],\n",
      "         [0.9577],\n",
      "         [0.9851],\n",
      "         [0.9826],\n",
      "         [0.8304],\n",
      "         [0.9814],\n",
      "         [0.9831],\n",
      "         [0.9861],\n",
      "         [0.2402],\n",
      "         [0.9934],\n",
      "         [0.0578],\n",
      "         [1.0011],\n",
      "         [1.0001],\n",
      "         [1.0047],\n",
      "         [0.9663],\n",
      "         [0.8708],\n",
      "         [1.0020],\n",
      "         [0.9979],\n",
      "         [0.8661],\n",
      "         [0.9806],\n",
      "         [0.9213],\n",
      "         [0.8637],\n",
      "         [0.0703],\n",
      "         [0.5524],\n",
      "         [0.9936],\n",
      "         [0.9960],\n",
      "         [0.9972],\n",
      "         [0.9990],\n",
      "         [0.2279],\n",
      "         [0.3891],\n",
      "         [0.3964],\n",
      "         [0.9949],\n",
      "         [0.9778],\n",
      "         [0.4602],\n",
      "         [0.2471],\n",
      "         [0.9836],\n",
      "         [0.3635],\n",
      "         [0.1788],\n",
      "         [0.2544],\n",
      "         [0.9936],\n",
      "         [0.6879],\n",
      "         [0.9988],\n",
      "         [0.9986],\n",
      "         [0.9955],\n",
      "         [0.9925],\n",
      "         [0.9855],\n",
      "         [0.6776],\n",
      "         [0.9723],\n",
      "         [0.9741],\n",
      "         [0.3453],\n",
      "         [0.9742],\n",
      "         [0.9774],\n",
      "         [0.0383],\n",
      "         [0.9847],\n",
      "         [0.9879],\n",
      "         [0.9901],\n",
      "         [0.9893],\n",
      "         [0.9892],\n",
      "         [0.0502],\n",
      "         [0.7606],\n",
      "         [0.5406],\n",
      "         [0.9795],\n",
      "         [0.9786],\n",
      "         [0.9831],\n",
      "         [0.9893],\n",
      "         [0.9593],\n",
      "         [0.3754],\n",
      "         [0.9994],\n",
      "         [0.6352],\n",
      "         [1.0032],\n",
      "         [1.0036],\n",
      "         [0.5291],\n",
      "         [0.9992],\n",
      "         [0.3947],\n",
      "         [0.9940],\n",
      "         [0.9956],\n",
      "         [0.9971],\n",
      "         [0.9996],\n",
      "         [0.9983],\n",
      "         [0.3853],\n",
      "         [1.0039],\n",
      "         [1.0043],\n",
      "         [1.0045],\n",
      "         [1.0034],\n",
      "         [0.9899],\n",
      "         [1.0015]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.4552],\n",
      "        [0.6327],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.4503],\n",
      "        [0.4668],\n",
      "        [0.5139],\n",
      "        [0.4527],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.3575],\n",
      "        [0.0247],\n",
      "        [0.4642],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.4480],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.9998],\n",
      "        [0.2735],\n",
      "        [0.8761],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.0335],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.5165],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.9164],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.0142],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.6920],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.8223],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.9814],\n",
      "        [0.9009],\n",
      "        [0.8379],\n",
      "        [0.0383],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.3840],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.4645],\n",
      "        [0.2547],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [0.1762],\n",
      "        [0.2610],\n",
      "        [0.9995],\n",
      "        [0.6555],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [0.9956],\n",
      "        [0.9999],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.0368],\n",
      "        [0.7391],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [0.9490],\n",
      "        [0.3747],\n",
      "        [0.9966],\n",
      "        [0.5945],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [1.0000]])\n",
      "######### Epoch: 40  ######### Train Loss: 0.00024544939515180886  ######### Relative L2 Test Norm: 14.484519958496094\n",
      "Output batch pred: tensor([[[0.2238],\n",
      "         [0.9723],\n",
      "         [0.5008],\n",
      "         [0.3562],\n",
      "         [0.9751],\n",
      "         [0.3397],\n",
      "         [0.3486],\n",
      "         [0.0436],\n",
      "         [0.5273],\n",
      "         [0.9757],\n",
      "         [0.9773],\n",
      "         [0.9771],\n",
      "         [0.9791],\n",
      "         [0.9499],\n",
      "         [0.9865],\n",
      "         [0.9866],\n",
      "         [0.5021],\n",
      "         [0.9833],\n",
      "         [0.2486],\n",
      "         [0.8416],\n",
      "         [0.9753],\n",
      "         [0.4362],\n",
      "         [0.9877],\n",
      "         [0.3852],\n",
      "         [0.9962],\n",
      "         [0.4691],\n",
      "         [1.0013],\n",
      "         [1.0009],\n",
      "         [0.9968],\n",
      "         [0.9937],\n",
      "         [0.9914],\n",
      "         [0.9835],\n",
      "         [0.3788],\n",
      "         [0.9848],\n",
      "         [0.9824],\n",
      "         [0.8432],\n",
      "         [0.9913],\n",
      "         [0.8680],\n",
      "         [0.9961],\n",
      "         [0.9257],\n",
      "         [0.3865],\n",
      "         [0.9946],\n",
      "         [0.9912],\n",
      "         [0.9913],\n",
      "         [0.9780],\n",
      "         [0.9915],\n",
      "         [0.3759],\n",
      "         [0.2642],\n",
      "         [0.9991],\n",
      "         [0.5199],\n",
      "         [0.9993],\n",
      "         [1.0004],\n",
      "         [0.4021],\n",
      "         [0.9900],\n",
      "         [0.6789],\n",
      "         [0.0438],\n",
      "         [0.9790],\n",
      "         [0.4952],\n",
      "         [0.7594],\n",
      "         [0.9832],\n",
      "         [0.9847],\n",
      "         [0.9856],\n",
      "         [0.9861],\n",
      "         [0.9858],\n",
      "         [0.9818],\n",
      "         [0.9799],\n",
      "         [0.2360],\n",
      "         [0.9706],\n",
      "         [0.0475],\n",
      "         [0.9133],\n",
      "         [0.2608],\n",
      "         [0.9810],\n",
      "         [0.6905],\n",
      "         [0.9497],\n",
      "         [0.4719],\n",
      "         [0.9882],\n",
      "         [0.9846],\n",
      "         [0.7136],\n",
      "         [0.9554],\n",
      "         [0.4864],\n",
      "         [0.9667],\n",
      "         [0.2196],\n",
      "         [0.9660],\n",
      "         [0.9747],\n",
      "         [0.9789],\n",
      "         [0.9858],\n",
      "         [0.4595],\n",
      "         [0.9951],\n",
      "         [0.9960],\n",
      "         [0.9921],\n",
      "         [0.9909],\n",
      "         [0.2146],\n",
      "         [0.4627],\n",
      "         [0.9812],\n",
      "         [0.9798],\n",
      "         [0.9819],\n",
      "         [0.9806],\n",
      "         [0.5067],\n",
      "         [0.9889],\n",
      "         [0.9909],\n",
      "         [0.9913],\n",
      "         [0.5087],\n",
      "         [0.9105],\n",
      "         [0.0658],\n",
      "         [0.7725],\n",
      "         [0.7321],\n",
      "         [0.9773],\n",
      "         [0.2490],\n",
      "         [0.9769],\n",
      "         [0.9776],\n",
      "         [0.9785],\n",
      "         [0.9786],\n",
      "         [0.3525],\n",
      "         [0.9812],\n",
      "         [0.9821],\n",
      "         [0.9846],\n",
      "         [0.9868],\n",
      "         [0.9884],\n",
      "         [0.9888],\n",
      "         [0.9933],\n",
      "         [0.9940],\n",
      "         [0.5238],\n",
      "         [0.9764],\n",
      "         [0.9121],\n",
      "         [0.9757],\n",
      "         [0.9727],\n",
      "         [0.9718],\n",
      "         [0.4274],\n",
      "         [0.9713],\n",
      "         [0.4328],\n",
      "         [0.9805],\n",
      "         [0.9867],\n",
      "         [0.9920],\n",
      "         [0.6255],\n",
      "         [0.9973],\n",
      "         [0.5303],\n",
      "         [0.0797],\n",
      "         [0.9917],\n",
      "         [0.3741],\n",
      "         [0.9839],\n",
      "         [0.9861],\n",
      "         [0.9877],\n",
      "         [0.0500],\n",
      "         [0.9926],\n",
      "         [0.9977],\n",
      "         [0.8290],\n",
      "         [0.6725],\n",
      "         [0.3660],\n",
      "         [0.9977],\n",
      "         [0.0759],\n",
      "         [0.9562],\n",
      "         [0.9871],\n",
      "         [0.9841],\n",
      "         [0.9871],\n",
      "         [0.9908],\n",
      "         [0.9910],\n",
      "         [0.1909],\n",
      "         [1.0000],\n",
      "         [0.2826],\n",
      "         [0.9642],\n",
      "         [0.4766],\n",
      "         [0.9947],\n",
      "         [0.5105],\n",
      "         [0.4478],\n",
      "         [0.9859],\n",
      "         [0.9883],\n",
      "         [0.0648],\n",
      "         [0.4493],\n",
      "         [0.9775],\n",
      "         [0.0520],\n",
      "         [0.5443],\n",
      "         [0.9886],\n",
      "         [0.9735],\n",
      "         [0.8882],\n",
      "         [0.8382],\n",
      "         [0.9691],\n",
      "         [0.9658],\n",
      "         [0.5216]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2518],\n",
      "        [0.9999],\n",
      "        [0.5151],\n",
      "        [0.3780],\n",
      "        [0.9995],\n",
      "        [0.3575],\n",
      "        [0.3728],\n",
      "        [0.0247],\n",
      "        [0.5334],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9490],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [0.8223],\n",
      "        [0.9956],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9999],\n",
      "        [0.6555],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9967],\n",
      "        [0.9994],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9164],\n",
      "        [0.2735],\n",
      "        [0.9997],\n",
      "        [0.6628],\n",
      "        [0.9420],\n",
      "        [0.4642],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.9724],\n",
      "        [0.5108],\n",
      "        [0.9996],\n",
      "        [0.2547],\n",
      "        [0.9962],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [0.8933],\n",
      "        [0.0288],\n",
      "        [0.7540],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9820],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.9996],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.7820],\n",
      "        [0.6327],\n",
      "        [0.3573],\n",
      "        [0.9997],\n",
      "        [0.0335],\n",
      "        [0.9515],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.9520],\n",
      "        [0.4645],\n",
      "        [0.9998],\n",
      "        [0.5054],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.4480],\n",
      "        [0.9814],\n",
      "        [0.0142],\n",
      "        [0.5245],\n",
      "        [0.9998],\n",
      "        [0.9819],\n",
      "        [0.8761],\n",
      "        [0.8296],\n",
      "        [0.9999],\n",
      "        [0.9959],\n",
      "        [0.5463]])\n",
      "######### Epoch: 41  ######### Train Loss: 0.0003363847208674997  ######### Relative L2 Test Norm: 15.2177734375\n",
      "Output batch pred: tensor([[[0.9749],\n",
      "         [0.3717],\n",
      "         [0.9642],\n",
      "         [0.7352],\n",
      "         [0.9828],\n",
      "         [0.2606],\n",
      "         [0.9843],\n",
      "         [0.9797],\n",
      "         [0.9819],\n",
      "         [0.9761],\n",
      "         [0.5059],\n",
      "         [0.9718],\n",
      "         [0.9719],\n",
      "         [0.9751],\n",
      "         [0.9782],\n",
      "         [0.9824],\n",
      "         [0.9859],\n",
      "         [0.4630],\n",
      "         [0.3713],\n",
      "         [0.9891],\n",
      "         [0.9871],\n",
      "         [0.9838],\n",
      "         [0.9788],\n",
      "         [0.2340],\n",
      "         [0.9709],\n",
      "         [0.9700],\n",
      "         [0.9565],\n",
      "         [0.9692],\n",
      "         [0.6704],\n",
      "         [0.9732],\n",
      "         [0.9755],\n",
      "         [0.9714],\n",
      "         [0.5004],\n",
      "         [0.4568],\n",
      "         [0.9855],\n",
      "         [0.9868],\n",
      "         [0.7305],\n",
      "         [0.9889],\n",
      "         [0.9882],\n",
      "         [0.8143],\n",
      "         [0.9825],\n",
      "         [0.5092],\n",
      "         [0.9755],\n",
      "         [0.9695],\n",
      "         [0.8962],\n",
      "         [0.9715],\n",
      "         [0.0512],\n",
      "         [0.5041],\n",
      "         [0.9800],\n",
      "         [0.9824],\n",
      "         [0.9865],\n",
      "         [0.8634],\n",
      "         [0.9888],\n",
      "         [0.9897],\n",
      "         [0.9910],\n",
      "         [0.9881],\n",
      "         [0.3729],\n",
      "         [0.9827],\n",
      "         [0.9802],\n",
      "         [0.0738],\n",
      "         [0.9851],\n",
      "         [0.9534],\n",
      "         [0.4525],\n",
      "         [0.9874],\n",
      "         [0.4701],\n",
      "         [0.9849],\n",
      "         [0.9802],\n",
      "         [0.9751],\n",
      "         [0.9696],\n",
      "         [0.9666],\n",
      "         [0.9642],\n",
      "         [0.8866],\n",
      "         [0.4778],\n",
      "         [0.9707],\n",
      "         [0.9771],\n",
      "         [0.0649],\n",
      "         [0.9859],\n",
      "         [0.9510],\n",
      "         [0.9845],\n",
      "         [0.9797],\n",
      "         [0.9712],\n",
      "         [0.0374],\n",
      "         [0.1931],\n",
      "         [0.6173],\n",
      "         [0.9581],\n",
      "         [0.4284],\n",
      "         [0.3449],\n",
      "         [0.4306],\n",
      "         [0.9776],\n",
      "         [0.5288],\n",
      "         [0.9477],\n",
      "         [0.9813],\n",
      "         [0.5429],\n",
      "         [0.9785],\n",
      "         [0.9775],\n",
      "         [0.9754],\n",
      "         [0.5965],\n",
      "         [0.9728],\n",
      "         [0.8261],\n",
      "         [0.8832],\n",
      "         [0.9758],\n",
      "         [0.4905],\n",
      "         [0.6607],\n",
      "         [0.3730],\n",
      "         [0.9780],\n",
      "         [0.9782],\n",
      "         [0.9767],\n",
      "         [0.3634],\n",
      "         [0.9823],\n",
      "         [0.9834],\n",
      "         [0.9887],\n",
      "         [0.9892],\n",
      "         [0.3858],\n",
      "         [0.9943],\n",
      "         [0.9945],\n",
      "         [0.9931],\n",
      "         [0.9919],\n",
      "         [0.9890],\n",
      "         [0.2559],\n",
      "         [0.0510],\n",
      "         [0.9886],\n",
      "         [0.9491],\n",
      "         [0.9888],\n",
      "         [0.9161],\n",
      "         [0.4992],\n",
      "         [0.9754],\n",
      "         [0.4637],\n",
      "         [0.2594],\n",
      "         [0.4473],\n",
      "         [0.5052],\n",
      "         [0.5567],\n",
      "         [0.7711],\n",
      "         [0.9905],\n",
      "         [0.9913],\n",
      "         [0.9906],\n",
      "         [0.7791],\n",
      "         [0.2360],\n",
      "         [0.2335],\n",
      "         [0.9734],\n",
      "         [0.9675],\n",
      "         [0.0549],\n",
      "         [0.9629],\n",
      "         [0.0327],\n",
      "         [0.4885],\n",
      "         [0.9682],\n",
      "         [0.2548],\n",
      "         [0.3449],\n",
      "         [0.9232],\n",
      "         [0.2547],\n",
      "         [0.9794],\n",
      "         [0.9781],\n",
      "         [0.9749],\n",
      "         [0.1652],\n",
      "         [0.9672],\n",
      "         [0.3291],\n",
      "         [0.4227],\n",
      "         [0.9561],\n",
      "         [0.3518],\n",
      "         [0.4994],\n",
      "         [0.9807],\n",
      "         [0.9781],\n",
      "         [0.9771],\n",
      "         [0.9726],\n",
      "         [0.9682],\n",
      "         [0.0207],\n",
      "         [0.8296],\n",
      "         [0.9642],\n",
      "         [0.9681],\n",
      "         [0.9719],\n",
      "         [0.8446],\n",
      "         [0.9864],\n",
      "         [0.4647],\n",
      "         [0.3936],\n",
      "         [0.9818],\n",
      "         [0.9944],\n",
      "         [0.9900],\n",
      "         [0.0690],\n",
      "         [0.9784]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.3912],\n",
      "        [0.9820],\n",
      "        [0.7129],\n",
      "        [0.9997],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.4645],\n",
      "        [0.3780],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.5038],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6920],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.9999],\n",
      "        [0.9962],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [0.0247],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.8933],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0383],\n",
      "        [0.9999],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.0142],\n",
      "        [0.2208],\n",
      "        [0.6327],\n",
      "        [0.9999],\n",
      "        [0.4611],\n",
      "        [0.3747],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [0.9490],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.6555],\n",
      "        [0.3930],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2610],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.5009],\n",
      "        [0.9819],\n",
      "        [0.4668],\n",
      "        [0.2646],\n",
      "        [0.4503],\n",
      "        [0.5030],\n",
      "        [0.5463],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.2518],\n",
      "        [0.2547],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.9996],\n",
      "        [0.0000],\n",
      "        [0.5139],\n",
      "        [0.9999],\n",
      "        [0.2729],\n",
      "        [0.3575],\n",
      "        [0.9164],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.9999],\n",
      "        [0.3573],\n",
      "        [0.4454],\n",
      "        [0.9724],\n",
      "        [0.3728],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [0.0209],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.3840],\n",
      "        [0.9814],\n",
      "        [0.9996],\n",
      "        [0.9995],\n",
      "        [0.0288],\n",
      "        [0.9998]])\n",
      "######### Epoch: 42  ######### Train Loss: 0.0004071698058396578  ######### Relative L2 Test Norm: 15.23586368560791\n",
      "Output batch pred: tensor([[[0.9783],\n",
      "         [0.9363],\n",
      "         [0.5961],\n",
      "         [0.9570],\n",
      "         [0.9719],\n",
      "         [0.9723],\n",
      "         [0.9717],\n",
      "         [0.9685],\n",
      "         [0.9727],\n",
      "         [0.2273],\n",
      "         [0.9722],\n",
      "         [0.8317],\n",
      "         [0.9683],\n",
      "         [0.3555],\n",
      "         [0.3507],\n",
      "         [0.9689],\n",
      "         [0.9761],\n",
      "         [0.9803],\n",
      "         [0.0392],\n",
      "         [0.9891],\n",
      "         [0.9913],\n",
      "         [0.9910],\n",
      "         [0.9874],\n",
      "         [0.5017],\n",
      "         [0.4884],\n",
      "         [0.3699],\n",
      "         [0.7406],\n",
      "         [0.2350],\n",
      "         [0.9622],\n",
      "         [0.9633],\n",
      "         [0.9678],\n",
      "         [0.8995],\n",
      "         [0.9763],\n",
      "         [0.9835],\n",
      "         [0.9868],\n",
      "         [0.9883],\n",
      "         [0.9880],\n",
      "         [0.9849],\n",
      "         [0.9834],\n",
      "         [0.9810],\n",
      "         [0.9785],\n",
      "         [0.9759],\n",
      "         [0.8299],\n",
      "         [0.9753],\n",
      "         [0.8497],\n",
      "         [0.9780],\n",
      "         [0.9811],\n",
      "         [0.9757],\n",
      "         [0.6721],\n",
      "         [0.9808],\n",
      "         [0.9770],\n",
      "         [0.9781],\n",
      "         [0.4356],\n",
      "         [0.9767],\n",
      "         [0.9765],\n",
      "         [0.9768],\n",
      "         [0.5218],\n",
      "         [0.9765],\n",
      "         [0.0586],\n",
      "         [0.9763],\n",
      "         [0.0517],\n",
      "         [0.9759],\n",
      "         [0.8412],\n",
      "         [0.9771],\n",
      "         [0.3637],\n",
      "         [0.0578],\n",
      "         [0.9775],\n",
      "         [0.0539],\n",
      "         [0.9411],\n",
      "         [0.9761],\n",
      "         [0.9127],\n",
      "         [0.2270],\n",
      "         [0.9648],\n",
      "         [0.2166],\n",
      "         [0.9656],\n",
      "         [0.9667],\n",
      "         [0.9683],\n",
      "         [0.9699],\n",
      "         [0.4407],\n",
      "         [0.9772],\n",
      "         [0.8024],\n",
      "         [0.9768],\n",
      "         [0.9759],\n",
      "         [0.3304],\n",
      "         [0.6677],\n",
      "         [0.9669],\n",
      "         [0.9483],\n",
      "         [0.9679],\n",
      "         [0.4797],\n",
      "         [0.4456],\n",
      "         [0.9749],\n",
      "         [0.9771],\n",
      "         [0.9802],\n",
      "         [0.5003],\n",
      "         [0.0521],\n",
      "         [0.9775],\n",
      "         [0.9742],\n",
      "         [0.9736],\n",
      "         [0.9710],\n",
      "         [0.9695],\n",
      "         [0.3491],\n",
      "         [0.4853],\n",
      "         [0.4422],\n",
      "         [0.9670],\n",
      "         [0.9833],\n",
      "         [0.4632],\n",
      "         [0.9887],\n",
      "         [0.9892],\n",
      "         [0.8999],\n",
      "         [0.2651],\n",
      "         [0.9880],\n",
      "         [0.9840],\n",
      "         [0.5094],\n",
      "         [0.2385],\n",
      "         [0.9841],\n",
      "         [0.7735],\n",
      "         [0.9840],\n",
      "         [0.9830],\n",
      "         [0.9826],\n",
      "         [0.9834],\n",
      "         [0.9832],\n",
      "         [0.6487],\n",
      "         [0.9069],\n",
      "         [0.5438],\n",
      "         [0.5151],\n",
      "         [0.9850],\n",
      "         [0.9850],\n",
      "         [0.3452],\n",
      "         [0.7327],\n",
      "         [0.9747],\n",
      "         [0.4309],\n",
      "         [0.3675],\n",
      "         [0.4967],\n",
      "         [0.1616],\n",
      "         [0.9758],\n",
      "         [0.9745],\n",
      "         [0.9450],\n",
      "         [0.0437],\n",
      "         [0.9703],\n",
      "         [0.9096],\n",
      "         [0.7139],\n",
      "         [0.9751],\n",
      "         [0.4496],\n",
      "         [0.0615],\n",
      "         [0.2519],\n",
      "         [0.9649],\n",
      "         [0.2520],\n",
      "         [0.9730],\n",
      "         [0.9772],\n",
      "         [0.2128],\n",
      "         [0.9846],\n",
      "         [0.9908],\n",
      "         [0.9921],\n",
      "         [0.9917],\n",
      "         [0.4489],\n",
      "         [0.4523],\n",
      "         [0.9809],\n",
      "         [0.3756],\n",
      "         [0.3570],\n",
      "         [0.9398],\n",
      "         [0.9771],\n",
      "         [0.0581],\n",
      "         [0.9799],\n",
      "         [0.9853],\n",
      "         [0.9872],\n",
      "         [0.9848],\n",
      "         [0.9738],\n",
      "         [0.9846],\n",
      "         [0.9800],\n",
      "         [0.5429],\n",
      "         [0.9754],\n",
      "         [0.5058],\n",
      "         [0.4388],\n",
      "         [0.4956],\n",
      "         [0.3632],\n",
      "         [0.9783],\n",
      "         [0.9772],\n",
      "         [0.9802]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.9420],\n",
      "        [0.5945],\n",
      "        [0.9814],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [0.9967],\n",
      "        [0.3840],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.0000],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.4988],\n",
      "        [0.3930],\n",
      "        [0.7391],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.6555],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5245],\n",
      "        [0.9997],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [0.8296],\n",
      "        [0.9994],\n",
      "        [0.3753],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.2577],\n",
      "        [0.9959],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.6628],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.4668],\n",
      "        [0.9966],\n",
      "        [0.9962],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.5054],\n",
      "        [0.4611],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8761],\n",
      "        [0.2646],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.8933],\n",
      "        [0.5334],\n",
      "        [0.5165],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.3912],\n",
      "        [0.5139],\n",
      "        [0.1762],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9515],\n",
      "        [0.0288],\n",
      "        [0.9804],\n",
      "        [0.9044],\n",
      "        [0.6920],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [0.0368],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.2208],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.3728],\n",
      "        [0.9490],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.4552],\n",
      "        [0.5080],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000]])\n",
      "######### Epoch: 43  ######### Train Loss: 0.00044097169302403927  ######### Relative L2 Test Norm: 15.395465850830078\n",
      "Output batch pred: tensor([[[0.9849],\n",
      "         [0.9762],\n",
      "         [0.8141],\n",
      "         [0.4646],\n",
      "         [0.3618],\n",
      "         [0.6444],\n",
      "         [0.9777],\n",
      "         [0.0463],\n",
      "         [0.9722],\n",
      "         [0.9714],\n",
      "         [0.9709],\n",
      "         [0.9720],\n",
      "         [0.9730],\n",
      "         [0.8983],\n",
      "         [0.9741],\n",
      "         [0.4972],\n",
      "         [0.9752],\n",
      "         [0.9763],\n",
      "         [0.2541],\n",
      "         [0.4363],\n",
      "         [0.9819],\n",
      "         [0.4551],\n",
      "         [0.9882],\n",
      "         [0.9901],\n",
      "         [0.4746],\n",
      "         [0.2553],\n",
      "         [0.9875],\n",
      "         [0.9880],\n",
      "         [0.9836],\n",
      "         [0.9791],\n",
      "         [0.9790],\n",
      "         [0.7525],\n",
      "         [0.2255],\n",
      "         [0.9756],\n",
      "         [0.4872],\n",
      "         [0.9822],\n",
      "         [0.4382],\n",
      "         [0.9845],\n",
      "         [0.4428],\n",
      "         [0.9837],\n",
      "         [0.4981],\n",
      "         [0.9813],\n",
      "         [0.9789],\n",
      "         [0.3683],\n",
      "         [0.9411],\n",
      "         [0.9803],\n",
      "         [0.1763],\n",
      "         [0.2145],\n",
      "         [0.9835],\n",
      "         [0.8532],\n",
      "         [0.9646],\n",
      "         [0.3373],\n",
      "         [0.0215],\n",
      "         [0.9692],\n",
      "         [0.9655],\n",
      "         [0.6597],\n",
      "         [0.8299],\n",
      "         [0.9680],\n",
      "         [0.8375],\n",
      "         [0.3616],\n",
      "         [0.9878],\n",
      "         [0.2614],\n",
      "         [0.9901],\n",
      "         [0.9921],\n",
      "         [0.7812],\n",
      "         [0.4595],\n",
      "         [0.9813],\n",
      "         [0.9739],\n",
      "         [0.0461],\n",
      "         [0.2219],\n",
      "         [0.2376],\n",
      "         [0.9676],\n",
      "         [0.9636],\n",
      "         [0.9670],\n",
      "         [0.0315],\n",
      "         [0.9717],\n",
      "         [0.8264],\n",
      "         [0.9758],\n",
      "         [0.9767],\n",
      "         [0.6645],\n",
      "         [0.9799],\n",
      "         [0.9806],\n",
      "         [0.9812],\n",
      "         [0.8922],\n",
      "         [0.9838],\n",
      "         [0.9823],\n",
      "         [0.9840],\n",
      "         [0.9826],\n",
      "         [0.0590],\n",
      "         [0.5457],\n",
      "         [0.0567],\n",
      "         [0.9884],\n",
      "         [0.9904],\n",
      "         [0.9582],\n",
      "         [0.9922],\n",
      "         [0.9928],\n",
      "         [0.5602],\n",
      "         [0.9877],\n",
      "         [0.9832],\n",
      "         [0.4440],\n",
      "         [0.0467],\n",
      "         [0.9770],\n",
      "         [0.9776],\n",
      "         [0.9797],\n",
      "         [0.9818],\n",
      "         [0.3701],\n",
      "         [0.9859],\n",
      "         [0.3826],\n",
      "         [0.9899],\n",
      "         [0.9841],\n",
      "         [0.9294],\n",
      "         [0.9500],\n",
      "         [0.2434],\n",
      "         [0.9802],\n",
      "         [0.9786],\n",
      "         [0.9776],\n",
      "         [0.9799],\n",
      "         [0.9813],\n",
      "         [0.9795],\n",
      "         [0.9817],\n",
      "         [0.5285],\n",
      "         [0.3393],\n",
      "         [0.7080],\n",
      "         [0.3676],\n",
      "         [0.9652],\n",
      "         [0.9668],\n",
      "         [0.9672],\n",
      "         [0.4783],\n",
      "         [0.3514],\n",
      "         [0.4405],\n",
      "         [0.9703],\n",
      "         [0.9861],\n",
      "         [0.9875],\n",
      "         [0.3848],\n",
      "         [0.9821],\n",
      "         [0.9809],\n",
      "         [0.9772],\n",
      "         [0.4406],\n",
      "         [0.9691],\n",
      "         [0.9579],\n",
      "         [0.4912],\n",
      "         [0.4998],\n",
      "         [0.9804],\n",
      "         [0.9828],\n",
      "         [0.9873],\n",
      "         [0.9889],\n",
      "         [0.5118],\n",
      "         [0.9826],\n",
      "         [0.0722],\n",
      "         [0.6044],\n",
      "         [0.9767],\n",
      "         [0.9726],\n",
      "         [0.9716],\n",
      "         [0.7301],\n",
      "         [0.2538],\n",
      "         [0.9813],\n",
      "         [0.9845],\n",
      "         [0.9861],\n",
      "         [0.9864],\n",
      "         [0.5017],\n",
      "         [0.9831],\n",
      "         [0.9814],\n",
      "         [0.9796],\n",
      "         [0.9427],\n",
      "         [0.9610],\n",
      "         [0.9807],\n",
      "         [0.9817],\n",
      "         [0.9832],\n",
      "         [0.9844],\n",
      "         [0.9852],\n",
      "         [0.5153],\n",
      "         [0.9797],\n",
      "         [0.9777],\n",
      "         [0.5052],\n",
      "         [0.9032],\n",
      "         [0.8987],\n",
      "         [0.0632],\n",
      "         [0.3620]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.9819],\n",
      "        [0.7820],\n",
      "        [0.4642],\n",
      "        [0.3753],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.9996],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2735],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.4668],\n",
      "        [0.2577],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.2518],\n",
      "        [0.9999],\n",
      "        [0.4988],\n",
      "        [0.9997],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.9994],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.9420],\n",
      "        [0.9999],\n",
      "        [0.1762],\n",
      "        [0.2208],\n",
      "        [0.9998],\n",
      "        [0.8379],\n",
      "        [0.9814],\n",
      "        [0.3575],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.7540],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.2547],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.5334],\n",
      "        [0.0209],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.9999],\n",
      "        [0.9956],\n",
      "        [0.9164],\n",
      "        [0.9490],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.3573],\n",
      "        [0.6920],\n",
      "        [0.3912],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5009],\n",
      "        [0.3747],\n",
      "        [0.4552],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.3930],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.9997],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.5080],\n",
      "        [0.5108],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.5054],\n",
      "        [0.9997],\n",
      "        [0.0368],\n",
      "        [0.5945],\n",
      "        [0.9999],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9520],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5139],\n",
      "        [0.9009],\n",
      "        [0.8933],\n",
      "        [0.0288],\n",
      "        [0.3728]])\n",
      "######### Epoch: 44  ######### Train Loss: 0.0003579701005946845  ######### Relative L2 Test Norm: 14.876906394958496\n",
      "Output batch pred: tensor([[[0.9812],\n",
      "         [0.4864],\n",
      "         [0.9787],\n",
      "         [0.9792],\n",
      "         [0.9450],\n",
      "         [0.9845],\n",
      "         [0.4598],\n",
      "         [0.3745],\n",
      "         [0.9924],\n",
      "         [0.9931],\n",
      "         [0.9915],\n",
      "         [0.0531],\n",
      "         [0.5015],\n",
      "         [0.9888],\n",
      "         [0.6503],\n",
      "         [0.2394],\n",
      "         [0.3363],\n",
      "         [0.3645],\n",
      "         [0.9781],\n",
      "         [0.9750],\n",
      "         [0.4416],\n",
      "         [0.5263],\n",
      "         [0.9753],\n",
      "         [0.7979],\n",
      "         [0.9784],\n",
      "         [0.5473],\n",
      "         [0.9850],\n",
      "         [0.9895],\n",
      "         [0.6854],\n",
      "         [0.9899],\n",
      "         [0.9779],\n",
      "         [0.2607],\n",
      "         [0.9919],\n",
      "         [0.9882],\n",
      "         [0.9815],\n",
      "         [0.9794],\n",
      "         [0.3460],\n",
      "         [0.2390],\n",
      "         [0.2098],\n",
      "         [0.9843],\n",
      "         [0.9878],\n",
      "         [0.9762],\n",
      "         [0.8602],\n",
      "         [0.9841],\n",
      "         [0.9793],\n",
      "         [0.9778],\n",
      "         [0.9769],\n",
      "         [0.9337],\n",
      "         [0.9747],\n",
      "         [0.9760],\n",
      "         [0.9811],\n",
      "         [0.9855],\n",
      "         [0.9143],\n",
      "         [0.8602],\n",
      "         [0.9983],\n",
      "         [0.9963],\n",
      "         [0.9960],\n",
      "         [0.2667],\n",
      "         [0.3676],\n",
      "         [0.7150],\n",
      "         [0.4412],\n",
      "         [0.9802],\n",
      "         [0.9811],\n",
      "         [0.0439],\n",
      "         [0.9904],\n",
      "         [0.9953],\n",
      "         [0.9970],\n",
      "         [0.9979],\n",
      "         [0.9972],\n",
      "         [0.9927],\n",
      "         [0.2567],\n",
      "         [0.1695],\n",
      "         [0.9734],\n",
      "         [0.9698],\n",
      "         [0.0389],\n",
      "         [0.9666],\n",
      "         [0.0470],\n",
      "         [0.9758],\n",
      "         [0.9831],\n",
      "         [0.8383],\n",
      "         [0.9871],\n",
      "         [0.0581],\n",
      "         [0.9902],\n",
      "         [0.9889],\n",
      "         [0.9525],\n",
      "         [0.5013],\n",
      "         [0.5093],\n",
      "         [0.9857],\n",
      "         [0.9873],\n",
      "         [0.9846],\n",
      "         [0.9893],\n",
      "         [0.7674],\n",
      "         [0.9843],\n",
      "         [0.9840],\n",
      "         [0.9808],\n",
      "         [0.9653],\n",
      "         [0.9714],\n",
      "         [0.5003],\n",
      "         [0.9731],\n",
      "         [0.3502],\n",
      "         [0.9468],\n",
      "         [0.7762],\n",
      "         [0.9887],\n",
      "         [0.9919],\n",
      "         [0.9341],\n",
      "         [0.9896],\n",
      "         [0.9181],\n",
      "         [0.5063],\n",
      "         [0.2464],\n",
      "         [0.9850],\n",
      "         [0.4427],\n",
      "         [0.8503],\n",
      "         [0.9868],\n",
      "         [0.9879],\n",
      "         [0.9881],\n",
      "         [0.9883],\n",
      "         [0.9862],\n",
      "         [0.3589],\n",
      "         [0.7347],\n",
      "         [0.9829],\n",
      "         [0.0590],\n",
      "         [0.5256],\n",
      "         [0.5103],\n",
      "         [0.4647],\n",
      "         [0.9923],\n",
      "         [0.9979],\n",
      "         [0.9890],\n",
      "         [1.0037],\n",
      "         [0.4640],\n",
      "         [0.5374],\n",
      "         [1.0000],\n",
      "         [0.3676],\n",
      "         [0.9885],\n",
      "         [0.4431],\n",
      "         [0.9773],\n",
      "         [0.9719],\n",
      "         [0.9672],\n",
      "         [0.3466],\n",
      "         [0.9670],\n",
      "         [0.2203],\n",
      "         [0.3543],\n",
      "         [0.9728],\n",
      "         [0.9794],\n",
      "         [0.9844],\n",
      "         [0.9898],\n",
      "         [0.9940],\n",
      "         [0.9973],\n",
      "         [0.0715],\n",
      "         [0.5339],\n",
      "         [0.2877],\n",
      "         [0.9831],\n",
      "         [0.6965],\n",
      "         [0.0610],\n",
      "         [0.4969],\n",
      "         [0.9779],\n",
      "         [0.9766],\n",
      "         [0.3514],\n",
      "         [0.5932],\n",
      "         [0.9761],\n",
      "         [0.9807],\n",
      "         [0.9855],\n",
      "         [0.9873],\n",
      "         [0.4433],\n",
      "         [0.9945],\n",
      "         [0.9964],\n",
      "         [0.9252],\n",
      "         [0.9963],\n",
      "         [0.9969],\n",
      "         [0.9941],\n",
      "         [0.9954],\n",
      "         [0.9086],\n",
      "         [0.9993],\n",
      "         [1.0005],\n",
      "         [0.0590],\n",
      "         [0.9956],\n",
      "         [0.4600],\n",
      "         [0.9920],\n",
      "         [0.4407]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.3840],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0000],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [0.6327],\n",
      "        [0.2547],\n",
      "        [0.3573],\n",
      "        [0.3875],\n",
      "        [0.9999],\n",
      "        [0.9962],\n",
      "        [0.4645],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.9999],\n",
      "        [0.5463],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.9956],\n",
      "        [0.9724],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.3575],\n",
      "        [0.2518],\n",
      "        [0.2208],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.8379],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.8933],\n",
      "        [0.8223],\n",
      "        [0.9994],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.3780],\n",
      "        [0.6920],\n",
      "        [0.4552],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0288],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.1762],\n",
      "        [0.9995],\n",
      "        [0.9997],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.9966],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.5009],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.9515],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [0.5054],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.7129],\n",
      "        [0.9997],\n",
      "        [0.0383],\n",
      "        [0.5245],\n",
      "        [0.5139],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.9995],\n",
      "        [0.4611],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0174],\n",
      "        [0.5108],\n",
      "        [0.2735],\n",
      "        [0.9814],\n",
      "        [0.6628],\n",
      "        [0.0142],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.3808],\n",
      "        [0.5945],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.9999],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.4503]])\n",
      "######### Epoch: 45  ######### Train Loss: 0.0003389309858903289  ######### Relative L2 Test Norm: 14.147846221923828\n",
      "Output batch pred: tensor([[[0.9859],\n",
      "         [0.4462],\n",
      "         [0.9824],\n",
      "         [0.9820],\n",
      "         [0.9809],\n",
      "         [0.9711],\n",
      "         [0.9858],\n",
      "         [0.9866],\n",
      "         [0.4473],\n",
      "         [0.3407],\n",
      "         [0.9910],\n",
      "         [0.9919],\n",
      "         [0.9925],\n",
      "         [0.7231],\n",
      "         [0.3829],\n",
      "         [0.9907],\n",
      "         [0.9953],\n",
      "         [0.4505],\n",
      "         [0.9990],\n",
      "         [1.0016],\n",
      "         [0.5193],\n",
      "         [0.0717],\n",
      "         [0.2657],\n",
      "         [1.0054],\n",
      "         [1.0032],\n",
      "         [0.9992],\n",
      "         [0.3424],\n",
      "         [0.9876],\n",
      "         [0.9825],\n",
      "         [0.9758],\n",
      "         [0.9774],\n",
      "         [0.9784],\n",
      "         [0.9801],\n",
      "         [0.9538],\n",
      "         [0.9987],\n",
      "         [0.5140],\n",
      "         [0.2630],\n",
      "         [1.0134],\n",
      "         [1.0138],\n",
      "         [0.4653],\n",
      "         [0.3851],\n",
      "         [0.9963],\n",
      "         [0.5128],\n",
      "         [0.0296],\n",
      "         [0.3507],\n",
      "         [0.9832],\n",
      "         [0.2461],\n",
      "         [0.4985],\n",
      "         [0.9978],\n",
      "         [0.8587],\n",
      "         [1.0055],\n",
      "         [0.7888],\n",
      "         [0.6303],\n",
      "         [0.3713],\n",
      "         [0.9932],\n",
      "         [0.9828],\n",
      "         [0.9838],\n",
      "         [0.6609],\n",
      "         [0.9842],\n",
      "         [0.9867],\n",
      "         [0.8108],\n",
      "         [0.5530],\n",
      "         [0.0661],\n",
      "         [0.3853],\n",
      "         [0.2627],\n",
      "         [0.4530],\n",
      "         [0.9959],\n",
      "         [0.4723],\n",
      "         [0.9932],\n",
      "         [0.9912],\n",
      "         [0.9556],\n",
      "         [0.9945],\n",
      "         [0.9994],\n",
      "         [0.9977],\n",
      "         [1.0032],\n",
      "         [1.0024],\n",
      "         [0.9999],\n",
      "         [0.2515],\n",
      "         [0.5348],\n",
      "         [0.4578],\n",
      "         [0.9100],\n",
      "         [0.2049],\n",
      "         [0.9862],\n",
      "         [0.9866],\n",
      "         [0.2579],\n",
      "         [0.5167],\n",
      "         [1.0031],\n",
      "         [0.9378],\n",
      "         [1.0094],\n",
      "         [1.0087],\n",
      "         [0.9772],\n",
      "         [0.5412],\n",
      "         [1.0050],\n",
      "         [1.0012],\n",
      "         [0.9970],\n",
      "         [0.5175],\n",
      "         [0.9105],\n",
      "         [0.9849],\n",
      "         [0.9714],\n",
      "         [0.9829],\n",
      "         [0.9823],\n",
      "         [0.9831],\n",
      "         [0.5420],\n",
      "         [0.8563],\n",
      "         [0.2617],\n",
      "         [0.0783],\n",
      "         [1.0113],\n",
      "         [1.0178],\n",
      "         [1.0185],\n",
      "         [1.0143],\n",
      "         [1.0132],\n",
      "         [1.0063],\n",
      "         [0.9964],\n",
      "         [0.9923],\n",
      "         [0.0361],\n",
      "         [0.9833],\n",
      "         [0.4939],\n",
      "         [0.3572],\n",
      "         [0.9894],\n",
      "         [0.9962],\n",
      "         [0.9974],\n",
      "         [1.0000],\n",
      "         [0.9835],\n",
      "         [0.9983],\n",
      "         [0.9946],\n",
      "         [0.4988],\n",
      "         [0.9810],\n",
      "         [0.9823],\n",
      "         [0.9667],\n",
      "         [0.2648],\n",
      "         [0.5148],\n",
      "         [0.9977],\n",
      "         [0.4729],\n",
      "         [1.0058],\n",
      "         [1.0069],\n",
      "         [0.7642],\n",
      "         [0.6665],\n",
      "         [0.0483],\n",
      "         [0.9824],\n",
      "         [0.8367],\n",
      "         [0.9688],\n",
      "         [0.9692],\n",
      "         [0.6637],\n",
      "         [0.8843],\n",
      "         [0.9840],\n",
      "         [0.9935],\n",
      "         [0.3876],\n",
      "         [1.0014],\n",
      "         [1.0023],\n",
      "         [0.9997],\n",
      "         [0.9934],\n",
      "         [0.9890],\n",
      "         [0.9843],\n",
      "         [0.0496],\n",
      "         [0.4323],\n",
      "         [0.9831],\n",
      "         [0.9852],\n",
      "         [0.3797],\n",
      "         [0.9948],\n",
      "         [0.9388],\n",
      "         [0.0451],\n",
      "         [0.1703],\n",
      "         [0.9937],\n",
      "         [0.9542],\n",
      "         [0.9724],\n",
      "         [0.9812],\n",
      "         [0.9823],\n",
      "         [0.4437],\n",
      "         [0.8544],\n",
      "         [0.9897],\n",
      "         [0.9938],\n",
      "         [0.9970],\n",
      "         [0.0628],\n",
      "         [0.3818],\n",
      "         [0.7917],\n",
      "         [0.9989],\n",
      "         [0.9959],\n",
      "         [0.9906]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9994],\n",
      "        [0.6920],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4503],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.0383],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.9995],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.2518],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [0.5151],\n",
      "        [0.0000],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.5009],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [0.9997],\n",
      "        [0.7391],\n",
      "        [0.5945],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.9997],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.7820],\n",
      "        [0.5463],\n",
      "        [0.0335],\n",
      "        [0.3840],\n",
      "        [0.2610],\n",
      "        [0.4454],\n",
      "        [0.9999],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9420],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.5245],\n",
      "        [0.4645],\n",
      "        [0.9009],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9515],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.5165],\n",
      "        [0.8933],\n",
      "        [0.9998],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.8223],\n",
      "        [0.2577],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [0.5054],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9814],\n",
      "        [0.2735],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.9959],\n",
      "        [0.9966],\n",
      "        [0.7129],\n",
      "        [0.6327],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0288],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9994],\n",
      "        [0.9164],\n",
      "        [0.0209],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.9820],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.8379],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.3780],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000]])\n",
      "######### Epoch: 46  ######### Train Loss: 0.00026826324756257236  ######### Relative L2 Test Norm: 13.791784286499023\n",
      "Output batch pred: tensor([[[0.9969],\n",
      "         [0.9968],\n",
      "         [0.9964],\n",
      "         [0.9954],\n",
      "         [0.9884],\n",
      "         [1.0022],\n",
      "         [1.0068],\n",
      "         [1.0077],\n",
      "         [1.0090],\n",
      "         [0.0340],\n",
      "         [0.8753],\n",
      "         [0.9146],\n",
      "         [0.9249],\n",
      "         [0.0616],\n",
      "         [0.8497],\n",
      "         [0.9963],\n",
      "         [0.3654],\n",
      "         [0.4418],\n",
      "         [0.9648],\n",
      "         [0.0566],\n",
      "         [0.3832],\n",
      "         [1.0034],\n",
      "         [0.1828],\n",
      "         [0.5221],\n",
      "         [1.0030],\n",
      "         [0.5117],\n",
      "         [0.4523],\n",
      "         [0.3814],\n",
      "         [0.3594],\n",
      "         [0.9922],\n",
      "         [0.4511],\n",
      "         [0.9903],\n",
      "         [0.9875],\n",
      "         [0.3618],\n",
      "         [0.4496],\n",
      "         [0.7273],\n",
      "         [0.9980],\n",
      "         [0.2521],\n",
      "         [1.0030],\n",
      "         [0.7629],\n",
      "         [1.0068],\n",
      "         [0.9721],\n",
      "         [1.0043],\n",
      "         [1.0017],\n",
      "         [0.9990],\n",
      "         [0.3434],\n",
      "         [0.9956],\n",
      "         [0.9947],\n",
      "         [0.9957],\n",
      "         [0.9958],\n",
      "         [1.0002],\n",
      "         [1.0028],\n",
      "         [1.0050],\n",
      "         [1.0068],\n",
      "         [0.8030],\n",
      "         [0.5743],\n",
      "         [0.9766],\n",
      "         [1.0128],\n",
      "         [1.0136],\n",
      "         [1.0136],\n",
      "         [0.8426],\n",
      "         [1.0154],\n",
      "         [1.0120],\n",
      "         [0.2279],\n",
      "         [1.0103],\n",
      "         [0.8796],\n",
      "         [1.0027],\n",
      "         [0.0450],\n",
      "         [0.8561],\n",
      "         [0.9940],\n",
      "         [0.9929],\n",
      "         [0.9902],\n",
      "         [0.4604],\n",
      "         [0.9273],\n",
      "         [1.0031],\n",
      "         [1.0068],\n",
      "         [1.0111],\n",
      "         [0.2601],\n",
      "         [0.2781],\n",
      "         [1.0106],\n",
      "         [1.0073],\n",
      "         [1.0032],\n",
      "         [0.9583],\n",
      "         [0.5071],\n",
      "         [0.4954],\n",
      "         [0.0613],\n",
      "         [0.9906],\n",
      "         [0.5098],\n",
      "         [0.0448],\n",
      "         [0.9957],\n",
      "         [0.3837],\n",
      "         [0.9970],\n",
      "         [0.6947],\n",
      "         [0.9787],\n",
      "         [0.9935],\n",
      "         [0.6134],\n",
      "         [0.9902],\n",
      "         [0.2491],\n",
      "         [0.9769],\n",
      "         [0.5266],\n",
      "         [0.9886],\n",
      "         [0.9902],\n",
      "         [0.9918],\n",
      "         [0.9930],\n",
      "         [0.9956],\n",
      "         [0.9949],\n",
      "         [1.0017],\n",
      "         [1.0034],\n",
      "         [1.0039],\n",
      "         [1.0074],\n",
      "         [1.0075],\n",
      "         [1.0067],\n",
      "         [0.7846],\n",
      "         [1.0007],\n",
      "         [0.9974],\n",
      "         [0.9962],\n",
      "         [0.3639],\n",
      "         [0.3468],\n",
      "         [0.9941],\n",
      "         [0.0491],\n",
      "         [0.9975],\n",
      "         [0.9997],\n",
      "         [0.9992],\n",
      "         [0.9436],\n",
      "         [1.0029],\n",
      "         [0.9996],\n",
      "         [1.0015],\n",
      "         [0.5065],\n",
      "         [0.2480],\n",
      "         [0.4646],\n",
      "         [0.9967],\n",
      "         [0.4603],\n",
      "         [1.0000],\n",
      "         [1.0009],\n",
      "         [0.2630],\n",
      "         [0.4549],\n",
      "         [1.0045],\n",
      "         [1.0055],\n",
      "         [1.0044],\n",
      "         [1.0042],\n",
      "         [1.0038],\n",
      "         [1.0045],\n",
      "         [0.6656],\n",
      "         [0.9988],\n",
      "         [1.0034],\n",
      "         [0.5278],\n",
      "         [0.0613],\n",
      "         [0.5027],\n",
      "         [0.2486],\n",
      "         [0.9940],\n",
      "         [0.2306],\n",
      "         [0.9903],\n",
      "         [0.9892],\n",
      "         [0.9913],\n",
      "         [0.9941],\n",
      "         [0.5112],\n",
      "         [0.0381],\n",
      "         [1.0063],\n",
      "         [0.5640],\n",
      "         [1.0100],\n",
      "         [1.0072],\n",
      "         [1.0055],\n",
      "         [0.9988],\n",
      "         [0.9974],\n",
      "         [0.4488],\n",
      "         [0.4338],\n",
      "         [0.5088],\n",
      "         [0.9909],\n",
      "         [0.9835],\n",
      "         [0.6842],\n",
      "         [1.0072],\n",
      "         [1.0125],\n",
      "         [1.0158],\n",
      "         [1.0188],\n",
      "         [0.4058],\n",
      "         [0.9439],\n",
      "         [0.3879],\n",
      "         [0.9912]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.9820],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.9967],\n",
      "        [0.0000],\n",
      "        [0.8296],\n",
      "        [0.8761],\n",
      "        [0.8933],\n",
      "        [0.0383],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.4454],\n",
      "        [0.9490],\n",
      "        [0.0288],\n",
      "        [0.3840],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [0.5080],\n",
      "        [0.9999],\n",
      "        [0.5030],\n",
      "        [0.4527],\n",
      "        [0.3912],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.4552],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9997],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.7540],\n",
      "        [0.5463],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9998],\n",
      "        [0.0247],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.5054],\n",
      "        [0.4988],\n",
      "        [0.0335],\n",
      "        [0.9999],\n",
      "        [0.5139],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [0.9724],\n",
      "        [0.9998],\n",
      "        [0.5945],\n",
      "        [0.9999],\n",
      "        [0.2686],\n",
      "        [0.9804],\n",
      "        [0.5245],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.3573],\n",
      "        [0.9998],\n",
      "        [0.0209],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9164],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.5038],\n",
      "        [0.2610],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.9956],\n",
      "        [0.9996],\n",
      "        [0.5151],\n",
      "        [0.0368],\n",
      "        [0.5009],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5108],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.9997],\n",
      "        [0.4580],\n",
      "        [0.4480],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3875],\n",
      "        [0.9044],\n",
      "        [0.3808],\n",
      "        [0.9814]])\n",
      "######### Epoch: 47  ######### Train Loss: 0.00025913366698659956  ######### Relative L2 Test Norm: 13.356518745422363\n",
      "Output batch pred: tensor([[[0.8664],\n",
      "         [0.5095],\n",
      "         [0.8173],\n",
      "         [0.4497],\n",
      "         [0.0358],\n",
      "         [0.9956],\n",
      "         [0.1599],\n",
      "         [0.9976],\n",
      "         [0.9866],\n",
      "         [0.9993],\n",
      "         [1.0006],\n",
      "         [0.5185],\n",
      "         [1.0036],\n",
      "         [1.0047],\n",
      "         [1.0044],\n",
      "         [0.3657],\n",
      "         [0.5061],\n",
      "         [0.9980],\n",
      "         [0.0581],\n",
      "         [0.9826],\n",
      "         [0.0619],\n",
      "         [0.9218],\n",
      "         [0.9384],\n",
      "         [1.0025],\n",
      "         [0.3530],\n",
      "         [0.0354],\n",
      "         [1.0118],\n",
      "         [0.3795],\n",
      "         [1.0105],\n",
      "         [0.5586],\n",
      "         [0.9262],\n",
      "         [0.5120],\n",
      "         [0.6922],\n",
      "         [0.4388],\n",
      "         [0.9954],\n",
      "         [0.9977],\n",
      "         [0.5050],\n",
      "         [1.0007],\n",
      "         [1.0050],\n",
      "         [1.0061],\n",
      "         [1.0056],\n",
      "         [0.4477],\n",
      "         [0.8690],\n",
      "         [1.0078],\n",
      "         [1.0065],\n",
      "         [1.0068],\n",
      "         [1.0075],\n",
      "         [1.0090],\n",
      "         [0.5235],\n",
      "         [0.0636],\n",
      "         [0.4658],\n",
      "         [1.0125],\n",
      "         [1.0107],\n",
      "         [1.0079],\n",
      "         [1.0050],\n",
      "         [1.0012],\n",
      "         [0.0433],\n",
      "         [0.2526],\n",
      "         [0.4619],\n",
      "         [1.0038],\n",
      "         [1.0047],\n",
      "         [0.7867],\n",
      "         [0.9711],\n",
      "         [1.0076],\n",
      "         [1.0074],\n",
      "         [1.0065],\n",
      "         [0.2380],\n",
      "         [1.0020],\n",
      "         [0.5542],\n",
      "         [1.0004],\n",
      "         [0.2597],\n",
      "         [1.0056],\n",
      "         [1.0106],\n",
      "         [1.0119],\n",
      "         [1.0171],\n",
      "         [1.0170],\n",
      "         [1.0183],\n",
      "         [1.0150],\n",
      "         [1.0113],\n",
      "         [0.8590],\n",
      "         [0.5251],\n",
      "         [0.9996],\n",
      "         [0.9992],\n",
      "         [0.0425],\n",
      "         [1.0083],\n",
      "         [1.0135],\n",
      "         [0.7077],\n",
      "         [1.0166],\n",
      "         [1.0216],\n",
      "         [1.0026],\n",
      "         [1.0174],\n",
      "         [1.0136],\n",
      "         [1.0084],\n",
      "         [0.6244],\n",
      "         [1.0030],\n",
      "         [1.0013],\n",
      "         [1.0007],\n",
      "         [0.2659],\n",
      "         [0.9143],\n",
      "         [1.0076],\n",
      "         [1.0080],\n",
      "         [1.0043],\n",
      "         [0.4693],\n",
      "         [1.0005],\n",
      "         [0.9983],\n",
      "         [0.0494],\n",
      "         [0.3674],\n",
      "         [0.4619],\n",
      "         [0.9695],\n",
      "         [1.0061],\n",
      "         [1.0137],\n",
      "         [1.0162],\n",
      "         [0.4898],\n",
      "         [1.0151],\n",
      "         [0.5163],\n",
      "         [1.0057],\n",
      "         [0.3751],\n",
      "         [0.9897],\n",
      "         [0.4388],\n",
      "         [0.9877],\n",
      "         [0.9907],\n",
      "         [0.2411],\n",
      "         [0.9963],\n",
      "         [1.0007],\n",
      "         [0.2460],\n",
      "         [0.7333],\n",
      "         [0.6632],\n",
      "         [0.9993],\n",
      "         [0.9252],\n",
      "         [0.2475],\n",
      "         [0.0526],\n",
      "         [0.9575],\n",
      "         [0.7795],\n",
      "         [0.9946],\n",
      "         [0.3769],\n",
      "         [1.0025],\n",
      "         [1.0028],\n",
      "         [1.0082],\n",
      "         [1.0110],\n",
      "         [1.0118],\n",
      "         [1.0121],\n",
      "         [1.0129],\n",
      "         [0.5347],\n",
      "         [0.3781],\n",
      "         [1.0112],\n",
      "         [1.0111],\n",
      "         [0.3657],\n",
      "         [1.0105],\n",
      "         [1.0111],\n",
      "         [0.3883],\n",
      "         [1.0072],\n",
      "         [1.0074],\n",
      "         [1.0060],\n",
      "         [0.7539],\n",
      "         [0.5384],\n",
      "         [1.0060],\n",
      "         [1.0063],\n",
      "         [0.9937],\n",
      "         [0.5123],\n",
      "         [1.0101],\n",
      "         [1.0133],\n",
      "         [1.0141],\n",
      "         [1.0140],\n",
      "         [1.0129],\n",
      "         [1.0130],\n",
      "         [1.0125],\n",
      "         [0.8782],\n",
      "         [0.4631],\n",
      "         [1.0103],\n",
      "         [1.0108],\n",
      "         [0.3943],\n",
      "         [1.0086],\n",
      "         [1.0059],\n",
      "         [0.2476],\n",
      "         [0.3759],\n",
      "         [0.9667],\n",
      "         [0.2136],\n",
      "         [0.9880]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.8379],\n",
      "        [0.5108],\n",
      "        [0.7820],\n",
      "        [0.4580],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [0.9995],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.9820],\n",
      "        [0.0335],\n",
      "        [0.9044],\n",
      "        [0.9164],\n",
      "        [0.9997],\n",
      "        [0.3573],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.9994],\n",
      "        [0.5334],\n",
      "        [0.8933],\n",
      "        [0.5080],\n",
      "        [0.6628],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [0.4454],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.0368],\n",
      "        [0.4503],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.0209],\n",
      "        [0.2686],\n",
      "        [0.4645],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.7391],\n",
      "        [0.9420],\n",
      "        [0.9962],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.0142],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.8761],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.3780],\n",
      "        [0.4611],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.9999],\n",
      "        [0.3840],\n",
      "        [0.9956],\n",
      "        [0.4527],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.6920],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.2646],\n",
      "        [0.0383],\n",
      "        [0.9515],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3575],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.7129],\n",
      "        [0.5245],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.9814],\n",
      "        [0.5009],\n",
      "        [0.9966],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.2518],\n",
      "        [0.3808],\n",
      "        [0.9520],\n",
      "        [0.2208],\n",
      "        [0.9804]])\n",
      "######### Epoch: 48  ######### Train Loss: 0.00026989905745722353  ######### Relative L2 Test Norm: 13.784088134765625\n",
      "Output batch pred: tensor([[[0.9952],\n",
      "         [1.0073],\n",
      "         [0.5199],\n",
      "         [1.0065],\n",
      "         [0.2654],\n",
      "         [1.0072],\n",
      "         [1.0074],\n",
      "         [0.3925],\n",
      "         [1.0049],\n",
      "         [0.0436],\n",
      "         [0.3727],\n",
      "         [1.0052],\n",
      "         [0.5242],\n",
      "         [1.0051],\n",
      "         [1.0043],\n",
      "         [0.3459],\n",
      "         [1.0047],\n",
      "         [0.3689],\n",
      "         [1.0080],\n",
      "         [0.1697],\n",
      "         [1.0106],\n",
      "         [1.0092],\n",
      "         [1.0095],\n",
      "         [1.0123],\n",
      "         [1.0121],\n",
      "         [1.0106],\n",
      "         [1.0116],\n",
      "         [1.0125],\n",
      "         [1.0111],\n",
      "         [0.9366],\n",
      "         [1.0146],\n",
      "         [0.3794],\n",
      "         [1.0010],\n",
      "         [0.5385],\n",
      "         [1.0147],\n",
      "         [1.0146],\n",
      "         [1.0125],\n",
      "         [0.9517],\n",
      "         [0.7978],\n",
      "         [0.3498],\n",
      "         [0.3774],\n",
      "         [0.5052],\n",
      "         [0.9998],\n",
      "         [1.0007],\n",
      "         [0.9973],\n",
      "         [0.5039],\n",
      "         [1.0020],\n",
      "         [0.3685],\n",
      "         [1.0052],\n",
      "         [1.0070],\n",
      "         [0.7558],\n",
      "         [0.3892],\n",
      "         [0.8305],\n",
      "         [1.0086],\n",
      "         [1.0087],\n",
      "         [1.0074],\n",
      "         [0.4500],\n",
      "         [0.5335],\n",
      "         [0.9066],\n",
      "         [0.9991],\n",
      "         [0.9983],\n",
      "         [0.9573],\n",
      "         [0.5086],\n",
      "         [1.0011],\n",
      "         [1.0043],\n",
      "         [1.0066],\n",
      "         [1.0093],\n",
      "         [1.0111],\n",
      "         [1.0013],\n",
      "         [0.5700],\n",
      "         [1.0130],\n",
      "         [0.2436],\n",
      "         [0.9764],\n",
      "         [0.9754],\n",
      "         [0.0529],\n",
      "         [1.0085],\n",
      "         [1.0076],\n",
      "         [0.2582],\n",
      "         [0.0449],\n",
      "         [1.0070],\n",
      "         [0.2539],\n",
      "         [0.6872],\n",
      "         [0.9321],\n",
      "         [0.8613],\n",
      "         [0.4428],\n",
      "         [0.2040],\n",
      "         [0.2409],\n",
      "         [0.9938],\n",
      "         [0.7165],\n",
      "         [0.9950],\n",
      "         [0.4544],\n",
      "         [0.5042],\n",
      "         [0.4618],\n",
      "         [1.0032],\n",
      "         [0.2411],\n",
      "         [1.0073],\n",
      "         [1.0093],\n",
      "         [0.6261],\n",
      "         [0.3826],\n",
      "         [1.0115],\n",
      "         [1.0098],\n",
      "         [1.0090],\n",
      "         [1.0032],\n",
      "         [0.5103],\n",
      "         [1.0052],\n",
      "         [0.0429],\n",
      "         [1.0019],\n",
      "         [0.6896],\n",
      "         [0.9985],\n",
      "         [0.9984],\n",
      "         [0.9973],\n",
      "         [0.9795],\n",
      "         [0.4554],\n",
      "         [0.8695],\n",
      "         [1.0037],\n",
      "         [0.4991],\n",
      "         [0.6633],\n",
      "         [1.0074],\n",
      "         [1.0090],\n",
      "         [1.0083],\n",
      "         [1.0081],\n",
      "         [1.0086],\n",
      "         [0.0392],\n",
      "         [0.9951],\n",
      "         [1.0047],\n",
      "         [1.0051],\n",
      "         [0.0239],\n",
      "         [1.0080],\n",
      "         [1.0096],\n",
      "         [1.0099],\n",
      "         [1.0089],\n",
      "         [1.0126],\n",
      "         [1.0123],\n",
      "         [0.2652],\n",
      "         [0.4618],\n",
      "         [1.0094],\n",
      "         [0.2527],\n",
      "         [1.0098],\n",
      "         [0.4655],\n",
      "         [0.0549],\n",
      "         [0.0629],\n",
      "         [1.0109],\n",
      "         [1.0118],\n",
      "         [0.4713],\n",
      "         [1.0135],\n",
      "         [0.9417],\n",
      "         [1.0139],\n",
      "         [0.4587],\n",
      "         [1.0139],\n",
      "         [1.0132],\n",
      "         [1.0118],\n",
      "         [0.8749],\n",
      "         [1.0077],\n",
      "         [1.0039],\n",
      "         [0.9682],\n",
      "         [0.9994],\n",
      "         [0.4359],\n",
      "         [0.0356],\n",
      "         [1.0016],\n",
      "         [1.0024],\n",
      "         [1.0043],\n",
      "         [1.0051],\n",
      "         [0.3732],\n",
      "         [1.0109],\n",
      "         [0.5624],\n",
      "         [1.0102],\n",
      "         [1.0103],\n",
      "         [0.5133],\n",
      "         [1.0090],\n",
      "         [1.0073],\n",
      "         [1.0048],\n",
      "         [1.0048],\n",
      "         [1.0054],\n",
      "         [1.0049],\n",
      "         [0.7820],\n",
      "         [1.0037],\n",
      "         [1.0033],\n",
      "         [0.8585]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9819],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [0.9999],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9966],\n",
      "        [0.0142],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.9997],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.9814],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.7540],\n",
      "        [0.3575],\n",
      "        [0.3875],\n",
      "        [0.5038],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.3912],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.5245],\n",
      "        [0.8761],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9520],\n",
      "        [0.9490],\n",
      "        [0.0335],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.6555],\n",
      "        [0.9044],\n",
      "        [0.8223],\n",
      "        [0.4503],\n",
      "        [0.2208],\n",
      "        [0.2610],\n",
      "        [0.9967],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.5080],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [0.5030],\n",
      "        [0.9998],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [0.4642],\n",
      "        [0.8379],\n",
      "        [0.9997],\n",
      "        [0.4988],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.9804],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.0247],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9515],\n",
      "        [0.9998],\n",
      "        [0.4454],\n",
      "        [0.0174],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.8139]])\n",
      "######### Epoch: 49  ######### Train Loss: 0.00025294910301454365  ######### Relative L2 Test Norm: 13.526103973388672\n",
      "Output batch pred: tensor([[[0.3577],\n",
      "         [1.0146],\n",
      "         [1.0146],\n",
      "         [1.0123],\n",
      "         [0.9728],\n",
      "         [0.4645],\n",
      "         [0.8663],\n",
      "         [0.9591],\n",
      "         [0.4928],\n",
      "         [0.9897],\n",
      "         [0.4829],\n",
      "         [0.9932],\n",
      "         [0.5088],\n",
      "         [0.8471],\n",
      "         [1.0023],\n",
      "         [0.0508],\n",
      "         [1.0066],\n",
      "         [1.0049],\n",
      "         [1.0051],\n",
      "         [0.2307],\n",
      "         [0.9969],\n",
      "         [0.9979],\n",
      "         [0.9954],\n",
      "         [0.9951],\n",
      "         [0.9752],\n",
      "         [0.0394],\n",
      "         [0.9961],\n",
      "         [0.3699],\n",
      "         [0.0408],\n",
      "         [0.3814],\n",
      "         [1.0092],\n",
      "         [0.9955],\n",
      "         [0.4584],\n",
      "         [1.0090],\n",
      "         [1.0077],\n",
      "         [1.0065],\n",
      "         [0.8259],\n",
      "         [1.0049],\n",
      "         [0.5165],\n",
      "         [1.0071],\n",
      "         [0.2448],\n",
      "         [1.0091],\n",
      "         [1.0096],\n",
      "         [1.0101],\n",
      "         [0.0471],\n",
      "         [0.7806],\n",
      "         [0.3769],\n",
      "         [1.0031],\n",
      "         [1.0014],\n",
      "         [1.0022],\n",
      "         [1.0041],\n",
      "         [0.9941],\n",
      "         [1.0103],\n",
      "         [0.8749],\n",
      "         [1.0159],\n",
      "         [0.5547],\n",
      "         [0.5653],\n",
      "         [1.0154],\n",
      "         [1.0116],\n",
      "         [0.3616],\n",
      "         [1.0032],\n",
      "         [0.4436],\n",
      "         [0.4988],\n",
      "         [0.9871],\n",
      "         [0.9963],\n",
      "         [1.0028],\n",
      "         [0.9715],\n",
      "         [0.3714],\n",
      "         [0.9334],\n",
      "         [1.0107],\n",
      "         [1.0086],\n",
      "         [0.5190],\n",
      "         [1.0013],\n",
      "         [0.9983],\n",
      "         [0.0327],\n",
      "         [0.9924],\n",
      "         [0.9780],\n",
      "         [0.6622],\n",
      "         [0.4427],\n",
      "         [0.9959],\n",
      "         [0.4948],\n",
      "         [1.0019],\n",
      "         [1.0034],\n",
      "         [0.8682],\n",
      "         [1.0058],\n",
      "         [0.0372],\n",
      "         [0.5144],\n",
      "         [1.0088],\n",
      "         [0.2653],\n",
      "         [1.0113],\n",
      "         [1.0119],\n",
      "         [1.0117],\n",
      "         [1.0109],\n",
      "         [1.0086],\n",
      "         [1.0071],\n",
      "         [1.0015],\n",
      "         [0.3346],\n",
      "         [0.4304],\n",
      "         [0.1527],\n",
      "         [0.9928],\n",
      "         [0.9977],\n",
      "         [0.9995],\n",
      "         [0.1990],\n",
      "         [0.4473],\n",
      "         [1.0109],\n",
      "         [1.0135],\n",
      "         [1.0111],\n",
      "         [1.0141],\n",
      "         [1.0141],\n",
      "         [1.0119],\n",
      "         [0.0609],\n",
      "         [0.3713],\n",
      "         [0.4667],\n",
      "         [0.6146],\n",
      "         [0.9981],\n",
      "         [0.3790],\n",
      "         [1.0010],\n",
      "         [0.4947],\n",
      "         [0.9411],\n",
      "         [0.2290],\n",
      "         [1.0017],\n",
      "         [1.0057],\n",
      "         [0.5623],\n",
      "         [1.0069],\n",
      "         [1.0090],\n",
      "         [1.0097],\n",
      "         [1.0060],\n",
      "         [0.9354],\n",
      "         [1.0067],\n",
      "         [1.0043],\n",
      "         [0.6927],\n",
      "         [1.0005],\n",
      "         [0.4268],\n",
      "         [0.9950],\n",
      "         [0.9954],\n",
      "         [0.9960],\n",
      "         [0.0249],\n",
      "         [0.5190],\n",
      "         [0.6606],\n",
      "         [0.2535],\n",
      "         [0.7365],\n",
      "         [1.0069],\n",
      "         [0.9358],\n",
      "         [1.0065],\n",
      "         [1.0039],\n",
      "         [1.0039],\n",
      "         [1.0032],\n",
      "         [0.2429],\n",
      "         [1.0050],\n",
      "         [0.3650],\n",
      "         [0.0396],\n",
      "         [1.0098],\n",
      "         [1.0088],\n",
      "         [1.0101],\n",
      "         [0.4573],\n",
      "         [1.0084],\n",
      "         [1.0057],\n",
      "         [1.0055],\n",
      "         [1.0041],\n",
      "         [1.0042],\n",
      "         [0.7961],\n",
      "         [0.9183],\n",
      "         [0.3787],\n",
      "         [0.9773],\n",
      "         [1.0171],\n",
      "         [1.0208],\n",
      "         [0.7728],\n",
      "         [1.0174],\n",
      "         [1.0146],\n",
      "         [1.0104],\n",
      "         [0.2553],\n",
      "         [1.0000],\n",
      "         [0.9998],\n",
      "         [0.2408],\n",
      "         [0.4530],\n",
      "         [1.0004],\n",
      "         [1.0067],\n",
      "         [1.0098]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.3573],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.4668],\n",
      "        [0.8379],\n",
      "        [0.9515],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9999],\n",
      "        [0.5165],\n",
      "        [0.8139],\n",
      "        [0.9998],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.0288],\n",
      "        [0.9999],\n",
      "        [0.3840],\n",
      "        [0.0209],\n",
      "        [0.3875],\n",
      "        [0.9997],\n",
      "        [0.9814],\n",
      "        [0.4552],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.9997],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.7391],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.5030],\n",
      "        [0.9819],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.3780],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.6555],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.9996],\n",
      "        [0.9995],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.3575],\n",
      "        [0.4480],\n",
      "        [0.1762],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.4503],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.3747],\n",
      "        [0.4642],\n",
      "        [0.5945],\n",
      "        [0.9966],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.9164],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [0.9998],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.5151],\n",
      "        [0.6327],\n",
      "        [0.2686],\n",
      "        [0.6920],\n",
      "        [0.9967],\n",
      "        [0.9044],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9994],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.8761],\n",
      "        [0.3808],\n",
      "        [0.9420],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [0.4611],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9996]])\n",
      "######### Epoch: 50  ######### Train Loss: 0.0002702622441574931  ######### Relative L2 Test Norm: 14.307427406311035\n",
      "Output batch pred: tensor([[[0.8721],\n",
      "         [1.0071],\n",
      "         [1.0086],\n",
      "         [1.0075],\n",
      "         [0.9361],\n",
      "         [0.3740],\n",
      "         [0.9918],\n",
      "         [1.0012],\n",
      "         [0.2447],\n",
      "         [0.5298],\n",
      "         [1.0011],\n",
      "         [0.9997],\n",
      "         [1.0007],\n",
      "         [0.9993],\n",
      "         [0.6441],\n",
      "         [0.2371],\n",
      "         [0.3590],\n",
      "         [0.9926],\n",
      "         [0.4414],\n",
      "         [0.5279],\n",
      "         [0.2273],\n",
      "         [0.5059],\n",
      "         [0.5124],\n",
      "         [0.5283],\n",
      "         [1.0162],\n",
      "         [0.0572],\n",
      "         [1.0222],\n",
      "         [0.6450],\n",
      "         [1.0174],\n",
      "         [1.0136],\n",
      "         [1.0094],\n",
      "         [1.0055],\n",
      "         [0.9979],\n",
      "         [0.9993],\n",
      "         [0.0139],\n",
      "         [0.9216],\n",
      "         [0.9978],\n",
      "         [0.4391],\n",
      "         [1.0029],\n",
      "         [0.0470],\n",
      "         [1.0073],\n",
      "         [1.0088],\n",
      "         [0.2421],\n",
      "         [0.2643],\n",
      "         [1.0104],\n",
      "         [1.0125],\n",
      "         [1.0107],\n",
      "         [1.0094],\n",
      "         [1.0068],\n",
      "         [0.7293],\n",
      "         [0.9637],\n",
      "         [0.9976],\n",
      "         [0.9938],\n",
      "         [0.9904],\n",
      "         [0.9911],\n",
      "         [0.4979],\n",
      "         [0.9910],\n",
      "         [0.3582],\n",
      "         [0.9527],\n",
      "         [0.9963],\n",
      "         [0.9985],\n",
      "         [0.0364],\n",
      "         [0.9998],\n",
      "         [0.9671],\n",
      "         [1.0005],\n",
      "         [1.0023],\n",
      "         [0.3603],\n",
      "         [1.0000],\n",
      "         [0.9992],\n",
      "         [0.9816],\n",
      "         [0.8986],\n",
      "         [0.5366],\n",
      "         [0.7542],\n",
      "         [0.4275],\n",
      "         [0.9813],\n",
      "         [0.9460],\n",
      "         [0.4306],\n",
      "         [0.2278],\n",
      "         [0.4474],\n",
      "         [0.9981],\n",
      "         [1.0028],\n",
      "         [0.3528],\n",
      "         [1.0110],\n",
      "         [0.3859],\n",
      "         [1.0135],\n",
      "         [0.2507],\n",
      "         [0.9978],\n",
      "         [1.0066],\n",
      "         [1.0044],\n",
      "         [1.0020],\n",
      "         [1.0004],\n",
      "         [0.9980],\n",
      "         [0.9993],\n",
      "         [0.0316],\n",
      "         [1.0015],\n",
      "         [1.0019],\n",
      "         [1.0020],\n",
      "         [0.5026],\n",
      "         [0.6973],\n",
      "         [0.2486],\n",
      "         [1.0043],\n",
      "         [0.0453],\n",
      "         [1.0069],\n",
      "         [1.0110],\n",
      "         [1.0128],\n",
      "         [1.0135],\n",
      "         [1.0141],\n",
      "         [1.0123],\n",
      "         [1.0091],\n",
      "         [1.0049],\n",
      "         [0.9997],\n",
      "         [0.9901],\n",
      "         [0.8377],\n",
      "         [0.9902],\n",
      "         [0.9700],\n",
      "         [0.9922],\n",
      "         [0.9940],\n",
      "         [0.9990],\n",
      "         [1.0024],\n",
      "         [1.0061],\n",
      "         [0.9300],\n",
      "         [1.0079],\n",
      "         [1.0084],\n",
      "         [0.9471],\n",
      "         [1.0054],\n",
      "         [0.3619],\n",
      "         [1.0038],\n",
      "         [1.0042],\n",
      "         [1.0047],\n",
      "         [1.0067],\n",
      "         [0.7955],\n",
      "         [1.0055],\n",
      "         [1.0039],\n",
      "         [0.4993],\n",
      "         [0.4963],\n",
      "         [0.9961],\n",
      "         [0.8494],\n",
      "         [0.4463],\n",
      "         [0.0271],\n",
      "         [0.9999],\n",
      "         [0.0284],\n",
      "         [0.5276],\n",
      "         [1.0157],\n",
      "         [1.0161],\n",
      "         [1.0205],\n",
      "         [1.0205],\n",
      "         [0.3928],\n",
      "         [0.4581],\n",
      "         [0.8766],\n",
      "         [0.8275],\n",
      "         [0.4513],\n",
      "         [1.0016],\n",
      "         [0.5143],\n",
      "         [0.3382],\n",
      "         [1.0039],\n",
      "         [1.0051],\n",
      "         [1.0051],\n",
      "         [1.0064],\n",
      "         [1.0072],\n",
      "         [0.3610],\n",
      "         [0.5009],\n",
      "         [1.0076],\n",
      "         [0.9988],\n",
      "         [0.4631],\n",
      "         [0.7651],\n",
      "         [1.0134],\n",
      "         [1.0125],\n",
      "         [0.1753],\n",
      "         [1.0111],\n",
      "         [1.0072],\n",
      "         [1.0004],\n",
      "         [0.3457],\n",
      "         [0.4214],\n",
      "         [0.9878],\n",
      "         [0.6540],\n",
      "         [0.9865],\n",
      "         [0.1879],\n",
      "         [0.0412]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.8379],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9044],\n",
      "        [0.3875],\n",
      "        [0.9820],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.5245],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.2735],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.5334],\n",
      "        [0.2577],\n",
      "        [0.5080],\n",
      "        [0.5054],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.9009],\n",
      "        [0.9999],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.2518],\n",
      "        [0.2729],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9420],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.3747],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [0.8761],\n",
      "        [0.5463],\n",
      "        [0.7391],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.4611],\n",
      "        [0.2646],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.9999],\n",
      "        [0.2547],\n",
      "        [0.9804],\n",
      "        [0.9995],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.6628],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9164],\n",
      "        [0.9999],\n",
      "        [0.3753],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.5030],\n",
      "        [0.5038],\n",
      "        [0.9994],\n",
      "        [0.8223],\n",
      "        [0.4645],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.5165],\n",
      "        [0.9997],\n",
      "        [0.9962],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.4454],\n",
      "        [0.8296],\n",
      "        [0.7820],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.3573],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.3780],\n",
      "        [0.4988],\n",
      "        [0.9999],\n",
      "        [0.9819],\n",
      "        [0.4552],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.0383]])\n",
      "######### Epoch: 51  ######### Train Loss: 0.00026372139109298587  ######### Relative L2 Test Norm: 14.751212120056152\n",
      "Output batch pred: tensor([[[0.9881],\n",
      "         [0.9741],\n",
      "         [0.9846],\n",
      "         [0.9856],\n",
      "         [0.3419],\n",
      "         [0.2218],\n",
      "         [0.9959],\n",
      "         [0.9993],\n",
      "         [0.9086],\n",
      "         [0.7912],\n",
      "         [0.8631],\n",
      "         [1.0037],\n",
      "         [1.0008],\n",
      "         [0.9980],\n",
      "         [0.4451],\n",
      "         [0.9908],\n",
      "         [0.5354],\n",
      "         [0.5263],\n",
      "         [0.7328],\n",
      "         [0.0181],\n",
      "         [0.9605],\n",
      "         [0.3388],\n",
      "         [1.0037],\n",
      "         [0.4561],\n",
      "         [0.0397],\n",
      "         [0.9275],\n",
      "         [1.0031],\n",
      "         [0.9905],\n",
      "         [0.5032],\n",
      "         [1.0042],\n",
      "         [0.5106],\n",
      "         [0.0594],\n",
      "         [0.3707],\n",
      "         [1.0082],\n",
      "         [1.0077],\n",
      "         [0.2629],\n",
      "         [0.0515],\n",
      "         [1.0037],\n",
      "         [1.0002],\n",
      "         [0.9967],\n",
      "         [0.9931],\n",
      "         [0.9168],\n",
      "         [0.9922],\n",
      "         [0.9920],\n",
      "         [0.9941],\n",
      "         [0.3604],\n",
      "         [1.0025],\n",
      "         [1.0048],\n",
      "         [1.0032],\n",
      "         [1.0065],\n",
      "         [1.0060],\n",
      "         [1.0051],\n",
      "         [0.0308],\n",
      "         [0.9835],\n",
      "         [1.0012],\n",
      "         [1.0005],\n",
      "         [0.6124],\n",
      "         [1.0001],\n",
      "         [0.9985],\n",
      "         [0.9970],\n",
      "         [0.9562],\n",
      "         [0.4907],\n",
      "         [0.9801],\n",
      "         [0.4411],\n",
      "         [0.9888],\n",
      "         [0.9872],\n",
      "         [0.9873],\n",
      "         [0.0235],\n",
      "         [0.9916],\n",
      "         [0.3592],\n",
      "         [0.9983],\n",
      "         [1.0010],\n",
      "         [0.5227],\n",
      "         [0.6664],\n",
      "         [1.0075],\n",
      "         [1.0077],\n",
      "         [0.9963],\n",
      "         [0.2485],\n",
      "         [1.0065],\n",
      "         [1.0039],\n",
      "         [1.0038],\n",
      "         [0.2467],\n",
      "         [1.0014],\n",
      "         [0.9982],\n",
      "         [0.4508],\n",
      "         [0.9991],\n",
      "         [0.9989],\n",
      "         [0.9986],\n",
      "         [0.0366],\n",
      "         [0.4509],\n",
      "         [0.3749],\n",
      "         [0.7041],\n",
      "         [1.0039],\n",
      "         [0.5127],\n",
      "         [0.5180],\n",
      "         [1.0102],\n",
      "         [1.0080],\n",
      "         [1.0070],\n",
      "         [1.0055],\n",
      "         [1.0041],\n",
      "         [1.0026],\n",
      "         [0.5124],\n",
      "         [0.9994],\n",
      "         [0.1619],\n",
      "         [0.9991],\n",
      "         [0.9999],\n",
      "         [0.9257],\n",
      "         [1.0004],\n",
      "         [0.9992],\n",
      "         [0.5154],\n",
      "         [0.9993],\n",
      "         [0.9646],\n",
      "         [0.9992],\n",
      "         [0.3549],\n",
      "         [1.0022],\n",
      "         [1.0032],\n",
      "         [1.0046],\n",
      "         [1.0045],\n",
      "         [0.3810],\n",
      "         [1.0037],\n",
      "         [1.0014],\n",
      "         [0.9995],\n",
      "         [0.9635],\n",
      "         [0.9972],\n",
      "         [0.5089],\n",
      "         [0.4366],\n",
      "         [0.9992],\n",
      "         [0.9989],\n",
      "         [0.3574],\n",
      "         [1.0009],\n",
      "         [0.8720],\n",
      "         [0.4370],\n",
      "         [0.9997],\n",
      "         [0.9999],\n",
      "         [0.9990],\n",
      "         [0.9968],\n",
      "         [0.3699],\n",
      "         [0.4333],\n",
      "         [1.0028],\n",
      "         [1.0041],\n",
      "         [1.0062],\n",
      "         [1.0089],\n",
      "         [1.0080],\n",
      "         [0.2102],\n",
      "         [0.2594],\n",
      "         [0.4649],\n",
      "         [0.2357],\n",
      "         [0.9990],\n",
      "         [0.9976],\n",
      "         [0.5276],\n",
      "         [0.9980],\n",
      "         [0.0321],\n",
      "         [1.0050],\n",
      "         [1.0069],\n",
      "         [0.6901],\n",
      "         [1.0097],\n",
      "         [1.0063],\n",
      "         [0.2353],\n",
      "         [0.9437],\n",
      "         [1.0015],\n",
      "         [0.5016],\n",
      "         [0.7176],\n",
      "         [0.8107],\n",
      "         [0.9920],\n",
      "         [0.4345],\n",
      "         [0.9969],\n",
      "         [0.9990],\n",
      "         [1.0011],\n",
      "         [1.0019],\n",
      "         [1.0027],\n",
      "         [0.0344],\n",
      "         [0.3451],\n",
      "         [0.9995],\n",
      "         [0.8487],\n",
      "         [0.8597],\n",
      "         [0.7655],\n",
      "         [0.9943],\n",
      "         [0.2284]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9999],\n",
      "        [0.9819],\n",
      "        [0.9967],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.8761],\n",
      "        [0.7540],\n",
      "        [0.8223],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.5334],\n",
      "        [0.7129],\n",
      "        [0.0000],\n",
      "        [0.9520],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.0288],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.0368],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.9724],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9420],\n",
      "        [0.5038],\n",
      "        [0.9804],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.5165],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9820],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0142],\n",
      "        [0.4527],\n",
      "        [0.3808],\n",
      "        [0.6628],\n",
      "        [0.9956],\n",
      "        [0.4988],\n",
      "        [0.5030],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.3747],\n",
      "        [0.9999],\n",
      "        [0.8379],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.3912],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.2729],\n",
      "        [0.4668],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [0.9999],\n",
      "        [0.9959],\n",
      "        [0.2518],\n",
      "        [0.9164],\n",
      "        [0.9996],\n",
      "        [0.5080],\n",
      "        [0.6920],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.3575],\n",
      "        [0.9962],\n",
      "        [0.8139],\n",
      "        [0.8296],\n",
      "        [0.7391],\n",
      "        [0.9997],\n",
      "        [0.2646]])\n",
      "######### Epoch: 52  ######### Train Loss: 0.00019649749447125942  ######### Relative L2 Test Norm: 14.08388614654541\n",
      "Output batch pred: tensor([[[0.9625],\n",
      "         [0.9963],\n",
      "         [0.9929],\n",
      "         [0.9895],\n",
      "         [0.9864],\n",
      "         [0.9821],\n",
      "         [0.9821],\n",
      "         [0.7581],\n",
      "         [0.9812],\n",
      "         [0.5124],\n",
      "         [0.9850],\n",
      "         [0.9120],\n",
      "         [0.2258],\n",
      "         [0.9933],\n",
      "         [0.2351],\n",
      "         [0.0374],\n",
      "         [1.0001],\n",
      "         [0.0343],\n",
      "         [0.9842],\n",
      "         [0.9920],\n",
      "         [0.9906],\n",
      "         [0.9891],\n",
      "         [0.7091],\n",
      "         [0.4383],\n",
      "         [0.7641],\n",
      "         [0.5027],\n",
      "         [0.9290],\n",
      "         [1.0073],\n",
      "         [0.5284],\n",
      "         [1.0124],\n",
      "         [0.5705],\n",
      "         [0.3798],\n",
      "         [0.3546],\n",
      "         [0.5288],\n",
      "         [0.6206],\n",
      "         [0.9985],\n",
      "         [0.5179],\n",
      "         [0.4570],\n",
      "         [1.0055],\n",
      "         [1.0086],\n",
      "         [1.0111],\n",
      "         [0.0179],\n",
      "         [1.0115],\n",
      "         [1.0092],\n",
      "         [1.0043],\n",
      "         [1.0004],\n",
      "         [0.9940],\n",
      "         [0.9920],\n",
      "         [0.6645],\n",
      "         [0.9907],\n",
      "         [0.4511],\n",
      "         [0.4519],\n",
      "         [0.9942],\n",
      "         [1.0128],\n",
      "         [1.0177],\n",
      "         [1.0194],\n",
      "         [1.0195],\n",
      "         [1.0169],\n",
      "         [1.0116],\n",
      "         [1.0038],\n",
      "         [0.9938],\n",
      "         [0.9805],\n",
      "         [0.2185],\n",
      "         [0.9709],\n",
      "         [0.9688],\n",
      "         [0.9692],\n",
      "         [0.8288],\n",
      "         [0.9792],\n",
      "         [0.4133],\n",
      "         [0.9909],\n",
      "         [0.4901],\n",
      "         [0.8694],\n",
      "         [0.3574],\n",
      "         [0.9420],\n",
      "         [1.0014],\n",
      "         [0.8589],\n",
      "         [0.9777],\n",
      "         [0.9947],\n",
      "         [0.9922],\n",
      "         [0.9884],\n",
      "         [0.9880],\n",
      "         [0.9855],\n",
      "         [0.4145],\n",
      "         [0.5079],\n",
      "         [0.0301],\n",
      "         [0.0453],\n",
      "         [0.3622],\n",
      "         [0.4815],\n",
      "         [0.4487],\n",
      "         [0.1539],\n",
      "         [0.9969],\n",
      "         [0.9065],\n",
      "         [1.0013],\n",
      "         [1.0038],\n",
      "         [1.0047],\n",
      "         [0.5076],\n",
      "         [0.3668],\n",
      "         [0.9623],\n",
      "         [0.2455],\n",
      "         [1.0004],\n",
      "         [0.4466],\n",
      "         [0.0489],\n",
      "         [0.9985],\n",
      "         [0.9971],\n",
      "         [0.9966],\n",
      "         [0.9960],\n",
      "         [0.9626],\n",
      "         [0.9966],\n",
      "         [0.4575],\n",
      "         [0.9981],\n",
      "         [0.9980],\n",
      "         [0.2380],\n",
      "         [0.9994],\n",
      "         [0.6969],\n",
      "         [1.0023],\n",
      "         [1.0030],\n",
      "         [1.0019],\n",
      "         [1.0026],\n",
      "         [1.0013],\n",
      "         [0.9992],\n",
      "         [0.9986],\n",
      "         [0.9952],\n",
      "         [0.9128],\n",
      "         [0.9914],\n",
      "         [0.2389],\n",
      "         [0.4833],\n",
      "         [0.2284],\n",
      "         [0.9857],\n",
      "         [0.9890],\n",
      "         [0.3655],\n",
      "         [0.4294],\n",
      "         [0.9963],\n",
      "         [0.9969],\n",
      "         [0.9982],\n",
      "         [0.9996],\n",
      "         [1.0019],\n",
      "         [0.9985],\n",
      "         [0.1959],\n",
      "         [0.9994],\n",
      "         [0.9864],\n",
      "         [0.9841],\n",
      "         [0.9970],\n",
      "         [0.9980],\n",
      "         [0.3537],\n",
      "         [0.3301],\n",
      "         [0.9964],\n",
      "         [0.9964],\n",
      "         [0.9956],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [0.9653],\n",
      "         [0.5170],\n",
      "         [0.0344],\n",
      "         [0.8574],\n",
      "         [1.0072],\n",
      "         [1.0091],\n",
      "         [0.5184],\n",
      "         [1.0101],\n",
      "         [0.6709],\n",
      "         [1.0081],\n",
      "         [0.8282],\n",
      "         [0.3761],\n",
      "         [1.0020],\n",
      "         [0.9995],\n",
      "         [0.3655],\n",
      "         [0.9955],\n",
      "         [0.2498],\n",
      "         [0.0311],\n",
      "         [0.9965],\n",
      "         [0.9986],\n",
      "         [0.7446],\n",
      "         [0.9973],\n",
      "         [1.0016],\n",
      "         [0.0315],\n",
      "         [1.0025],\n",
      "         [0.3632],\n",
      "         [1.0004],\n",
      "         [0.9985]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9490],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.2518],\n",
      "        [0.9998],\n",
      "        [0.2547],\n",
      "        [0.0247],\n",
      "        [0.9999],\n",
      "        [0.0383],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.6920],\n",
      "        [0.4611],\n",
      "        [0.7391],\n",
      "        [0.5080],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.9999],\n",
      "        [0.5463],\n",
      "        [0.3808],\n",
      "        [0.3575],\n",
      "        [0.5151],\n",
      "        [0.5945],\n",
      "        [0.9962],\n",
      "        [0.5108],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.4580],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9967],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [0.4503],\n",
      "        [0.9999],\n",
      "        [0.5009],\n",
      "        [0.8379],\n",
      "        [0.3728],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.4454],\n",
      "        [0.5245],\n",
      "        [0.0174],\n",
      "        [0.0368],\n",
      "        [0.3912],\n",
      "        [0.4988],\n",
      "        [0.4642],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5030],\n",
      "        [0.3747],\n",
      "        [0.9420],\n",
      "        [0.2577],\n",
      "        [0.9997],\n",
      "        [0.4527],\n",
      "        [0.0335],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9515],\n",
      "        [0.9997],\n",
      "        [0.4668],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.9997],\n",
      "        [0.2735],\n",
      "        [0.5038],\n",
      "        [0.2646],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.3930],\n",
      "        [0.4480],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9996],\n",
      "        [0.9804],\n",
      "        [0.9814],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.5165],\n",
      "        [0.0288],\n",
      "        [0.8139],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.9994],\n",
      "        [0.2729],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.9998],\n",
      "        [1.0000]])\n",
      "######### Epoch: 53  ######### Train Loss: 0.00025280131376348436  ######### Relative L2 Test Norm: 14.680950164794922\n",
      "Output batch pred: tensor([[[0.9943],\n",
      "         [0.9963],\n",
      "         [0.0229],\n",
      "         [0.9990],\n",
      "         [0.9975],\n",
      "         [0.9968],\n",
      "         [0.9946],\n",
      "         [0.4363],\n",
      "         [0.9889],\n",
      "         [0.8413],\n",
      "         [0.9860],\n",
      "         [0.0223],\n",
      "         [0.4424],\n",
      "         [0.9887],\n",
      "         [0.9885],\n",
      "         [0.2266],\n",
      "         [0.9900],\n",
      "         [0.3316],\n",
      "         [0.3573],\n",
      "         [0.9908],\n",
      "         [0.0451],\n",
      "         [0.0354],\n",
      "         [0.9928],\n",
      "         [0.4543],\n",
      "         [0.9960],\n",
      "         [0.9979],\n",
      "         [0.4379],\n",
      "         [0.9857],\n",
      "         [0.9959],\n",
      "         [0.9934],\n",
      "         [0.9931],\n",
      "         [0.9547],\n",
      "         [0.6390],\n",
      "         [0.9897],\n",
      "         [0.9892],\n",
      "         [0.9920],\n",
      "         [0.0298],\n",
      "         [0.9135],\n",
      "         [0.5473],\n",
      "         [0.9952],\n",
      "         [0.9199],\n",
      "         [0.2332],\n",
      "         [0.0423],\n",
      "         [0.9903],\n",
      "         [0.4866],\n",
      "         [0.8397],\n",
      "         [0.2321],\n",
      "         [0.9942],\n",
      "         [0.9980],\n",
      "         [0.7264],\n",
      "         [1.0021],\n",
      "         [1.0030],\n",
      "         [0.1950],\n",
      "         [0.6121],\n",
      "         [0.9994],\n",
      "         [0.9970],\n",
      "         [0.9955],\n",
      "         [0.9795],\n",
      "         [0.3463],\n",
      "         [0.9955],\n",
      "         [0.8666],\n",
      "         [0.9947],\n",
      "         [0.7777],\n",
      "         [1.0018],\n",
      "         [1.0042],\n",
      "         [1.0059],\n",
      "         [0.3638],\n",
      "         [0.5106],\n",
      "         [1.0039],\n",
      "         [1.0038],\n",
      "         [1.0024],\n",
      "         [1.0012],\n",
      "         [0.5020],\n",
      "         [0.9966],\n",
      "         [0.5133],\n",
      "         [0.5033],\n",
      "         [0.9893],\n",
      "         [0.9898],\n",
      "         [0.9896],\n",
      "         [0.9877],\n",
      "         [0.2282],\n",
      "         [0.9926],\n",
      "         [0.9930],\n",
      "         [0.9981],\n",
      "         [0.3740],\n",
      "         [1.0003],\n",
      "         [0.4524],\n",
      "         [0.9662],\n",
      "         [0.9990],\n",
      "         [0.9952],\n",
      "         [0.9928],\n",
      "         [0.9932],\n",
      "         [0.3721],\n",
      "         [0.3546],\n",
      "         [0.5003],\n",
      "         [0.9956],\n",
      "         [1.0003],\n",
      "         [1.0017],\n",
      "         [1.0003],\n",
      "         [0.9998],\n",
      "         [0.4928],\n",
      "         [0.9934],\n",
      "         [0.4414],\n",
      "         [0.9861],\n",
      "         [0.9835],\n",
      "         [0.9852],\n",
      "         [0.4296],\n",
      "         [0.3701],\n",
      "         [0.4417],\n",
      "         [0.3635],\n",
      "         [0.9804],\n",
      "         [0.0405],\n",
      "         [0.9990],\n",
      "         [0.2486],\n",
      "         [0.9959],\n",
      "         [0.9934],\n",
      "         [0.9913],\n",
      "         [0.6806],\n",
      "         [0.9781],\n",
      "         [0.9920],\n",
      "         [0.9937],\n",
      "         [0.4346],\n",
      "         [0.9963],\n",
      "         [0.9584],\n",
      "         [0.9998],\n",
      "         [0.2484],\n",
      "         [0.4593],\n",
      "         [0.9951],\n",
      "         [0.9963],\n",
      "         [0.5140],\n",
      "         [0.9974],\n",
      "         [0.9984],\n",
      "         [0.3669],\n",
      "         [0.8683],\n",
      "         [0.9907],\n",
      "         [1.0045],\n",
      "         [1.0042],\n",
      "         [0.9437],\n",
      "         [1.0025],\n",
      "         [0.9284],\n",
      "         [0.9990],\n",
      "         [0.9977],\n",
      "         [0.9967],\n",
      "         [0.2467],\n",
      "         [0.9011],\n",
      "         [0.9587],\n",
      "         [0.9940],\n",
      "         [0.9908],\n",
      "         [0.9905],\n",
      "         [0.5128],\n",
      "         [0.9861],\n",
      "         [0.7267],\n",
      "         [0.0084],\n",
      "         [0.9881],\n",
      "         [0.1532],\n",
      "         [0.5376],\n",
      "         [0.9975],\n",
      "         [1.0003],\n",
      "         [1.0032],\n",
      "         [0.5204],\n",
      "         [1.0012],\n",
      "         [1.0012],\n",
      "         [0.7845],\n",
      "         [0.9953],\n",
      "         [0.9930],\n",
      "         [0.8069],\n",
      "         [0.4926],\n",
      "         [0.9892],\n",
      "         [0.9876],\n",
      "         [0.0380],\n",
      "         [0.3248],\n",
      "         [0.9889],\n",
      "         [0.6603],\n",
      "         [0.9878],\n",
      "         [0.9871],\n",
      "         [0.9883],\n",
      "         [0.9891],\n",
      "         [0.2152]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.9996],\n",
      "        [0.0209],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.4642],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.9998],\n",
      "        [0.3575],\n",
      "        [0.3840],\n",
      "        [0.9997],\n",
      "        [0.0383],\n",
      "        [0.0247],\n",
      "        [0.9996],\n",
      "        [0.4645],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.6327],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.8933],\n",
      "        [0.5463],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [0.2577],\n",
      "        [0.0368],\n",
      "        [0.9994],\n",
      "        [0.5009],\n",
      "        [0.8139],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2208],\n",
      "        [0.5945],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [0.3728],\n",
      "        [0.9999],\n",
      "        [0.8379],\n",
      "        [0.9956],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.9997],\n",
      "        [0.3753],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.9999],\n",
      "        [0.5165],\n",
      "        [0.5108],\n",
      "        [0.9959],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.3875],\n",
      "        [0.9995],\n",
      "        [0.4552],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9967],\n",
      "        [0.9999],\n",
      "        [0.3930],\n",
      "        [0.3747],\n",
      "        [0.5038],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.3912],\n",
      "        [0.4527],\n",
      "        [0.3780],\n",
      "        [0.9724],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.4454],\n",
      "        [0.9997],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.4668],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.8296],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.2735],\n",
      "        [0.8761],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.7820],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0335],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2518]])\n",
      "######### Epoch: 54  ######### Train Loss: 0.0001874818408396095  ######### Relative L2 Test Norm: 14.6990327835083\n",
      "Output batch pred: tensor([[[0.2432],\n",
      "         [0.9975],\n",
      "         [0.9965],\n",
      "         [0.5144],\n",
      "         [0.6786],\n",
      "         [0.9616],\n",
      "         [0.9970],\n",
      "         [0.9965],\n",
      "         [0.0162],\n",
      "         [0.4563],\n",
      "         [0.9941],\n",
      "         [0.9941],\n",
      "         [0.9922],\n",
      "         [0.9934],\n",
      "         [0.5094],\n",
      "         [0.2235],\n",
      "         [0.9888],\n",
      "         [0.9885],\n",
      "         [0.9873],\n",
      "         [0.2395],\n",
      "         [0.0369],\n",
      "         [0.4499],\n",
      "         [0.9936],\n",
      "         [0.9941],\n",
      "         [0.9963],\n",
      "         [0.4403],\n",
      "         [0.4547],\n",
      "         [0.9962],\n",
      "         [0.9942],\n",
      "         [0.2226],\n",
      "         [0.9883],\n",
      "         [0.9877],\n",
      "         [0.9850],\n",
      "         [0.9865],\n",
      "         [0.4999],\n",
      "         [0.8036],\n",
      "         [0.4877],\n",
      "         [0.5433],\n",
      "         [0.9934],\n",
      "         [0.4388],\n",
      "         [0.7790],\n",
      "         [0.9727],\n",
      "         [0.9914],\n",
      "         [0.6782],\n",
      "         [0.5242],\n",
      "         [0.9458],\n",
      "         [0.9862],\n",
      "         [0.9866],\n",
      "         [0.9871],\n",
      "         [0.9904],\n",
      "         [0.3208],\n",
      "         [0.9794],\n",
      "         [0.9927],\n",
      "         [0.9946],\n",
      "         [0.9955],\n",
      "         [0.4971],\n",
      "         [0.1551],\n",
      "         [0.9971],\n",
      "         [0.9612],\n",
      "         [0.6535],\n",
      "         [0.3582],\n",
      "         [0.9967],\n",
      "         [0.0422],\n",
      "         [0.9948],\n",
      "         [0.0366],\n",
      "         [0.2411],\n",
      "         [0.0409],\n",
      "         [0.9900],\n",
      "         [0.9880],\n",
      "         [0.2263],\n",
      "         [0.2415],\n",
      "         [0.9912],\n",
      "         [0.9923],\n",
      "         [0.4986],\n",
      "         [0.9892],\n",
      "         [0.9900],\n",
      "         [0.9884],\n",
      "         [0.9887],\n",
      "         [0.9858],\n",
      "         [0.3430],\n",
      "         [0.9899],\n",
      "         [0.9912],\n",
      "         [0.9910],\n",
      "         [0.9942],\n",
      "         [0.7193],\n",
      "         [0.9957],\n",
      "         [0.9942],\n",
      "         [0.9935],\n",
      "         [0.0439],\n",
      "         [0.8937],\n",
      "         [0.0256],\n",
      "         [0.3476],\n",
      "         [0.9830],\n",
      "         [0.9834],\n",
      "         [0.9822],\n",
      "         [0.3558],\n",
      "         [0.9846],\n",
      "         [0.9876],\n",
      "         [0.2297],\n",
      "         [0.4891],\n",
      "         [0.8476],\n",
      "         [0.9924],\n",
      "         [0.9929],\n",
      "         [0.9585],\n",
      "         [0.9939],\n",
      "         [0.9925],\n",
      "         [0.9933],\n",
      "         [0.2012],\n",
      "         [0.0507],\n",
      "         [0.5047],\n",
      "         [0.7678],\n",
      "         [0.4459],\n",
      "         [0.3772],\n",
      "         [0.9829],\n",
      "         [0.9959],\n",
      "         [0.9962],\n",
      "         [0.9970],\n",
      "         [0.9989],\n",
      "         [0.6199],\n",
      "         [0.9418],\n",
      "         [1.0016],\n",
      "         [1.0009],\n",
      "         [0.4633],\n",
      "         [0.9962],\n",
      "         [0.9934],\n",
      "         [0.3638],\n",
      "         [0.9933],\n",
      "         [0.9957],\n",
      "         [0.4507],\n",
      "         [0.9989],\n",
      "         [0.3790],\n",
      "         [1.0029],\n",
      "         [1.0039],\n",
      "         [0.9318],\n",
      "         [1.0023],\n",
      "         [0.8718],\n",
      "         [0.8622],\n",
      "         [0.9942],\n",
      "         [0.9910],\n",
      "         [0.9908],\n",
      "         [0.9859],\n",
      "         [0.9919],\n",
      "         [0.3560],\n",
      "         [0.9949],\n",
      "         [0.5334],\n",
      "         [0.9987],\n",
      "         [0.9880],\n",
      "         [0.9985],\n",
      "         [0.9980],\n",
      "         [0.9963],\n",
      "         [0.9928],\n",
      "         [0.4881],\n",
      "         [0.9897],\n",
      "         [0.9892],\n",
      "         [0.3476],\n",
      "         [0.9906],\n",
      "         [0.9882],\n",
      "         [0.9908],\n",
      "         [0.9889],\n",
      "         [0.9182],\n",
      "         [0.9764],\n",
      "         [0.4295],\n",
      "         [0.8369],\n",
      "         [0.9887],\n",
      "         [0.0209],\n",
      "         [0.9883],\n",
      "         [0.9082],\n",
      "         [0.9900],\n",
      "         [0.9915],\n",
      "         [0.9930],\n",
      "         [0.4943],\n",
      "         [0.9944],\n",
      "         [0.9967],\n",
      "         [0.4339],\n",
      "         [0.9962],\n",
      "         [0.3399],\n",
      "         [0.9958],\n",
      "         [0.7435]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2610],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.5139],\n",
      "        [0.6555],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0000],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.9998],\n",
      "        [0.5151],\n",
      "        [0.2518],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [0.0335],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5165],\n",
      "        [0.7820],\n",
      "        [0.5009],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.7540],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.5334],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.1762],\n",
      "        [0.9998],\n",
      "        [0.9490],\n",
      "        [0.6327],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9997],\n",
      "        [0.0142],\n",
      "        [0.2646],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.2577],\n",
      "        [0.2735],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.8761],\n",
      "        [0.0209],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.5038],\n",
      "        [0.8223],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9999],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.0383],\n",
      "        [0.5080],\n",
      "        [0.7391],\n",
      "        [0.4552],\n",
      "        [0.3930],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.4668],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.9999],\n",
      "        [0.5245],\n",
      "        [0.9999],\n",
      "        [0.9820],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.9044],\n",
      "        [0.9814],\n",
      "        [0.4503],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.9997],\n",
      "        [0.8933],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [0.9994],\n",
      "        [0.7129]])\n",
      "######### Epoch: 55  ######### Train Loss: 0.00021382760314736515  ######### Relative L2 Test Norm: 14.763204574584961\n",
      "Output batch pred: tensor([[[0.9942],\n",
      "         [0.6525],\n",
      "         [0.9540],\n",
      "         [0.9943],\n",
      "         [0.9908],\n",
      "         [0.7610],\n",
      "         [0.6761],\n",
      "         [0.0350],\n",
      "         [0.9848],\n",
      "         [0.7977],\n",
      "         [0.9849],\n",
      "         [0.2392],\n",
      "         [0.9510],\n",
      "         [0.8499],\n",
      "         [0.4353],\n",
      "         [0.3562],\n",
      "         [0.9949],\n",
      "         [0.7878],\n",
      "         [0.9977],\n",
      "         [0.5062],\n",
      "         [0.9980],\n",
      "         [0.9986],\n",
      "         [0.9981],\n",
      "         [0.9967],\n",
      "         [0.9587],\n",
      "         [0.9905],\n",
      "         [0.9891],\n",
      "         [0.4858],\n",
      "         [0.9814],\n",
      "         [0.0286],\n",
      "         [0.9777],\n",
      "         [0.4080],\n",
      "         [0.3447],\n",
      "         [0.4223],\n",
      "         [0.9807],\n",
      "         [0.2276],\n",
      "         [0.9890],\n",
      "         [0.0378],\n",
      "         [0.0571],\n",
      "         [1.0000],\n",
      "         [0.5616],\n",
      "         [0.9998],\n",
      "         [0.7268],\n",
      "         [0.9961],\n",
      "         [0.9944],\n",
      "         [0.9917],\n",
      "         [0.0131],\n",
      "         [0.9857],\n",
      "         [0.9851],\n",
      "         [0.0310],\n",
      "         [0.9861],\n",
      "         [0.3292],\n",
      "         [0.9892],\n",
      "         [0.4452],\n",
      "         [0.5062],\n",
      "         [0.9904],\n",
      "         [0.9935],\n",
      "         [0.9817],\n",
      "         [0.9939],\n",
      "         [0.9320],\n",
      "         [0.3553],\n",
      "         [0.9188],\n",
      "         [0.9904],\n",
      "         [0.9901],\n",
      "         [0.2162],\n",
      "         [0.9914],\n",
      "         [0.9925],\n",
      "         [0.9937],\n",
      "         [0.9950],\n",
      "         [0.9963],\n",
      "         [0.0341],\n",
      "         [0.9954],\n",
      "         [0.9949],\n",
      "         [0.6773],\n",
      "         [0.2489],\n",
      "         [0.4416],\n",
      "         [0.9900],\n",
      "         [0.3486],\n",
      "         [0.9873],\n",
      "         [0.9895],\n",
      "         [0.8967],\n",
      "         [0.9740],\n",
      "         [0.9939],\n",
      "         [0.8484],\n",
      "         [0.1658],\n",
      "         [0.5474],\n",
      "         [0.9996],\n",
      "         [0.9987],\n",
      "         [0.2340],\n",
      "         [0.9917],\n",
      "         [0.9897],\n",
      "         [0.9874],\n",
      "         [0.9869],\n",
      "         [0.9863],\n",
      "         [0.9856],\n",
      "         [0.9886],\n",
      "         [0.4426],\n",
      "         [0.9182],\n",
      "         [0.9938],\n",
      "         [0.9945],\n",
      "         [0.9150],\n",
      "         [0.9908],\n",
      "         [0.3619],\n",
      "         [0.9916],\n",
      "         [0.9900],\n",
      "         [0.9890],\n",
      "         [0.3479],\n",
      "         [0.3312],\n",
      "         [0.0308],\n",
      "         [0.9534],\n",
      "         [0.9898],\n",
      "         [0.9856],\n",
      "         [0.4914],\n",
      "         [0.9892],\n",
      "         [0.2440],\n",
      "         [0.9864],\n",
      "         [0.5068],\n",
      "         [0.9896],\n",
      "         [0.9894],\n",
      "         [0.3576],\n",
      "         [0.9907],\n",
      "         [0.9908],\n",
      "         [0.9915],\n",
      "         [0.3733],\n",
      "         [0.2011],\n",
      "         [0.9926],\n",
      "         [0.9936],\n",
      "         [0.4572],\n",
      "         [0.0333],\n",
      "         [0.9958],\n",
      "         [0.9956],\n",
      "         [0.7487],\n",
      "         [0.9975],\n",
      "         [0.9965],\n",
      "         [0.9963],\n",
      "         [0.9949],\n",
      "         [0.9953],\n",
      "         [0.9812],\n",
      "         [0.9948],\n",
      "         [0.5030],\n",
      "         [0.8510],\n",
      "         [0.9939],\n",
      "         [0.3768],\n",
      "         [0.9925],\n",
      "         [0.2390],\n",
      "         [0.4979],\n",
      "         [0.9908],\n",
      "         [0.9894],\n",
      "         [0.5036],\n",
      "         [0.9868],\n",
      "         [0.9867],\n",
      "         [0.9875],\n",
      "         [0.9875],\n",
      "         [0.5213],\n",
      "         [0.9936],\n",
      "         [0.9842],\n",
      "         [0.8701],\n",
      "         [0.6205],\n",
      "         [0.9984],\n",
      "         [0.9994],\n",
      "         [0.4686],\n",
      "         [0.9977],\n",
      "         [0.4571],\n",
      "         [0.9915],\n",
      "         [0.2357],\n",
      "         [0.9905],\n",
      "         [0.9889],\n",
      "         [0.9880],\n",
      "         [0.5009],\n",
      "         [0.9924],\n",
      "         [0.4893],\n",
      "         [0.9943],\n",
      "         [0.4297],\n",
      "         [0.9950],\n",
      "         [0.9817],\n",
      "         [0.9945],\n",
      "         [0.9936],\n",
      "         [0.9941]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.6327],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.7391],\n",
      "        [0.6628],\n",
      "        [0.0368],\n",
      "        [0.9994],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.9515],\n",
      "        [0.8296],\n",
      "        [0.4503],\n",
      "        [0.3753],\n",
      "        [0.9999],\n",
      "        [0.7540],\n",
      "        [0.9998],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.9997],\n",
      "        [0.4480],\n",
      "        [0.3875],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.0383],\n",
      "        [0.9997],\n",
      "        [0.5463],\n",
      "        [0.9996],\n",
      "        [0.6920],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.3780],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.0288],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.2686],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.9724],\n",
      "        [0.9967],\n",
      "        [0.8139],\n",
      "        [0.1762],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.4580],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.3575],\n",
      "        [0.0247],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.9959],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.0209],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.9998],\n",
      "        [0.5080],\n",
      "        [0.8223],\n",
      "        [0.9999],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.5245],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [0.8379],\n",
      "        [0.5945],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000]])\n",
      "######### Epoch: 56  ######### Train Loss: 0.00022584943508263677  ######### Relative L2 Test Norm: 14.360286712646484\n",
      "Output batch pred: tensor([[[0.2599],\n",
      "         [0.9906],\n",
      "         [0.9914],\n",
      "         [0.3686],\n",
      "         [0.9895],\n",
      "         [0.9894],\n",
      "         [0.9910],\n",
      "         [0.9906],\n",
      "         [0.3384],\n",
      "         [0.5003],\n",
      "         [0.4381],\n",
      "         [0.3733],\n",
      "         [0.3479],\n",
      "         [0.9964],\n",
      "         [0.9983],\n",
      "         [0.9976],\n",
      "         [0.1988],\n",
      "         [0.5160],\n",
      "         [0.9944],\n",
      "         [0.9927],\n",
      "         [0.9908],\n",
      "         [0.9892],\n",
      "         [0.9514],\n",
      "         [0.9864],\n",
      "         [0.7575],\n",
      "         [0.9833],\n",
      "         [0.9860],\n",
      "         [0.9858],\n",
      "         [0.0302],\n",
      "         [0.9902],\n",
      "         [0.9920],\n",
      "         [0.9903],\n",
      "         [0.9942],\n",
      "         [0.0455],\n",
      "         [0.9941],\n",
      "         [0.9914],\n",
      "         [0.0577],\n",
      "         [0.0506],\n",
      "         [0.3506],\n",
      "         [0.9854],\n",
      "         [0.9840],\n",
      "         [0.4779],\n",
      "         [0.9833],\n",
      "         [0.9847],\n",
      "         [0.9454],\n",
      "         [0.9889],\n",
      "         [0.9919],\n",
      "         [0.9225],\n",
      "         [0.5057],\n",
      "         [0.4639],\n",
      "         [1.0006],\n",
      "         [0.9990],\n",
      "         [0.0216],\n",
      "         [0.9914],\n",
      "         [0.9912],\n",
      "         [0.0222],\n",
      "         [0.9740],\n",
      "         [0.9851],\n",
      "         [0.9839],\n",
      "         [0.5256],\n",
      "         [0.9869],\n",
      "         [0.7323],\n",
      "         [0.9905],\n",
      "         [0.9916],\n",
      "         [0.6835],\n",
      "         [0.9936],\n",
      "         [0.9955],\n",
      "         [0.8151],\n",
      "         [0.4400],\n",
      "         [0.2470],\n",
      "         [0.9985],\n",
      "         [0.2473],\n",
      "         [1.0003],\n",
      "         [0.7334],\n",
      "         [1.0006],\n",
      "         [0.9996],\n",
      "         [0.9987],\n",
      "         [0.9602],\n",
      "         [0.9911],\n",
      "         [0.8934],\n",
      "         [0.9102],\n",
      "         [0.8480],\n",
      "         [0.9787],\n",
      "         [0.9799],\n",
      "         [0.9808],\n",
      "         [0.4977],\n",
      "         [0.9868],\n",
      "         [0.9895],\n",
      "         [0.3606],\n",
      "         [0.0415],\n",
      "         [0.9980],\n",
      "         [0.4520],\n",
      "         [0.6159],\n",
      "         [0.9948],\n",
      "         [0.1592],\n",
      "         [0.9882],\n",
      "         [0.9851],\n",
      "         [0.9836],\n",
      "         [0.9812],\n",
      "         [0.8386],\n",
      "         [0.9837],\n",
      "         [0.5041],\n",
      "         [0.6444],\n",
      "         [0.7784],\n",
      "         [0.9941],\n",
      "         [0.9930],\n",
      "         [0.2427],\n",
      "         [0.3682],\n",
      "         [0.9896],\n",
      "         [0.4425],\n",
      "         [0.0445],\n",
      "         [0.9853],\n",
      "         [0.9833],\n",
      "         [0.4398],\n",
      "         [0.9561],\n",
      "         [0.9937],\n",
      "         [0.9987],\n",
      "         [0.9836],\n",
      "         [1.0042],\n",
      "         [0.6957],\n",
      "         [1.0069],\n",
      "         [0.3739],\n",
      "         [1.0008],\n",
      "         [0.9943],\n",
      "         [0.9936],\n",
      "         [0.5025],\n",
      "         [0.9895],\n",
      "         [0.8516],\n",
      "         [0.9759],\n",
      "         [0.8401],\n",
      "         [0.4562],\n",
      "         [0.9827],\n",
      "         [0.9959],\n",
      "         [0.0435],\n",
      "         [0.9981],\n",
      "         [0.2386],\n",
      "         [0.4576],\n",
      "         [0.9324],\n",
      "         [0.9921],\n",
      "         [0.9894],\n",
      "         [0.4358],\n",
      "         [0.9905],\n",
      "         [0.9898],\n",
      "         [0.4956],\n",
      "         [0.9919],\n",
      "         [0.9936],\n",
      "         [0.9141],\n",
      "         [0.9931],\n",
      "         [0.9899],\n",
      "         [0.9892],\n",
      "         [0.9849],\n",
      "         [0.9858],\n",
      "         [0.9841],\n",
      "         [0.9849],\n",
      "         [0.9873],\n",
      "         [0.9880],\n",
      "         [0.9923],\n",
      "         [0.9931],\n",
      "         [0.5319],\n",
      "         [0.9827],\n",
      "         [0.9967],\n",
      "         [0.2536],\n",
      "         [0.2560],\n",
      "         [0.5459],\n",
      "         [0.3527],\n",
      "         [0.3668],\n",
      "         [0.4931],\n",
      "         [0.9835],\n",
      "         [0.9838],\n",
      "         [0.9834],\n",
      "         [0.9877],\n",
      "         [0.9889],\n",
      "         [0.4494],\n",
      "         [0.4916],\n",
      "         [0.9939],\n",
      "         [0.9941],\n",
      "         [0.2441],\n",
      "         [0.3816]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2735],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.5038],\n",
      "        [0.4454],\n",
      "        [0.3840],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.0383],\n",
      "        [0.0335],\n",
      "        [0.3728],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9009],\n",
      "        [0.5054],\n",
      "        [0.4642],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9819],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.5334],\n",
      "        [0.9997],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.4480],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [0.6920],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.9044],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [0.4527],\n",
      "        [0.5945],\n",
      "        [0.9999],\n",
      "        [0.1762],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.6327],\n",
      "        [0.7540],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [0.2547],\n",
      "        [0.3808],\n",
      "        [0.9997],\n",
      "        [0.4552],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.4580],\n",
      "        [0.9515],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.9994],\n",
      "        [0.6555],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [0.8296],\n",
      "        [0.9804],\n",
      "        [0.8139],\n",
      "        [0.4645],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.4611],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.5030],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.2729],\n",
      "        [0.5463],\n",
      "        [0.3747],\n",
      "        [0.3930],\n",
      "        [0.5108],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.5009],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.3912]])\n",
      "######### Epoch: 57  ######### Train Loss: 0.00018021637515630573  ######### Relative L2 Test Norm: 14.288057327270508\n",
      "Output batch pred: tensor([[[0.9914],\n",
      "         [0.9916],\n",
      "         [0.0393],\n",
      "         [0.8489],\n",
      "         [0.9922],\n",
      "         [0.9914],\n",
      "         [0.9917],\n",
      "         [0.9918],\n",
      "         [0.9937],\n",
      "         [0.9940],\n",
      "         [0.3362],\n",
      "         [0.6878],\n",
      "         [0.3587],\n",
      "         [0.9934],\n",
      "         [0.4481],\n",
      "         [0.3570],\n",
      "         [0.9927],\n",
      "         [0.9917],\n",
      "         [0.4571],\n",
      "         [0.9925],\n",
      "         [0.6083],\n",
      "         [0.9915],\n",
      "         [0.3611],\n",
      "         [0.8582],\n",
      "         [0.5044],\n",
      "         [0.9942],\n",
      "         [0.0481],\n",
      "         [0.9951],\n",
      "         [0.9803],\n",
      "         [0.3701],\n",
      "         [0.1642],\n",
      "         [0.9914],\n",
      "         [0.9545],\n",
      "         [0.3647],\n",
      "         [0.2261],\n",
      "         [0.9912],\n",
      "         [0.9873],\n",
      "         [0.9915],\n",
      "         [0.9939],\n",
      "         [0.9927],\n",
      "         [0.9922],\n",
      "         [0.5486],\n",
      "         [0.8603],\n",
      "         [0.9701],\n",
      "         [0.9900],\n",
      "         [0.5026],\n",
      "         [0.8393],\n",
      "         [0.4317],\n",
      "         [0.9934],\n",
      "         [0.9959],\n",
      "         [0.5058],\n",
      "         [0.9988],\n",
      "         [0.9977],\n",
      "         [0.9985],\n",
      "         [0.9959],\n",
      "         [0.0272],\n",
      "         [0.7417],\n",
      "         [0.7649],\n",
      "         [0.9886],\n",
      "         [0.9872],\n",
      "         [0.9832],\n",
      "         [0.9867],\n",
      "         [0.9863],\n",
      "         [0.9883],\n",
      "         [0.2462],\n",
      "         [0.9896],\n",
      "         [0.2051],\n",
      "         [0.9943],\n",
      "         [0.4659],\n",
      "         [0.9973],\n",
      "         [0.4531],\n",
      "         [0.9991],\n",
      "         [0.5491],\n",
      "         [0.9967],\n",
      "         [0.7246],\n",
      "         [0.2443],\n",
      "         [0.9556],\n",
      "         [0.9889],\n",
      "         [0.2322],\n",
      "         [0.8915],\n",
      "         [0.9853],\n",
      "         [0.9074],\n",
      "         [0.9888],\n",
      "         [0.9910],\n",
      "         [0.3780],\n",
      "         [0.9960],\n",
      "         [0.9980],\n",
      "         [0.9979],\n",
      "         [0.6579],\n",
      "         [0.9965],\n",
      "         [0.9947],\n",
      "         [0.9913],\n",
      "         [0.0484],\n",
      "         [0.2506],\n",
      "         [0.9890],\n",
      "         [0.5071],\n",
      "         [0.9882],\n",
      "         [0.9892],\n",
      "         [0.9881],\n",
      "         [0.9891],\n",
      "         [0.9854],\n",
      "         [0.3561],\n",
      "         [0.9854],\n",
      "         [0.9831],\n",
      "         [0.5043],\n",
      "         [0.9834],\n",
      "         [0.9859],\n",
      "         [0.0483],\n",
      "         [0.9277],\n",
      "         [0.9923],\n",
      "         [0.8134],\n",
      "         [0.0440],\n",
      "         [0.6790],\n",
      "         [0.9954],\n",
      "         [0.0404],\n",
      "         [0.9940],\n",
      "         [0.9825],\n",
      "         [0.0564],\n",
      "         [0.5074],\n",
      "         [0.9944],\n",
      "         [0.9951],\n",
      "         [0.9949],\n",
      "         [0.9547],\n",
      "         [0.9827],\n",
      "         [0.9930],\n",
      "         [0.9936],\n",
      "         [0.9935],\n",
      "         [0.9583],\n",
      "         [0.5035],\n",
      "         [0.4569],\n",
      "         [0.9921],\n",
      "         [0.9952],\n",
      "         [0.9964],\n",
      "         [0.9254],\n",
      "         [0.9978],\n",
      "         [0.9964],\n",
      "         [0.4562],\n",
      "         [0.4423],\n",
      "         [0.9936],\n",
      "         [0.9922],\n",
      "         [0.3771],\n",
      "         [0.9900],\n",
      "         [0.9891],\n",
      "         [0.2335],\n",
      "         [0.9922],\n",
      "         [0.3431],\n",
      "         [0.9948],\n",
      "         [0.9936],\n",
      "         [0.9941],\n",
      "         [0.9919],\n",
      "         [0.9930],\n",
      "         [0.4449],\n",
      "         [0.5099],\n",
      "         [0.7764],\n",
      "         [0.9766],\n",
      "         [0.9889],\n",
      "         [0.9913],\n",
      "         [0.2446],\n",
      "         [0.9923],\n",
      "         [0.4947],\n",
      "         [0.9903],\n",
      "         [0.9160],\n",
      "         [0.9894],\n",
      "         [0.9884],\n",
      "         [0.9866],\n",
      "         [0.9856],\n",
      "         [0.2308],\n",
      "         [0.4832],\n",
      "         [0.3533],\n",
      "         [0.9907],\n",
      "         [0.4343],\n",
      "         [0.9918],\n",
      "         [0.9950],\n",
      "         [0.0225],\n",
      "         [0.9950],\n",
      "         [0.5292],\n",
      "         [0.9926],\n",
      "         [0.9917]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.9997],\n",
      "        [0.0288],\n",
      "        [0.8223],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.6628],\n",
      "        [0.3747],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.3728],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.8296],\n",
      "        [0.5030],\n",
      "        [0.9994],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [0.3840],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.3875],\n",
      "        [0.2547],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.5463],\n",
      "        [0.8379],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.8139],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.0174],\n",
      "        [0.7129],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.9998],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.2646],\n",
      "        [0.9490],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.8761],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.3912],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.0247],\n",
      "        [0.6555],\n",
      "        [0.9995],\n",
      "        [0.0142],\n",
      "        [0.9997],\n",
      "        [0.9819],\n",
      "        [0.0383],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9420],\n",
      "        [0.9820],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.5080],\n",
      "        [0.4642],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9044],\n",
      "        [0.9996],\n",
      "        [0.9996],\n",
      "        [0.4611],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9997],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.5165],\n",
      "        [0.7540],\n",
      "        [0.9804],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.4988],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.9994],\n",
      "        [1.0000]])\n",
      "######### Epoch: 58  ######### Train Loss: 0.0001751222589518875  ######### Relative L2 Test Norm: 14.267128944396973\n",
      "Output batch pred: tensor([[[0.4989],\n",
      "         [0.9922],\n",
      "         [0.9905],\n",
      "         [0.9915],\n",
      "         [0.9915],\n",
      "         [0.5071],\n",
      "         [0.2362],\n",
      "         [0.3741],\n",
      "         [0.9953],\n",
      "         [0.9835],\n",
      "         [0.3815],\n",
      "         [0.9026],\n",
      "         [0.4386],\n",
      "         [0.9951],\n",
      "         [0.9937],\n",
      "         [0.9937],\n",
      "         [0.2299],\n",
      "         [0.0333],\n",
      "         [0.9129],\n",
      "         [0.0510],\n",
      "         [0.9203],\n",
      "         [0.9943],\n",
      "         [0.0433],\n",
      "         [0.9627],\n",
      "         [0.9981],\n",
      "         [0.9972],\n",
      "         [0.9623],\n",
      "         [0.9903],\n",
      "         [0.9310],\n",
      "         [0.4926],\n",
      "         [0.4510],\n",
      "         [0.9892],\n",
      "         [0.9879],\n",
      "         [0.9889],\n",
      "         [0.0269],\n",
      "         [0.9922],\n",
      "         [0.9930],\n",
      "         [0.5083],\n",
      "         [0.2535],\n",
      "         [0.9955],\n",
      "         [0.9951],\n",
      "         [0.9935],\n",
      "         [0.9201],\n",
      "         [0.8492],\n",
      "         [0.9896],\n",
      "         [0.9885],\n",
      "         [0.9877],\n",
      "         [0.9518],\n",
      "         [0.3562],\n",
      "         [0.9900],\n",
      "         [0.3370],\n",
      "         [0.9922],\n",
      "         [0.9930],\n",
      "         [0.9906],\n",
      "         [0.9922],\n",
      "         [0.5065],\n",
      "         [0.9924],\n",
      "         [0.9921],\n",
      "         [0.9914],\n",
      "         [0.9718],\n",
      "         [0.9903],\n",
      "         [0.0311],\n",
      "         [0.9917],\n",
      "         [0.2390],\n",
      "         [0.9933],\n",
      "         [0.9924],\n",
      "         [0.4595],\n",
      "         [0.9952],\n",
      "         [0.9960],\n",
      "         [0.3697],\n",
      "         [0.5194],\n",
      "         [0.4690],\n",
      "         [0.9952],\n",
      "         [0.9841],\n",
      "         [0.9959],\n",
      "         [0.9960],\n",
      "         [0.9960],\n",
      "         [0.3791],\n",
      "         [0.4468],\n",
      "         [0.9956],\n",
      "         [0.9991],\n",
      "         [0.4645],\n",
      "         [1.0002],\n",
      "         [1.0005],\n",
      "         [0.8554],\n",
      "         [0.2492],\n",
      "         [0.9982],\n",
      "         [0.9839],\n",
      "         [0.9951],\n",
      "         [0.9530],\n",
      "         [0.9895],\n",
      "         [0.9911],\n",
      "         [0.9896],\n",
      "         [0.9911],\n",
      "         [0.4461],\n",
      "         [0.9918],\n",
      "         [0.8131],\n",
      "         [0.9933],\n",
      "         [0.3748],\n",
      "         [0.9943],\n",
      "         [0.9947],\n",
      "         [0.4673],\n",
      "         [0.9951],\n",
      "         [0.9950],\n",
      "         [0.9940],\n",
      "         [0.8623],\n",
      "         [0.9937],\n",
      "         [0.9952],\n",
      "         [0.9938],\n",
      "         [0.9932],\n",
      "         [0.9800],\n",
      "         [0.9924],\n",
      "         [0.9920],\n",
      "         [0.9908],\n",
      "         [0.6044],\n",
      "         [0.9889],\n",
      "         [0.9871],\n",
      "         [0.9868],\n",
      "         [0.9886],\n",
      "         [0.8573],\n",
      "         [0.9872],\n",
      "         [0.3607],\n",
      "         [0.7376],\n",
      "         [0.4409],\n",
      "         [0.0569],\n",
      "         [0.9943],\n",
      "         [0.9933],\n",
      "         [0.9955],\n",
      "         [0.9968],\n",
      "         [0.3493],\n",
      "         [0.9980],\n",
      "         [0.0383],\n",
      "         [0.9952],\n",
      "         [0.5001],\n",
      "         [0.9965],\n",
      "         [0.7218],\n",
      "         [0.9935],\n",
      "         [0.9928],\n",
      "         [0.9922],\n",
      "         [0.1609],\n",
      "         [0.9923],\n",
      "         [0.9938],\n",
      "         [0.3554],\n",
      "         [0.4406],\n",
      "         [0.9933],\n",
      "         [0.9912],\n",
      "         [0.9900],\n",
      "         [0.9899],\n",
      "         [0.5438],\n",
      "         [0.4939],\n",
      "         [0.6445],\n",
      "         [0.5243],\n",
      "         [0.0482],\n",
      "         [0.9924],\n",
      "         [0.7694],\n",
      "         [0.6787],\n",
      "         [0.9973],\n",
      "         [0.9970],\n",
      "         [0.5411],\n",
      "         [0.9925],\n",
      "         [0.3511],\n",
      "         [0.2466],\n",
      "         [0.9852],\n",
      "         [0.9836],\n",
      "         [0.4995],\n",
      "         [0.2395],\n",
      "         [0.9846],\n",
      "         [0.9873],\n",
      "         [0.9879],\n",
      "         [0.6835],\n",
      "         [0.7823],\n",
      "         [0.2488],\n",
      "         [0.9977],\n",
      "         [0.2129],\n",
      "         [0.9986],\n",
      "         [0.5229],\n",
      "         [0.9953],\n",
      "         [0.0544]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.5038],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.2610],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.3930],\n",
      "        [0.8761],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.0174],\n",
      "        [0.8933],\n",
      "        [0.0383],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9956],\n",
      "        [0.9164],\n",
      "        [0.5009],\n",
      "        [0.4645],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5054],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9044],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9962],\n",
      "        [0.9999],\n",
      "        [0.5080],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3747],\n",
      "        [0.5108],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.3875],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.2547],\n",
      "        [0.9999],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.8296],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9966],\n",
      "        [0.3808],\n",
      "        [0.7129],\n",
      "        [0.4503],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.9994],\n",
      "        [0.0209],\n",
      "        [0.9959],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.1762],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.5030],\n",
      "        [0.6327],\n",
      "        [0.5245],\n",
      "        [0.0288],\n",
      "        [0.9998],\n",
      "        [0.7391],\n",
      "        [0.6555],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.5334],\n",
      "        [0.9994],\n",
      "        [0.3728],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.2729],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.7540],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9997],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.0335]])\n",
      "######### Epoch: 59  ######### Train Loss: 0.0001619089744053781  ######### Relative L2 Test Norm: 14.114388465881348\n",
      "Output batch pred: tensor([[[0.4612],\n",
      "         [1.0007],\n",
      "         [1.0009],\n",
      "         [0.4703],\n",
      "         [0.8582],\n",
      "         [0.2534],\n",
      "         [0.9946],\n",
      "         [0.9910],\n",
      "         [0.5125],\n",
      "         [0.9903],\n",
      "         [0.4900],\n",
      "         [0.1629],\n",
      "         [0.6477],\n",
      "         [0.9793],\n",
      "         [0.9934],\n",
      "         [0.4612],\n",
      "         [0.9957],\n",
      "         [0.5156],\n",
      "         [0.9963],\n",
      "         [0.0554],\n",
      "         [0.9976],\n",
      "         [0.7487],\n",
      "         [0.4543],\n",
      "         [0.3799],\n",
      "         [0.9791],\n",
      "         [0.9972],\n",
      "         [0.3523],\n",
      "         [0.9979],\n",
      "         [0.4686],\n",
      "         [0.9961],\n",
      "         [0.9953],\n",
      "         [0.9948],\n",
      "         [0.3649],\n",
      "         [0.9938],\n",
      "         [0.9944],\n",
      "         [0.9947],\n",
      "         [0.4450],\n",
      "         [0.8670],\n",
      "         [0.9043],\n",
      "         [0.7892],\n",
      "         [0.0568],\n",
      "         [0.9984],\n",
      "         [0.5063],\n",
      "         [0.9621],\n",
      "         [0.9964],\n",
      "         [0.9946],\n",
      "         [0.2309],\n",
      "         [0.6713],\n",
      "         [0.9878],\n",
      "         [0.9881],\n",
      "         [0.3534],\n",
      "         [0.9854],\n",
      "         [0.9855],\n",
      "         [0.9860],\n",
      "         [0.9887],\n",
      "         [0.9895],\n",
      "         [0.3735],\n",
      "         [0.9930],\n",
      "         [0.8143],\n",
      "         [0.9838],\n",
      "         [0.9837],\n",
      "         [0.9979],\n",
      "         [0.9982],\n",
      "         [0.4616],\n",
      "         [0.9964],\n",
      "         [0.9971],\n",
      "         [0.2561],\n",
      "         [0.9951],\n",
      "         [0.9931],\n",
      "         [0.4429],\n",
      "         [0.9972],\n",
      "         [0.9955],\n",
      "         [0.5106],\n",
      "         [0.9991],\n",
      "         [0.4490],\n",
      "         [0.9977],\n",
      "         [0.5101],\n",
      "         [0.9944],\n",
      "         [0.5530],\n",
      "         [0.9916],\n",
      "         [0.9930],\n",
      "         [0.9787],\n",
      "         [0.6106],\n",
      "         [0.9937],\n",
      "         [0.0336],\n",
      "         [0.9985],\n",
      "         [0.3718],\n",
      "         [0.9999],\n",
      "         [0.3961],\n",
      "         [1.0011],\n",
      "         [1.0013],\n",
      "         [0.9654],\n",
      "         [0.9957],\n",
      "         [0.2488],\n",
      "         [0.9201],\n",
      "         [0.9902],\n",
      "         [0.0438],\n",
      "         [0.9874],\n",
      "         [0.9901],\n",
      "         [0.5175],\n",
      "         [0.9581],\n",
      "         [0.9939],\n",
      "         [0.9957],\n",
      "         [0.0386],\n",
      "         [0.9967],\n",
      "         [0.9955],\n",
      "         [0.9958],\n",
      "         [0.9940],\n",
      "         [0.6905],\n",
      "         [0.2419],\n",
      "         [0.5310],\n",
      "         [0.9911],\n",
      "         [0.9895],\n",
      "         [0.8543],\n",
      "         [0.9288],\n",
      "         [0.9907],\n",
      "         [0.9896],\n",
      "         [0.9912],\n",
      "         [0.0393],\n",
      "         [0.9912],\n",
      "         [0.9928],\n",
      "         [0.5040],\n",
      "         [0.7211],\n",
      "         [0.3466],\n",
      "         [0.9957],\n",
      "         [0.9970],\n",
      "         [0.9938],\n",
      "         [0.2524],\n",
      "         [0.9997],\n",
      "         [1.0010],\n",
      "         [1.0014],\n",
      "         [1.0014],\n",
      "         [0.2493],\n",
      "         [0.5553],\n",
      "         [0.9999],\n",
      "         [0.9983],\n",
      "         [0.9944],\n",
      "         [0.9213],\n",
      "         [0.9929],\n",
      "         [0.3516],\n",
      "         [0.9905],\n",
      "         [0.9887],\n",
      "         [0.8394],\n",
      "         [0.9920],\n",
      "         [0.9931],\n",
      "         [0.9930],\n",
      "         [0.2610],\n",
      "         [0.3811],\n",
      "         [0.0633],\n",
      "         [0.5210],\n",
      "         [0.9168],\n",
      "         [0.9932],\n",
      "         [0.9936],\n",
      "         [0.9936],\n",
      "         [0.0522],\n",
      "         [0.9934],\n",
      "         [0.9943],\n",
      "         [0.2097],\n",
      "         [0.9956],\n",
      "         [0.3670],\n",
      "         [0.9971],\n",
      "         [0.5117],\n",
      "         [0.9964],\n",
      "         [0.9935],\n",
      "         [0.9925],\n",
      "         [0.0249],\n",
      "         [0.9884],\n",
      "         [0.9859],\n",
      "         [0.9872],\n",
      "         [0.9856],\n",
      "         [0.9875],\n",
      "         [0.9868],\n",
      "         [0.9891],\n",
      "         [0.7656],\n",
      "         [0.4508],\n",
      "         [0.9558],\n",
      "         [0.9976],\n",
      "         [0.9995]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.4552],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [0.8223],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.1762],\n",
      "        [0.6327],\n",
      "        [0.9820],\n",
      "        [0.9998],\n",
      "        [0.4645],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [0.9996],\n",
      "        [0.0288],\n",
      "        [0.9999],\n",
      "        [0.7129],\n",
      "        [0.4527],\n",
      "        [0.3840],\n",
      "        [0.9724],\n",
      "        [0.9995],\n",
      "        [0.3575],\n",
      "        [0.9998],\n",
      "        [0.4668],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.8379],\n",
      "        [0.8761],\n",
      "        [0.7540],\n",
      "        [0.0368],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2518],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9819],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.2729],\n",
      "        [0.9999],\n",
      "        [0.9959],\n",
      "        [0.4454],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9814],\n",
      "        [0.5945],\n",
      "        [0.9999],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.9967],\n",
      "        [0.3930],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.2577],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.8296],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [0.5038],\n",
      "        [0.6920],\n",
      "        [0.3573],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.9956],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.2547],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.2735],\n",
      "        [0.3875],\n",
      "        [0.0383],\n",
      "        [0.5139],\n",
      "        [0.8933],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9999],\n",
      "        [0.3747],\n",
      "        [0.9997],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.4580],\n",
      "        [0.9420],\n",
      "        [0.9995],\n",
      "        [1.0000]])\n",
      "######### Epoch: 60  ######### Train Loss: 0.0001531953166704625  ######### Relative L2 Test Norm: 13.47490406036377\n",
      "Output batch pred: tensor([[[0.2613],\n",
      "         [0.0813],\n",
      "         [1.0024],\n",
      "         [0.2680],\n",
      "         [0.9972],\n",
      "         [0.5179],\n",
      "         [0.9904],\n",
      "         [0.2369],\n",
      "         [0.9907],\n",
      "         [0.9913],\n",
      "         [0.4989],\n",
      "         [0.4582],\n",
      "         [0.9982],\n",
      "         [1.0002],\n",
      "         [1.0010],\n",
      "         [0.6646],\n",
      "         [0.9986],\n",
      "         [0.7875],\n",
      "         [0.9928],\n",
      "         [0.8418],\n",
      "         [0.9904],\n",
      "         [0.9896],\n",
      "         [0.9877],\n",
      "         [0.9893],\n",
      "         [0.7648],\n",
      "         [0.5067],\n",
      "         [0.2515],\n",
      "         [0.5102],\n",
      "         [1.0002],\n",
      "         [1.0002],\n",
      "         [1.0028],\n",
      "         [1.0009],\n",
      "         [1.0022],\n",
      "         [0.7015],\n",
      "         [0.9984],\n",
      "         [0.2117],\n",
      "         [0.9969],\n",
      "         [0.9946],\n",
      "         [0.9536],\n",
      "         [0.4482],\n",
      "         [0.3448],\n",
      "         [0.9834],\n",
      "         [0.4522],\n",
      "         [0.3786],\n",
      "         [0.8678],\n",
      "         [0.9236],\n",
      "         [0.9968],\n",
      "         [0.9831],\n",
      "         [0.0557],\n",
      "         [0.9801],\n",
      "         [0.8127],\n",
      "         [0.9561],\n",
      "         [0.9918],\n",
      "         [0.9916],\n",
      "         [0.9931],\n",
      "         [0.9967],\n",
      "         [0.6867],\n",
      "         [1.0007],\n",
      "         [1.0023],\n",
      "         [1.0034],\n",
      "         [1.0040],\n",
      "         [1.0010],\n",
      "         [1.0013],\n",
      "         [0.9979],\n",
      "         [0.6134],\n",
      "         [0.9887],\n",
      "         [0.9906],\n",
      "         [0.3568],\n",
      "         [0.3550],\n",
      "         [0.4533],\n",
      "         [0.9857],\n",
      "         [0.4418],\n",
      "         [0.3863],\n",
      "         [0.9921],\n",
      "         [0.9948],\n",
      "         [0.4497],\n",
      "         [0.9967],\n",
      "         [0.3774],\n",
      "         [0.9970],\n",
      "         [0.9954],\n",
      "         [0.9967],\n",
      "         [0.9968],\n",
      "         [0.0515],\n",
      "         [0.9975],\n",
      "         [0.9981],\n",
      "         [0.0456],\n",
      "         [0.9989],\n",
      "         [0.9982],\n",
      "         [0.9977],\n",
      "         [0.9944],\n",
      "         [0.7248],\n",
      "         [0.9922],\n",
      "         [0.9923],\n",
      "         [0.9918],\n",
      "         [0.9898],\n",
      "         [0.9910],\n",
      "         [0.9216],\n",
      "         [0.9957],\n",
      "         [0.9977],\n",
      "         [0.5241],\n",
      "         [0.2514],\n",
      "         [1.0043],\n",
      "         [0.2725],\n",
      "         [1.0082],\n",
      "         [0.9892],\n",
      "         [0.0443],\n",
      "         [1.0036],\n",
      "         [1.0023],\n",
      "         [0.9387],\n",
      "         [0.9952],\n",
      "         [0.9922],\n",
      "         [0.4577],\n",
      "         [0.4566],\n",
      "         [0.9890],\n",
      "         [0.9760],\n",
      "         [0.9920],\n",
      "         [0.9940],\n",
      "         [0.9957],\n",
      "         [0.4504],\n",
      "         [0.5394],\n",
      "         [1.0000],\n",
      "         [0.5149],\n",
      "         [0.0580],\n",
      "         [0.3781],\n",
      "         [0.9966],\n",
      "         [0.9933],\n",
      "         [0.9927],\n",
      "         [0.9925],\n",
      "         [0.4995],\n",
      "         [0.9892],\n",
      "         [0.9934],\n",
      "         [0.9936],\n",
      "         [0.9949],\n",
      "         [0.9965],\n",
      "         [0.9975],\n",
      "         [0.9978],\n",
      "         [0.9953],\n",
      "         [0.3612],\n",
      "         [0.9933],\n",
      "         [0.9921],\n",
      "         [0.2325],\n",
      "         [0.9888],\n",
      "         [0.9879],\n",
      "         [0.9898],\n",
      "         [0.8463],\n",
      "         [0.0295],\n",
      "         [0.9911],\n",
      "         [0.5378],\n",
      "         [0.9942],\n",
      "         [0.2486],\n",
      "         [0.9941],\n",
      "         [0.3856],\n",
      "         [0.9018],\n",
      "         [0.9966],\n",
      "         [0.5233],\n",
      "         [0.9966],\n",
      "         [0.4687],\n",
      "         [0.9991],\n",
      "         [0.7489],\n",
      "         [0.3493],\n",
      "         [1.0010],\n",
      "         [1.0010],\n",
      "         [0.3657],\n",
      "         [0.8641],\n",
      "         [0.0262],\n",
      "         [0.9175],\n",
      "         [0.9605],\n",
      "         [0.5133],\n",
      "         [0.5490],\n",
      "         [0.9892],\n",
      "         [0.9884],\n",
      "         [0.9553],\n",
      "         [0.9903],\n",
      "         [0.9946],\n",
      "         [0.9973],\n",
      "         [0.5147],\n",
      "         [0.0757],\n",
      "         [0.1929]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2518],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.4988],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.6327],\n",
      "        [0.9999],\n",
      "        [0.7540],\n",
      "        [0.9967],\n",
      "        [0.8139],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7391],\n",
      "        [0.5080],\n",
      "        [0.2686],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.9994],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.4527],\n",
      "        [0.3573],\n",
      "        [0.9819],\n",
      "        [0.4552],\n",
      "        [0.3875],\n",
      "        [0.8379],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [0.0368],\n",
      "        [0.9804],\n",
      "        [0.7820],\n",
      "        [0.9520],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.3728],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [0.9997],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.5108],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [0.0174],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.4642],\n",
      "        [0.9999],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.0247],\n",
      "        [0.3808],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [0.9959],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [0.9995],\n",
      "        [0.3930],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9999],\n",
      "        [0.4668],\n",
      "        [0.9999],\n",
      "        [0.7129],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [0.8296],\n",
      "        [0.0000],\n",
      "        [0.8933],\n",
      "        [0.9515],\n",
      "        [0.5139],\n",
      "        [0.5463],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.0335],\n",
      "        [0.1762]])\n",
      "######### Epoch: 61  ######### Train Loss: 0.00017952972848434  ######### Relative L2 Test Norm: 13.536624908447266\n",
      "Output batch pred: tensor([[[0.9934],\n",
      "         [0.9938],\n",
      "         [0.9933],\n",
      "         [0.4582],\n",
      "         [0.9902],\n",
      "         [0.9930],\n",
      "         [0.9789],\n",
      "         [0.3794],\n",
      "         [0.9930],\n",
      "         [0.4369],\n",
      "         [0.9962],\n",
      "         [0.9178],\n",
      "         [0.6153],\n",
      "         [0.2619],\n",
      "         [1.0021],\n",
      "         [1.0002],\n",
      "         [0.4794],\n",
      "         [0.5696],\n",
      "         [0.5354],\n",
      "         [0.2644],\n",
      "         [1.0001],\n",
      "         [0.4675],\n",
      "         [0.2688],\n",
      "         [0.5164],\n",
      "         [0.9945],\n",
      "         [0.9923],\n",
      "         [0.1746],\n",
      "         [0.9937],\n",
      "         [0.0494],\n",
      "         [0.9957],\n",
      "         [0.9958],\n",
      "         [0.3758],\n",
      "         [0.9982],\n",
      "         [0.2629],\n",
      "         [1.0010],\n",
      "         [1.0022],\n",
      "         [1.0026],\n",
      "         [1.0015],\n",
      "         [1.0015],\n",
      "         [1.0011],\n",
      "         [1.0015],\n",
      "         [1.0006],\n",
      "         [0.7325],\n",
      "         [0.3724],\n",
      "         [0.7770],\n",
      "         [0.9242],\n",
      "         [0.9963],\n",
      "         [0.9942],\n",
      "         [0.9958],\n",
      "         [0.9841],\n",
      "         [0.8571],\n",
      "         [0.0492],\n",
      "         [0.9965],\n",
      "         [0.9973],\n",
      "         [0.0572],\n",
      "         [0.8226],\n",
      "         [0.8717],\n",
      "         [0.9979],\n",
      "         [0.9976],\n",
      "         [0.9930],\n",
      "         [0.8638],\n",
      "         [0.9967],\n",
      "         [0.9951],\n",
      "         [0.9951],\n",
      "         [0.9952],\n",
      "         [0.4588],\n",
      "         [0.9945],\n",
      "         [0.9949],\n",
      "         [0.9230],\n",
      "         [0.9941],\n",
      "         [0.9934],\n",
      "         [0.9917],\n",
      "         [0.2420],\n",
      "         [0.9920],\n",
      "         [0.9926],\n",
      "         [0.9921],\n",
      "         [0.9925],\n",
      "         [0.9929],\n",
      "         [0.9922],\n",
      "         [0.9024],\n",
      "         [0.9952],\n",
      "         [0.9979],\n",
      "         [0.9987],\n",
      "         [1.0002],\n",
      "         [1.0026],\n",
      "         [0.5162],\n",
      "         [1.0030],\n",
      "         [1.0026],\n",
      "         [1.0008],\n",
      "         [0.9977],\n",
      "         [0.9953],\n",
      "         [0.9948],\n",
      "         [0.9936],\n",
      "         [0.9905],\n",
      "         [0.4922],\n",
      "         [0.9928],\n",
      "         [0.9735],\n",
      "         [0.3420],\n",
      "         [0.9943],\n",
      "         [0.9967],\n",
      "         [0.5153],\n",
      "         [0.9967],\n",
      "         [0.9979],\n",
      "         [0.9843],\n",
      "         [0.9969],\n",
      "         [0.9625],\n",
      "         [0.3773],\n",
      "         [0.9989],\n",
      "         [0.9977],\n",
      "         [0.0760],\n",
      "         [0.4560],\n",
      "         [0.9968],\n",
      "         [0.4608],\n",
      "         [0.7507],\n",
      "         [0.2508],\n",
      "         [0.9982],\n",
      "         [0.5081],\n",
      "         [0.9957],\n",
      "         [0.3589],\n",
      "         [0.9926],\n",
      "         [0.9947],\n",
      "         [0.0515],\n",
      "         [0.5243],\n",
      "         [0.4532],\n",
      "         [0.9995],\n",
      "         [0.2476],\n",
      "         [1.0017],\n",
      "         [1.0028],\n",
      "         [0.9675],\n",
      "         [1.0018],\n",
      "         [0.8533],\n",
      "         [0.5386],\n",
      "         [1.0012],\n",
      "         [0.3697],\n",
      "         [0.9374],\n",
      "         [0.3795],\n",
      "         [0.3872],\n",
      "         [0.0587],\n",
      "         [0.9950],\n",
      "         [0.0408],\n",
      "         [0.5064],\n",
      "         [0.9956],\n",
      "         [0.9968],\n",
      "         [0.4616],\n",
      "         [0.2041],\n",
      "         [0.9941],\n",
      "         [0.9947],\n",
      "         [0.2485],\n",
      "         [0.9958],\n",
      "         [0.5419],\n",
      "         [0.9957],\n",
      "         [0.9962],\n",
      "         [0.6542],\n",
      "         [0.5041],\n",
      "         [0.9640],\n",
      "         [0.9976],\n",
      "         [0.9990],\n",
      "         [0.0310],\n",
      "         [0.9853],\n",
      "         [0.0570],\n",
      "         [0.3426],\n",
      "         [0.9909],\n",
      "         [0.9901],\n",
      "         [0.9894],\n",
      "         [0.9890],\n",
      "         [0.9896],\n",
      "         [0.9900],\n",
      "         [0.3660],\n",
      "         [0.6778],\n",
      "         [0.9979],\n",
      "         [0.9612],\n",
      "         [1.0036],\n",
      "         [1.0032],\n",
      "         [0.7951],\n",
      "         [0.5265],\n",
      "         [1.0007],\n",
      "         [0.4543],\n",
      "         [0.6909]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.5945],\n",
      "        [0.2729],\n",
      "        [0.9997],\n",
      "        [0.9962],\n",
      "        [0.4668],\n",
      "        [0.5463],\n",
      "        [0.5151],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [0.2735],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.9999],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.6920],\n",
      "        [0.3753],\n",
      "        [0.7391],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9820],\n",
      "        [0.8223],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.7820],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9966],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.3573],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5080],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.0368],\n",
      "        [0.4480],\n",
      "        [0.9959],\n",
      "        [0.4527],\n",
      "        [0.7129],\n",
      "        [0.2547],\n",
      "        [0.9999],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.5165],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.9164],\n",
      "        [0.3840],\n",
      "        [0.3912],\n",
      "        [0.0288],\n",
      "        [0.9967],\n",
      "        [0.0142],\n",
      "        [0.5030],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2646],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [0.6327],\n",
      "        [0.5038],\n",
      "        [0.9515],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.9819],\n",
      "        [0.0383],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.6555],\n",
      "        [0.9995],\n",
      "        [0.9420],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.5139],\n",
      "        [0.9997],\n",
      "        [0.4552],\n",
      "        [0.6628]])\n",
      "######### Epoch: 62  ######### Train Loss: 0.00018770151655189693  ######### Relative L2 Test Norm: 13.862584114074707\n",
      "Output batch pred: tensor([[[0.2748],\n",
      "         [1.0083],\n",
      "         [1.0080],\n",
      "         [0.9464],\n",
      "         [0.9342],\n",
      "         [0.8685],\n",
      "         [0.3813],\n",
      "         [0.5076],\n",
      "         [0.4501],\n",
      "         [0.9948],\n",
      "         [0.5127],\n",
      "         [0.5123],\n",
      "         [0.9977],\n",
      "         [1.0019],\n",
      "         [0.6700],\n",
      "         [0.1837],\n",
      "         [1.0049],\n",
      "         [0.5290],\n",
      "         [0.9834],\n",
      "         [0.9993],\n",
      "         [0.9979],\n",
      "         [0.9969],\n",
      "         [0.9940],\n",
      "         [0.7221],\n",
      "         [0.9953],\n",
      "         [0.6816],\n",
      "         [0.3822],\n",
      "         [0.9999],\n",
      "         [0.6998],\n",
      "         [0.5659],\n",
      "         [1.0023],\n",
      "         [1.0001],\n",
      "         [0.9956],\n",
      "         [0.3474],\n",
      "         [0.9944],\n",
      "         [0.9921],\n",
      "         [0.9918],\n",
      "         [0.9887],\n",
      "         [0.9894],\n",
      "         [0.8386],\n",
      "         [0.9898],\n",
      "         [0.9916],\n",
      "         [0.2491],\n",
      "         [0.8653],\n",
      "         [0.9967],\n",
      "         [0.2098],\n",
      "         [0.9983],\n",
      "         [0.2604],\n",
      "         [0.9982],\n",
      "         [0.9978],\n",
      "         [0.9946],\n",
      "         [0.9945],\n",
      "         [0.9564],\n",
      "         [0.9907],\n",
      "         [0.9907],\n",
      "         [0.0368],\n",
      "         [0.9921],\n",
      "         [0.9942],\n",
      "         [0.9975],\n",
      "         [0.0604],\n",
      "         [1.0020],\n",
      "         [1.0056],\n",
      "         [1.0048],\n",
      "         [0.0578],\n",
      "         [0.0596],\n",
      "         [1.0022],\n",
      "         [1.0039],\n",
      "         [0.4548],\n",
      "         [0.9996],\n",
      "         [0.8192],\n",
      "         [0.9989],\n",
      "         [0.6169],\n",
      "         [0.5060],\n",
      "         [1.0013],\n",
      "         [0.0676],\n",
      "         [0.3795],\n",
      "         [0.0580],\n",
      "         [1.0027],\n",
      "         [0.4688],\n",
      "         [0.7806],\n",
      "         [1.0016],\n",
      "         [0.9856],\n",
      "         [0.9960],\n",
      "         [0.2430],\n",
      "         [0.4596],\n",
      "         [0.9836],\n",
      "         [0.9959],\n",
      "         [0.4437],\n",
      "         [0.9959],\n",
      "         [0.3551],\n",
      "         [0.5507],\n",
      "         [0.3900],\n",
      "         [0.9975],\n",
      "         [0.2435],\n",
      "         [0.9941],\n",
      "         [0.9932],\n",
      "         [0.9925],\n",
      "         [0.9901],\n",
      "         [0.9910],\n",
      "         [0.9790],\n",
      "         [0.9920],\n",
      "         [0.8506],\n",
      "         [0.3646],\n",
      "         [0.2587],\n",
      "         [1.0001],\n",
      "         [0.0363],\n",
      "         [1.0026],\n",
      "         [1.0024],\n",
      "         [1.0027],\n",
      "         [0.3657],\n",
      "         [0.5365],\n",
      "         [0.9947],\n",
      "         [0.9937],\n",
      "         [0.9898],\n",
      "         [0.9905],\n",
      "         [0.9901],\n",
      "         [0.3628],\n",
      "         [0.5056],\n",
      "         [0.9946],\n",
      "         [0.9979],\n",
      "         [0.5276],\n",
      "         [1.0018],\n",
      "         [0.7975],\n",
      "         [1.0053],\n",
      "         [0.4720],\n",
      "         [1.0038],\n",
      "         [0.2433],\n",
      "         [0.4697],\n",
      "         [0.9970],\n",
      "         [0.9844],\n",
      "         [0.9245],\n",
      "         [0.9971],\n",
      "         [0.9063],\n",
      "         [0.9994],\n",
      "         [1.0014],\n",
      "         [0.4754],\n",
      "         [0.9626],\n",
      "         [0.0505],\n",
      "         [1.0024],\n",
      "         [0.9995],\n",
      "         [0.4605],\n",
      "         [0.9961],\n",
      "         [0.5218],\n",
      "         [0.3713],\n",
      "         [0.9966],\n",
      "         [0.3868],\n",
      "         [0.7477],\n",
      "         [0.0583],\n",
      "         [0.5259],\n",
      "         [0.9978],\n",
      "         [0.9958],\n",
      "         [0.9970],\n",
      "         [0.9955],\n",
      "         [0.9937],\n",
      "         [0.9924],\n",
      "         [0.5014],\n",
      "         [0.9901],\n",
      "         [0.9885],\n",
      "         [0.9548],\n",
      "         [0.9904],\n",
      "         [0.9901],\n",
      "         [0.9948],\n",
      "         [0.9964],\n",
      "         [0.9978],\n",
      "         [0.9974],\n",
      "         [0.2463],\n",
      "         [0.9994],\n",
      "         [0.9962],\n",
      "         [0.9962],\n",
      "         [0.9619],\n",
      "         [0.9944],\n",
      "         [0.9922],\n",
      "         [0.9154],\n",
      "         [0.9946],\n",
      "         [0.4471],\n",
      "         [0.9968],\n",
      "         [1.0009],\n",
      "         [1.0016]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2729],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.9044],\n",
      "        [0.8296],\n",
      "        [0.3840],\n",
      "        [0.5009],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.9724],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9956],\n",
      "        [0.3573],\n",
      "        [0.9995],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9994],\n",
      "        [0.2735],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.0288],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.5945],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [0.0335],\n",
      "        [0.3753],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.7391],\n",
      "        [0.9997],\n",
      "        [0.9814],\n",
      "        [0.9994],\n",
      "        [0.2610],\n",
      "        [0.4645],\n",
      "        [0.9819],\n",
      "        [0.9998],\n",
      "        [0.4454],\n",
      "        [0.9999],\n",
      "        [0.3575],\n",
      "        [0.5334],\n",
      "        [0.3912],\n",
      "        [0.9999],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.3747],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.5245],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.7540],\n",
      "        [0.9997],\n",
      "        [0.4611],\n",
      "        [0.9999],\n",
      "        [0.2518],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [0.8761],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.9420],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.3930],\n",
      "        [0.7129],\n",
      "        [0.0368],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.9999],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.9999],\n",
      "        [0.9515],\n",
      "        [0.9996],\n",
      "        [0.9996],\n",
      "        [0.8933],\n",
      "        [0.9999],\n",
      "        [0.4480],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9966]])\n",
      "######### Epoch: 63  ######### Train Loss: 0.00019713444635272026  ######### Relative L2 Test Norm: 13.123981475830078\n",
      "Output batch pred: tensor([[[0.9918],\n",
      "         [0.9924],\n",
      "         [0.9944],\n",
      "         [0.9942],\n",
      "         [0.5039],\n",
      "         [0.2719],\n",
      "         [0.3771],\n",
      "         [0.1878],\n",
      "         [0.8597],\n",
      "         [1.0005],\n",
      "         [0.0618],\n",
      "         [0.2171],\n",
      "         [1.0008],\n",
      "         [0.9991],\n",
      "         [0.9975],\n",
      "         [0.9996],\n",
      "         [0.9990],\n",
      "         [0.5123],\n",
      "         [0.9998],\n",
      "         [0.9999],\n",
      "         [0.9980],\n",
      "         [0.9992],\n",
      "         [0.9998],\n",
      "         [0.8703],\n",
      "         [0.9989],\n",
      "         [0.0418],\n",
      "         [0.9983],\n",
      "         [0.9966],\n",
      "         [0.9960],\n",
      "         [0.5135],\n",
      "         [0.5460],\n",
      "         [0.0583],\n",
      "         [0.6569],\n",
      "         [0.9936],\n",
      "         [0.7246],\n",
      "         [0.9973],\n",
      "         [0.9990],\n",
      "         [0.9670],\n",
      "         [1.0022],\n",
      "         [0.9920],\n",
      "         [0.5170],\n",
      "         [0.0356],\n",
      "         [1.0031],\n",
      "         [0.3586],\n",
      "         [0.9983],\n",
      "         [0.9627],\n",
      "         [0.9930],\n",
      "         [0.9926],\n",
      "         [0.9777],\n",
      "         [0.5089],\n",
      "         [0.9862],\n",
      "         [0.9878],\n",
      "         [0.9078],\n",
      "         [0.9891],\n",
      "         [0.9921],\n",
      "         [0.0612],\n",
      "         [0.5379],\n",
      "         [0.6199],\n",
      "         [0.9604],\n",
      "         [1.0019],\n",
      "         [1.0013],\n",
      "         [0.9995],\n",
      "         [0.9984],\n",
      "         [0.9982],\n",
      "         [0.9971],\n",
      "         [0.5046],\n",
      "         [0.9955],\n",
      "         [0.9932],\n",
      "         [0.9049],\n",
      "         [0.9975],\n",
      "         [1.0003],\n",
      "         [1.0019],\n",
      "         [0.9679],\n",
      "         [0.2501],\n",
      "         [0.9999],\n",
      "         [0.9984],\n",
      "         [0.9964],\n",
      "         [0.9955],\n",
      "         [0.5097],\n",
      "         [0.9793],\n",
      "         [0.4539],\n",
      "         [0.3791],\n",
      "         [0.9959],\n",
      "         [0.6863],\n",
      "         [0.3941],\n",
      "         [0.4653],\n",
      "         [0.9956],\n",
      "         [0.9398],\n",
      "         [1.0088],\n",
      "         [1.0081],\n",
      "         [0.8621],\n",
      "         [0.4765],\n",
      "         [0.8677],\n",
      "         [0.4468],\n",
      "         [0.4489],\n",
      "         [0.9948],\n",
      "         [0.2424],\n",
      "         [0.9940],\n",
      "         [0.2460],\n",
      "         [0.9944],\n",
      "         [0.0505],\n",
      "         [0.4453],\n",
      "         [0.4558],\n",
      "         [0.9941],\n",
      "         [0.9937],\n",
      "         [0.9927],\n",
      "         [0.9915],\n",
      "         [0.3593],\n",
      "         [0.3739],\n",
      "         [0.9956],\n",
      "         [0.9999],\n",
      "         [1.0018],\n",
      "         [1.0038],\n",
      "         [0.9451],\n",
      "         [0.7597],\n",
      "         [1.0063],\n",
      "         [1.0053],\n",
      "         [1.0031],\n",
      "         [0.9999],\n",
      "         [0.5186],\n",
      "         [0.9938],\n",
      "         [0.9914],\n",
      "         [0.9895],\n",
      "         [0.2364],\n",
      "         [0.3601],\n",
      "         [0.9882],\n",
      "         [0.9899],\n",
      "         [0.9193],\n",
      "         [0.3675],\n",
      "         [0.9968],\n",
      "         [0.9998],\n",
      "         [1.0000],\n",
      "         [0.5648],\n",
      "         [0.0603],\n",
      "         [0.7929],\n",
      "         [1.0021],\n",
      "         [0.0704],\n",
      "         [0.9998],\n",
      "         [0.2692],\n",
      "         [0.5146],\n",
      "         [1.0023],\n",
      "         [0.0402],\n",
      "         [1.0043],\n",
      "         [1.0039],\n",
      "         [1.0006],\n",
      "         [0.7819],\n",
      "         [0.4573],\n",
      "         [0.9976],\n",
      "         [0.9946],\n",
      "         [0.9926],\n",
      "         [0.9904],\n",
      "         [0.9869],\n",
      "         [0.3551],\n",
      "         [0.2362],\n",
      "         [0.9910],\n",
      "         [0.9945],\n",
      "         [0.9994],\n",
      "         [1.0018],\n",
      "         [0.4761],\n",
      "         [1.0066],\n",
      "         [0.2723],\n",
      "         [0.4831],\n",
      "         [0.7056],\n",
      "         [0.9841],\n",
      "         [0.5300],\n",
      "         [0.9990],\n",
      "         [0.3620],\n",
      "         [0.9968],\n",
      "         [0.8183],\n",
      "         [0.9969],\n",
      "         [0.9959],\n",
      "         [0.9979],\n",
      "         [0.9966],\n",
      "         [0.9953],\n",
      "         [0.3457],\n",
      "         [0.9943],\n",
      "         [0.9939],\n",
      "         [0.9911]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4988],\n",
      "        [0.2735],\n",
      "        [0.3747],\n",
      "        [0.1762],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.2208],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9997],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.5334],\n",
      "        [0.0383],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [0.5009],\n",
      "        [0.0000],\n",
      "        [0.9994],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.0368],\n",
      "        [0.5245],\n",
      "        [0.5945],\n",
      "        [0.9420],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.5030],\n",
      "        [0.9997],\n",
      "        [0.9956],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9520],\n",
      "        [0.2577],\n",
      "        [0.9995],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.5108],\n",
      "        [0.9804],\n",
      "        [0.4611],\n",
      "        [0.3912],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [0.3930],\n",
      "        [0.4527],\n",
      "        [0.9814],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.8139],\n",
      "        [0.4645],\n",
      "        [0.8296],\n",
      "        [0.4454],\n",
      "        [0.4503],\n",
      "        [0.9999],\n",
      "        [0.2518],\n",
      "        [0.9997],\n",
      "        [0.2547],\n",
      "        [0.9998],\n",
      "        [0.0174],\n",
      "        [0.4480],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.3753],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.0247],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.7391],\n",
      "        [0.4552],\n",
      "        [0.9996],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.4642],\n",
      "        [0.9999],\n",
      "        [0.2686],\n",
      "        [0.4668],\n",
      "        [0.6628],\n",
      "        [0.9724],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000]])\n",
      "######### Epoch: 64  ######### Train Loss: 0.00022666466247756034  ######### Relative L2 Test Norm: 13.509042739868164\n",
      "Output batch pred: tensor([[[0.9994],\n",
      "         [1.0033],\n",
      "         [1.0027],\n",
      "         [1.0008],\n",
      "         [0.3831],\n",
      "         [0.9966],\n",
      "         [0.5161],\n",
      "         [0.9904],\n",
      "         [0.9902],\n",
      "         [0.8566],\n",
      "         [0.9885],\n",
      "         [0.9883],\n",
      "         [0.9184],\n",
      "         [0.9942],\n",
      "         [0.2534],\n",
      "         [0.0469],\n",
      "         [0.7960],\n",
      "         [0.5248],\n",
      "         [0.9929],\n",
      "         [1.0056],\n",
      "         [1.0031],\n",
      "         [1.0023],\n",
      "         [1.0008],\n",
      "         [0.2076],\n",
      "         [0.5235],\n",
      "         [0.9964],\n",
      "         [0.9940],\n",
      "         [0.9963],\n",
      "         [0.3463],\n",
      "         [0.9181],\n",
      "         [0.9963],\n",
      "         [0.2663],\n",
      "         [0.9968],\n",
      "         [0.4572],\n",
      "         [0.9978],\n",
      "         [0.8161],\n",
      "         [0.2414],\n",
      "         [0.2445],\n",
      "         [0.9946],\n",
      "         [0.9927],\n",
      "         [0.9948],\n",
      "         [0.3623],\n",
      "         [0.9946],\n",
      "         [0.1637],\n",
      "         [0.9982],\n",
      "         [0.9990],\n",
      "         [1.0009],\n",
      "         [1.0013],\n",
      "         [1.0018],\n",
      "         [1.0015],\n",
      "         [0.9885],\n",
      "         [1.0001],\n",
      "         [0.9998],\n",
      "         [0.9989],\n",
      "         [0.9965],\n",
      "         [0.9958],\n",
      "         [0.0456],\n",
      "         [0.4434],\n",
      "         [0.9917],\n",
      "         [0.4570],\n",
      "         [0.9918],\n",
      "         [0.0278],\n",
      "         [0.8470],\n",
      "         [0.9898],\n",
      "         [0.9903],\n",
      "         [0.9902],\n",
      "         [0.9910],\n",
      "         [0.0504],\n",
      "         [0.9952],\n",
      "         [0.9970],\n",
      "         [0.5252],\n",
      "         [1.0010],\n",
      "         [1.0006],\n",
      "         [1.0029],\n",
      "         [0.0654],\n",
      "         [1.0023],\n",
      "         [0.9967],\n",
      "         [0.9978],\n",
      "         [0.9954],\n",
      "         [0.5505],\n",
      "         [0.9906],\n",
      "         [0.9915],\n",
      "         [0.9922],\n",
      "         [0.5022],\n",
      "         [0.4998],\n",
      "         [0.6962],\n",
      "         [1.0002],\n",
      "         [1.0046],\n",
      "         [1.0049],\n",
      "         [1.0074],\n",
      "         [0.7901],\n",
      "         [1.0087],\n",
      "         [1.0056],\n",
      "         [0.4560],\n",
      "         [0.5454],\n",
      "         [0.9674],\n",
      "         [0.4567],\n",
      "         [0.3835],\n",
      "         [0.9994],\n",
      "         [0.2583],\n",
      "         [0.9858],\n",
      "         [0.6173],\n",
      "         [0.9989],\n",
      "         [0.9863],\n",
      "         [0.3671],\n",
      "         [0.0413],\n",
      "         [0.3474],\n",
      "         [0.5080],\n",
      "         [0.9940],\n",
      "         [0.9918],\n",
      "         [0.9943],\n",
      "         [0.9945],\n",
      "         [0.4623],\n",
      "         [0.9980],\n",
      "         [0.9999],\n",
      "         [0.9676],\n",
      "         [0.2531],\n",
      "         [0.5136],\n",
      "         [0.9422],\n",
      "         [0.8545],\n",
      "         [1.0012],\n",
      "         [0.9055],\n",
      "         [0.9969],\n",
      "         [0.3776],\n",
      "         [0.9505],\n",
      "         [0.6711],\n",
      "         [0.9889],\n",
      "         [0.3499],\n",
      "         [0.7136],\n",
      "         [0.9898],\n",
      "         [0.9908],\n",
      "         [0.9189],\n",
      "         [0.9946],\n",
      "         [0.9965],\n",
      "         [0.9969],\n",
      "         [0.9995],\n",
      "         [1.0001],\n",
      "         [0.2614],\n",
      "         [0.9993],\n",
      "         [0.9650],\n",
      "         [0.5491],\n",
      "         [1.0007],\n",
      "         [0.3807],\n",
      "         [0.9990],\n",
      "         [1.0006],\n",
      "         [0.9993],\n",
      "         [0.9988],\n",
      "         [0.4651],\n",
      "         [0.9960],\n",
      "         [0.8597],\n",
      "         [0.9918],\n",
      "         [0.9896],\n",
      "         [0.9910],\n",
      "         [0.9900],\n",
      "         [0.9893],\n",
      "         [0.9915],\n",
      "         [0.9926],\n",
      "         [0.9977],\n",
      "         [0.9991],\n",
      "         [0.4617],\n",
      "         [0.4542],\n",
      "         [1.0034],\n",
      "         [0.0475],\n",
      "         [0.0697],\n",
      "         [0.6680],\n",
      "         [0.2540],\n",
      "         [0.3761],\n",
      "         [0.0666],\n",
      "         [0.9778],\n",
      "         [0.9947],\n",
      "         [0.9950],\n",
      "         [0.5031],\n",
      "         [0.4629],\n",
      "         [0.3690],\n",
      "         [0.9977],\n",
      "         [0.9985],\n",
      "         [0.7486],\n",
      "         [0.5211]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9956],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9997],\n",
      "        [0.5151],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [0.0209],\n",
      "        [0.7540],\n",
      "        [0.5080],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.2208],\n",
      "        [0.5165],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.9996],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.2547],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.9966],\n",
      "        [0.1762],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.4503],\n",
      "        [0.9997],\n",
      "        [0.4645],\n",
      "        [0.9998],\n",
      "        [0.0142],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5038],\n",
      "        [0.4988],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.5245],\n",
      "        [0.9520],\n",
      "        [0.4527],\n",
      "        [0.3875],\n",
      "        [0.9999],\n",
      "        [0.2686],\n",
      "        [0.9804],\n",
      "        [0.5945],\n",
      "        [0.9997],\n",
      "        [0.9819],\n",
      "        [0.3747],\n",
      "        [0.0174],\n",
      "        [0.3575],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.2577],\n",
      "        [0.5009],\n",
      "        [0.9164],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.9998],\n",
      "        [0.3930],\n",
      "        [0.9420],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.5334],\n",
      "        [0.9999],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.4642],\n",
      "        [0.9999],\n",
      "        [0.8296],\n",
      "        [0.9994],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.4580],\n",
      "        [0.4480],\n",
      "        [0.9962],\n",
      "        [0.0000],\n",
      "        [0.0288],\n",
      "        [0.6327],\n",
      "        [0.2518],\n",
      "        [0.3753],\n",
      "        [0.0383],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.4668],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7129],\n",
      "        [0.5108]])\n",
      "######### Epoch: 65  ######### Train Loss: 0.00018513313261792064  ######### Relative L2 Test Norm: 13.862407684326172\n",
      "Output batch pred: tensor([[[0.2538],\n",
      "         [0.9983],\n",
      "         [0.0565],\n",
      "         [0.2631],\n",
      "         [0.0445],\n",
      "         [0.9989],\n",
      "         [0.1789],\n",
      "         [0.0512],\n",
      "         [0.8663],\n",
      "         [0.9940],\n",
      "         [0.9925],\n",
      "         [0.9916],\n",
      "         [0.9885],\n",
      "         [0.9922],\n",
      "         [0.9926],\n",
      "         [0.5140],\n",
      "         [0.8626],\n",
      "         [0.9991],\n",
      "         [0.4545],\n",
      "         [1.0026],\n",
      "         [1.0043],\n",
      "         [1.0041],\n",
      "         [1.0021],\n",
      "         [0.7538],\n",
      "         [1.0002],\n",
      "         [0.9956],\n",
      "         [0.9155],\n",
      "         [0.4328],\n",
      "         [0.9903],\n",
      "         [0.9547],\n",
      "         [0.9908],\n",
      "         [0.6502],\n",
      "         [0.9817],\n",
      "         [0.2391],\n",
      "         [0.4490],\n",
      "         [1.0002],\n",
      "         [0.5175],\n",
      "         [0.2491],\n",
      "         [0.9996],\n",
      "         [1.0001],\n",
      "         [0.9973],\n",
      "         [0.6113],\n",
      "         [0.9930],\n",
      "         [0.9573],\n",
      "         [0.9900],\n",
      "         [0.9284],\n",
      "         [0.5252],\n",
      "         [0.0301],\n",
      "         [0.9940],\n",
      "         [0.9940],\n",
      "         [0.9945],\n",
      "         [0.5129],\n",
      "         [0.9957],\n",
      "         [0.9931],\n",
      "         [0.9929],\n",
      "         [0.9901],\n",
      "         [0.3621],\n",
      "         [0.1982],\n",
      "         [0.9878],\n",
      "         [0.3512],\n",
      "         [0.4962],\n",
      "         [0.9910],\n",
      "         [0.8135],\n",
      "         [0.4995],\n",
      "         [0.9977],\n",
      "         [0.9974],\n",
      "         [0.9861],\n",
      "         [0.9983],\n",
      "         [0.9995],\n",
      "         [0.9969],\n",
      "         [0.9968],\n",
      "         [1.0003],\n",
      "         [0.9601],\n",
      "         [1.0008],\n",
      "         [1.0007],\n",
      "         [0.5115],\n",
      "         [0.3903],\n",
      "         [0.9277],\n",
      "         [0.9987],\n",
      "         [0.9984],\n",
      "         [0.9966],\n",
      "         [0.3630],\n",
      "         [0.9947],\n",
      "         [0.4608],\n",
      "         [0.9941],\n",
      "         [0.9948],\n",
      "         [0.9958],\n",
      "         [0.9968],\n",
      "         [0.4654],\n",
      "         [0.2712],\n",
      "         [0.4816],\n",
      "         [1.0045],\n",
      "         [0.4810],\n",
      "         [1.0051],\n",
      "         [1.0038],\n",
      "         [0.4635],\n",
      "         [0.9792],\n",
      "         [0.9827],\n",
      "         [0.0576],\n",
      "         [0.3751],\n",
      "         [0.3791],\n",
      "         [0.9917],\n",
      "         [0.6748],\n",
      "         [0.7828],\n",
      "         [0.3656],\n",
      "         [0.5231],\n",
      "         [1.0000],\n",
      "         [1.0006],\n",
      "         [0.8539],\n",
      "         [0.9996],\n",
      "         [1.0002],\n",
      "         [0.9988],\n",
      "         [0.3460],\n",
      "         [0.9224],\n",
      "         [0.9914],\n",
      "         [0.9922],\n",
      "         [0.9917],\n",
      "         [0.4981],\n",
      "         [0.9921],\n",
      "         [0.9911],\n",
      "         [0.9931],\n",
      "         [0.9942],\n",
      "         [0.4393],\n",
      "         [0.9939],\n",
      "         [0.9935],\n",
      "         [0.9915],\n",
      "         [0.7171],\n",
      "         [0.9921],\n",
      "         [0.9924],\n",
      "         [0.9936],\n",
      "         [0.9948],\n",
      "         [0.5457],\n",
      "         [0.9985],\n",
      "         [0.2636],\n",
      "         [1.0032],\n",
      "         [1.0025],\n",
      "         [1.0052],\n",
      "         [0.7018],\n",
      "         [1.0017],\n",
      "         [0.4620],\n",
      "         [0.9974],\n",
      "         [0.9959],\n",
      "         [0.9952],\n",
      "         [0.9935],\n",
      "         [0.0424],\n",
      "         [0.9899],\n",
      "         [0.2522],\n",
      "         [0.3626],\n",
      "         [0.9957],\n",
      "         [0.9845],\n",
      "         [0.9978],\n",
      "         [0.5561],\n",
      "         [0.9987],\n",
      "         [0.0581],\n",
      "         [0.3702],\n",
      "         [0.9990],\n",
      "         [0.9982],\n",
      "         [0.9991],\n",
      "         [0.9991],\n",
      "         [1.0002],\n",
      "         [1.0003],\n",
      "         [0.9088],\n",
      "         [0.2448],\n",
      "         [0.3507],\n",
      "         [1.0033],\n",
      "         [1.0020],\n",
      "         [0.0531],\n",
      "         [0.9999],\n",
      "         [0.5102],\n",
      "         [0.9961],\n",
      "         [0.8507],\n",
      "         [0.9922],\n",
      "         [0.5116],\n",
      "         [0.7639],\n",
      "         [0.0384],\n",
      "         [0.9925],\n",
      "         [0.9586],\n",
      "         [0.9942]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2610],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.2646],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.0209],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.5139],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.8933],\n",
      "        [0.4454],\n",
      "        [0.9997],\n",
      "        [0.9490],\n",
      "        [0.9997],\n",
      "        [0.6327],\n",
      "        [0.9820],\n",
      "        [0.2518],\n",
      "        [0.4480],\n",
      "        [0.9998],\n",
      "        [0.5054],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9999],\n",
      "        [0.9164],\n",
      "        [0.5245],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.3840],\n",
      "        [0.2208],\n",
      "        [0.9994],\n",
      "        [0.3728],\n",
      "        [0.5030],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.9804],\n",
      "        [0.9996],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [0.9420],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.3912],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.2729],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.9724],\n",
      "        [0.9814],\n",
      "        [0.0335],\n",
      "        [0.3875],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.7540],\n",
      "        [0.3780],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.9999],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.0247],\n",
      "        [0.9962],\n",
      "        [0.2686],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.9996],\n",
      "        [0.0368],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.2547],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.7391],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.9966]])\n",
      "######### Epoch: 66  ######### Train Loss: 0.000161133793881163  ######### Relative L2 Test Norm: 13.867868423461914\n",
      "Output batch pred: tensor([[[0.9125],\n",
      "         [0.9926],\n",
      "         [0.9949],\n",
      "         [0.9961],\n",
      "         [0.9975],\n",
      "         [0.9989],\n",
      "         [1.0001],\n",
      "         [0.5170],\n",
      "         [0.9970],\n",
      "         [0.6134],\n",
      "         [0.0406],\n",
      "         [0.9952],\n",
      "         [0.9964],\n",
      "         [0.9961],\n",
      "         [0.9956],\n",
      "         [0.9985],\n",
      "         [0.2544],\n",
      "         [0.6591],\n",
      "         [0.4685],\n",
      "         [0.5206],\n",
      "         [0.7455],\n",
      "         [0.8147],\n",
      "         [0.9944],\n",
      "         [0.3431],\n",
      "         [0.5032],\n",
      "         [0.9927],\n",
      "         [0.4577],\n",
      "         [0.9933],\n",
      "         [0.0333],\n",
      "         [0.9949],\n",
      "         [0.9624],\n",
      "         [0.9970],\n",
      "         [0.9955],\n",
      "         [0.5205],\n",
      "         [0.9552],\n",
      "         [0.7707],\n",
      "         [0.5536],\n",
      "         [0.3414],\n",
      "         [0.9959],\n",
      "         [0.9958],\n",
      "         [0.9952],\n",
      "         [0.7212],\n",
      "         [0.9945],\n",
      "         [0.9581],\n",
      "         [0.3733],\n",
      "         [0.6740],\n",
      "         [0.9912],\n",
      "         [0.9892],\n",
      "         [0.5013],\n",
      "         [0.9918],\n",
      "         [0.9926],\n",
      "         [0.9948],\n",
      "         [0.9953],\n",
      "         [0.7874],\n",
      "         [0.3722],\n",
      "         [0.9994],\n",
      "         [0.0229],\n",
      "         [0.9999],\n",
      "         [0.9978],\n",
      "         [0.9981],\n",
      "         [0.9954],\n",
      "         [0.2326],\n",
      "         [0.9903],\n",
      "         [0.9910],\n",
      "         [0.9880],\n",
      "         [0.9904],\n",
      "         [0.9897],\n",
      "         [0.0558],\n",
      "         [0.0568],\n",
      "         [0.3655],\n",
      "         [0.9974],\n",
      "         [1.0010],\n",
      "         [1.0032],\n",
      "         [1.0028],\n",
      "         [0.4476],\n",
      "         [0.9314],\n",
      "         [1.0007],\n",
      "         [0.5215],\n",
      "         [0.9972],\n",
      "         [0.9944],\n",
      "         [0.9941],\n",
      "         [0.9929],\n",
      "         [0.9940],\n",
      "         [0.4464],\n",
      "         [0.5068],\n",
      "         [0.9979],\n",
      "         [0.9991],\n",
      "         [0.9996],\n",
      "         [0.9992],\n",
      "         [0.8689],\n",
      "         [0.9968],\n",
      "         [0.6882],\n",
      "         [0.5276],\n",
      "         [0.8980],\n",
      "         [0.1620],\n",
      "         [0.9915],\n",
      "         [0.4458],\n",
      "         [0.3646],\n",
      "         [0.9934],\n",
      "         [0.8579],\n",
      "         [0.3797],\n",
      "         [0.9959],\n",
      "         [0.9959],\n",
      "         [0.9937],\n",
      "         [0.9960],\n",
      "         [0.3629],\n",
      "         [0.4538],\n",
      "         [0.9958],\n",
      "         [0.9924],\n",
      "         [0.9972],\n",
      "         [0.0569],\n",
      "         [0.9972],\n",
      "         [0.9973],\n",
      "         [0.9247],\n",
      "         [0.9985],\n",
      "         [0.2535],\n",
      "         [0.3597],\n",
      "         [0.9952],\n",
      "         [0.9933],\n",
      "         [0.9946],\n",
      "         [0.5023],\n",
      "         [0.9935],\n",
      "         [0.9943],\n",
      "         [0.9972],\n",
      "         [0.9980],\n",
      "         [0.9997],\n",
      "         [1.0001],\n",
      "         [0.3836],\n",
      "         [0.9399],\n",
      "         [0.9878],\n",
      "         [0.0578],\n",
      "         [0.9990],\n",
      "         [0.4652],\n",
      "         [0.4685],\n",
      "         [0.2659],\n",
      "         [0.4526],\n",
      "         [0.0409],\n",
      "         [0.9964],\n",
      "         [0.5012],\n",
      "         [0.9944],\n",
      "         [0.4960],\n",
      "         [0.9809],\n",
      "         [0.9926],\n",
      "         [0.9936],\n",
      "         [0.9942],\n",
      "         [0.9946],\n",
      "         [0.3636],\n",
      "         [0.9962],\n",
      "         [0.9945],\n",
      "         [0.4420],\n",
      "         [0.9964],\n",
      "         [0.9949],\n",
      "         [0.2463],\n",
      "         [0.5388],\n",
      "         [0.8503],\n",
      "         [0.9574],\n",
      "         [0.9925],\n",
      "         [0.9924],\n",
      "         [0.9717],\n",
      "         [0.0262],\n",
      "         [0.2305],\n",
      "         [0.9917],\n",
      "         [0.9916],\n",
      "         [0.8430],\n",
      "         [0.9922],\n",
      "         [0.9928],\n",
      "         [0.9989],\n",
      "         [0.2367],\n",
      "         [1.0008],\n",
      "         [1.0021],\n",
      "         [0.2072],\n",
      "         [1.0023],\n",
      "         [1.0010],\n",
      "         [0.9871],\n",
      "         [0.9954],\n",
      "         [0.9812],\n",
      "         [0.9923],\n",
      "         [0.2352]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.8933],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.0247],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.2686],\n",
      "        [0.6327],\n",
      "        [0.4668],\n",
      "        [0.5139],\n",
      "        [0.7129],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [0.9999],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9420],\n",
      "        [0.7391],\n",
      "        [0.5463],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.3875],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.7540],\n",
      "        [0.3840],\n",
      "        [0.9997],\n",
      "        [0.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0368],\n",
      "        [0.0335],\n",
      "        [0.3728],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4454],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.5030],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.5245],\n",
      "        [0.8761],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.3808],\n",
      "        [0.9997],\n",
      "        [0.8296],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [0.3753],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9164],\n",
      "        [0.9814],\n",
      "        [0.0288],\n",
      "        [0.9966],\n",
      "        [0.4611],\n",
      "        [0.4645],\n",
      "        [0.2735],\n",
      "        [0.4527],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9998],\n",
      "        [0.4988],\n",
      "        [0.9820],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [0.5334],\n",
      "        [0.8223],\n",
      "        [0.9520],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.0209],\n",
      "        [0.2577],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.9962],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.2610]])\n",
      "######### Epoch: 67  ######### Train Loss: 0.00014649250078946352  ######### Relative L2 Test Norm: 14.329145431518555\n",
      "Output batch pred: tensor([[[0.9988],\n",
      "         [0.9998],\n",
      "         [1.0002],\n",
      "         [0.2443],\n",
      "         [0.9992],\n",
      "         [0.4516],\n",
      "         [0.9963],\n",
      "         [0.9976],\n",
      "         [0.9951],\n",
      "         [0.9952],\n",
      "         [0.8424],\n",
      "         [0.9192],\n",
      "         [0.0448],\n",
      "         [0.4574],\n",
      "         [0.8526],\n",
      "         [0.5423],\n",
      "         [0.9982],\n",
      "         [0.9971],\n",
      "         [0.9976],\n",
      "         [0.4414],\n",
      "         [0.1603],\n",
      "         [0.2288],\n",
      "         [0.9742],\n",
      "         [0.9934],\n",
      "         [0.9932],\n",
      "         [0.4494],\n",
      "         [0.6852],\n",
      "         [0.9933],\n",
      "         [0.5153],\n",
      "         [0.9965],\n",
      "         [0.5044],\n",
      "         [0.9969],\n",
      "         [0.6096],\n",
      "         [0.0269],\n",
      "         [0.4999],\n",
      "         [0.9297],\n",
      "         [0.9903],\n",
      "         [0.9913],\n",
      "         [0.8081],\n",
      "         [0.3564],\n",
      "         [0.2424],\n",
      "         [0.4982],\n",
      "         [0.9914],\n",
      "         [0.9932],\n",
      "         [0.9937],\n",
      "         [0.6732],\n",
      "         [0.9936],\n",
      "         [0.9930],\n",
      "         [0.9935],\n",
      "         [0.9922],\n",
      "         [0.9941],\n",
      "         [0.9949],\n",
      "         [0.9952],\n",
      "         [0.5082],\n",
      "         [0.9612],\n",
      "         [0.9963],\n",
      "         [0.9946],\n",
      "         [0.4385],\n",
      "         [0.9809],\n",
      "         [0.9917],\n",
      "         [0.9922],\n",
      "         [0.7380],\n",
      "         [0.7148],\n",
      "         [0.9910],\n",
      "         [0.9927],\n",
      "         [0.3350],\n",
      "         [0.9944],\n",
      "         [0.3795],\n",
      "         [0.4660],\n",
      "         [0.5599],\n",
      "         [1.0009],\n",
      "         [1.0014],\n",
      "         [0.3896],\n",
      "         [0.8666],\n",
      "         [0.2569],\n",
      "         [0.5230],\n",
      "         [0.9958],\n",
      "         [0.9951],\n",
      "         [0.9915],\n",
      "         [0.9566],\n",
      "         [0.9916],\n",
      "         [0.0404],\n",
      "         [0.9924],\n",
      "         [0.4459],\n",
      "         [0.5025],\n",
      "         [0.9965],\n",
      "         [0.9987],\n",
      "         [0.4508],\n",
      "         [0.9991],\n",
      "         [0.2449],\n",
      "         [0.9970],\n",
      "         [0.9957],\n",
      "         [0.9935],\n",
      "         [0.9901],\n",
      "         [0.9903],\n",
      "         [0.0192],\n",
      "         [0.9164],\n",
      "         [0.9900],\n",
      "         [0.8609],\n",
      "         [0.9927],\n",
      "         [0.9934],\n",
      "         [0.9941],\n",
      "         [0.9970],\n",
      "         [0.9954],\n",
      "         [0.5158],\n",
      "         [0.0512],\n",
      "         [0.9925],\n",
      "         [0.9932],\n",
      "         [0.0438],\n",
      "         [0.9924],\n",
      "         [0.9925],\n",
      "         [0.4581],\n",
      "         [0.9939],\n",
      "         [0.9947],\n",
      "         [0.9954],\n",
      "         [0.9958],\n",
      "         [0.9961],\n",
      "         [0.9838],\n",
      "         [0.9952],\n",
      "         [0.9955],\n",
      "         [0.9817],\n",
      "         [0.3551],\n",
      "         [0.9945],\n",
      "         [0.9968],\n",
      "         [0.9975],\n",
      "         [0.9943],\n",
      "         [0.9981],\n",
      "         [0.2553],\n",
      "         [0.9992],\n",
      "         [0.9961],\n",
      "         [0.9961],\n",
      "         [0.0497],\n",
      "         [0.3400],\n",
      "         [0.9937],\n",
      "         [0.9917],\n",
      "         [0.9913],\n",
      "         [0.9905],\n",
      "         [0.9136],\n",
      "         [0.1988],\n",
      "         [0.5105],\n",
      "         [0.9858],\n",
      "         [0.5346],\n",
      "         [0.4588],\n",
      "         [0.3820],\n",
      "         [1.0006],\n",
      "         [0.9980],\n",
      "         [0.9977],\n",
      "         [0.0360],\n",
      "         [0.3597],\n",
      "         [0.9924],\n",
      "         [0.3613],\n",
      "         [0.9899],\n",
      "         [0.9911],\n",
      "         [0.9899],\n",
      "         [0.7643],\n",
      "         [0.6497],\n",
      "         [0.9922],\n",
      "         [0.7834],\n",
      "         [0.9961],\n",
      "         [0.9025],\n",
      "         [0.2537],\n",
      "         [0.9949],\n",
      "         [0.9939],\n",
      "         [0.9952],\n",
      "         [0.9937],\n",
      "         [0.3569],\n",
      "         [0.2337],\n",
      "         [0.3638],\n",
      "         [0.9925],\n",
      "         [0.4959],\n",
      "         [0.9612],\n",
      "         [0.9551],\n",
      "         [0.9931],\n",
      "         [0.9972],\n",
      "         [0.9985],\n",
      "         [0.9985],\n",
      "         [0.0346],\n",
      "         [0.9988]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.9009],\n",
      "        [0.0368],\n",
      "        [0.4645],\n",
      "        [0.8223],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9999],\n",
      "        [0.4480],\n",
      "        [0.1762],\n",
      "        [0.2518],\n",
      "        [0.9724],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.6628],\n",
      "        [0.9997],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.0000],\n",
      "        [0.5030],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.3753],\n",
      "        [0.2646],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.9804],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [0.7129],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.9996],\n",
      "        [0.3930],\n",
      "        [0.4668],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.8296],\n",
      "        [0.2686],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.9520],\n",
      "        [0.9998],\n",
      "        [0.0247],\n",
      "        [0.9997],\n",
      "        [0.4527],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.9998],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0142],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [0.8379],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.5139],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.3728],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.8933],\n",
      "        [0.2208],\n",
      "        [0.5108],\n",
      "        [0.9819],\n",
      "        [0.5245],\n",
      "        [0.4580],\n",
      "        [0.3875],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.0209],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.7391],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.9997],\n",
      "        [0.8761],\n",
      "        [0.2735],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.2547],\n",
      "        [0.3808],\n",
      "        [0.9994],\n",
      "        [0.4988],\n",
      "        [0.9515],\n",
      "        [0.9420],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0174],\n",
      "        [1.0000]])\n",
      "######### Epoch: 68  ######### Train Loss: 0.00013096279872115701  ######### Relative L2 Test Norm: 14.260395050048828\n",
      "Output batch pred: tensor([[[0.9492],\n",
      "         [0.9905],\n",
      "         [0.9918],\n",
      "         [0.9941],\n",
      "         [0.4500],\n",
      "         [0.9957],\n",
      "         [0.9973],\n",
      "         [0.4609],\n",
      "         [0.6108],\n",
      "         [0.9954],\n",
      "         [0.5060],\n",
      "         [0.0458],\n",
      "         [0.7383],\n",
      "         [0.9912],\n",
      "         [0.9898],\n",
      "         [0.9552],\n",
      "         [0.9918],\n",
      "         [0.7155],\n",
      "         [0.3489],\n",
      "         [0.9940],\n",
      "         [0.9208],\n",
      "         [0.9957],\n",
      "         [0.9966],\n",
      "         [0.4573],\n",
      "         [0.9986],\n",
      "         [0.9849],\n",
      "         [0.5085],\n",
      "         [0.9973],\n",
      "         [0.9962],\n",
      "         [0.9946],\n",
      "         [0.0334],\n",
      "         [0.9907],\n",
      "         [0.9157],\n",
      "         [0.3673],\n",
      "         [0.9839],\n",
      "         [0.4373],\n",
      "         [0.2325],\n",
      "         [0.9900],\n",
      "         [0.9921],\n",
      "         [0.9954],\n",
      "         [0.9959],\n",
      "         [0.3657],\n",
      "         [0.9855],\n",
      "         [0.9984],\n",
      "         [0.9983],\n",
      "         [0.0315],\n",
      "         [0.9958],\n",
      "         [0.3732],\n",
      "         [0.9954],\n",
      "         [0.9954],\n",
      "         [0.9945],\n",
      "         [0.9949],\n",
      "         [0.2309],\n",
      "         [0.9942],\n",
      "         [0.8573],\n",
      "         [0.9929],\n",
      "         [0.9909],\n",
      "         [0.4870],\n",
      "         [0.9754],\n",
      "         [0.9866],\n",
      "         [0.4902],\n",
      "         [0.5054],\n",
      "         [0.9868],\n",
      "         [0.9903],\n",
      "         [0.9902],\n",
      "         [0.2483],\n",
      "         [0.9956],\n",
      "         [0.4437],\n",
      "         [0.4482],\n",
      "         [0.5466],\n",
      "         [0.9996],\n",
      "         [0.9993],\n",
      "         [0.5351],\n",
      "         [0.9960],\n",
      "         [0.9961],\n",
      "         [0.9951],\n",
      "         [0.3389],\n",
      "         [0.6514],\n",
      "         [0.8434],\n",
      "         [0.9947],\n",
      "         [0.9607],\n",
      "         [0.9937],\n",
      "         [0.9976],\n",
      "         [0.9972],\n",
      "         [0.9878],\n",
      "         [1.0004],\n",
      "         [1.0016],\n",
      "         [0.5191],\n",
      "         [0.0409],\n",
      "         [0.9980],\n",
      "         [0.9979],\n",
      "         [0.9758],\n",
      "         [0.9940],\n",
      "         [0.9924],\n",
      "         [0.5111],\n",
      "         [0.0467],\n",
      "         [0.3691],\n",
      "         [0.3567],\n",
      "         [0.9926],\n",
      "         [0.9921],\n",
      "         [0.2415],\n",
      "         [0.8502],\n",
      "         [0.9576],\n",
      "         [0.3331],\n",
      "         [0.9911],\n",
      "         [0.9894],\n",
      "         [0.9913],\n",
      "         [0.4913],\n",
      "         [0.5080],\n",
      "         [0.9933],\n",
      "         [0.9933],\n",
      "         [0.4600],\n",
      "         [0.9942],\n",
      "         [0.9966],\n",
      "         [0.9944],\n",
      "         [0.2317],\n",
      "         [0.9920],\n",
      "         [0.9920],\n",
      "         [0.9889],\n",
      "         [0.0295],\n",
      "         [0.9883],\n",
      "         [0.0284],\n",
      "         [0.6783],\n",
      "         [0.9906],\n",
      "         [0.9922],\n",
      "         [0.9308],\n",
      "         [0.9953],\n",
      "         [0.9963],\n",
      "         [0.8681],\n",
      "         [0.6819],\n",
      "         [0.3730],\n",
      "         [0.9989],\n",
      "         [1.0010],\n",
      "         [0.9994],\n",
      "         [0.9991],\n",
      "         [0.9984],\n",
      "         [0.9993],\n",
      "         [0.9967],\n",
      "         [0.9936],\n",
      "         [0.9024],\n",
      "         [0.9948],\n",
      "         [0.9965],\n",
      "         [0.9956],\n",
      "         [0.9961],\n",
      "         [0.2565],\n",
      "         [0.9982],\n",
      "         [0.7720],\n",
      "         [0.9984],\n",
      "         [0.3600],\n",
      "         [0.1609],\n",
      "         [0.2498],\n",
      "         [0.9916],\n",
      "         [0.3565],\n",
      "         [0.7783],\n",
      "         [0.9922],\n",
      "         [0.9912],\n",
      "         [0.5491],\n",
      "         [0.4577],\n",
      "         [0.8144],\n",
      "         [0.2042],\n",
      "         [0.9964],\n",
      "         [0.9972],\n",
      "         [0.9188],\n",
      "         [0.9973],\n",
      "         [0.9975],\n",
      "         [0.2390],\n",
      "         [0.9976],\n",
      "         [0.0266],\n",
      "         [0.0525],\n",
      "         [0.4458],\n",
      "         [0.5021],\n",
      "         [0.9969],\n",
      "         [0.9956],\n",
      "         [0.9947],\n",
      "         [0.9935],\n",
      "         [0.9922],\n",
      "         [0.4277],\n",
      "         [0.9905]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9420],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [0.5945],\n",
      "        [0.9998],\n",
      "        [0.5080],\n",
      "        [0.0335],\n",
      "        [0.7129],\n",
      "        [0.9996],\n",
      "        [0.9996],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.3728],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.3930],\n",
      "        [0.9956],\n",
      "        [0.4552],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.3808],\n",
      "        [0.9804],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.9999],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.9819],\n",
      "        [0.9999],\n",
      "        [0.5038],\n",
      "        [0.5165],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [0.4503],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3575],\n",
      "        [0.6327],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [0.0288],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [0.9724],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5151],\n",
      "        [0.0368],\n",
      "        [0.3875],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.8223],\n",
      "        [0.9520],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.4668],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0142],\n",
      "        [0.9997],\n",
      "        [0.0174],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.6555],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.7391],\n",
      "        [0.9999],\n",
      "        [0.3753],\n",
      "        [0.1762],\n",
      "        [0.2729],\n",
      "        [0.9962],\n",
      "        [0.3780],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5463],\n",
      "        [0.4645],\n",
      "        [0.7820],\n",
      "        [0.2208],\n",
      "        [0.9995],\n",
      "        [0.9995],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.9999],\n",
      "        [0.0000],\n",
      "        [0.0383],\n",
      "        [0.4527],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [1.0000]])\n",
      "######### Epoch: 69  ######### Train Loss: 0.0001526723353890702  ######### Relative L2 Test Norm: 14.44659423828125\n",
      "Output batch pred: tensor([[[0.3636],\n",
      "         [0.4532],\n",
      "         [0.9337],\n",
      "         [0.9971],\n",
      "         [0.9983],\n",
      "         [1.0001],\n",
      "         [0.9662],\n",
      "         [1.0018],\n",
      "         [1.0022],\n",
      "         [1.0025],\n",
      "         [1.0020],\n",
      "         [1.0033],\n",
      "         [1.0017],\n",
      "         [0.9992],\n",
      "         [0.0434],\n",
      "         [0.9978],\n",
      "         [0.9967],\n",
      "         [0.2547],\n",
      "         [0.9944],\n",
      "         [0.9952],\n",
      "         [0.9953],\n",
      "         [0.5059],\n",
      "         [0.9955],\n",
      "         [0.4486],\n",
      "         [0.4610],\n",
      "         [0.9937],\n",
      "         [0.9909],\n",
      "         [0.5481],\n",
      "         [0.1559],\n",
      "         [0.9930],\n",
      "         [0.2385],\n",
      "         [0.9945],\n",
      "         [0.9957],\n",
      "         [0.0292],\n",
      "         [0.4426],\n",
      "         [0.0514],\n",
      "         [0.9975],\n",
      "         [0.9965],\n",
      "         [0.9952],\n",
      "         [0.2500],\n",
      "         [0.3569],\n",
      "         [0.4395],\n",
      "         [0.1958],\n",
      "         [0.9908],\n",
      "         [0.9893],\n",
      "         [0.9901],\n",
      "         [0.0311],\n",
      "         [0.9930],\n",
      "         [0.9189],\n",
      "         [0.9941],\n",
      "         [0.9578],\n",
      "         [0.9938],\n",
      "         [0.9912],\n",
      "         [0.9189],\n",
      "         [0.9914],\n",
      "         [0.9094],\n",
      "         [0.4919],\n",
      "         [0.5983],\n",
      "         [0.8348],\n",
      "         [0.9868],\n",
      "         [0.9853],\n",
      "         [0.9850],\n",
      "         [0.9868],\n",
      "         [0.9839],\n",
      "         [0.9867],\n",
      "         [0.8437],\n",
      "         [0.9905],\n",
      "         [0.0276],\n",
      "         [0.9930],\n",
      "         [0.9955],\n",
      "         [0.9986],\n",
      "         [0.9997],\n",
      "         [1.0007],\n",
      "         [0.7486],\n",
      "         [0.6936],\n",
      "         [0.5184],\n",
      "         [0.0506],\n",
      "         [0.9980],\n",
      "         [0.9952],\n",
      "         [0.9956],\n",
      "         [0.9962],\n",
      "         [0.9948],\n",
      "         [0.9840],\n",
      "         [0.9961],\n",
      "         [0.6785],\n",
      "         [0.8175],\n",
      "         [0.9998],\n",
      "         [0.3454],\n",
      "         [0.9887],\n",
      "         [0.3841],\n",
      "         [0.4636],\n",
      "         [0.7895],\n",
      "         [1.0004],\n",
      "         [0.9963],\n",
      "         [0.9982],\n",
      "         [0.9988],\n",
      "         [0.9978],\n",
      "         [0.9959],\n",
      "         [0.3520],\n",
      "         [0.4548],\n",
      "         [0.9933],\n",
      "         [0.8531],\n",
      "         [0.9894],\n",
      "         [0.3637],\n",
      "         [0.4989],\n",
      "         [0.6395],\n",
      "         [0.5056],\n",
      "         [0.2307],\n",
      "         [0.2351],\n",
      "         [0.4937],\n",
      "         [0.0393],\n",
      "         [0.9899],\n",
      "         [0.2444],\n",
      "         [0.9942],\n",
      "         [0.9970],\n",
      "         [0.4537],\n",
      "         [0.9957],\n",
      "         [0.4394],\n",
      "         [0.5052],\n",
      "         [0.9910],\n",
      "         [0.4330],\n",
      "         [0.9917],\n",
      "         [0.9919],\n",
      "         [0.9794],\n",
      "         [0.5156],\n",
      "         [0.9954],\n",
      "         [0.3777],\n",
      "         [0.9962],\n",
      "         [0.9961],\n",
      "         [0.8656],\n",
      "         [0.9938],\n",
      "         [0.9921],\n",
      "         [0.9888],\n",
      "         [0.9885],\n",
      "         [0.8920],\n",
      "         [0.9851],\n",
      "         [0.0135],\n",
      "         [0.9888],\n",
      "         [0.9925],\n",
      "         [0.9947],\n",
      "         [0.9981],\n",
      "         [0.9662],\n",
      "         [1.0015],\n",
      "         [0.5050],\n",
      "         [0.7281],\n",
      "         [0.9985],\n",
      "         [0.3700],\n",
      "         [0.9936],\n",
      "         [0.5211],\n",
      "         [0.2225],\n",
      "         [0.3453],\n",
      "         [0.9834],\n",
      "         [0.9838],\n",
      "         [0.9867],\n",
      "         [0.9896],\n",
      "         [0.9906],\n",
      "         [0.9933],\n",
      "         [0.3608],\n",
      "         [0.5442],\n",
      "         [0.9999],\n",
      "         [0.9987],\n",
      "         [0.9997],\n",
      "         [0.9578],\n",
      "         [0.9971],\n",
      "         [0.9962],\n",
      "         [0.9926],\n",
      "         [0.3328],\n",
      "         [0.9918],\n",
      "         [0.4939],\n",
      "         [0.9908],\n",
      "         [0.9928],\n",
      "         [0.9729],\n",
      "         [0.7650],\n",
      "         [0.9794],\n",
      "         [0.9932],\n",
      "         [0.0229],\n",
      "         [0.9920],\n",
      "         [0.2524]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.3808],\n",
      "        [0.4611],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.4668],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.0142],\n",
      "        [0.4503],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.3753],\n",
      "        [0.4527],\n",
      "        [0.2208],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0335],\n",
      "        [0.9999],\n",
      "        [0.9009],\n",
      "        [0.9999],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.5038],\n",
      "        [0.5945],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.9997],\n",
      "        [0.0288],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.7129],\n",
      "        [0.6628],\n",
      "        [0.5139],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [0.9819],\n",
      "        [0.3930],\n",
      "        [0.4645],\n",
      "        [0.7540],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.3728],\n",
      "        [0.4642],\n",
      "        [0.9997],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.5108],\n",
      "        [0.6327],\n",
      "        [0.5165],\n",
      "        [0.2547],\n",
      "        [0.2577],\n",
      "        [0.5009],\n",
      "        [0.0209],\n",
      "        [0.9956],\n",
      "        [0.2610],\n",
      "        [0.9967],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.6920],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.2518],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9995],\n",
      "        [0.3780],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9966],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [0.7391],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.9998],\n",
      "        [0.2735]])\n",
      "######### Epoch: 70  ######### Train Loss: 0.00016246650193352252  ######### Relative L2 Test Norm: 14.366520881652832\n",
      "Output batch pred: tensor([[[0.5430],\n",
      "         [0.9987],\n",
      "         [0.9977],\n",
      "         [0.5298],\n",
      "         [0.9962],\n",
      "         [0.9943],\n",
      "         [0.9596],\n",
      "         [0.9943],\n",
      "         [0.9941],\n",
      "         [0.8408],\n",
      "         [0.3702],\n",
      "         [0.9922],\n",
      "         [0.9102],\n",
      "         [0.3336],\n",
      "         [0.3485],\n",
      "         [0.9920],\n",
      "         [0.2323],\n",
      "         [0.9918],\n",
      "         [0.9206],\n",
      "         [0.9962],\n",
      "         [0.9926],\n",
      "         [0.8669],\n",
      "         [0.0320],\n",
      "         [0.9971],\n",
      "         [0.9957],\n",
      "         [0.4980],\n",
      "         [0.0166],\n",
      "         [0.9923],\n",
      "         [0.4942],\n",
      "         [0.9912],\n",
      "         [0.9913],\n",
      "         [0.2404],\n",
      "         [0.3520],\n",
      "         [0.9933],\n",
      "         [0.4406],\n",
      "         [0.5110],\n",
      "         [0.5082],\n",
      "         [0.9942],\n",
      "         [0.4590],\n",
      "         [0.3632],\n",
      "         [0.9925],\n",
      "         [0.9565],\n",
      "         [0.9932],\n",
      "         [0.3667],\n",
      "         [0.9936],\n",
      "         [0.9959],\n",
      "         [0.4358],\n",
      "         [0.9968],\n",
      "         [0.9855],\n",
      "         [0.9997],\n",
      "         [0.9994],\n",
      "         [0.4978],\n",
      "         [0.9958],\n",
      "         [0.9814],\n",
      "         [0.9906],\n",
      "         [0.9884],\n",
      "         [0.9853],\n",
      "         [0.0228],\n",
      "         [0.5349],\n",
      "         [0.9867],\n",
      "         [0.9878],\n",
      "         [0.6433],\n",
      "         [0.9908],\n",
      "         [0.9927],\n",
      "         [0.9536],\n",
      "         [0.9948],\n",
      "         [0.4547],\n",
      "         [0.4601],\n",
      "         [0.3599],\n",
      "         [0.9981],\n",
      "         [0.9991],\n",
      "         [0.9662],\n",
      "         [1.0013],\n",
      "         [0.9893],\n",
      "         [0.2410],\n",
      "         [0.4498],\n",
      "         [0.3472],\n",
      "         [0.2591],\n",
      "         [0.9960],\n",
      "         [0.9955],\n",
      "         [0.9312],\n",
      "         [0.7637],\n",
      "         [0.9917],\n",
      "         [0.2435],\n",
      "         [0.9916],\n",
      "         [0.9925],\n",
      "         [0.5055],\n",
      "         [0.8550],\n",
      "         [0.9994],\n",
      "         [0.9986],\n",
      "         [1.0006],\n",
      "         [1.0009],\n",
      "         [0.9994],\n",
      "         [0.9981],\n",
      "         [0.9987],\n",
      "         [0.4503],\n",
      "         [0.8139],\n",
      "         [0.9953],\n",
      "         [0.9928],\n",
      "         [0.3603],\n",
      "         [0.0524],\n",
      "         [0.9908],\n",
      "         [0.0484],\n",
      "         [0.9894],\n",
      "         [0.2028],\n",
      "         [0.9905],\n",
      "         [0.3739],\n",
      "         [0.0316],\n",
      "         [0.9920],\n",
      "         [0.9924],\n",
      "         [0.9938],\n",
      "         [0.5073],\n",
      "         [0.2399],\n",
      "         [0.9997],\n",
      "         [0.9984],\n",
      "         [0.9959],\n",
      "         [0.9981],\n",
      "         [0.9028],\n",
      "         [0.9951],\n",
      "         [0.9903],\n",
      "         [0.9916],\n",
      "         [0.9882],\n",
      "         [0.9901],\n",
      "         [0.9896],\n",
      "         [0.9162],\n",
      "         [0.4327],\n",
      "         [0.3638],\n",
      "         [0.9780],\n",
      "         [0.0298],\n",
      "         [0.9891],\n",
      "         [0.0435],\n",
      "         [0.9891],\n",
      "         [0.9701],\n",
      "         [0.2327],\n",
      "         [0.9904],\n",
      "         [0.9893],\n",
      "         [0.7378],\n",
      "         [0.9933],\n",
      "         [0.9950],\n",
      "         [0.0276],\n",
      "         [0.9967],\n",
      "         [0.9991],\n",
      "         [1.0005],\n",
      "         [0.9998],\n",
      "         [1.0003],\n",
      "         [0.9999],\n",
      "         [0.6152],\n",
      "         [0.9986],\n",
      "         [0.9962],\n",
      "         [0.9968],\n",
      "         [0.1567],\n",
      "         [0.9950],\n",
      "         [0.9943],\n",
      "         [0.9936],\n",
      "         [0.9919],\n",
      "         [0.6845],\n",
      "         [0.5132],\n",
      "         [0.9938],\n",
      "         [0.9947],\n",
      "         [0.9940],\n",
      "         [0.4448],\n",
      "         [0.9951],\n",
      "         [0.9958],\n",
      "         [0.9956],\n",
      "         [0.5133],\n",
      "         [0.9931],\n",
      "         [0.9935],\n",
      "         [0.8554],\n",
      "         [0.9937],\n",
      "         [0.2312],\n",
      "         [0.7174],\n",
      "         [0.4972],\n",
      "         [0.9955],\n",
      "         [0.9984],\n",
      "         [0.6794],\n",
      "         [0.9980],\n",
      "         [0.7867],\n",
      "         [0.4628]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.5334],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [0.3912],\n",
      "        [0.9996],\n",
      "        [0.8933],\n",
      "        [0.3575],\n",
      "        [0.3728],\n",
      "        [0.9998],\n",
      "        [0.2610],\n",
      "        [0.9967],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [0.8379],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.3747],\n",
      "        [0.9997],\n",
      "        [0.4527],\n",
      "        [0.5139],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.9999],\n",
      "        [0.3875],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4454],\n",
      "        [0.9996],\n",
      "        [0.9814],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.4642],\n",
      "        [0.3753],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.2518],\n",
      "        [0.4503],\n",
      "        [0.3573],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5080],\n",
      "        [0.8223],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.3780],\n",
      "        [0.0368],\n",
      "        [0.9999],\n",
      "        [0.0288],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.2577],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9044],\n",
      "        [0.4480],\n",
      "        [0.3840],\n",
      "        [0.9804],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.5945],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.6628],\n",
      "        [0.5165],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [0.2547],\n",
      "        [0.6920],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.4645]])\n",
      "######### Epoch: 71  ######### Train Loss: 0.0001541155797895044  ######### Relative L2 Test Norm: 14.313594818115234\n",
      "Output batch pred: tensor([[[0.0438],\n",
      "         [0.5059],\n",
      "         [0.9959],\n",
      "         [0.9971],\n",
      "         [0.9950],\n",
      "         [0.9956],\n",
      "         [0.9936],\n",
      "         [0.2214],\n",
      "         [0.9911],\n",
      "         [0.9902],\n",
      "         [0.0437],\n",
      "         [0.9911],\n",
      "         [0.9943],\n",
      "         [0.3653],\n",
      "         [0.9981],\n",
      "         [0.5129],\n",
      "         [0.0480],\n",
      "         [1.0013],\n",
      "         [0.5027],\n",
      "         [0.0539],\n",
      "         [0.9993],\n",
      "         [0.9981],\n",
      "         [0.9955],\n",
      "         [0.8124],\n",
      "         [0.9931],\n",
      "         [0.3673],\n",
      "         [0.4304],\n",
      "         [0.9561],\n",
      "         [0.9915],\n",
      "         [0.9907],\n",
      "         [0.9915],\n",
      "         [0.4499],\n",
      "         [0.9955],\n",
      "         [0.9936],\n",
      "         [0.9992],\n",
      "         [1.0012],\n",
      "         [0.9992],\n",
      "         [0.9668],\n",
      "         [0.5487],\n",
      "         [1.0007],\n",
      "         [0.5565],\n",
      "         [0.9951],\n",
      "         [0.9934],\n",
      "         [0.8409],\n",
      "         [0.9918],\n",
      "         [0.6017],\n",
      "         [0.2278],\n",
      "         [0.3588],\n",
      "         [0.8980],\n",
      "         [0.4562],\n",
      "         [0.2017],\n",
      "         [0.9947],\n",
      "         [0.6779],\n",
      "         [0.9959],\n",
      "         [0.4428],\n",
      "         [0.2382],\n",
      "         [0.9925],\n",
      "         [0.9896],\n",
      "         [0.9899],\n",
      "         [0.8517],\n",
      "         [0.9888],\n",
      "         [0.9712],\n",
      "         [0.9914],\n",
      "         [0.9947],\n",
      "         [0.8510],\n",
      "         [0.9954],\n",
      "         [0.3404],\n",
      "         [0.5129],\n",
      "         [0.6919],\n",
      "         [0.9998],\n",
      "         [0.9993],\n",
      "         [0.0322],\n",
      "         [0.9959],\n",
      "         [0.9958],\n",
      "         [0.5097],\n",
      "         [0.9927],\n",
      "         [0.9895],\n",
      "         [0.3692],\n",
      "         [0.8569],\n",
      "         [0.0317],\n",
      "         [0.9769],\n",
      "         [0.9904],\n",
      "         [0.9189],\n",
      "         [0.9948],\n",
      "         [0.9956],\n",
      "         [0.9979],\n",
      "         [0.9988],\n",
      "         [0.9985],\n",
      "         [0.9987],\n",
      "         [0.4587],\n",
      "         [0.9971],\n",
      "         [0.5010],\n",
      "         [0.9536],\n",
      "         [0.9933],\n",
      "         [0.9956],\n",
      "         [0.9956],\n",
      "         [0.2417],\n",
      "         [0.9970],\n",
      "         [0.9961],\n",
      "         [0.4439],\n",
      "         [0.9951],\n",
      "         [0.2372],\n",
      "         [0.4343],\n",
      "         [0.5205],\n",
      "         [0.9894],\n",
      "         [0.3584],\n",
      "         [0.9871],\n",
      "         [0.4881],\n",
      "         [0.9901],\n",
      "         [0.2477],\n",
      "         [0.2508],\n",
      "         [0.9971],\n",
      "         [0.9995],\n",
      "         [1.0006],\n",
      "         [1.0013],\n",
      "         [1.0019],\n",
      "         [1.0013],\n",
      "         [1.0017],\n",
      "         [0.2476],\n",
      "         [0.9995],\n",
      "         [0.9977],\n",
      "         [0.9969],\n",
      "         [0.9834],\n",
      "         [0.7416],\n",
      "         [0.9833],\n",
      "         [0.9956],\n",
      "         [0.3575],\n",
      "         [0.9226],\n",
      "         [0.9953],\n",
      "         [0.9945],\n",
      "         [0.3545],\n",
      "         [0.5106],\n",
      "         [0.9896],\n",
      "         [0.0151],\n",
      "         [0.9873],\n",
      "         [0.9861],\n",
      "         [0.9526],\n",
      "         [0.3454],\n",
      "         [0.9912],\n",
      "         [0.4981],\n",
      "         [0.9823],\n",
      "         [0.9986],\n",
      "         [0.7903],\n",
      "         [0.1727],\n",
      "         [0.6636],\n",
      "         [1.0033],\n",
      "         [0.9405],\n",
      "         [1.0008],\n",
      "         [0.0452],\n",
      "         [0.9966],\n",
      "         [0.4557],\n",
      "         [0.9912],\n",
      "         [0.7117],\n",
      "         [0.9094],\n",
      "         [0.9897],\n",
      "         [0.9899],\n",
      "         [0.9911],\n",
      "         [0.3693],\n",
      "         [0.9933],\n",
      "         [0.9930],\n",
      "         [0.9958],\n",
      "         [0.9967],\n",
      "         [0.7712],\n",
      "         [0.9977],\n",
      "         [0.4513],\n",
      "         [0.4558],\n",
      "         [1.0012],\n",
      "         [0.9978],\n",
      "         [1.0010],\n",
      "         [0.3410],\n",
      "         [0.9977],\n",
      "         [0.9971],\n",
      "         [0.9950],\n",
      "         [0.9948],\n",
      "         [0.9928],\n",
      "         [0.5099],\n",
      "         [0.9927],\n",
      "         [0.0202]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.0288],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.0383],\n",
      "        [0.9966],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.5080],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [0.4988],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.4454],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.9490],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.2547],\n",
      "        [0.3808],\n",
      "        [0.8761],\n",
      "        [0.4642],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.9998],\n",
      "        [0.4527],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.8223],\n",
      "        [0.9967],\n",
      "        [0.3573],\n",
      "        [0.5108],\n",
      "        [0.6628],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.3930],\n",
      "        [0.8379],\n",
      "        [0.0247],\n",
      "        [0.9804],\n",
      "        [0.9997],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.9998],\n",
      "        [0.5038],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [0.4503],\n",
      "        [0.9999],\n",
      "        [0.2577],\n",
      "        [0.4480],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.7129],\n",
      "        [0.9819],\n",
      "        [0.9999],\n",
      "        [0.3753],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9515],\n",
      "        [0.3728],\n",
      "        [0.9997],\n",
      "        [0.5030],\n",
      "        [0.9814],\n",
      "        [0.9998],\n",
      "        [0.7540],\n",
      "        [0.1762],\n",
      "        [0.6327],\n",
      "        [0.9999],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.8933],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.0000]])\n",
      "######### Epoch: 72  ######### Train Loss: 0.00016136153135448694  ######### Relative L2 Test Norm: 14.572982788085938\n",
      "Output batch pred: tensor([[[0.9934],\n",
      "         [0.5121],\n",
      "         [0.0464],\n",
      "         [0.9913],\n",
      "         [0.9931],\n",
      "         [0.1601],\n",
      "         [0.9940],\n",
      "         [0.9944],\n",
      "         [0.9916],\n",
      "         [0.4351],\n",
      "         [0.9942],\n",
      "         [0.5490],\n",
      "         [0.9956],\n",
      "         [0.9967],\n",
      "         [0.8673],\n",
      "         [0.9972],\n",
      "         [0.9810],\n",
      "         [1.0016],\n",
      "         [0.3871],\n",
      "         [0.7785],\n",
      "         [0.8530],\n",
      "         [0.9398],\n",
      "         [1.0004],\n",
      "         [0.9978],\n",
      "         [0.9971],\n",
      "         [0.9945],\n",
      "         [0.9954],\n",
      "         [0.9936],\n",
      "         [0.0301],\n",
      "         [0.0357],\n",
      "         [0.9927],\n",
      "         [0.9938],\n",
      "         [0.9952],\n",
      "         [0.9941],\n",
      "         [0.5402],\n",
      "         [0.3572],\n",
      "         [0.9844],\n",
      "         [0.2030],\n",
      "         [0.5130],\n",
      "         [0.9983],\n",
      "         [0.9977],\n",
      "         [0.6901],\n",
      "         [0.9986],\n",
      "         [0.7430],\n",
      "         [0.3667],\n",
      "         [0.9844],\n",
      "         [0.9608],\n",
      "         [0.9955],\n",
      "         [0.0434],\n",
      "         [0.9988],\n",
      "         [0.7873],\n",
      "         [0.2453],\n",
      "         [0.3811],\n",
      "         [1.0007],\n",
      "         [0.7269],\n",
      "         [0.9966],\n",
      "         [0.9039],\n",
      "         [0.9617],\n",
      "         [0.4450],\n",
      "         [0.9920],\n",
      "         [0.4960],\n",
      "         [0.9470],\n",
      "         [0.9874],\n",
      "         [0.9902],\n",
      "         [0.9913],\n",
      "         [0.9914],\n",
      "         [0.3342],\n",
      "         [0.9944],\n",
      "         [0.9958],\n",
      "         [0.3597],\n",
      "         [0.0429],\n",
      "         [0.9972],\n",
      "         [0.8539],\n",
      "         [0.2386],\n",
      "         [0.9975],\n",
      "         [0.9852],\n",
      "         [0.9189],\n",
      "         [0.9979],\n",
      "         [0.9622],\n",
      "         [0.3621],\n",
      "         [0.2494],\n",
      "         [0.4371],\n",
      "         [0.9939],\n",
      "         [0.4909],\n",
      "         [0.8095],\n",
      "         [0.4982],\n",
      "         [0.9938],\n",
      "         [0.2452],\n",
      "         [0.9968],\n",
      "         [0.9990],\n",
      "         [1.0000],\n",
      "         [1.0003],\n",
      "         [0.0181],\n",
      "         [0.9993],\n",
      "         [0.9977],\n",
      "         [0.9990],\n",
      "         [0.9981],\n",
      "         [0.9997],\n",
      "         [0.9992],\n",
      "         [1.0022],\n",
      "         [0.5118],\n",
      "         [0.3462],\n",
      "         [0.9322],\n",
      "         [1.0013],\n",
      "         [1.0017],\n",
      "         [0.9996],\n",
      "         [0.4523],\n",
      "         [0.5079],\n",
      "         [0.9902],\n",
      "         [0.9884],\n",
      "         [0.4846],\n",
      "         [0.9869],\n",
      "         [0.2398],\n",
      "         [0.9895],\n",
      "         [0.4528],\n",
      "         [0.8552],\n",
      "         [0.2332],\n",
      "         [0.9956],\n",
      "         [0.4508],\n",
      "         [0.9971],\n",
      "         [0.3651],\n",
      "         [0.9999],\n",
      "         [0.3651],\n",
      "         [0.0366],\n",
      "         [0.9999],\n",
      "         [0.9992],\n",
      "         [0.5203],\n",
      "         [0.9966],\n",
      "         [0.6120],\n",
      "         [0.9970],\n",
      "         [0.4371],\n",
      "         [0.9952],\n",
      "         [0.9929],\n",
      "         [0.4564],\n",
      "         [0.4547],\n",
      "         [0.9922],\n",
      "         [0.9917],\n",
      "         [0.9910],\n",
      "         [0.2401],\n",
      "         [0.9924],\n",
      "         [0.0284],\n",
      "         [0.9912],\n",
      "         [0.9920],\n",
      "         [0.9930],\n",
      "         [0.9952],\n",
      "         [0.5311],\n",
      "         [0.4464],\n",
      "         [0.9959],\n",
      "         [0.9965],\n",
      "         [0.9973],\n",
      "         [0.9966],\n",
      "         [0.9210],\n",
      "         [0.9949],\n",
      "         [0.9936],\n",
      "         [0.9926],\n",
      "         [0.0485],\n",
      "         [0.4981],\n",
      "         [0.2320],\n",
      "         [0.9928],\n",
      "         [0.9947],\n",
      "         [0.9950],\n",
      "         [0.6790],\n",
      "         [0.9967],\n",
      "         [0.9945],\n",
      "         [0.6547],\n",
      "         [0.9962],\n",
      "         [0.9954],\n",
      "         [0.9945],\n",
      "         [0.3758],\n",
      "         [0.9968],\n",
      "         [0.9937],\n",
      "         [0.9973],\n",
      "         [0.9843],\n",
      "         [0.9984],\n",
      "         [0.9982],\n",
      "         [0.9964],\n",
      "         [0.9955],\n",
      "         [0.9959]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.5165],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9962],\n",
      "        [0.4480],\n",
      "        [0.9998],\n",
      "        [0.5463],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9967],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.7391],\n",
      "        [0.8139],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0142],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.3728],\n",
      "        [0.9819],\n",
      "        [0.2208],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.3840],\n",
      "        [0.9820],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.2577],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.9956],\n",
      "        [0.8761],\n",
      "        [0.9515],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9420],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.8933],\n",
      "        [0.9999],\n",
      "        [0.9490],\n",
      "        [0.3808],\n",
      "        [0.2735],\n",
      "        [0.4503],\n",
      "        [0.9997],\n",
      "        [0.4988],\n",
      "        [0.7820],\n",
      "        [0.5030],\n",
      "        [0.9996],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5054],\n",
      "        [0.3573],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.8296],\n",
      "        [0.2547],\n",
      "        [0.9995],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.9996],\n",
      "        [0.4454],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [0.4642],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.9999],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.5038],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9997],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9995],\n",
      "        [0.9997]])\n",
      "######### Epoch: 73  ######### Train Loss: 0.0001622670388314873  ######### Relative L2 Test Norm: 14.259900093078613\n",
      "Output batch pred: tensor([[[0.9939],\n",
      "         [0.9807],\n",
      "         [0.9967],\n",
      "         [0.9959],\n",
      "         [0.9974],\n",
      "         [0.9979],\n",
      "         [0.9973],\n",
      "         [0.9949],\n",
      "         [0.9971],\n",
      "         [0.9955],\n",
      "         [0.9954],\n",
      "         [0.9952],\n",
      "         [0.9904],\n",
      "         [0.9938],\n",
      "         [0.5051],\n",
      "         [0.9916],\n",
      "         [0.9895],\n",
      "         [0.9905],\n",
      "         [0.9904],\n",
      "         [0.9278],\n",
      "         [0.8534],\n",
      "         [0.3660],\n",
      "         [0.9927],\n",
      "         [0.9925],\n",
      "         [0.7713],\n",
      "         [0.9963],\n",
      "         [0.9980],\n",
      "         [0.9978],\n",
      "         [0.4545],\n",
      "         [0.9990],\n",
      "         [0.9988],\n",
      "         [0.9994],\n",
      "         [0.9995],\n",
      "         [0.9992],\n",
      "         [0.5222],\n",
      "         [0.4635],\n",
      "         [0.9961],\n",
      "         [0.9959],\n",
      "         [0.3753],\n",
      "         [0.7820],\n",
      "         [0.9917],\n",
      "         [0.9581],\n",
      "         [0.9939],\n",
      "         [0.3413],\n",
      "         [0.9968],\n",
      "         [0.7461],\n",
      "         [0.9988],\n",
      "         [0.9999],\n",
      "         [1.0021],\n",
      "         [1.0003],\n",
      "         [1.0018],\n",
      "         [0.2036],\n",
      "         [0.9999],\n",
      "         [0.9984],\n",
      "         [0.5148],\n",
      "         [0.6531],\n",
      "         [0.9930],\n",
      "         [0.9953],\n",
      "         [0.9951],\n",
      "         [0.2342],\n",
      "         [0.9937],\n",
      "         [0.9827],\n",
      "         [0.9930],\n",
      "         [0.4368],\n",
      "         [0.9936],\n",
      "         [0.9921],\n",
      "         [0.0169],\n",
      "         [0.6860],\n",
      "         [0.9966],\n",
      "         [0.9258],\n",
      "         [0.9891],\n",
      "         [0.6878],\n",
      "         [0.0334],\n",
      "         [1.0027],\n",
      "         [1.0057],\n",
      "         [1.0025],\n",
      "         [0.3636],\n",
      "         [1.0004],\n",
      "         [0.9971],\n",
      "         [0.4555],\n",
      "         [0.9925],\n",
      "         [0.3723],\n",
      "         [0.9927],\n",
      "         [0.9956],\n",
      "         [0.9972],\n",
      "         [0.9982],\n",
      "         [0.0440],\n",
      "         [0.5014],\n",
      "         [0.9997],\n",
      "         [0.4578],\n",
      "         [0.0560],\n",
      "         [0.8559],\n",
      "         [1.0010],\n",
      "         [0.3818],\n",
      "         [0.5067],\n",
      "         [0.3689],\n",
      "         [1.0016],\n",
      "         [0.5451],\n",
      "         [0.9657],\n",
      "         [1.0001],\n",
      "         [0.5031],\n",
      "         [0.9989],\n",
      "         [0.9978],\n",
      "         [0.9555],\n",
      "         [0.9971],\n",
      "         [0.9961],\n",
      "         [0.4383],\n",
      "         [0.5523],\n",
      "         [0.4992],\n",
      "         [0.3618],\n",
      "         [0.3660],\n",
      "         [1.0032],\n",
      "         [0.0395],\n",
      "         [1.0003],\n",
      "         [0.2373],\n",
      "         [0.9986],\n",
      "         [0.9986],\n",
      "         [0.2479],\n",
      "         [0.5140],\n",
      "         [0.9954],\n",
      "         [0.3359],\n",
      "         [0.5039],\n",
      "         [0.9956],\n",
      "         [0.9958],\n",
      "         [0.4611],\n",
      "         [0.9957],\n",
      "         [0.4383],\n",
      "         [0.0466],\n",
      "         [0.8469],\n",
      "         [0.2498],\n",
      "         [0.9984],\n",
      "         [0.8674],\n",
      "         [0.3612],\n",
      "         [0.9967],\n",
      "         [0.4450],\n",
      "         [0.2450],\n",
      "         [0.9633],\n",
      "         [0.9857],\n",
      "         [0.4561],\n",
      "         [0.2467],\n",
      "         [0.9988],\n",
      "         [0.7269],\n",
      "         [1.0008],\n",
      "         [1.0011],\n",
      "         [0.9988],\n",
      "         [0.9990],\n",
      "         [0.9967],\n",
      "         [0.1619],\n",
      "         [0.9925],\n",
      "         [0.2291],\n",
      "         [0.6031],\n",
      "         [0.9899],\n",
      "         [0.9104],\n",
      "         [0.5233],\n",
      "         [0.9923],\n",
      "         [0.8990],\n",
      "         [0.9940],\n",
      "         [0.9939],\n",
      "         [0.9943],\n",
      "         [0.9961],\n",
      "         [0.9246],\n",
      "         [0.9958],\n",
      "         [0.9970],\n",
      "         [0.2558],\n",
      "         [0.9979],\n",
      "         [0.9777],\n",
      "         [0.8171],\n",
      "         [0.9974],\n",
      "         [0.9966],\n",
      "         [0.5008],\n",
      "         [0.9924],\n",
      "         [0.9924],\n",
      "         [0.0398],\n",
      "         [0.0315],\n",
      "         [0.9885],\n",
      "         [0.9873],\n",
      "         [0.0417],\n",
      "         [0.9893]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9164],\n",
      "        [0.8296],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.7540],\n",
      "        [0.9997],\n",
      "        [0.9520],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5139],\n",
      "        [0.6327],\n",
      "        [0.9962],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.9996],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.0000],\n",
      "        [0.6628],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [0.9804],\n",
      "        [0.6555],\n",
      "        [0.0142],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0209],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.0383],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.5038],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [0.5463],\n",
      "        [0.4988],\n",
      "        [0.3728],\n",
      "        [0.3747],\n",
      "        [0.9997],\n",
      "        [0.0174],\n",
      "        [0.9966],\n",
      "        [0.2547],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.5080],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.0288],\n",
      "        [0.8139],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.2646],\n",
      "        [0.9515],\n",
      "        [0.9820],\n",
      "        [0.4580],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.5945],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.9996],\n",
      "        [0.9044],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0368],\n",
      "        [0.0247],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000]])\n",
      "######### Epoch: 74  ######### Train Loss: 0.00014415931946132332  ######### Relative L2 Test Norm: 14.049111366271973\n",
      "Output batch pred: tensor([[[1.0006],\n",
      "         [1.0015],\n",
      "         [0.3485],\n",
      "         [1.0018],\n",
      "         [0.5096],\n",
      "         [1.0012],\n",
      "         [0.9999],\n",
      "         [0.9992],\n",
      "         [0.9982],\n",
      "         [0.9977],\n",
      "         [0.9958],\n",
      "         [0.9970],\n",
      "         [0.9163],\n",
      "         [0.9962],\n",
      "         [0.9970],\n",
      "         [0.4989],\n",
      "         [0.0348],\n",
      "         [0.9952],\n",
      "         [0.8529],\n",
      "         [0.9977],\n",
      "         [0.9983],\n",
      "         [0.2532],\n",
      "         [0.9971],\n",
      "         [1.0007],\n",
      "         [0.8243],\n",
      "         [1.0039],\n",
      "         [1.0049],\n",
      "         [1.0047],\n",
      "         [1.0035],\n",
      "         [1.0035],\n",
      "         [0.9877],\n",
      "         [0.5000],\n",
      "         [0.4499],\n",
      "         [0.9967],\n",
      "         [0.5151],\n",
      "         [0.2415],\n",
      "         [0.9973],\n",
      "         [0.0423],\n",
      "         [0.5142],\n",
      "         [0.9277],\n",
      "         [1.0007],\n",
      "         [0.9979],\n",
      "         [0.5190],\n",
      "         [0.9972],\n",
      "         [0.9950],\n",
      "         [0.4957],\n",
      "         [0.0442],\n",
      "         [0.1584],\n",
      "         [0.9811],\n",
      "         [0.9954],\n",
      "         [0.3814],\n",
      "         [0.9980],\n",
      "         [1.0020],\n",
      "         [0.9613],\n",
      "         [0.2474],\n",
      "         [0.9999],\n",
      "         [0.9976],\n",
      "         [0.4528],\n",
      "         [0.9914],\n",
      "         [0.3276],\n",
      "         [0.4899],\n",
      "         [0.4368],\n",
      "         [0.9872],\n",
      "         [0.9747],\n",
      "         [0.3515],\n",
      "         [0.6826],\n",
      "         [0.9938],\n",
      "         [0.0414],\n",
      "         [0.9972],\n",
      "         [0.9985],\n",
      "         [0.7238],\n",
      "         [0.4615],\n",
      "         [0.9986],\n",
      "         [0.4488],\n",
      "         [0.9980],\n",
      "         [0.9991],\n",
      "         [0.9994],\n",
      "         [0.3746],\n",
      "         [0.9977],\n",
      "         [0.9983],\n",
      "         [0.9613],\n",
      "         [0.9962],\n",
      "         [0.3735],\n",
      "         [0.9964],\n",
      "         [0.9955],\n",
      "         [0.9980],\n",
      "         [0.8612],\n",
      "         [0.5447],\n",
      "         [0.7883],\n",
      "         [0.7756],\n",
      "         [0.0454],\n",
      "         [1.0002],\n",
      "         [0.9983],\n",
      "         [0.9638],\n",
      "         [0.9963],\n",
      "         [0.9956],\n",
      "         [0.9951],\n",
      "         [0.9963],\n",
      "         [0.9972],\n",
      "         [0.2398],\n",
      "         [0.9963],\n",
      "         [0.6554],\n",
      "         [0.9989],\n",
      "         [0.3707],\n",
      "         [0.4422],\n",
      "         [0.5222],\n",
      "         [0.8492],\n",
      "         [1.0000],\n",
      "         [0.9985],\n",
      "         [0.9980],\n",
      "         [0.4584],\n",
      "         [0.9990],\n",
      "         [0.3633],\n",
      "         [0.9979],\n",
      "         [0.9987],\n",
      "         [0.3683],\n",
      "         [0.4477],\n",
      "         [0.9969],\n",
      "         [0.3740],\n",
      "         [0.9842],\n",
      "         [0.9954],\n",
      "         [0.9963],\n",
      "         [0.5518],\n",
      "         [0.2467],\n",
      "         [0.9965],\n",
      "         [0.2297],\n",
      "         [0.9941],\n",
      "         [0.9958],\n",
      "         [0.9982],\n",
      "         [0.7472],\n",
      "         [0.6180],\n",
      "         [0.5214],\n",
      "         [1.0026],\n",
      "         [0.2136],\n",
      "         [1.0043],\n",
      "         [1.0042],\n",
      "         [1.0040],\n",
      "         [0.2599],\n",
      "         [0.9966],\n",
      "         [0.9989],\n",
      "         [0.9971],\n",
      "         [0.9945],\n",
      "         [0.9956],\n",
      "         [0.0425],\n",
      "         [0.0277],\n",
      "         [0.9974],\n",
      "         [0.9993],\n",
      "         [0.9990],\n",
      "         [1.0012],\n",
      "         [1.0014],\n",
      "         [0.9276],\n",
      "         [1.0002],\n",
      "         [0.9976],\n",
      "         [0.9962],\n",
      "         [0.0336],\n",
      "         [0.9336],\n",
      "         [0.8654],\n",
      "         [0.9967],\n",
      "         [0.9973],\n",
      "         [0.9053],\n",
      "         [0.9979],\n",
      "         [0.9999],\n",
      "         [0.4678],\n",
      "         [1.0003],\n",
      "         [0.9992],\n",
      "         [0.9623],\n",
      "         [0.9942],\n",
      "         [0.2351],\n",
      "         [0.4329],\n",
      "         [0.3498],\n",
      "         [0.6667],\n",
      "         [0.5201],\n",
      "         [0.9883],\n",
      "         [0.0434],\n",
      "         [0.9904],\n",
      "         [0.9756],\n",
      "         [0.9975],\n",
      "         [0.9991]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9994],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.4988],\n",
      "        [0.4552],\n",
      "        [0.9998],\n",
      "        [0.5139],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.5080],\n",
      "        [0.9044],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5030],\n",
      "        [0.0368],\n",
      "        [0.1762],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9967],\n",
      "        [0.9998],\n",
      "        [0.9420],\n",
      "        [0.2646],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.4642],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [0.5054],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.3747],\n",
      "        [0.6628],\n",
      "        [0.9994],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.4645],\n",
      "        [0.9998],\n",
      "        [0.4527],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9490],\n",
      "        [0.9999],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.5334],\n",
      "        [0.7540],\n",
      "        [0.7391],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2610],\n",
      "        [0.9994],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.4454],\n",
      "        [0.5165],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.4503],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5463],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.5945],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.2735],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9995],\n",
      "        [0.0247],\n",
      "        [0.9164],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9997],\n",
      "        [0.2577],\n",
      "        [0.4480],\n",
      "        [0.3728],\n",
      "        [0.6555],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.9962],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [1.0000]])\n",
      "######### Epoch: 75  ######### Train Loss: 0.00015630027337465435  ######### Relative L2 Test Norm: 13.92790412902832\n",
      "Output batch pred: tensor([[[0.9906],\n",
      "         [0.9953],\n",
      "         [0.9969],\n",
      "         [0.9989],\n",
      "         [1.0019],\n",
      "         [0.9701],\n",
      "         [1.0033],\n",
      "         [1.0011],\n",
      "         [0.8473],\n",
      "         [0.7397],\n",
      "         [0.9921],\n",
      "         [0.0212],\n",
      "         [0.4327],\n",
      "         [0.4427],\n",
      "         [0.9937],\n",
      "         [0.0414],\n",
      "         [0.3429],\n",
      "         [0.9996],\n",
      "         [1.0001],\n",
      "         [0.2395],\n",
      "         [0.9988],\n",
      "         [0.9953],\n",
      "         [0.8997],\n",
      "         [0.9924],\n",
      "         [0.6499],\n",
      "         [0.5136],\n",
      "         [0.9920],\n",
      "         [0.9954],\n",
      "         [0.9993],\n",
      "         [1.0008],\n",
      "         [0.9660],\n",
      "         [0.4635],\n",
      "         [1.0016],\n",
      "         [1.0012],\n",
      "         [1.0016],\n",
      "         [1.0021],\n",
      "         [0.2464],\n",
      "         [1.0043],\n",
      "         [1.0046],\n",
      "         [1.0049],\n",
      "         [1.0033],\n",
      "         [1.0010],\n",
      "         [0.9969],\n",
      "         [0.9937],\n",
      "         [0.9927],\n",
      "         [0.0324],\n",
      "         [0.9907],\n",
      "         [0.9919],\n",
      "         [0.9903],\n",
      "         [0.5568],\n",
      "         [0.4527],\n",
      "         [1.0043],\n",
      "         [0.3763],\n",
      "         [0.3519],\n",
      "         [0.2096],\n",
      "         [0.9595],\n",
      "         [0.9977],\n",
      "         [0.8129],\n",
      "         [0.9933],\n",
      "         [0.2350],\n",
      "         [0.4372],\n",
      "         [0.9837],\n",
      "         [0.9998],\n",
      "         [0.5139],\n",
      "         [1.0027],\n",
      "         [1.0046],\n",
      "         [1.0033],\n",
      "         [0.2538],\n",
      "         [0.9972],\n",
      "         [0.0436],\n",
      "         [0.9924],\n",
      "         [0.1630],\n",
      "         [0.2479],\n",
      "         [0.5296],\n",
      "         [0.5081],\n",
      "         [1.0003],\n",
      "         [1.0041],\n",
      "         [0.9692],\n",
      "         [0.4534],\n",
      "         [1.0018],\n",
      "         [0.9274],\n",
      "         [0.9968],\n",
      "         [0.9947],\n",
      "         [0.9927],\n",
      "         [0.2500],\n",
      "         [0.9945],\n",
      "         [0.6892],\n",
      "         [0.9965],\n",
      "         [0.9974],\n",
      "         [0.9992],\n",
      "         [0.9985],\n",
      "         [0.9968],\n",
      "         [0.9952],\n",
      "         [0.3627],\n",
      "         [0.4974],\n",
      "         [0.2334],\n",
      "         [0.3798],\n",
      "         [0.4990],\n",
      "         [0.9964],\n",
      "         [0.9998],\n",
      "         [1.0014],\n",
      "         [1.0020],\n",
      "         [0.9988],\n",
      "         [0.0399],\n",
      "         [0.9971],\n",
      "         [0.9356],\n",
      "         [0.9968],\n",
      "         [0.9974],\n",
      "         [0.9866],\n",
      "         [0.5249],\n",
      "         [1.0003],\n",
      "         [0.9904],\n",
      "         [1.0021],\n",
      "         [0.9277],\n",
      "         [0.9803],\n",
      "         [0.9963],\n",
      "         [0.6053],\n",
      "         [0.2443],\n",
      "         [0.4547],\n",
      "         [0.9916],\n",
      "         [0.9956],\n",
      "         [0.9964],\n",
      "         [1.0008],\n",
      "         [0.8683],\n",
      "         [1.0031],\n",
      "         [1.0038],\n",
      "         [0.5218],\n",
      "         [0.3810],\n",
      "         [1.0008],\n",
      "         [0.9990],\n",
      "         [0.0518],\n",
      "         [0.3778],\n",
      "         [0.9977],\n",
      "         [0.5201],\n",
      "         [1.0010],\n",
      "         [0.9876],\n",
      "         [1.0010],\n",
      "         [0.0329],\n",
      "         [0.4652],\n",
      "         [0.4596],\n",
      "         [0.5434],\n",
      "         [0.7836],\n",
      "         [0.9949],\n",
      "         [0.9959],\n",
      "         [0.5142],\n",
      "         [0.4600],\n",
      "         [1.0004],\n",
      "         [0.6859],\n",
      "         [1.0021],\n",
      "         [1.0013],\n",
      "         [0.9188],\n",
      "         [0.3571],\n",
      "         [0.9938],\n",
      "         [0.9941],\n",
      "         [0.8605],\n",
      "         [0.9927],\n",
      "         [0.0503],\n",
      "         [0.7236],\n",
      "         [0.3780],\n",
      "         [1.0006],\n",
      "         [0.7782],\n",
      "         [1.0020],\n",
      "         [1.0007],\n",
      "         [0.5033],\n",
      "         [0.9967],\n",
      "         [0.3619],\n",
      "         [0.9957],\n",
      "         [0.3604],\n",
      "         [0.9970],\n",
      "         [0.9991],\n",
      "         [1.0007],\n",
      "         [1.0016],\n",
      "         [0.9992],\n",
      "         [0.8556],\n",
      "         [0.9973],\n",
      "         [0.9933],\n",
      "         [0.9911],\n",
      "         [0.0415]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9515],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.8139],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [0.0000],\n",
      "        [0.4480],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.8761],\n",
      "        [0.9999],\n",
      "        [0.6327],\n",
      "        [0.5139],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9956],\n",
      "        [0.5463],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.3573],\n",
      "        [0.2208],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.4454],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9999],\n",
      "        [0.0209],\n",
      "        [0.9997],\n",
      "        [0.1762],\n",
      "        [0.2686],\n",
      "        [0.5245],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9490],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [0.9044],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.5030],\n",
      "        [0.2518],\n",
      "        [0.3930],\n",
      "        [0.4988],\n",
      "        [0.9995],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.0247],\n",
      "        [0.9967],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9819],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.2729],\n",
      "        [0.4668],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5108],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [0.9994],\n",
      "        [0.0142],\n",
      "        [0.4642],\n",
      "        [0.4611],\n",
      "        [0.5334],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.3747],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9996],\n",
      "        [0.0335],\n",
      "        [0.6920],\n",
      "        [0.3840],\n",
      "        [0.9999],\n",
      "        [0.7391],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.5009],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.0368]])\n",
      "######### Epoch: 76  ######### Train Loss: 0.0001466726534999907  ######### Relative L2 Test Norm: 13.789701461791992\n",
      "Output batch pred: tensor([[[0.3701],\n",
      "         [0.9998],\n",
      "         [1.0016],\n",
      "         [1.0012],\n",
      "         [1.0006],\n",
      "         [1.0012],\n",
      "         [0.9279],\n",
      "         [0.9988],\n",
      "         [0.4632],\n",
      "         [0.9979],\n",
      "         [0.9964],\n",
      "         [0.9971],\n",
      "         [0.2610],\n",
      "         [0.9952],\n",
      "         [0.4442],\n",
      "         [0.9946],\n",
      "         [0.4976],\n",
      "         [0.0493],\n",
      "         [0.9954],\n",
      "         [0.9949],\n",
      "         [0.8634],\n",
      "         [0.9952],\n",
      "         [0.9609],\n",
      "         [0.5101],\n",
      "         [0.9987],\n",
      "         [1.0013],\n",
      "         [1.0028],\n",
      "         [1.0041],\n",
      "         [1.0028],\n",
      "         [1.0017],\n",
      "         [0.3748],\n",
      "         [0.9962],\n",
      "         [0.9759],\n",
      "         [0.9951],\n",
      "         [0.9937],\n",
      "         [0.0483],\n",
      "         [0.9987],\n",
      "         [0.2583],\n",
      "         [0.9900],\n",
      "         [0.1762],\n",
      "         [0.9686],\n",
      "         [0.6631],\n",
      "         [0.8506],\n",
      "         [0.0440],\n",
      "         [0.9824],\n",
      "         [0.9929],\n",
      "         [0.9117],\n",
      "         [0.9297],\n",
      "         [0.9928],\n",
      "         [0.5109],\n",
      "         [0.9961],\n",
      "         [0.9982],\n",
      "         [1.0013],\n",
      "         [0.4678],\n",
      "         [1.0011],\n",
      "         [0.9988],\n",
      "         [0.3461],\n",
      "         [0.9944],\n",
      "         [0.9943],\n",
      "         [0.9943],\n",
      "         [0.9926],\n",
      "         [0.2006],\n",
      "         [0.9199],\n",
      "         [0.9900],\n",
      "         [0.0351],\n",
      "         [0.5423],\n",
      "         [0.9969],\n",
      "         [0.9036],\n",
      "         [0.9986],\n",
      "         [0.9985],\n",
      "         [1.0003],\n",
      "         [0.4638],\n",
      "         [0.4496],\n",
      "         [1.0009],\n",
      "         [1.0010],\n",
      "         [1.0017],\n",
      "         [1.0002],\n",
      "         [0.9961],\n",
      "         [0.9966],\n",
      "         [0.0347],\n",
      "         [0.9939],\n",
      "         [0.9931],\n",
      "         [0.9800],\n",
      "         [0.9950],\n",
      "         [0.9960],\n",
      "         [0.9991],\n",
      "         [0.9992],\n",
      "         [0.3879],\n",
      "         [0.7282],\n",
      "         [1.0003],\n",
      "         [0.9633],\n",
      "         [0.9958],\n",
      "         [0.4452],\n",
      "         [0.2384],\n",
      "         [0.6761],\n",
      "         [0.9954],\n",
      "         [0.3624],\n",
      "         [0.9992],\n",
      "         [0.9982],\n",
      "         [0.8668],\n",
      "         [1.0014],\n",
      "         [0.5109],\n",
      "         [0.9982],\n",
      "         [0.5213],\n",
      "         [0.0283],\n",
      "         [0.0436],\n",
      "         [0.9925],\n",
      "         [0.9926],\n",
      "         [0.9928],\n",
      "         [0.8120],\n",
      "         [0.6880],\n",
      "         [0.9967],\n",
      "         [0.9868],\n",
      "         [1.0017],\n",
      "         [1.0033],\n",
      "         [1.0039],\n",
      "         [0.4520],\n",
      "         [1.0025],\n",
      "         [0.2616],\n",
      "         [0.9589],\n",
      "         [0.5192],\n",
      "         [0.9972],\n",
      "         [0.9950],\n",
      "         [0.9952],\n",
      "         [0.9956],\n",
      "         [0.9942],\n",
      "         [0.9959],\n",
      "         [0.3426],\n",
      "         [0.7838],\n",
      "         [0.9985],\n",
      "         [0.9965],\n",
      "         [0.3765],\n",
      "         [0.6186],\n",
      "         [0.5382],\n",
      "         [1.0011],\n",
      "         [0.5566],\n",
      "         [0.9989],\n",
      "         [0.5074],\n",
      "         [0.8530],\n",
      "         [0.9968],\n",
      "         [0.5182],\n",
      "         [0.4515],\n",
      "         [0.9979],\n",
      "         [0.9993],\n",
      "         [1.0022],\n",
      "         [1.0021],\n",
      "         [0.3662],\n",
      "         [1.0016],\n",
      "         [0.9987],\n",
      "         [0.7425],\n",
      "         [0.2322],\n",
      "         [0.9927],\n",
      "         [0.4573],\n",
      "         [0.0557],\n",
      "         [0.4551],\n",
      "         [0.3646],\n",
      "         [0.9986],\n",
      "         [1.0008],\n",
      "         [0.2441],\n",
      "         [1.0038],\n",
      "         [0.5081],\n",
      "         [1.0023],\n",
      "         [0.2444],\n",
      "         [0.9985],\n",
      "         [0.5044],\n",
      "         [0.7695],\n",
      "         [0.3798],\n",
      "         [0.2495],\n",
      "         [0.9978],\n",
      "         [0.9989],\n",
      "         [0.3762],\n",
      "         [0.9996],\n",
      "         [0.9988],\n",
      "         [0.9977],\n",
      "         [0.9966],\n",
      "         [0.9970],\n",
      "         [0.9966],\n",
      "         [0.0355]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.3780],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.9966],\n",
      "        [0.4988],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.8379],\n",
      "        [0.9999],\n",
      "        [0.9490],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.9996],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.9819],\n",
      "        [0.1762],\n",
      "        [0.9515],\n",
      "        [0.6327],\n",
      "        [0.8139],\n",
      "        [0.0288],\n",
      "        [0.9820],\n",
      "        [0.9999],\n",
      "        [0.8933],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [0.9994],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9044],\n",
      "        [0.9956],\n",
      "        [0.0142],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.3930],\n",
      "        [0.6920],\n",
      "        [0.9998],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.2577],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [0.5030],\n",
      "        [0.9967],\n",
      "        [0.5151],\n",
      "        [0.0000],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.6628],\n",
      "        [0.9995],\n",
      "        [0.9804],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.9420],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.7540],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [0.3808],\n",
      "        [0.5945],\n",
      "        [0.5245],\n",
      "        [0.9997],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.8223],\n",
      "        [0.9998],\n",
      "        [0.5165],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7129],\n",
      "        [0.2518],\n",
      "        [0.9998],\n",
      "        [0.4668],\n",
      "        [0.0383],\n",
      "        [0.4611],\n",
      "        [0.3747],\n",
      "        [0.9994],\n",
      "        [0.9994],\n",
      "        [0.2547],\n",
      "        [0.9997],\n",
      "        [0.5009],\n",
      "        [0.9997],\n",
      "        [0.2610],\n",
      "        [0.9999],\n",
      "        [0.5038],\n",
      "        [0.7391],\n",
      "        [0.3912],\n",
      "        [0.2646],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0174]])\n",
      "######### Epoch: 77  ######### Train Loss: 0.0001312634558416903  ######### Relative L2 Test Norm: 13.723151206970215\n",
      "Output batch pred: tensor([[[0.5300],\n",
      "         [0.9990],\n",
      "         [0.2601],\n",
      "         [0.0448],\n",
      "         [0.9258],\n",
      "         [1.0006],\n",
      "         [0.9991],\n",
      "         [0.2455],\n",
      "         [0.8487],\n",
      "         [0.0499],\n",
      "         [0.9991],\n",
      "         [0.9997],\n",
      "         [1.0006],\n",
      "         [0.8586],\n",
      "         [0.6838],\n",
      "         [0.9996],\n",
      "         [0.9595],\n",
      "         [0.9985],\n",
      "         [0.9981],\n",
      "         [0.0239],\n",
      "         [0.3597],\n",
      "         [0.0516],\n",
      "         [0.9966],\n",
      "         [0.9956],\n",
      "         [0.9978],\n",
      "         [0.9981],\n",
      "         [0.3609],\n",
      "         [0.4411],\n",
      "         [0.9988],\n",
      "         [0.9973],\n",
      "         [0.9963],\n",
      "         [0.0460],\n",
      "         [0.9969],\n",
      "         [0.9986],\n",
      "         [0.0409],\n",
      "         [0.2597],\n",
      "         [1.0027],\n",
      "         [1.0014],\n",
      "         [0.4712],\n",
      "         [0.8733],\n",
      "         [1.0016],\n",
      "         [0.9994],\n",
      "         [0.4541],\n",
      "         [0.5066],\n",
      "         [0.5015],\n",
      "         [0.4428],\n",
      "         [0.4471],\n",
      "         [0.4567],\n",
      "         [0.9886],\n",
      "         [0.5198],\n",
      "         [0.5018],\n",
      "         [0.9952],\n",
      "         [0.9976],\n",
      "         [0.9989],\n",
      "         [0.9974],\n",
      "         [0.9971],\n",
      "         [0.9181],\n",
      "         [0.9853],\n",
      "         [0.9971],\n",
      "         [0.9959],\n",
      "         [0.7858],\n",
      "         [0.9983],\n",
      "         [0.9990],\n",
      "         [0.8638],\n",
      "         [1.0001],\n",
      "         [0.9992],\n",
      "         [0.3700],\n",
      "         [0.9987],\n",
      "         [0.9995],\n",
      "         [0.9645],\n",
      "         [0.9991],\n",
      "         [0.6586],\n",
      "         [0.9979],\n",
      "         [0.9971],\n",
      "         [0.1703],\n",
      "         [0.6134],\n",
      "         [0.9965],\n",
      "         [0.9961],\n",
      "         [0.9966],\n",
      "         [0.9971],\n",
      "         [0.9976],\n",
      "         [0.2595],\n",
      "         [0.9999],\n",
      "         [0.3799],\n",
      "         [0.7804],\n",
      "         [1.0026],\n",
      "         [1.0004],\n",
      "         [0.9998],\n",
      "         [0.9620],\n",
      "         [0.9955],\n",
      "         [0.9304],\n",
      "         [0.7373],\n",
      "         [0.9901],\n",
      "         [0.2357],\n",
      "         [0.3801],\n",
      "         [0.5179],\n",
      "         [0.9982],\n",
      "         [0.4526],\n",
      "         [1.0006],\n",
      "         [1.0000],\n",
      "         [0.3507],\n",
      "         [0.9988],\n",
      "         [0.3473],\n",
      "         [0.2065],\n",
      "         [0.5050],\n",
      "         [0.9925],\n",
      "         [0.9912],\n",
      "         [0.9923],\n",
      "         [0.6904],\n",
      "         [0.9966],\n",
      "         [0.9839],\n",
      "         [0.9991],\n",
      "         [0.9977],\n",
      "         [0.5462],\n",
      "         [0.3849],\n",
      "         [0.5213],\n",
      "         [0.9834],\n",
      "         [0.9956],\n",
      "         [0.9941],\n",
      "         [0.9956],\n",
      "         [0.9969],\n",
      "         [0.9036],\n",
      "         [0.2400],\n",
      "         [0.9987],\n",
      "         [0.9987],\n",
      "         [0.3693],\n",
      "         [0.9995],\n",
      "         [0.9978],\n",
      "         [0.9969],\n",
      "         [0.9994],\n",
      "         [0.9641],\n",
      "         [0.3852],\n",
      "         [0.9989],\n",
      "         [0.9990],\n",
      "         [1.0004],\n",
      "         [0.9983],\n",
      "         [0.8170],\n",
      "         [0.9960],\n",
      "         [0.9958],\n",
      "         [0.7171],\n",
      "         [0.2386],\n",
      "         [0.9953],\n",
      "         [0.9940],\n",
      "         [0.2477],\n",
      "         [0.9977],\n",
      "         [0.9985],\n",
      "         [0.4703],\n",
      "         [1.0015],\n",
      "         [1.0007],\n",
      "         [0.9984],\n",
      "         [0.9985],\n",
      "         [0.4986],\n",
      "         [0.9937],\n",
      "         [0.9940],\n",
      "         [0.9733],\n",
      "         [0.9942],\n",
      "         [0.5497],\n",
      "         [0.4397],\n",
      "         [0.0531],\n",
      "         [0.9976],\n",
      "         [0.9851],\n",
      "         [0.9980],\n",
      "         [0.3636],\n",
      "         [0.9951],\n",
      "         [0.0352],\n",
      "         [0.9997],\n",
      "         [0.0423],\n",
      "         [0.9281],\n",
      "         [1.0009],\n",
      "         [0.4517],\n",
      "         [0.9980],\n",
      "         [0.9976],\n",
      "         [0.5043],\n",
      "         [0.9959],\n",
      "         [0.4996],\n",
      "         [0.9930],\n",
      "         [0.9939],\n",
      "         [0.9947]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.5245],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [0.0209],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.8139],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [0.6555],\n",
      "        [0.9967],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.3753],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0174],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.5108],\n",
      "        [0.5080],\n",
      "        [0.4552],\n",
      "        [0.4580],\n",
      "        [0.4645],\n",
      "        [0.9959],\n",
      "        [0.5151],\n",
      "        [0.4988],\n",
      "        [0.9962],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.9819],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.9995],\n",
      "        [0.9996],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [0.5945],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.7129],\n",
      "        [0.9999],\n",
      "        [0.2518],\n",
      "        [0.3912],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.2208],\n",
      "        [0.5054],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [0.9999],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [0.3930],\n",
      "        [0.5165],\n",
      "        [0.9820],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.3875],\n",
      "        [0.9996],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9994],\n",
      "        [0.9966],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [0.9998],\n",
      "        [0.5463],\n",
      "        [0.4480],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.9956],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997]])\n",
      "######### Epoch: 78  ######### Train Loss: 0.00013975561887491494  ######### Relative L2 Test Norm: 13.751348495483398\n",
      "Output batch pred: tensor([[[0.9955],\n",
      "         [0.9938],\n",
      "         [0.0249],\n",
      "         [0.9941],\n",
      "         [0.9944],\n",
      "         [0.9953],\n",
      "         [0.9979],\n",
      "         [0.9980],\n",
      "         [0.9375],\n",
      "         [0.8493],\n",
      "         [0.9943],\n",
      "         [0.9973],\n",
      "         [0.2473],\n",
      "         [0.9133],\n",
      "         [0.9915],\n",
      "         [0.4384],\n",
      "         [0.6026],\n",
      "         [0.5009],\n",
      "         [0.8576],\n",
      "         [0.4567],\n",
      "         [0.4989],\n",
      "         [0.0493],\n",
      "         [0.9929],\n",
      "         [0.5040],\n",
      "         [0.9971],\n",
      "         [0.9981],\n",
      "         [0.5194],\n",
      "         [0.4587],\n",
      "         [0.9986],\n",
      "         [1.0018],\n",
      "         [0.2483],\n",
      "         [1.0022],\n",
      "         [1.0023],\n",
      "         [1.0004],\n",
      "         [0.9666],\n",
      "         [1.0005],\n",
      "         [0.9985],\n",
      "         [0.7848],\n",
      "         [0.9972],\n",
      "         [0.3712],\n",
      "         [0.9953],\n",
      "         [0.3622],\n",
      "         [0.3431],\n",
      "         [0.2527],\n",
      "         [0.9936],\n",
      "         [0.3683],\n",
      "         [0.9954],\n",
      "         [0.9956],\n",
      "         [0.9948],\n",
      "         [0.9966],\n",
      "         [0.9574],\n",
      "         [0.9987],\n",
      "         [0.5104],\n",
      "         [0.9978],\n",
      "         [0.9981],\n",
      "         [0.4442],\n",
      "         [0.9983],\n",
      "         [0.9988],\n",
      "         [0.7738],\n",
      "         [0.9843],\n",
      "         [0.9858],\n",
      "         [0.9969],\n",
      "         [0.4638],\n",
      "         [0.2591],\n",
      "         [0.9978],\n",
      "         [0.4496],\n",
      "         [0.9966],\n",
      "         [0.6535],\n",
      "         [0.9948],\n",
      "         [0.6873],\n",
      "         [0.5198],\n",
      "         [0.9208],\n",
      "         [0.0475],\n",
      "         [0.9958],\n",
      "         [0.9973],\n",
      "         [0.4480],\n",
      "         [1.0002],\n",
      "         [0.4625],\n",
      "         [1.0025],\n",
      "         [0.7327],\n",
      "         [1.0030],\n",
      "         [1.0009],\n",
      "         [0.9094],\n",
      "         [1.0010],\n",
      "         [0.9991],\n",
      "         [0.9974],\n",
      "         [0.9960],\n",
      "         [0.9965],\n",
      "         [0.9952],\n",
      "         [0.9952],\n",
      "         [0.9966],\n",
      "         [0.5305],\n",
      "         [0.2377],\n",
      "         [0.0579],\n",
      "         [0.9961],\n",
      "         [0.0501],\n",
      "         [0.0459],\n",
      "         [0.9858],\n",
      "         [0.0557],\n",
      "         [0.9646],\n",
      "         [0.5107],\n",
      "         [0.9803],\n",
      "         [0.9875],\n",
      "         [0.9989],\n",
      "         [0.4613],\n",
      "         [0.7458],\n",
      "         [0.9969],\n",
      "         [0.9967],\n",
      "         [0.8589],\n",
      "         [0.2576],\n",
      "         [0.9962],\n",
      "         [0.5544],\n",
      "         [0.9966],\n",
      "         [0.9968],\n",
      "         [0.6796],\n",
      "         [0.9966],\n",
      "         [0.9948],\n",
      "         [0.9939],\n",
      "         [0.9944],\n",
      "         [0.3793],\n",
      "         [0.3565],\n",
      "         [0.9931],\n",
      "         [0.8116],\n",
      "         [0.9946],\n",
      "         [0.9932],\n",
      "         [0.9955],\n",
      "         [0.2088],\n",
      "         [0.9996],\n",
      "         [1.0010],\n",
      "         [1.0003],\n",
      "         [0.5531],\n",
      "         [1.0015],\n",
      "         [1.0008],\n",
      "         [0.5049],\n",
      "         [0.9983],\n",
      "         [0.9950],\n",
      "         [0.9957],\n",
      "         [0.3747],\n",
      "         [0.9937],\n",
      "         [0.9920],\n",
      "         [0.9934],\n",
      "         [0.9946],\n",
      "         [0.3737],\n",
      "         [0.9970],\n",
      "         [0.9986],\n",
      "         [0.9982],\n",
      "         [0.9998],\n",
      "         [0.3707],\n",
      "         [0.0469],\n",
      "         [0.9955],\n",
      "         [0.9970],\n",
      "         [0.9960],\n",
      "         [0.9941],\n",
      "         [0.3422],\n",
      "         [0.4594],\n",
      "         [0.8530],\n",
      "         [0.9958],\n",
      "         [0.9961],\n",
      "         [1.0004],\n",
      "         [1.0014],\n",
      "         [1.0007],\n",
      "         [0.9999],\n",
      "         [0.1677],\n",
      "         [0.5171],\n",
      "         [0.9203],\n",
      "         [0.2363],\n",
      "         [0.2413],\n",
      "         [0.9864],\n",
      "         [0.9885],\n",
      "         [0.5116],\n",
      "         [0.3583],\n",
      "         [0.9579],\n",
      "         [0.9953],\n",
      "         [0.0540],\n",
      "         [0.9990],\n",
      "         [0.9992],\n",
      "         [0.9978],\n",
      "         [0.9979]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.9999],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.8139],\n",
      "        [0.9956],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [0.8933],\n",
      "        [0.9999],\n",
      "        [0.4503],\n",
      "        [0.5945],\n",
      "        [0.5080],\n",
      "        [0.8379],\n",
      "        [0.4668],\n",
      "        [0.5038],\n",
      "        [0.0335],\n",
      "        [0.9997],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.4552],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.9998],\n",
      "        [0.3747],\n",
      "        [0.3573],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9420],\n",
      "        [0.9999],\n",
      "        [0.5054],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.9814],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.2729],\n",
      "        [0.9999],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [0.5165],\n",
      "        [0.9044],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.9999],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.2518],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.0142],\n",
      "        [0.9804],\n",
      "        [0.0288],\n",
      "        [0.9490],\n",
      "        [0.5009],\n",
      "        [0.9724],\n",
      "        [0.9819],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [0.7129],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.8296],\n",
      "        [0.2735],\n",
      "        [0.9997],\n",
      "        [0.5463],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.3728],\n",
      "        [0.9997],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.4645],\n",
      "        [0.8223],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [0.5139],\n",
      "        [0.9009],\n",
      "        [0.2547],\n",
      "        [0.2610],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.3753],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9997]])\n",
      "######### Epoch: 79  ######### Train Loss: 0.00015172187704592943  ######### Relative L2 Test Norm: 13.983358383178711\n",
      "Output batch pred: tensor([[[0.9981],\n",
      "         [0.5056],\n",
      "         [0.9991],\n",
      "         [0.8579],\n",
      "         [0.9643],\n",
      "         [0.9996],\n",
      "         [0.9994],\n",
      "         [0.9993],\n",
      "         [0.9977],\n",
      "         [0.9976],\n",
      "         [0.9977],\n",
      "         [0.9378],\n",
      "         [0.5105],\n",
      "         [0.9992],\n",
      "         [0.8691],\n",
      "         [0.9978],\n",
      "         [0.0439],\n",
      "         [0.7714],\n",
      "         [0.9954],\n",
      "         [0.9947],\n",
      "         [0.2436],\n",
      "         [0.9944],\n",
      "         [0.9941],\n",
      "         [0.9966],\n",
      "         [0.9851],\n",
      "         [0.5200],\n",
      "         [1.0002],\n",
      "         [1.0020],\n",
      "         [1.0004],\n",
      "         [1.0008],\n",
      "         [0.9981],\n",
      "         [0.3461],\n",
      "         [0.3624],\n",
      "         [0.9819],\n",
      "         [0.5167],\n",
      "         [0.3727],\n",
      "         [0.3825],\n",
      "         [0.9953],\n",
      "         [0.4695],\n",
      "         [0.9960],\n",
      "         [0.9792],\n",
      "         [0.9988],\n",
      "         [0.9964],\n",
      "         [0.9955],\n",
      "         [0.2082],\n",
      "         [0.9935],\n",
      "         [0.5416],\n",
      "         [0.9934],\n",
      "         [0.9923],\n",
      "         [0.9923],\n",
      "         [0.9959],\n",
      "         [0.9974],\n",
      "         [0.9948],\n",
      "         [0.9993],\n",
      "         [1.0013],\n",
      "         [1.0012],\n",
      "         [0.3809],\n",
      "         [0.0542],\n",
      "         [0.9960],\n",
      "         [0.9937],\n",
      "         [0.6740],\n",
      "         [0.1648],\n",
      "         [0.9862],\n",
      "         [0.9887],\n",
      "         [0.9889],\n",
      "         [0.9905],\n",
      "         [0.4962],\n",
      "         [0.9918],\n",
      "         [0.6527],\n",
      "         [0.9962],\n",
      "         [0.6150],\n",
      "         [0.4460],\n",
      "         [0.9985],\n",
      "         [0.9983],\n",
      "         [0.2448],\n",
      "         [0.5254],\n",
      "         [0.9973],\n",
      "         [0.9968],\n",
      "         [0.9952],\n",
      "         [0.9947],\n",
      "         [0.9941],\n",
      "         [0.9131],\n",
      "         [0.9916],\n",
      "         [0.9911],\n",
      "         [0.9887],\n",
      "         [0.9919],\n",
      "         [0.0482],\n",
      "         [0.9907],\n",
      "         [0.9568],\n",
      "         [0.6834],\n",
      "         [0.8983],\n",
      "         [0.0188],\n",
      "         [0.9955],\n",
      "         [0.5138],\n",
      "         [0.5085],\n",
      "         [0.9995],\n",
      "         [0.9997],\n",
      "         [0.9979],\n",
      "         [0.4468],\n",
      "         [0.8595],\n",
      "         [0.9813],\n",
      "         [0.3549],\n",
      "         [0.8063],\n",
      "         [0.9891],\n",
      "         [0.5047],\n",
      "         [0.9891],\n",
      "         [0.9892],\n",
      "         [0.7776],\n",
      "         [0.9947],\n",
      "         [0.9957],\n",
      "         [0.0348],\n",
      "         [0.9988],\n",
      "         [1.0005],\n",
      "         [0.9991],\n",
      "         [0.9991],\n",
      "         [0.9247],\n",
      "         [0.2458],\n",
      "         [0.9927],\n",
      "         [0.9939],\n",
      "         [0.5526],\n",
      "         [0.9921],\n",
      "         [0.9920],\n",
      "         [0.9933],\n",
      "         [0.9942],\n",
      "         [0.9959],\n",
      "         [0.3424],\n",
      "         [0.9206],\n",
      "         [0.9958],\n",
      "         [0.4508],\n",
      "         [0.7178],\n",
      "         [0.0507],\n",
      "         [0.3647],\n",
      "         [0.9954],\n",
      "         [0.9954],\n",
      "         [0.4583],\n",
      "         [0.2573],\n",
      "         [0.9996],\n",
      "         [0.9639],\n",
      "         [0.4491],\n",
      "         [1.0002],\n",
      "         [0.9991],\n",
      "         [0.9976],\n",
      "         [0.0462],\n",
      "         [0.9974],\n",
      "         [0.3734],\n",
      "         [0.9956],\n",
      "         [0.9959],\n",
      "         [0.5035],\n",
      "         [0.9947],\n",
      "         [0.3797],\n",
      "         [0.9953],\n",
      "         [0.9943],\n",
      "         [0.9532],\n",
      "         [0.0413],\n",
      "         [0.9948],\n",
      "         [0.4629],\n",
      "         [0.2433],\n",
      "         [0.9834],\n",
      "         [0.4667],\n",
      "         [0.9987],\n",
      "         [0.9982],\n",
      "         [0.9975],\n",
      "         [0.9969],\n",
      "         [0.9972],\n",
      "         [0.4476],\n",
      "         [0.2397],\n",
      "         [0.4533],\n",
      "         [0.9978],\n",
      "         [0.5340],\n",
      "         [0.9970],\n",
      "         [0.2581],\n",
      "         [0.7438],\n",
      "         [0.0436],\n",
      "         [0.2599],\n",
      "         [0.3645],\n",
      "         [0.8448],\n",
      "         [0.9957],\n",
      "         [0.9968]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [0.9520],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9164],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9994],\n",
      "        [0.0288],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.3747],\n",
      "        [0.9819],\n",
      "        [0.5151],\n",
      "        [0.3840],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.9998],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [0.2208],\n",
      "        [0.9996],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [0.3875],\n",
      "        [0.0368],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.1762],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9997],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.5165],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.6628],\n",
      "        [0.8761],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.5038],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [0.8296],\n",
      "        [0.9820],\n",
      "        [0.3728],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.7540],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.6920],\n",
      "        [0.0335],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.4611],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0209],\n",
      "        [0.9999],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.0247],\n",
      "        [0.9999],\n",
      "        [0.4642],\n",
      "        [0.2577],\n",
      "        [0.9814],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.4503],\n",
      "        [0.2518],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.7129],\n",
      "        [0.0174],\n",
      "        [0.2729],\n",
      "        [0.3753],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [1.0000]])\n",
      "######### Epoch: 80  ######### Train Loss: 0.00012463734310586005  ######### Relative L2 Test Norm: 14.007055282592773\n",
      "Output batch pred: tensor([[[0.8075],\n",
      "         [0.9908],\n",
      "         [0.9921],\n",
      "         [0.9305],\n",
      "         [0.8638],\n",
      "         [0.9835],\n",
      "         [0.9969],\n",
      "         [0.9980],\n",
      "         [0.9987],\n",
      "         [0.9974],\n",
      "         [0.0476],\n",
      "         [0.9627],\n",
      "         [0.9846],\n",
      "         [0.9963],\n",
      "         [0.9965],\n",
      "         [0.3615],\n",
      "         [0.9933],\n",
      "         [0.3663],\n",
      "         [0.9924],\n",
      "         [0.9923],\n",
      "         [0.9925],\n",
      "         [0.9944],\n",
      "         [0.9948],\n",
      "         [0.0305],\n",
      "         [0.9966],\n",
      "         [0.9847],\n",
      "         [0.9968],\n",
      "         [0.0442],\n",
      "         [0.9962],\n",
      "         [0.9962],\n",
      "         [0.9962],\n",
      "         [0.9956],\n",
      "         [0.3553],\n",
      "         [0.9935],\n",
      "         [0.6738],\n",
      "         [0.7799],\n",
      "         [0.9923],\n",
      "         [0.6878],\n",
      "         [0.9951],\n",
      "         [0.9943],\n",
      "         [0.7447],\n",
      "         [0.7713],\n",
      "         [0.8463],\n",
      "         [0.9971],\n",
      "         [0.2423],\n",
      "         [0.9153],\n",
      "         [0.9952],\n",
      "         [0.8509],\n",
      "         [0.5510],\n",
      "         [0.9949],\n",
      "         [0.2532],\n",
      "         [0.9949],\n",
      "         [0.9965],\n",
      "         [0.4567],\n",
      "         [0.9951],\n",
      "         [0.4576],\n",
      "         [0.3810],\n",
      "         [0.4941],\n",
      "         [0.4358],\n",
      "         [0.9881],\n",
      "         [0.9879],\n",
      "         [0.9871],\n",
      "         [0.8941],\n",
      "         [0.9900],\n",
      "         [0.9167],\n",
      "         [0.9915],\n",
      "         [0.9932],\n",
      "         [0.9958],\n",
      "         [0.9613],\n",
      "         [0.9974],\n",
      "         [0.2406],\n",
      "         [0.9960],\n",
      "         [0.2502],\n",
      "         [0.5222],\n",
      "         [0.3814],\n",
      "         [0.4685],\n",
      "         [0.4556],\n",
      "         [0.0605],\n",
      "         [0.0442],\n",
      "         [0.9969],\n",
      "         [0.9967],\n",
      "         [0.9959],\n",
      "         [0.3795],\n",
      "         [0.9916],\n",
      "         [0.1658],\n",
      "         [0.9920],\n",
      "         [0.5116],\n",
      "         [0.3593],\n",
      "         [0.2552],\n",
      "         [0.8541],\n",
      "         [0.9927],\n",
      "         [0.9933],\n",
      "         [0.9947],\n",
      "         [0.9939],\n",
      "         [0.4388],\n",
      "         [0.9941],\n",
      "         [0.9243],\n",
      "         [0.9968],\n",
      "         [0.9966],\n",
      "         [0.9961],\n",
      "         [0.9952],\n",
      "         [0.5050],\n",
      "         [0.9939],\n",
      "         [0.5161],\n",
      "         [0.9936],\n",
      "         [0.3399],\n",
      "         [0.9957],\n",
      "         [0.9959],\n",
      "         [0.9964],\n",
      "         [0.9985],\n",
      "         [1.0007],\n",
      "         [1.0006],\n",
      "         [0.0571],\n",
      "         [0.9991],\n",
      "         [0.9979],\n",
      "         [0.9937],\n",
      "         [0.9942],\n",
      "         [0.9907],\n",
      "         [0.2022],\n",
      "         [0.9881],\n",
      "         [0.9894],\n",
      "         [0.4418],\n",
      "         [0.6493],\n",
      "         [0.9746],\n",
      "         [0.9964],\n",
      "         [0.9833],\n",
      "         [0.0479],\n",
      "         [0.4688],\n",
      "         [0.5124],\n",
      "         [1.0003],\n",
      "         [0.9989],\n",
      "         [0.9988],\n",
      "         [0.9997],\n",
      "         [0.9995],\n",
      "         [0.9996],\n",
      "         [1.0001],\n",
      "         [0.5186],\n",
      "         [0.9996],\n",
      "         [0.9964],\n",
      "         [1.0009],\n",
      "         [0.2625],\n",
      "         [0.9975],\n",
      "         [0.9979],\n",
      "         [0.9957],\n",
      "         [0.0313],\n",
      "         [0.4448],\n",
      "         [0.0415],\n",
      "         [0.9928],\n",
      "         [0.3696],\n",
      "         [0.5395],\n",
      "         [0.9922],\n",
      "         [0.9528],\n",
      "         [0.9937],\n",
      "         [0.9953],\n",
      "         [0.9963],\n",
      "         [0.9965],\n",
      "         [0.3697],\n",
      "         [0.5370],\n",
      "         [0.9957],\n",
      "         [0.9951],\n",
      "         [0.6158],\n",
      "         [0.9967],\n",
      "         [0.9926],\n",
      "         [0.7214],\n",
      "         [0.5056],\n",
      "         [0.9957],\n",
      "         [0.5036],\n",
      "         [0.9945],\n",
      "         [0.2651],\n",
      "         [0.4669],\n",
      "         [0.2451],\n",
      "         [0.3519],\n",
      "         [0.9950],\n",
      "         [0.9594],\n",
      "         [0.5119],\n",
      "         [0.9920],\n",
      "         [0.9900],\n",
      "         [0.9907]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.7820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.8379],\n",
      "        [0.9819],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.0335],\n",
      "        [0.9490],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3747],\n",
      "        [0.9996],\n",
      "        [0.3808],\n",
      "        [0.9994],\n",
      "        [0.9995],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.9994],\n",
      "        [0.0288],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.7129],\n",
      "        [0.7391],\n",
      "        [0.8139],\n",
      "        [0.9997],\n",
      "        [0.2577],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.4580],\n",
      "        [0.9999],\n",
      "        [0.4611],\n",
      "        [0.3930],\n",
      "        [0.4988],\n",
      "        [0.4480],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.5151],\n",
      "        [0.3875],\n",
      "        [0.4668],\n",
      "        [0.4552],\n",
      "        [0.0368],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.9997],\n",
      "        [0.5139],\n",
      "        [0.3753],\n",
      "        [0.2735],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.9962],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.2208],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.6327],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.0247],\n",
      "        [0.4642],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9999],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0000],\n",
      "        [0.4503],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.5334],\n",
      "        [0.9997],\n",
      "        [0.9420],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.3780],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.6920],\n",
      "        [0.5030],\n",
      "        [0.9997],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.4645],\n",
      "        [0.2518],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000]])\n",
      "######### Epoch: 81  ######### Train Loss: 0.00012792026973329484  ######### Relative L2 Test Norm: 13.979138374328613\n",
      "Output batch pred: tensor([[[0.8497],\n",
      "         [0.0300],\n",
      "         [0.9933],\n",
      "         [0.9925],\n",
      "         [0.5025],\n",
      "         [0.7637],\n",
      "         [0.9917],\n",
      "         [0.9935],\n",
      "         [0.5388],\n",
      "         [0.5181],\n",
      "         [0.9961],\n",
      "         [0.4453],\n",
      "         [0.9971],\n",
      "         [0.9971],\n",
      "         [0.9958],\n",
      "         [0.9952],\n",
      "         [0.9940],\n",
      "         [0.9944],\n",
      "         [0.7794],\n",
      "         [0.9918],\n",
      "         [0.7157],\n",
      "         [0.9782],\n",
      "         [0.9579],\n",
      "         [0.0582],\n",
      "         [0.9944],\n",
      "         [0.5139],\n",
      "         [0.1713],\n",
      "         [0.9957],\n",
      "         [0.9957],\n",
      "         [0.5163],\n",
      "         [0.9331],\n",
      "         [0.9936],\n",
      "         [0.9946],\n",
      "         [0.2358],\n",
      "         [0.9936],\n",
      "         [0.9921],\n",
      "         [0.4441],\n",
      "         [0.9190],\n",
      "         [0.9801],\n",
      "         [0.9910],\n",
      "         [0.8418],\n",
      "         [0.4552],\n",
      "         [0.9936],\n",
      "         [0.9211],\n",
      "         [0.9962],\n",
      "         [0.9978],\n",
      "         [0.3756],\n",
      "         [0.4670],\n",
      "         [0.9999],\n",
      "         [0.3528],\n",
      "         [0.9983],\n",
      "         [0.2662],\n",
      "         [0.0541],\n",
      "         [0.8597],\n",
      "         [0.9965],\n",
      "         [0.9833],\n",
      "         [0.0545],\n",
      "         [0.9596],\n",
      "         [0.5013],\n",
      "         [0.4499],\n",
      "         [0.9939],\n",
      "         [0.9920],\n",
      "         [0.2447],\n",
      "         [0.9918],\n",
      "         [0.9902],\n",
      "         [0.9907],\n",
      "         [0.3550],\n",
      "         [0.8997],\n",
      "         [0.9946],\n",
      "         [0.9973],\n",
      "         [0.9964],\n",
      "         [0.9994],\n",
      "         [0.9997],\n",
      "         [0.9992],\n",
      "         [0.9994],\n",
      "         [0.9986],\n",
      "         [0.9973],\n",
      "         [0.3726],\n",
      "         [0.0402],\n",
      "         [0.2452],\n",
      "         [0.9948],\n",
      "         [0.9953],\n",
      "         [0.7443],\n",
      "         [0.9964],\n",
      "         [0.9834],\n",
      "         [0.9952],\n",
      "         [0.0411],\n",
      "         [0.9920],\n",
      "         [0.5029],\n",
      "         [0.2352],\n",
      "         [0.9914],\n",
      "         [0.9905],\n",
      "         [0.6827],\n",
      "         [0.4933],\n",
      "         [0.9911],\n",
      "         [0.9919],\n",
      "         [0.9914],\n",
      "         [0.9918],\n",
      "         [0.9937],\n",
      "         [0.9931],\n",
      "         [0.8124],\n",
      "         [0.9898],\n",
      "         [0.9576],\n",
      "         [0.3821],\n",
      "         [0.9736],\n",
      "         [0.3655],\n",
      "         [0.9920],\n",
      "         [0.3796],\n",
      "         [0.9946],\n",
      "         [0.9952],\n",
      "         [0.3435],\n",
      "         [0.9979],\n",
      "         [0.9981],\n",
      "         [0.9989],\n",
      "         [0.3690],\n",
      "         [0.9575],\n",
      "         [0.9974],\n",
      "         [0.4449],\n",
      "         [0.3659],\n",
      "         [0.9132],\n",
      "         [0.9900],\n",
      "         [0.9871],\n",
      "         [0.9874],\n",
      "         [0.9861],\n",
      "         [0.2381],\n",
      "         [0.9884],\n",
      "         [0.0368],\n",
      "         [0.9927],\n",
      "         [0.9920],\n",
      "         [0.2491],\n",
      "         [0.9987],\n",
      "         [0.9979],\n",
      "         [0.0594],\n",
      "         [0.5113],\n",
      "         [0.9968],\n",
      "         [0.9945],\n",
      "         [0.9939],\n",
      "         [0.5280],\n",
      "         [0.8594],\n",
      "         [0.9922],\n",
      "         [0.9907],\n",
      "         [0.9924],\n",
      "         [0.2094],\n",
      "         [0.9956],\n",
      "         [0.9966],\n",
      "         [0.4552],\n",
      "         [0.9957],\n",
      "         [0.6767],\n",
      "         [0.6511],\n",
      "         [0.9902],\n",
      "         [0.9902],\n",
      "         [0.9893],\n",
      "         [0.6040],\n",
      "         [0.4995],\n",
      "         [0.9898],\n",
      "         [0.9911],\n",
      "         [0.9916],\n",
      "         [0.9927],\n",
      "         [0.9940],\n",
      "         [0.9936],\n",
      "         [0.9949],\n",
      "         [0.9950],\n",
      "         [0.9973],\n",
      "         [0.4508],\n",
      "         [0.2624],\n",
      "         [0.9971],\n",
      "         [0.3831],\n",
      "         [0.9954],\n",
      "         [0.4676],\n",
      "         [0.0424],\n",
      "         [0.9954],\n",
      "         [0.5567],\n",
      "         [0.9948],\n",
      "         [0.9962],\n",
      "         [0.4644],\n",
      "         [0.9941],\n",
      "         [0.5193],\n",
      "         [0.9944]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.8223],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5080],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5334],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.9999],\n",
      "        [0.6920],\n",
      "        [0.9814],\n",
      "        [0.9515],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5139],\n",
      "        [0.9164],\n",
      "        [0.9996],\n",
      "        [0.9997],\n",
      "        [0.2547],\n",
      "        [0.9997],\n",
      "        [0.9995],\n",
      "        [0.4503],\n",
      "        [0.9044],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.4611],\n",
      "        [0.9999],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [0.0247],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [0.0335],\n",
      "        [0.9520],\n",
      "        [0.5009],\n",
      "        [0.4552],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.3728],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.0142],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.9999],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9956],\n",
      "        [0.9490],\n",
      "        [0.3930],\n",
      "        [0.9724],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.9420],\n",
      "        [0.9996],\n",
      "        [0.4454],\n",
      "        [0.3747],\n",
      "        [0.8933],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0368],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [0.8379],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.5945],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.9962],\n",
      "        [0.4645],\n",
      "        [0.0174],\n",
      "        [0.9966],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [1.0000]])\n",
      "######### Epoch: 82  ######### Train Loss: 0.00013083324301987886  ######### Relative L2 Test Norm: 14.243597030639648\n",
      "Output batch pred: tensor([[[0.2487],\n",
      "         [0.9952],\n",
      "         [0.9941],\n",
      "         [0.9937],\n",
      "         [0.9578],\n",
      "         [0.9929],\n",
      "         [0.2597],\n",
      "         [0.9959],\n",
      "         [0.9956],\n",
      "         [0.9970],\n",
      "         [0.6946],\n",
      "         [0.9846],\n",
      "         [0.9990],\n",
      "         [0.9986],\n",
      "         [0.0478],\n",
      "         [0.4511],\n",
      "         [0.9954],\n",
      "         [0.9948],\n",
      "         [0.4661],\n",
      "         [0.9937],\n",
      "         [0.9948],\n",
      "         [0.9588],\n",
      "         [0.9948],\n",
      "         [0.9941],\n",
      "         [0.9947],\n",
      "         [0.9914],\n",
      "         [0.9929],\n",
      "         [0.2437],\n",
      "         [0.7694],\n",
      "         [0.9933],\n",
      "         [0.5313],\n",
      "         [0.9913],\n",
      "         [0.9915],\n",
      "         [0.9906],\n",
      "         [0.8540],\n",
      "         [0.9914],\n",
      "         [0.9916],\n",
      "         [0.9929],\n",
      "         [0.5522],\n",
      "         [0.9943],\n",
      "         [0.9939],\n",
      "         [0.3842],\n",
      "         [0.3780],\n",
      "         [0.9947],\n",
      "         [0.9929],\n",
      "         [0.9930],\n",
      "         [0.9899],\n",
      "         [0.9903],\n",
      "         [0.9864],\n",
      "         [0.8932],\n",
      "         [0.9890],\n",
      "         [0.9903],\n",
      "         [0.9911],\n",
      "         [0.9928],\n",
      "         [0.1663],\n",
      "         [0.9951],\n",
      "         [0.4416],\n",
      "         [0.9965],\n",
      "         [0.6135],\n",
      "         [0.9963],\n",
      "         [0.9221],\n",
      "         [0.9926],\n",
      "         [0.9936],\n",
      "         [0.7388],\n",
      "         [0.9915],\n",
      "         [0.0499],\n",
      "         [0.3563],\n",
      "         [0.9883],\n",
      "         [0.9902],\n",
      "         [0.5368],\n",
      "         [0.9906],\n",
      "         [0.2062],\n",
      "         [0.6750],\n",
      "         [0.3448],\n",
      "         [0.0263],\n",
      "         [0.9970],\n",
      "         [0.9979],\n",
      "         [0.9985],\n",
      "         [0.3471],\n",
      "         [0.9950],\n",
      "         [0.9913],\n",
      "         [0.9916],\n",
      "         [0.8470],\n",
      "         [0.9901],\n",
      "         [0.4356],\n",
      "         [0.9773],\n",
      "         [0.9894],\n",
      "         [0.9920],\n",
      "         [0.5122],\n",
      "         [0.9917],\n",
      "         [0.9930],\n",
      "         [0.9931],\n",
      "         [0.9933],\n",
      "         [0.4539],\n",
      "         [0.9924],\n",
      "         [0.9931],\n",
      "         [0.5007],\n",
      "         [0.5076],\n",
      "         [0.9928],\n",
      "         [0.9946],\n",
      "         [0.9953],\n",
      "         [0.5086],\n",
      "         [0.4593],\n",
      "         [0.0408],\n",
      "         [0.9979],\n",
      "         [0.9955],\n",
      "         [0.6561],\n",
      "         [0.9941],\n",
      "         [0.3783],\n",
      "         [0.9297],\n",
      "         [0.9501],\n",
      "         [0.5127],\n",
      "         [0.9927],\n",
      "         [0.9915],\n",
      "         [0.2380],\n",
      "         [0.5006],\n",
      "         [0.4989],\n",
      "         [0.8621],\n",
      "         [0.2543],\n",
      "         [0.4440],\n",
      "         [0.3657],\n",
      "         [0.9951],\n",
      "         [0.4515],\n",
      "         [0.9969],\n",
      "         [0.9984],\n",
      "         [0.3675],\n",
      "         [0.9970],\n",
      "         [0.9990],\n",
      "         [0.9807],\n",
      "         [0.7265],\n",
      "         [0.2580],\n",
      "         [0.9971],\n",
      "         [0.9956],\n",
      "         [0.8425],\n",
      "         [0.9892],\n",
      "         [0.9935],\n",
      "         [0.3554],\n",
      "         [0.4559],\n",
      "         [0.9935],\n",
      "         [0.9941],\n",
      "         [0.9954],\n",
      "         [0.9948],\n",
      "         [0.0345],\n",
      "         [0.9953],\n",
      "         [0.0548],\n",
      "         [0.9945],\n",
      "         [0.9944],\n",
      "         [0.9926],\n",
      "         [0.7784],\n",
      "         [0.3679],\n",
      "         [0.9163],\n",
      "         [0.5015],\n",
      "         [0.9775],\n",
      "         [0.9781],\n",
      "         [0.9901],\n",
      "         [0.0374],\n",
      "         [0.9884],\n",
      "         [0.9913],\n",
      "         [0.9896],\n",
      "         [0.3666],\n",
      "         [0.9947],\n",
      "         [0.9949],\n",
      "         [0.9970],\n",
      "         [0.2505],\n",
      "         [0.8168],\n",
      "         [0.9962],\n",
      "         [0.9951],\n",
      "         [0.9944],\n",
      "         [0.9586],\n",
      "         [0.9933],\n",
      "         [0.9126],\n",
      "         [0.4596],\n",
      "         [0.0563],\n",
      "         [0.2407],\n",
      "         [0.5013],\n",
      "         [0.0478],\n",
      "         [0.9960],\n",
      "         [0.5238]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2610],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.9995],\n",
      "        [0.2729],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0288],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [0.9490],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.7391],\n",
      "        [0.9999],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.3930],\n",
      "        [0.3875],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.3728],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.9995],\n",
      "        [0.2208],\n",
      "        [0.6555],\n",
      "        [0.3575],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.9994],\n",
      "        [0.9962],\n",
      "        [0.9996],\n",
      "        [0.8223],\n",
      "        [0.9999],\n",
      "        [0.4480],\n",
      "        [0.9820],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5038],\n",
      "        [0.4580],\n",
      "        [0.0174],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9164],\n",
      "        [0.9420],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.5030],\n",
      "        [0.5009],\n",
      "        [0.8379],\n",
      "        [0.2686],\n",
      "        [0.4503],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.6920],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.8139],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.4642],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.7540],\n",
      "        [0.3840],\n",
      "        [0.9009],\n",
      "        [0.5080],\n",
      "        [0.9804],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9515],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [0.4645],\n",
      "        [0.0335],\n",
      "        [0.2518],\n",
      "        [0.4988],\n",
      "        [0.0209],\n",
      "        [0.9997],\n",
      "        [0.5165]])\n",
      "######### Epoch: 83  ######### Train Loss: 0.00013348253560252488  ######### Relative L2 Test Norm: 14.187708854675293\n",
      "Output batch pred: tensor([[[0.5565],\n",
      "         [0.9970],\n",
      "         [0.9963],\n",
      "         [0.9946],\n",
      "         [0.9922],\n",
      "         [0.9907],\n",
      "         [0.9897],\n",
      "         [0.9893],\n",
      "         [0.9889],\n",
      "         [0.2471],\n",
      "         [0.9930],\n",
      "         [0.4430],\n",
      "         [0.7204],\n",
      "         [0.5065],\n",
      "         [0.9558],\n",
      "         [0.3774],\n",
      "         [0.9963],\n",
      "         [0.5169],\n",
      "         [0.8113],\n",
      "         [0.9928],\n",
      "         [0.9914],\n",
      "         [0.2383],\n",
      "         [0.8547],\n",
      "         [0.5111],\n",
      "         [0.0536],\n",
      "         [0.9954],\n",
      "         [0.2536],\n",
      "         [0.9960],\n",
      "         [0.0455],\n",
      "         [0.5187],\n",
      "         [0.9895],\n",
      "         [0.9923],\n",
      "         [0.9931],\n",
      "         [0.5121],\n",
      "         [0.9924],\n",
      "         [0.1700],\n",
      "         [0.7679],\n",
      "         [0.6538],\n",
      "         [0.9960],\n",
      "         [0.0588],\n",
      "         [0.9329],\n",
      "         [0.0276],\n",
      "         [0.9938],\n",
      "         [0.9928],\n",
      "         [0.9908],\n",
      "         [0.9921],\n",
      "         [0.4425],\n",
      "         [0.9897],\n",
      "         [0.9914],\n",
      "         [0.9931],\n",
      "         [0.9919],\n",
      "         [0.9913],\n",
      "         [0.9919],\n",
      "         [0.3745],\n",
      "         [0.9940],\n",
      "         [0.9809],\n",
      "         [0.9931],\n",
      "         [0.9962],\n",
      "         [0.0384],\n",
      "         [0.9982],\n",
      "         [0.3635],\n",
      "         [0.9980],\n",
      "         [0.9972],\n",
      "         [0.9832],\n",
      "         [0.9931],\n",
      "         [0.9933],\n",
      "         [0.0497],\n",
      "         [0.9893],\n",
      "         [0.3400],\n",
      "         [0.4463],\n",
      "         [0.3798],\n",
      "         [0.9586],\n",
      "         [0.9954],\n",
      "         [0.9963],\n",
      "         [0.9967],\n",
      "         [0.9952],\n",
      "         [0.9943],\n",
      "         [0.0261],\n",
      "         [0.9139],\n",
      "         [0.9934],\n",
      "         [0.9948],\n",
      "         [0.9943],\n",
      "         [0.9956],\n",
      "         [0.7461],\n",
      "         [0.9841],\n",
      "         [0.2626],\n",
      "         [0.9995],\n",
      "         [0.9983],\n",
      "         [0.4651],\n",
      "         [0.9947],\n",
      "         [0.2081],\n",
      "         [0.9910],\n",
      "         [0.4391],\n",
      "         [0.9803],\n",
      "         [0.9725],\n",
      "         [0.0356],\n",
      "         [0.3657],\n",
      "         [0.9917],\n",
      "         [0.9928],\n",
      "         [0.9921],\n",
      "         [0.5378],\n",
      "         [0.9898],\n",
      "         [0.9927],\n",
      "         [0.9927],\n",
      "         [0.9924],\n",
      "         [0.9934],\n",
      "         [0.4617],\n",
      "         [0.9903],\n",
      "         [0.9574],\n",
      "         [0.9920],\n",
      "         [0.9898],\n",
      "         [0.0429],\n",
      "         [0.9907],\n",
      "         [0.9907],\n",
      "         [0.9920],\n",
      "         [0.8975],\n",
      "         [0.5075],\n",
      "         [0.4630],\n",
      "         [0.5048],\n",
      "         [0.9971],\n",
      "         [0.5375],\n",
      "         [0.9963],\n",
      "         [0.9933],\n",
      "         [0.6756],\n",
      "         [0.6839],\n",
      "         [0.9878],\n",
      "         [0.9890],\n",
      "         [0.3541],\n",
      "         [0.7746],\n",
      "         [0.2409],\n",
      "         [0.9927],\n",
      "         [0.9945],\n",
      "         [0.2590],\n",
      "         [0.8518],\n",
      "         [0.3723],\n",
      "         [0.4554],\n",
      "         [0.8411],\n",
      "         [0.9179],\n",
      "         [0.4476],\n",
      "         [0.9913],\n",
      "         [0.5004],\n",
      "         [0.9941],\n",
      "         [0.9973],\n",
      "         [0.9978],\n",
      "         [0.2429],\n",
      "         [1.0015],\n",
      "         [1.0015],\n",
      "         [1.0005],\n",
      "         [0.9974],\n",
      "         [0.4402],\n",
      "         [0.9938],\n",
      "         [0.9929],\n",
      "         [0.9916],\n",
      "         [0.9903],\n",
      "         [0.3581],\n",
      "         [0.9929],\n",
      "         [0.9934],\n",
      "         [0.3440],\n",
      "         [0.9964],\n",
      "         [0.5011],\n",
      "         [0.3671],\n",
      "         [0.9957],\n",
      "         [0.9942],\n",
      "         [0.9204],\n",
      "         [0.9925],\n",
      "         [0.5065],\n",
      "         [0.9929],\n",
      "         [0.9929],\n",
      "         [0.6113],\n",
      "         [0.9581],\n",
      "         [0.9947],\n",
      "         [0.9946],\n",
      "         [0.9945],\n",
      "         [0.9938],\n",
      "         [0.9950],\n",
      "         [0.2380],\n",
      "         [0.8644],\n",
      "         [0.9956]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.5463],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.9997],\n",
      "        [0.4503],\n",
      "        [0.6920],\n",
      "        [0.5038],\n",
      "        [0.9420],\n",
      "        [0.3875],\n",
      "        [0.9999],\n",
      "        [0.5151],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.2577],\n",
      "        [0.8296],\n",
      "        [0.5108],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.5165],\n",
      "        [0.9956],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.7391],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [0.0368],\n",
      "        [0.9164],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9820],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.0383],\n",
      "        [0.9966],\n",
      "        [0.3575],\n",
      "        [0.4552],\n",
      "        [0.3930],\n",
      "        [0.9520],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.0142],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.9814],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9959],\n",
      "        [0.4480],\n",
      "        [0.9819],\n",
      "        [0.9724],\n",
      "        [0.0174],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.9962],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0288],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.5080],\n",
      "        [0.4642],\n",
      "        [0.5009],\n",
      "        [0.9997],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.7540],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.8223],\n",
      "        [0.3840],\n",
      "        [0.4611],\n",
      "        [0.8139],\n",
      "        [0.9044],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9996],\n",
      "        [0.3753],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.8379],\n",
      "        [0.9999]])\n",
      "######### Epoch: 84  ######### Train Loss: 0.00013180781388655305  ######### Relative L2 Test Norm: 13.980937004089355\n",
      "Output batch pred: tensor([[[0.2389],\n",
      "         [0.9910],\n",
      "         [0.2416],\n",
      "         [0.9909],\n",
      "         [0.9924],\n",
      "         [0.4455],\n",
      "         [0.9922],\n",
      "         [0.8989],\n",
      "         [0.9944],\n",
      "         [0.9944],\n",
      "         [0.7401],\n",
      "         [0.5005],\n",
      "         [0.9938],\n",
      "         [0.3588],\n",
      "         [0.8384],\n",
      "         [0.9914],\n",
      "         [0.9900],\n",
      "         [0.9901],\n",
      "         [0.9778],\n",
      "         [0.3543],\n",
      "         [0.5256],\n",
      "         [0.2483],\n",
      "         [0.7835],\n",
      "         [0.9970],\n",
      "         [0.9998],\n",
      "         [1.0000],\n",
      "         [1.0014],\n",
      "         [1.0015],\n",
      "         [0.9990],\n",
      "         [0.9265],\n",
      "         [0.3813],\n",
      "         [0.2562],\n",
      "         [0.9953],\n",
      "         [0.2521],\n",
      "         [0.9935],\n",
      "         [0.6478],\n",
      "         [0.9941],\n",
      "         [0.9936],\n",
      "         [0.9958],\n",
      "         [0.0331],\n",
      "         [0.9977],\n",
      "         [0.9982],\n",
      "         [0.0375],\n",
      "         [0.4631],\n",
      "         [0.8605],\n",
      "         [0.9965],\n",
      "         [0.9220],\n",
      "         [0.9970],\n",
      "         [0.9948],\n",
      "         [0.9968],\n",
      "         [0.0366],\n",
      "         [0.6764],\n",
      "         [0.9960],\n",
      "         [0.9973],\n",
      "         [0.9547],\n",
      "         [0.3739],\n",
      "         [0.5386],\n",
      "         [0.0482],\n",
      "         [0.9936],\n",
      "         [0.2341],\n",
      "         [0.9741],\n",
      "         [0.5139],\n",
      "         [0.5143],\n",
      "         [0.9578],\n",
      "         [0.9911],\n",
      "         [0.9930],\n",
      "         [0.9929],\n",
      "         [0.9936],\n",
      "         [0.9929],\n",
      "         [0.3608],\n",
      "         [0.9930],\n",
      "         [0.7168],\n",
      "         [0.9928],\n",
      "         [0.5502],\n",
      "         [0.2377],\n",
      "         [0.9926],\n",
      "         [0.9946],\n",
      "         [0.0482],\n",
      "         [0.3458],\n",
      "         [0.3717],\n",
      "         [0.9946],\n",
      "         [0.5020],\n",
      "         [0.8659],\n",
      "         [0.9964],\n",
      "         [0.4495],\n",
      "         [0.6143],\n",
      "         [0.5068],\n",
      "         [0.9917],\n",
      "         [0.9791],\n",
      "         [0.8123],\n",
      "         [0.0259],\n",
      "         [0.8494],\n",
      "         [0.9926],\n",
      "         [0.9933],\n",
      "         [0.9893],\n",
      "         [0.9937],\n",
      "         [0.9950],\n",
      "         [0.9973],\n",
      "         [0.3488],\n",
      "         [0.4592],\n",
      "         [0.9980],\n",
      "         [0.9863],\n",
      "         [0.4463],\n",
      "         [0.9378],\n",
      "         [0.9968],\n",
      "         [0.9976],\n",
      "         [0.9965],\n",
      "         [0.9953],\n",
      "         [0.3585],\n",
      "         [0.9927],\n",
      "         [0.9932],\n",
      "         [0.9919],\n",
      "         [0.9917],\n",
      "         [0.9924],\n",
      "         [0.9922],\n",
      "         [0.4391],\n",
      "         [0.9822],\n",
      "         [0.9941],\n",
      "         [0.9946],\n",
      "         [0.9618],\n",
      "         [0.9955],\n",
      "         [0.9975],\n",
      "         [0.5117],\n",
      "         [0.9966],\n",
      "         [0.0508],\n",
      "         [0.9942],\n",
      "         [0.9930],\n",
      "         [0.9894],\n",
      "         [0.9900],\n",
      "         [0.9884],\n",
      "         [0.9871],\n",
      "         [0.9869],\n",
      "         [0.9880],\n",
      "         [0.9885],\n",
      "         [0.9876],\n",
      "         [0.9908],\n",
      "         [0.7632],\n",
      "         [0.9918],\n",
      "         [0.9931],\n",
      "         [0.4629],\n",
      "         [0.9961],\n",
      "         [0.9601],\n",
      "         [0.9949],\n",
      "         [0.9948],\n",
      "         [0.4505],\n",
      "         [0.1707],\n",
      "         [0.9920],\n",
      "         [0.5107],\n",
      "         [0.9916],\n",
      "         [0.4960],\n",
      "         [0.9875],\n",
      "         [0.9909],\n",
      "         [0.9882],\n",
      "         [0.9918],\n",
      "         [0.9924],\n",
      "         [0.6845],\n",
      "         [0.0448],\n",
      "         [0.9946],\n",
      "         [0.9949],\n",
      "         [0.9959],\n",
      "         [0.3720],\n",
      "         [0.9965],\n",
      "         [0.9949],\n",
      "         [0.9161],\n",
      "         [0.4588],\n",
      "         [0.5081],\n",
      "         [0.9964],\n",
      "         [0.4635],\n",
      "         [0.9956],\n",
      "         [0.2095],\n",
      "         [0.9965],\n",
      "         [0.5175],\n",
      "         [0.9943],\n",
      "         [0.2435],\n",
      "         [0.9919],\n",
      "         [0.9935],\n",
      "         [0.3778],\n",
      "         [0.0449]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2610],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.3747],\n",
      "        [0.5245],\n",
      "        [0.2686],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9966],\n",
      "        [0.9044],\n",
      "        [0.3912],\n",
      "        [0.2735],\n",
      "        [0.9999],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.0209],\n",
      "        [0.4642],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.6555],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.3875],\n",
      "        [0.5334],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.9724],\n",
      "        [0.5165],\n",
      "        [0.5151],\n",
      "        [0.9490],\n",
      "        [0.9962],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.9998],\n",
      "        [0.6920],\n",
      "        [0.9998],\n",
      "        [0.5463],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.3573],\n",
      "        [0.3808],\n",
      "        [0.9997],\n",
      "        [0.4988],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.5945],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.7820],\n",
      "        [0.0000],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.4580],\n",
      "        [0.9999],\n",
      "        [0.9804],\n",
      "        [0.4454],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9515],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.1762],\n",
      "        [0.9999],\n",
      "        [0.5108],\n",
      "        [0.9997],\n",
      "        [0.5009],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.6628],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.8933],\n",
      "        [0.4611],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.9996],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.3930],\n",
      "        [0.0288]])\n",
      "######### Epoch: 85  ######### Train Loss: 0.00013558099453803152  ######### Relative L2 Test Norm: 13.952348709106445\n",
      "Output batch pred: tensor([[[0.2360],\n",
      "         [0.9931],\n",
      "         [0.9919],\n",
      "         [0.4328],\n",
      "         [0.5207],\n",
      "         [0.1574],\n",
      "         [0.4935],\n",
      "         [0.9919],\n",
      "         [0.9929],\n",
      "         [0.9922],\n",
      "         [0.5157],\n",
      "         [0.6508],\n",
      "         [0.3783],\n",
      "         [0.9904],\n",
      "         [0.9925],\n",
      "         [0.9903],\n",
      "         [0.5087],\n",
      "         [0.9196],\n",
      "         [0.5138],\n",
      "         [0.9948],\n",
      "         [0.9953],\n",
      "         [0.9947],\n",
      "         [0.9854],\n",
      "         [0.9958],\n",
      "         [0.2090],\n",
      "         [0.4479],\n",
      "         [0.9958],\n",
      "         [0.9960],\n",
      "         [0.2507],\n",
      "         [0.5529],\n",
      "         [0.9964],\n",
      "         [0.9973],\n",
      "         [0.9978],\n",
      "         [0.4673],\n",
      "         [0.9637],\n",
      "         [0.5052],\n",
      "         [0.9973],\n",
      "         [0.9964],\n",
      "         [0.9940],\n",
      "         [0.9943],\n",
      "         [0.2444],\n",
      "         [0.9927],\n",
      "         [0.9942],\n",
      "         [0.8580],\n",
      "         [0.9971],\n",
      "         [0.5018],\n",
      "         [0.9993],\n",
      "         [0.9994],\n",
      "         [0.0554],\n",
      "         [0.9968],\n",
      "         [0.4647],\n",
      "         [0.3648],\n",
      "         [0.9950],\n",
      "         [0.0314],\n",
      "         [0.9932],\n",
      "         [0.9934],\n",
      "         [0.9920],\n",
      "         [0.9513],\n",
      "         [0.2352],\n",
      "         [0.9883],\n",
      "         [0.9928],\n",
      "         [0.9795],\n",
      "         [0.8597],\n",
      "         [0.2546],\n",
      "         [0.9923],\n",
      "         [0.6722],\n",
      "         [0.9928],\n",
      "         [0.6084],\n",
      "         [0.9960],\n",
      "         [0.4577],\n",
      "         [0.5060],\n",
      "         [0.2414],\n",
      "         [0.5442],\n",
      "         [0.4412],\n",
      "         [0.9963],\n",
      "         [0.9942],\n",
      "         [0.3428],\n",
      "         [0.9945],\n",
      "         [0.7808],\n",
      "         [0.9954],\n",
      "         [0.9949],\n",
      "         [0.0478],\n",
      "         [0.9962],\n",
      "         [0.9982],\n",
      "         [0.9972],\n",
      "         [0.4648],\n",
      "         [0.9988],\n",
      "         [0.9189],\n",
      "         [0.9986],\n",
      "         [0.9977],\n",
      "         [0.9963],\n",
      "         [0.3656],\n",
      "         [0.9959],\n",
      "         [0.9976],\n",
      "         [0.0533],\n",
      "         [0.9965],\n",
      "         [0.7221],\n",
      "         [0.9960],\n",
      "         [0.9948],\n",
      "         [0.9940],\n",
      "         [0.3405],\n",
      "         [0.9914],\n",
      "         [0.2396],\n",
      "         [0.9305],\n",
      "         [0.2509],\n",
      "         [0.9932],\n",
      "         [0.9945],\n",
      "         [0.0269],\n",
      "         [0.9952],\n",
      "         [0.9945],\n",
      "         [0.9947],\n",
      "         [0.9960],\n",
      "         [0.9955],\n",
      "         [0.7427],\n",
      "         [0.9957],\n",
      "         [0.0284],\n",
      "         [0.9936],\n",
      "         [0.9940],\n",
      "         [0.4436],\n",
      "         [0.3797],\n",
      "         [0.9909],\n",
      "         [0.9917],\n",
      "         [0.9916],\n",
      "         [0.9912],\n",
      "         [0.8483],\n",
      "         [0.5048],\n",
      "         [0.6881],\n",
      "         [0.3705],\n",
      "         [0.9992],\n",
      "         [1.0005],\n",
      "         [0.0524],\n",
      "         [0.5164],\n",
      "         [1.0010],\n",
      "         [0.8519],\n",
      "         [0.9640],\n",
      "         [0.9968],\n",
      "         [0.7717],\n",
      "         [0.9953],\n",
      "         [0.9931],\n",
      "         [0.9900],\n",
      "         [0.0376],\n",
      "         [0.9906],\n",
      "         [0.9923],\n",
      "         [0.9910],\n",
      "         [0.3579],\n",
      "         [0.9935],\n",
      "         [0.9943],\n",
      "         [0.4498],\n",
      "         [0.3764],\n",
      "         [0.9973],\n",
      "         [0.0405],\n",
      "         [0.9982],\n",
      "         [0.4560],\n",
      "         [0.5210],\n",
      "         [0.9967],\n",
      "         [0.9957],\n",
      "         [0.9936],\n",
      "         [0.9940],\n",
      "         [0.9578],\n",
      "         [0.8974],\n",
      "         [0.9778],\n",
      "         [0.9731],\n",
      "         [0.9798],\n",
      "         [0.3562],\n",
      "         [0.9936],\n",
      "         [0.9931],\n",
      "         [0.9910],\n",
      "         [0.9912],\n",
      "         [0.9173],\n",
      "         [0.3647],\n",
      "         [0.9926],\n",
      "         [0.9942],\n",
      "         [0.9942],\n",
      "         [0.9971],\n",
      "         [0.9978],\n",
      "         [0.8177],\n",
      "         [0.9989],\n",
      "         [0.9958]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2518],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.5245],\n",
      "        [0.1762],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [0.5151],\n",
      "        [0.6327],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9967],\n",
      "        [0.5108],\n",
      "        [0.9044],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.2686],\n",
      "        [0.5463],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.4645],\n",
      "        [0.9490],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2646],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.2577],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.8379],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [0.9999],\n",
      "        [0.5945],\n",
      "        [0.9999],\n",
      "        [0.4611],\n",
      "        [0.5038],\n",
      "        [0.2547],\n",
      "        [0.5334],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.9962],\n",
      "        [0.9994],\n",
      "        [0.0383],\n",
      "        [0.9996],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9164],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.7129],\n",
      "        [0.9999],\n",
      "        [0.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4503],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [0.5080],\n",
      "        [0.6628],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [0.9520],\n",
      "        [0.9999],\n",
      "        [0.7391],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.0247],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.3728],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.3875],\n",
      "        [0.9998],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9515],\n",
      "        [0.8761],\n",
      "        [0.9814],\n",
      "        [0.9724],\n",
      "        [0.9804],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.9966]])\n",
      "######### Epoch: 86  ######### Train Loss: 0.00013827113434672356  ######### Relative L2 Test Norm: 14.12490177154541\n",
      "Output batch pred: tensor([[[0.9577],\n",
      "         [0.9922],\n",
      "         [0.2539],\n",
      "         [0.9930],\n",
      "         [0.9937],\n",
      "         [0.6844],\n",
      "         [0.9932],\n",
      "         [0.0455],\n",
      "         [0.8138],\n",
      "         [0.9836],\n",
      "         [0.2072],\n",
      "         [0.9970],\n",
      "         [0.9973],\n",
      "         [0.9969],\n",
      "         [0.9016],\n",
      "         [0.9935],\n",
      "         [0.9962],\n",
      "         [0.9966],\n",
      "         [0.9969],\n",
      "         [0.9958],\n",
      "         [0.5416],\n",
      "         [0.9972],\n",
      "         [0.9974],\n",
      "         [0.9964],\n",
      "         [0.9984],\n",
      "         [0.9974],\n",
      "         [0.0488],\n",
      "         [0.9999],\n",
      "         [1.0016],\n",
      "         [1.0024],\n",
      "         [1.0018],\n",
      "         [1.0025],\n",
      "         [0.0412],\n",
      "         [0.0365],\n",
      "         [0.9976],\n",
      "         [0.4479],\n",
      "         [0.9956],\n",
      "         [0.9930],\n",
      "         [0.5148],\n",
      "         [0.9922],\n",
      "         [0.3728],\n",
      "         [0.9907],\n",
      "         [0.9913],\n",
      "         [0.4545],\n",
      "         [0.5258],\n",
      "         [0.2371],\n",
      "         [0.9920],\n",
      "         [0.7381],\n",
      "         [0.9945],\n",
      "         [0.9940],\n",
      "         [0.3381],\n",
      "         [0.9905],\n",
      "         [0.9544],\n",
      "         [0.3647],\n",
      "         [0.0472],\n",
      "         [0.2319],\n",
      "         [0.6711],\n",
      "         [0.8539],\n",
      "         [0.9574],\n",
      "         [0.9933],\n",
      "         [0.9904],\n",
      "         [0.4493],\n",
      "         [0.9920],\n",
      "         [0.9934],\n",
      "         [0.9926],\n",
      "         [0.3782],\n",
      "         [0.9950],\n",
      "         [0.9975],\n",
      "         [0.9971],\n",
      "         [0.9991],\n",
      "         [0.3657],\n",
      "         [0.9175],\n",
      "         [0.2543],\n",
      "         [0.0342],\n",
      "         [0.2552],\n",
      "         [0.9944],\n",
      "         [0.3423],\n",
      "         [0.5029],\n",
      "         [0.8470],\n",
      "         [0.9984],\n",
      "         [0.9991],\n",
      "         [0.9993],\n",
      "         [0.9985],\n",
      "         [0.2498],\n",
      "         [0.9993],\n",
      "         [0.9967],\n",
      "         [0.9964],\n",
      "         [0.9941],\n",
      "         [0.9950],\n",
      "         [0.1622],\n",
      "         [0.2382],\n",
      "         [0.4542],\n",
      "         [0.5037],\n",
      "         [0.9976],\n",
      "         [0.6149],\n",
      "         [0.5238],\n",
      "         [0.9986],\n",
      "         [0.9987],\n",
      "         [0.9986],\n",
      "         [0.0493],\n",
      "         [0.9976],\n",
      "         [0.9962],\n",
      "         [0.4394],\n",
      "         [0.9931],\n",
      "         [0.9933],\n",
      "         [0.9938],\n",
      "         [0.5064],\n",
      "         [0.9924],\n",
      "         [0.9924],\n",
      "         [0.9908],\n",
      "         [0.9929],\n",
      "         [0.9926],\n",
      "         [0.7807],\n",
      "         [0.9962],\n",
      "         [0.8546],\n",
      "         [0.9984],\n",
      "         [0.9889],\n",
      "         [1.0000],\n",
      "         [1.0016],\n",
      "         [1.0023],\n",
      "         [0.9998],\n",
      "         [0.3717],\n",
      "         [0.9239],\n",
      "         [0.9969],\n",
      "         [0.5046],\n",
      "         [0.9943],\n",
      "         [0.9937],\n",
      "         [0.9941],\n",
      "         [0.5500],\n",
      "         [0.9817],\n",
      "         [0.9961],\n",
      "         [0.0201],\n",
      "         [0.9981],\n",
      "         [0.9978],\n",
      "         [0.3722],\n",
      "         [0.9973],\n",
      "         [0.9571],\n",
      "         [0.9977],\n",
      "         [0.7685],\n",
      "         [0.5070],\n",
      "         [0.9936],\n",
      "         [0.4422],\n",
      "         [0.6450],\n",
      "         [0.4422],\n",
      "         [0.4892],\n",
      "         [0.3676],\n",
      "         [0.9899],\n",
      "         [0.3561],\n",
      "         [0.4587],\n",
      "         [0.9942],\n",
      "         [0.7206],\n",
      "         [0.9970],\n",
      "         [0.9986],\n",
      "         [0.2486],\n",
      "         [0.9978],\n",
      "         [0.9789],\n",
      "         [0.5028],\n",
      "         [0.9972],\n",
      "         [0.9965],\n",
      "         [0.9958],\n",
      "         [0.9955],\n",
      "         [0.4604],\n",
      "         [0.9940],\n",
      "         [0.4400],\n",
      "         [0.9953],\n",
      "         [0.0402],\n",
      "         [0.9928],\n",
      "         [0.3625],\n",
      "         [0.9834],\n",
      "         [0.9963],\n",
      "         [0.9975],\n",
      "         [0.9247],\n",
      "         [0.9962],\n",
      "         [0.9946],\n",
      "         [0.9351],\n",
      "         [0.5173],\n",
      "         [0.9949],\n",
      "         [0.8635]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9520],\n",
      "        [0.9996],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [0.9999],\n",
      "        [0.0288],\n",
      "        [0.7820],\n",
      "        [0.9820],\n",
      "        [0.2208],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.0247],\n",
      "        [0.0174],\n",
      "        [0.9959],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.5245],\n",
      "        [0.2547],\n",
      "        [0.9962],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [0.9998],\n",
      "        [0.9490],\n",
      "        [0.3840],\n",
      "        [0.0335],\n",
      "        [0.2518],\n",
      "        [0.6555],\n",
      "        [0.8296],\n",
      "        [0.9515],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.9996],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.3930],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.8933],\n",
      "        [0.2686],\n",
      "        [0.0142],\n",
      "        [0.2729],\n",
      "        [0.9994],\n",
      "        [0.3575],\n",
      "        [0.5030],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.2577],\n",
      "        [0.4611],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0368],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.7540],\n",
      "        [0.9999],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.3780],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.9999],\n",
      "        [0.9420],\n",
      "        [0.9998],\n",
      "        [0.7391],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.6327],\n",
      "        [0.4552],\n",
      "        [0.4988],\n",
      "        [0.3875],\n",
      "        [0.9997],\n",
      "        [0.3753],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.9997],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.9956],\n",
      "        [0.3728],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9044],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.8379]])\n",
      "######### Epoch: 87  ######### Train Loss: 0.00012774838251061738  ######### Relative L2 Test Norm: 13.81210994720459\n",
      "Output batch pred: tensor([[[0.9938],\n",
      "         [0.0529],\n",
      "         [0.9972],\n",
      "         [0.4526],\n",
      "         [0.2613],\n",
      "         [0.8181],\n",
      "         [0.8557],\n",
      "         [0.0338],\n",
      "         [0.9963],\n",
      "         [0.4588],\n",
      "         [0.9933],\n",
      "         [0.9922],\n",
      "         [0.9928],\n",
      "         [0.3564],\n",
      "         [0.6485],\n",
      "         [0.9936],\n",
      "         [0.9921],\n",
      "         [0.9173],\n",
      "         [0.9917],\n",
      "         [0.4909],\n",
      "         [0.2019],\n",
      "         [0.9922],\n",
      "         [0.9921],\n",
      "         [0.3584],\n",
      "         [0.4476],\n",
      "         [0.9837],\n",
      "         [0.0448],\n",
      "         [0.8621],\n",
      "         [0.5249],\n",
      "         [1.0011],\n",
      "         [0.9867],\n",
      "         [0.9982],\n",
      "         [0.7761],\n",
      "         [0.9991],\n",
      "         [0.5079],\n",
      "         [0.9983],\n",
      "         [0.9980],\n",
      "         [0.9856],\n",
      "         [0.9973],\n",
      "         [0.9969],\n",
      "         [0.9964],\n",
      "         [0.9994],\n",
      "         [0.4511],\n",
      "         [0.9983],\n",
      "         [0.3790],\n",
      "         [0.8693],\n",
      "         [1.0000],\n",
      "         [0.7884],\n",
      "         [1.0006],\n",
      "         [0.9994],\n",
      "         [0.1681],\n",
      "         [0.9981],\n",
      "         [0.3493],\n",
      "         [0.9994],\n",
      "         [0.6153],\n",
      "         [0.5089],\n",
      "         [0.9967],\n",
      "         [0.9952],\n",
      "         [0.3812],\n",
      "         [0.9939],\n",
      "         [0.9941],\n",
      "         [0.3775],\n",
      "         [0.9960],\n",
      "         [0.4978],\n",
      "         [0.5131],\n",
      "         [0.9966],\n",
      "         [0.9954],\n",
      "         [0.9949],\n",
      "         [0.6883],\n",
      "         [0.9970],\n",
      "         [0.9957],\n",
      "         [0.9981],\n",
      "         [0.3751],\n",
      "         [0.9989],\n",
      "         [0.9967],\n",
      "         [0.9977],\n",
      "         [0.9982],\n",
      "         [0.2417],\n",
      "         [0.9961],\n",
      "         [0.9755],\n",
      "         [0.9933],\n",
      "         [0.9917],\n",
      "         [0.9956],\n",
      "         [0.9966],\n",
      "         [0.9967],\n",
      "         [0.9627],\n",
      "         [0.9260],\n",
      "         [0.9584],\n",
      "         [0.2574],\n",
      "         [0.9971],\n",
      "         [0.3614],\n",
      "         [0.7191],\n",
      "         [0.8411],\n",
      "         [0.5056],\n",
      "         [0.9914],\n",
      "         [0.9904],\n",
      "         [0.7350],\n",
      "         [0.0335],\n",
      "         [0.0474],\n",
      "         [0.9932],\n",
      "         [0.9941],\n",
      "         [0.3417],\n",
      "         [0.9950],\n",
      "         [0.9956],\n",
      "         [0.4422],\n",
      "         [0.3663],\n",
      "         [0.9959],\n",
      "         [0.2399],\n",
      "         [0.9963],\n",
      "         [0.9956],\n",
      "         [0.0247],\n",
      "         [0.5039],\n",
      "         [0.9950],\n",
      "         [0.9936],\n",
      "         [0.9948],\n",
      "         [0.9897],\n",
      "         [0.9929],\n",
      "         [0.9959],\n",
      "         [0.5319],\n",
      "         [0.9980],\n",
      "         [1.0001],\n",
      "         [0.4448],\n",
      "         [0.4488],\n",
      "         [0.4711],\n",
      "         [0.4685],\n",
      "         [1.0002],\n",
      "         [1.0008],\n",
      "         [0.0375],\n",
      "         [0.9999],\n",
      "         [0.9988],\n",
      "         [1.0005],\n",
      "         [1.0014],\n",
      "         [1.0021],\n",
      "         [0.9231],\n",
      "         [1.0026],\n",
      "         [0.2628],\n",
      "         [0.2440],\n",
      "         [0.9960],\n",
      "         [0.9967],\n",
      "         [0.9952],\n",
      "         [0.0474],\n",
      "         [0.5467],\n",
      "         [0.9568],\n",
      "         [0.9930],\n",
      "         [0.9938],\n",
      "         [0.9952],\n",
      "         [0.9976],\n",
      "         [0.9966],\n",
      "         [0.9975],\n",
      "         [0.9970],\n",
      "         [0.2487],\n",
      "         [0.9953],\n",
      "         [0.8999],\n",
      "         [0.5384],\n",
      "         [0.5143],\n",
      "         [0.9937],\n",
      "         [0.9826],\n",
      "         [0.9608],\n",
      "         [0.9973],\n",
      "         [0.9972],\n",
      "         [0.9971],\n",
      "         [0.4535],\n",
      "         [0.0368],\n",
      "         [0.9955],\n",
      "         [0.3592],\n",
      "         [0.9961],\n",
      "         [0.9966],\n",
      "         [0.9971],\n",
      "         [0.9962],\n",
      "         [0.6797],\n",
      "         [0.2346],\n",
      "         [0.9972],\n",
      "         [0.9963],\n",
      "         [0.9964],\n",
      "         [0.9952],\n",
      "         [0.5018],\n",
      "         [0.9296],\n",
      "         [0.9924]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.2735],\n",
      "        [0.7820],\n",
      "        [0.8223],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.4580],\n",
      "        [0.9819],\n",
      "        [0.0288],\n",
      "        [0.8296],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.9996],\n",
      "        [0.9967],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.9996],\n",
      "        [0.3875],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.6628],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.3840],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.9999],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9490],\n",
      "        [0.9044],\n",
      "        [0.9420],\n",
      "        [0.2686],\n",
      "        [0.9997],\n",
      "        [0.3728],\n",
      "        [0.6920],\n",
      "        [0.8139],\n",
      "        [0.5108],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.0174],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.3573],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.9966],\n",
      "        [0.9996],\n",
      "        [0.5245],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.4454],\n",
      "        [0.4480],\n",
      "        [0.4668],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.5463],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.5334],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.9804],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.0247],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9164],\n",
      "        [1.0000]])\n",
      "######### Epoch: 88  ######### Train Loss: 0.00012937696010340005  ######### Relative L2 Test Norm: 13.933767318725586\n",
      "Output batch pred: tensor([[[0.9643],\n",
      "         [0.3451],\n",
      "         [0.9982],\n",
      "         [0.9015],\n",
      "         [0.9950],\n",
      "         [0.7779],\n",
      "         [0.9922],\n",
      "         [0.9907],\n",
      "         [0.9912],\n",
      "         [0.9891],\n",
      "         [0.9913],\n",
      "         [0.9910],\n",
      "         [0.4466],\n",
      "         [0.9921],\n",
      "         [0.9928],\n",
      "         [0.3543],\n",
      "         [0.8552],\n",
      "         [0.9831],\n",
      "         [0.9967],\n",
      "         [0.9974],\n",
      "         [0.2594],\n",
      "         [0.9222],\n",
      "         [0.3689],\n",
      "         [0.4998],\n",
      "         [0.4513],\n",
      "         [0.4531],\n",
      "         [0.9899],\n",
      "         [0.9935],\n",
      "         [0.9955],\n",
      "         [0.9952],\n",
      "         [0.2398],\n",
      "         [0.0309],\n",
      "         [0.9997],\n",
      "         [1.0000],\n",
      "         [0.8683],\n",
      "         [0.9956],\n",
      "         [0.0431],\n",
      "         [0.9935],\n",
      "         [0.9924],\n",
      "         [0.6057],\n",
      "         [0.9909],\n",
      "         [0.6693],\n",
      "         [0.9909],\n",
      "         [0.9172],\n",
      "         [0.9927],\n",
      "         [0.9942],\n",
      "         [0.3831],\n",
      "         [0.5195],\n",
      "         [0.5206],\n",
      "         [0.4663],\n",
      "         [0.4643],\n",
      "         [0.3756],\n",
      "         [0.2527],\n",
      "         [0.3632],\n",
      "         [0.7470],\n",
      "         [0.5093],\n",
      "         [1.0002],\n",
      "         [1.0016],\n",
      "         [1.0031],\n",
      "         [0.5438],\n",
      "         [1.0022],\n",
      "         [1.0020],\n",
      "         [1.0028],\n",
      "         [1.0018],\n",
      "         [1.0006],\n",
      "         [0.9994],\n",
      "         [0.9983],\n",
      "         [0.9999],\n",
      "         [0.9989],\n",
      "         [0.9875],\n",
      "         [0.5189],\n",
      "         [0.3459],\n",
      "         [1.0006],\n",
      "         [1.0018],\n",
      "         [0.5156],\n",
      "         [1.0038],\n",
      "         [1.0041],\n",
      "         [1.0065],\n",
      "         [0.4569],\n",
      "         [1.0075],\n",
      "         [1.0073],\n",
      "         [1.0058],\n",
      "         [0.0549],\n",
      "         [1.0029],\n",
      "         [1.0008],\n",
      "         [0.9962],\n",
      "         [0.9946],\n",
      "         [0.9925],\n",
      "         [0.9907],\n",
      "         [0.9868],\n",
      "         [0.2387],\n",
      "         [0.8443],\n",
      "         [0.9921],\n",
      "         [0.0397],\n",
      "         [0.9970],\n",
      "         [0.9954],\n",
      "         [0.9974],\n",
      "         [0.9978],\n",
      "         [0.9969],\n",
      "         [0.9933],\n",
      "         [0.9578],\n",
      "         [0.4523],\n",
      "         [0.9914],\n",
      "         [0.9085],\n",
      "         [0.6784],\n",
      "         [0.9917],\n",
      "         [0.5444],\n",
      "         [0.9904],\n",
      "         [0.9931],\n",
      "         [0.9932],\n",
      "         [0.9951],\n",
      "         [0.8118],\n",
      "         [0.0251],\n",
      "         [0.3738],\n",
      "         [0.4427],\n",
      "         [0.5404],\n",
      "         [0.0373],\n",
      "         [0.9540],\n",
      "         [0.9951],\n",
      "         [0.5037],\n",
      "         [0.3594],\n",
      "         [0.9929],\n",
      "         [0.2407],\n",
      "         [0.9926],\n",
      "         [0.9952],\n",
      "         [0.9601],\n",
      "         [0.4491],\n",
      "         [0.4435],\n",
      "         [1.0015],\n",
      "         [0.0545],\n",
      "         [0.0519],\n",
      "         [1.0019],\n",
      "         [0.2146],\n",
      "         [0.9999],\n",
      "         [0.0566],\n",
      "         [0.5129],\n",
      "         [0.5003],\n",
      "         [0.2387],\n",
      "         [0.3686],\n",
      "         [0.2371],\n",
      "         [0.9939],\n",
      "         [0.7720],\n",
      "         [0.9983],\n",
      "         [0.9990],\n",
      "         [0.6587],\n",
      "         [0.8489],\n",
      "         [0.9989],\n",
      "         [0.7242],\n",
      "         [0.9994],\n",
      "         [0.9994],\n",
      "         [1.0000],\n",
      "         [1.0002],\n",
      "         [0.9994],\n",
      "         [0.1666],\n",
      "         [1.0014],\n",
      "         [0.9998],\n",
      "         [1.0010],\n",
      "         [0.2571],\n",
      "         [1.0007],\n",
      "         [1.0005],\n",
      "         [0.9988],\n",
      "         [0.9995],\n",
      "         [0.9990],\n",
      "         [0.9981],\n",
      "         [0.9867],\n",
      "         [0.9977],\n",
      "         [0.9359],\n",
      "         [0.9822],\n",
      "         [0.9951],\n",
      "         [0.9963],\n",
      "         [0.9958],\n",
      "         [0.9962],\n",
      "         [0.5003],\n",
      "         [0.9968],\n",
      "         [0.9792],\n",
      "         [0.9992],\n",
      "         [0.3826],\n",
      "         [1.0015]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9490],\n",
      "        [0.3573],\n",
      "        [0.9997],\n",
      "        [0.8761],\n",
      "        [0.9996],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.8296],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2735],\n",
      "        [0.9009],\n",
      "        [0.3780],\n",
      "        [0.4988],\n",
      "        [0.4552],\n",
      "        [0.4580],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.3930],\n",
      "        [0.5151],\n",
      "        [0.5165],\n",
      "        [0.4668],\n",
      "        [0.4642],\n",
      "        [0.3840],\n",
      "        [0.2646],\n",
      "        [0.3728],\n",
      "        [0.7129],\n",
      "        [0.5030],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [0.5139],\n",
      "        [0.3575],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.4480],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.0368],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [0.2686],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.9515],\n",
      "        [0.4645],\n",
      "        [0.9999],\n",
      "        [0.8933],\n",
      "        [0.6628],\n",
      "        [0.9998],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.7820],\n",
      "        [0.0000],\n",
      "        [0.3875],\n",
      "        [0.4503],\n",
      "        [0.5334],\n",
      "        [0.0174],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.3753],\n",
      "        [0.9998],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.4527],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.5108],\n",
      "        [0.5009],\n",
      "        [0.2547],\n",
      "        [0.3808],\n",
      "        [0.2518],\n",
      "        [0.9962],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.6327],\n",
      "        [0.8139],\n",
      "        [0.9998],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.2729],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.9998],\n",
      "        [0.9164],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.9997],\n",
      "        [0.3912],\n",
      "        [0.9997]])\n",
      "######### Epoch: 89  ######### Train Loss: 0.0001342736795777455  ######### Relative L2 Test Norm: 13.833005905151367\n",
      "Output batch pred: tensor([[[0.6069],\n",
      "         [0.0417],\n",
      "         [0.0403],\n",
      "         [0.0454],\n",
      "         [0.9947],\n",
      "         [0.9946],\n",
      "         [0.4941],\n",
      "         [0.9964],\n",
      "         [0.9972],\n",
      "         [0.9993],\n",
      "         [0.9989],\n",
      "         [0.9986],\n",
      "         [0.9973],\n",
      "         [0.9975],\n",
      "         [0.9953],\n",
      "         [0.9182],\n",
      "         [0.9916],\n",
      "         [0.9888],\n",
      "         [0.8432],\n",
      "         [0.9905],\n",
      "         [0.9920],\n",
      "         [0.5236],\n",
      "         [0.9959],\n",
      "         [0.9973],\n",
      "         [0.8608],\n",
      "         [0.9988],\n",
      "         [0.0278],\n",
      "         [0.9983],\n",
      "         [0.9967],\n",
      "         [0.9958],\n",
      "         [0.9958],\n",
      "         [0.9958],\n",
      "         [0.3610],\n",
      "         [1.0002],\n",
      "         [0.2386],\n",
      "         [1.0027],\n",
      "         [0.2539],\n",
      "         [0.9979],\n",
      "         [1.0011],\n",
      "         [0.9987],\n",
      "         [0.9951],\n",
      "         [0.3626],\n",
      "         [0.5336],\n",
      "         [0.9904],\n",
      "         [0.9912],\n",
      "         [0.9498],\n",
      "         [0.9940],\n",
      "         [0.9964],\n",
      "         [0.9954],\n",
      "         [0.5156],\n",
      "         [0.6946],\n",
      "         [0.3719],\n",
      "         [1.0017],\n",
      "         [0.4586],\n",
      "         [0.5128],\n",
      "         [0.9977],\n",
      "         [0.4454],\n",
      "         [0.7452],\n",
      "         [0.9988],\n",
      "         [0.9998],\n",
      "         [1.0007],\n",
      "         [1.0014],\n",
      "         [0.2504],\n",
      "         [0.9664],\n",
      "         [1.0010],\n",
      "         [0.0448],\n",
      "         [0.9661],\n",
      "         [1.0011],\n",
      "         [0.9649],\n",
      "         [0.3444],\n",
      "         [0.9965],\n",
      "         [0.9941],\n",
      "         [0.9922],\n",
      "         [0.9910],\n",
      "         [0.9894],\n",
      "         [0.9892],\n",
      "         [0.9901],\n",
      "         [0.3737],\n",
      "         [0.8599],\n",
      "         [0.5143],\n",
      "         [0.9977],\n",
      "         [1.0021],\n",
      "         [0.9245],\n",
      "         [1.0038],\n",
      "         [1.0033],\n",
      "         [0.3526],\n",
      "         [0.9997],\n",
      "         [0.4508],\n",
      "         [0.9912],\n",
      "         [0.9913],\n",
      "         [0.9888],\n",
      "         [0.9877],\n",
      "         [0.9877],\n",
      "         [0.2263],\n",
      "         [0.7117],\n",
      "         [0.9803],\n",
      "         [0.9954],\n",
      "         [0.5063],\n",
      "         [0.2427],\n",
      "         [0.9997],\n",
      "         [1.0012],\n",
      "         [1.0001],\n",
      "         [0.9993],\n",
      "         [1.0006],\n",
      "         [1.0010],\n",
      "         [1.0005],\n",
      "         [0.6837],\n",
      "         [1.0041],\n",
      "         [0.0596],\n",
      "         [0.4495],\n",
      "         [0.5112],\n",
      "         [0.2672],\n",
      "         [1.0024],\n",
      "         [0.8513],\n",
      "         [0.5587],\n",
      "         [0.2539],\n",
      "         [0.4492],\n",
      "         [0.9997],\n",
      "         [0.9976],\n",
      "         [0.6562],\n",
      "         [0.9998],\n",
      "         [0.9800],\n",
      "         [0.3809],\n",
      "         [0.9875],\n",
      "         [0.9986],\n",
      "         [1.0004],\n",
      "         [0.3756],\n",
      "         [0.5237],\n",
      "         [1.0006],\n",
      "         [0.8205],\n",
      "         [0.3693],\n",
      "         [0.4699],\n",
      "         [1.0018],\n",
      "         [0.7866],\n",
      "         [0.9974],\n",
      "         [0.0507],\n",
      "         [0.8992],\n",
      "         [0.5117],\n",
      "         [0.9923],\n",
      "         [0.9918],\n",
      "         [0.9162],\n",
      "         [0.9941],\n",
      "         [0.5013],\n",
      "         [0.5004],\n",
      "         [0.9963],\n",
      "         [0.9817],\n",
      "         [0.9938],\n",
      "         [0.9959],\n",
      "         [0.7671],\n",
      "         [0.9957],\n",
      "         [0.9929],\n",
      "         [0.9836],\n",
      "         [0.9963],\n",
      "         [0.3752],\n",
      "         [0.4627],\n",
      "         [1.0011],\n",
      "         [1.0016],\n",
      "         [1.0020],\n",
      "         [1.0019],\n",
      "         [0.4473],\n",
      "         [0.2078],\n",
      "         [0.9994],\n",
      "         [0.9967],\n",
      "         [0.0392],\n",
      "         [0.9336],\n",
      "         [0.2521],\n",
      "         [0.9961],\n",
      "         [0.0259],\n",
      "         [0.1611],\n",
      "         [0.9975],\n",
      "         [0.9983],\n",
      "         [0.9997],\n",
      "         [1.0007],\n",
      "         [1.0007],\n",
      "         [0.9998],\n",
      "         [0.4589],\n",
      "         [0.4627],\n",
      "         [0.3648]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.5945],\n",
      "        [0.0174],\n",
      "        [0.0209],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.4988],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.5334],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9959],\n",
      "        [0.5108],\n",
      "        [0.6628],\n",
      "        [0.3780],\n",
      "        [0.9997],\n",
      "        [0.4580],\n",
      "        [0.5080],\n",
      "        [0.9997],\n",
      "        [0.4503],\n",
      "        [0.7129],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.2610],\n",
      "        [0.9520],\n",
      "        [0.9998],\n",
      "        [0.0247],\n",
      "        [0.9490],\n",
      "        [0.9999],\n",
      "        [0.9515],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.8379],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [0.9994],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.6920],\n",
      "        [0.9804],\n",
      "        [0.9994],\n",
      "        [0.5038],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.4454],\n",
      "        [0.5009],\n",
      "        [0.2735],\n",
      "        [0.9999],\n",
      "        [0.8139],\n",
      "        [0.5463],\n",
      "        [0.2686],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.3912],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.3753],\n",
      "        [0.4668],\n",
      "        [0.9998],\n",
      "        [0.7540],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.8761],\n",
      "        [0.5151],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.5030],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.9820],\n",
      "        [0.9999],\n",
      "        [0.3875],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.9164],\n",
      "        [0.2729],\n",
      "        [0.9998],\n",
      "        [0.0142],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.4642],\n",
      "        [0.3747]])\n",
      "######### Epoch: 90  ######### Train Loss: 0.00013301888247951865  ######### Relative L2 Test Norm: 13.808769226074219\n",
      "Output batch pred: tensor([[[0.9967],\n",
      "         [0.9977],\n",
      "         [0.9235],\n",
      "         [0.9991],\n",
      "         [0.4647],\n",
      "         [0.9967],\n",
      "         [0.9995],\n",
      "         [0.2468],\n",
      "         [0.9982],\n",
      "         [0.9989],\n",
      "         [0.9990],\n",
      "         [0.9937],\n",
      "         [0.6888],\n",
      "         [0.7424],\n",
      "         [0.9975],\n",
      "         [0.3578],\n",
      "         [0.9964],\n",
      "         [0.9953],\n",
      "         [0.9955],\n",
      "         [0.5045],\n",
      "         [0.9974],\n",
      "         [0.9357],\n",
      "         [0.9979],\n",
      "         [0.9993],\n",
      "         [1.0004],\n",
      "         [0.0480],\n",
      "         [1.0004],\n",
      "         [0.9245],\n",
      "         [0.3439],\n",
      "         [0.4623],\n",
      "         [0.5096],\n",
      "         [0.3633],\n",
      "         [0.9987],\n",
      "         [1.0001],\n",
      "         [0.9994],\n",
      "         [0.3652],\n",
      "         [0.5348],\n",
      "         [0.0525],\n",
      "         [0.3841],\n",
      "         [0.5232],\n",
      "         [1.0017],\n",
      "         [0.4639],\n",
      "         [0.4461],\n",
      "         [0.9976],\n",
      "         [0.3415],\n",
      "         [0.9976],\n",
      "         [0.9968],\n",
      "         [0.9950],\n",
      "         [0.9955],\n",
      "         [0.9934],\n",
      "         [0.9938],\n",
      "         [0.4471],\n",
      "         [0.9951],\n",
      "         [0.0345],\n",
      "         [0.9962],\n",
      "         [0.9950],\n",
      "         [0.3729],\n",
      "         [0.6750],\n",
      "         [0.9977],\n",
      "         [0.5399],\n",
      "         [0.5011],\n",
      "         [0.9964],\n",
      "         [0.4552],\n",
      "         [0.2573],\n",
      "         [0.9947],\n",
      "         [0.6089],\n",
      "         [0.5033],\n",
      "         [0.9934],\n",
      "         [0.3690],\n",
      "         [0.9852],\n",
      "         [0.4412],\n",
      "         [0.9981],\n",
      "         [0.9995],\n",
      "         [0.3734],\n",
      "         [0.9982],\n",
      "         [0.9996],\n",
      "         [0.9853],\n",
      "         [0.9983],\n",
      "         [0.9971],\n",
      "         [0.9763],\n",
      "         [0.9949],\n",
      "         [0.8496],\n",
      "         [0.0314],\n",
      "         [0.4935],\n",
      "         [0.9961],\n",
      "         [0.0210],\n",
      "         [0.5209],\n",
      "         [0.9987],\n",
      "         [0.9997],\n",
      "         [0.9996],\n",
      "         [0.4584],\n",
      "         [0.5247],\n",
      "         [1.0014],\n",
      "         [0.2413],\n",
      "         [1.0036],\n",
      "         [1.0025],\n",
      "         [1.0025],\n",
      "         [1.0025],\n",
      "         [0.1680],\n",
      "         [0.9638],\n",
      "         [0.9984],\n",
      "         [0.2047],\n",
      "         [0.2350],\n",
      "         [0.5489],\n",
      "         [0.9954],\n",
      "         [0.9951],\n",
      "         [0.5049],\n",
      "         [0.9943],\n",
      "         [0.9944],\n",
      "         [0.9946],\n",
      "         [0.9951],\n",
      "         [0.9951],\n",
      "         [0.9955],\n",
      "         [0.7825],\n",
      "         [0.9952],\n",
      "         [0.0364],\n",
      "         [0.9966],\n",
      "         [0.6546],\n",
      "         [0.9976],\n",
      "         [0.9944],\n",
      "         [0.9019],\n",
      "         [0.9936],\n",
      "         [0.0397],\n",
      "         [0.9956],\n",
      "         [0.9953],\n",
      "         [0.2495],\n",
      "         [0.9947],\n",
      "         [0.9928],\n",
      "         [0.8624],\n",
      "         [0.9960],\n",
      "         [0.9969],\n",
      "         [0.9972],\n",
      "         [0.9976],\n",
      "         [0.2549],\n",
      "         [0.9965],\n",
      "         [0.9959],\n",
      "         [0.9936],\n",
      "         [0.9965],\n",
      "         [0.4990],\n",
      "         [0.9948],\n",
      "         [0.8593],\n",
      "         [0.9619],\n",
      "         [0.9990],\n",
      "         [0.9999],\n",
      "         [1.0013],\n",
      "         [0.3732],\n",
      "         [1.0005],\n",
      "         [0.7762],\n",
      "         [0.0501],\n",
      "         [0.9185],\n",
      "         [0.9973],\n",
      "         [0.9953],\n",
      "         [0.9942],\n",
      "         [0.2421],\n",
      "         [0.0419],\n",
      "         [0.9953],\n",
      "         [0.9546],\n",
      "         [0.9972],\n",
      "         [0.2405],\n",
      "         [0.8519],\n",
      "         [1.0026],\n",
      "         [1.0049],\n",
      "         [0.9920],\n",
      "         [0.4604],\n",
      "         [1.0050],\n",
      "         [0.9926],\n",
      "         [0.3900],\n",
      "         [1.0009],\n",
      "         [0.9998],\n",
      "         [0.9983],\n",
      "         [0.9953],\n",
      "         [0.4386],\n",
      "         [0.9940],\n",
      "         [0.8094],\n",
      "         [0.9933],\n",
      "         [0.9922],\n",
      "         [0.9579],\n",
      "         [0.7157]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9996],\n",
      "        [0.9998],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9956],\n",
      "        [0.6628],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.9997],\n",
      "        [0.9164],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.3573],\n",
      "        [0.4642],\n",
      "        [0.5080],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.5245],\n",
      "        [0.0335],\n",
      "        [0.3912],\n",
      "        [0.5151],\n",
      "        [0.9999],\n",
      "        [0.4645],\n",
      "        [0.4503],\n",
      "        [0.9967],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.3875],\n",
      "        [0.6555],\n",
      "        [0.9999],\n",
      "        [0.5334],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.9819],\n",
      "        [0.4454],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.0209],\n",
      "        [0.4988],\n",
      "        [0.9994],\n",
      "        [0.0000],\n",
      "        [0.5165],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9966],\n",
      "        [0.4552],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.2547],\n",
      "        [0.5463],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.8761],\n",
      "        [0.9959],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8379],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9998],\n",
      "        [0.8296],\n",
      "        [0.9520],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.9999],\n",
      "        [0.7391],\n",
      "        [0.0288],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [0.2646],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.8139],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.6920]])\n",
      "######### Epoch: 91  ######### Train Loss: 0.0001234450173797086  ######### Relative L2 Test Norm: 13.863251686096191\n",
      "Output batch pred: tensor([[[0.6859],\n",
      "         [0.9205],\n",
      "         [0.9971],\n",
      "         [0.9975],\n",
      "         [0.0424],\n",
      "         [0.9980],\n",
      "         [1.0009],\n",
      "         [0.4614],\n",
      "         [0.9826],\n",
      "         [1.0028],\n",
      "         [0.7905],\n",
      "         [1.0013],\n",
      "         [1.0018],\n",
      "         [1.0008],\n",
      "         [0.2055],\n",
      "         [0.0381],\n",
      "         [0.2510],\n",
      "         [0.5108],\n",
      "         [0.0137],\n",
      "         [0.9922],\n",
      "         [0.9937],\n",
      "         [0.5066],\n",
      "         [0.9931],\n",
      "         [0.9958],\n",
      "         [0.9982],\n",
      "         [0.8491],\n",
      "         [0.9898],\n",
      "         [0.4667],\n",
      "         [0.3680],\n",
      "         [1.0009],\n",
      "         [0.5006],\n",
      "         [0.9970],\n",
      "         [0.2497],\n",
      "         [0.4570],\n",
      "         [0.4490],\n",
      "         [0.9962],\n",
      "         [0.9973],\n",
      "         [0.4441],\n",
      "         [0.9986],\n",
      "         [0.9988],\n",
      "         [0.9971],\n",
      "         [0.9832],\n",
      "         [0.9974],\n",
      "         [0.9831],\n",
      "         [0.5388],\n",
      "         [0.9962],\n",
      "         [0.9954],\n",
      "         [0.9966],\n",
      "         [0.3601],\n",
      "         [0.9995],\n",
      "         [0.3757],\n",
      "         [0.7720],\n",
      "         [0.9997],\n",
      "         [0.8156],\n",
      "         [0.0332],\n",
      "         [0.9932],\n",
      "         [0.2292],\n",
      "         [0.4316],\n",
      "         [0.9928],\n",
      "         [0.9928],\n",
      "         [0.9955],\n",
      "         [0.4413],\n",
      "         [1.0003],\n",
      "         [0.3729],\n",
      "         [1.0021],\n",
      "         [1.0023],\n",
      "         [1.0025],\n",
      "         [0.0527],\n",
      "         [0.9982],\n",
      "         [0.4936],\n",
      "         [0.4987],\n",
      "         [0.9922],\n",
      "         [0.9928],\n",
      "         [0.9920],\n",
      "         [0.0383],\n",
      "         [0.6090],\n",
      "         [0.5535],\n",
      "         [0.9975],\n",
      "         [0.4679],\n",
      "         [0.0357],\n",
      "         [1.0004],\n",
      "         [1.0002],\n",
      "         [0.9985],\n",
      "         [0.9974],\n",
      "         [0.9982],\n",
      "         [0.9554],\n",
      "         [0.3768],\n",
      "         [0.9585],\n",
      "         [0.9949],\n",
      "         [0.1636],\n",
      "         [0.2453],\n",
      "         [0.9923],\n",
      "         [0.0498],\n",
      "         [0.9936],\n",
      "         [0.9955],\n",
      "         [0.9247],\n",
      "         [1.0006],\n",
      "         [1.0011],\n",
      "         [1.0034],\n",
      "         [1.0027],\n",
      "         [1.0031],\n",
      "         [0.9660],\n",
      "         [0.9984],\n",
      "         [0.9961],\n",
      "         [0.2419],\n",
      "         [0.9919],\n",
      "         [0.9892],\n",
      "         [0.9899],\n",
      "         [0.9925],\n",
      "         [0.6485],\n",
      "         [0.9960],\n",
      "         [0.9962],\n",
      "         [0.5363],\n",
      "         [1.0024],\n",
      "         [1.0028],\n",
      "         [1.0022],\n",
      "         [0.9980],\n",
      "         [0.8604],\n",
      "         [0.9951],\n",
      "         [0.0364],\n",
      "         [0.3762],\n",
      "         [0.9916],\n",
      "         [0.9936],\n",
      "         [0.8491],\n",
      "         [0.9925],\n",
      "         [0.9158],\n",
      "         [0.3718],\n",
      "         [0.2433],\n",
      "         [0.9997],\n",
      "         [1.0001],\n",
      "         [0.5077],\n",
      "         [0.2416],\n",
      "         [1.0001],\n",
      "         [0.7469],\n",
      "         [0.9993],\n",
      "         [1.0008],\n",
      "         [0.9973],\n",
      "         [1.0008],\n",
      "         [0.9872],\n",
      "         [0.9990],\n",
      "         [0.3461],\n",
      "         [0.9992],\n",
      "         [0.3688],\n",
      "         [0.5220],\n",
      "         [0.8674],\n",
      "         [0.9988],\n",
      "         [0.9993],\n",
      "         [0.6810],\n",
      "         [0.9995],\n",
      "         [0.9637],\n",
      "         [0.9990],\n",
      "         [0.9978],\n",
      "         [0.7232],\n",
      "         [0.3450],\n",
      "         [0.9981],\n",
      "         [0.9985],\n",
      "         [0.5160],\n",
      "         [0.9943],\n",
      "         [0.9973],\n",
      "         [0.5081],\n",
      "         [0.3585],\n",
      "         [0.9947],\n",
      "         [0.9960],\n",
      "         [0.2540],\n",
      "         [0.9961],\n",
      "         [0.4480],\n",
      "         [0.9923],\n",
      "         [0.9979],\n",
      "         [0.9992],\n",
      "         [0.5058],\n",
      "         [0.4495],\n",
      "         [1.0005],\n",
      "         [0.9380],\n",
      "         [0.9997],\n",
      "         [0.9992],\n",
      "         [0.9984],\n",
      "         [0.9019],\n",
      "         [0.9950]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.6628],\n",
      "        [0.9009],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.0335],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [0.4611],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.0247],\n",
      "        [0.2735],\n",
      "        [0.5151],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.9819],\n",
      "        [0.4645],\n",
      "        [0.3753],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [0.9996],\n",
      "        [0.2686],\n",
      "        [0.4642],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.5334],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.3747],\n",
      "        [0.9999],\n",
      "        [0.3875],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.0174],\n",
      "        [0.9966],\n",
      "        [0.2518],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.5945],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9420],\n",
      "        [0.3912],\n",
      "        [0.9520],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.2610],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.9994],\n",
      "        [0.9959],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.3840],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5030],\n",
      "        [0.2547],\n",
      "        [0.9999],\n",
      "        [0.7129],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.5165],\n",
      "        [0.8379],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.9999],\n",
      "        [0.9490],\n",
      "        [0.9995],\n",
      "        [0.9999],\n",
      "        [0.6920],\n",
      "        [0.3575],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.5139],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.4527],\n",
      "        [0.9997],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.8761],\n",
      "        [0.9998]])\n",
      "######### Epoch: 92  ######### Train Loss: 0.00013214413775131106  ######### Relative L2 Test Norm: 14.151371955871582\n",
      "Output batch pred: tensor([[[0.9960],\n",
      "         [0.2386],\n",
      "         [0.9811],\n",
      "         [0.9958],\n",
      "         [0.9962],\n",
      "         [0.9971],\n",
      "         [0.0349],\n",
      "         [0.4484],\n",
      "         [0.9978],\n",
      "         [0.6764],\n",
      "         [0.9978],\n",
      "         [0.9978],\n",
      "         [0.4365],\n",
      "         [0.3618],\n",
      "         [0.9960],\n",
      "         [0.4382],\n",
      "         [0.0432],\n",
      "         [0.9921],\n",
      "         [0.9740],\n",
      "         [0.0368],\n",
      "         [0.5488],\n",
      "         [0.0385],\n",
      "         [0.9948],\n",
      "         [0.9957],\n",
      "         [0.7821],\n",
      "         [0.9969],\n",
      "         [0.9972],\n",
      "         [0.9964],\n",
      "         [0.9981],\n",
      "         [0.9987],\n",
      "         [0.9623],\n",
      "         [0.3639],\n",
      "         [0.4995],\n",
      "         [0.2505],\n",
      "         [0.0352],\n",
      "         [0.9998],\n",
      "         [0.9994],\n",
      "         [0.9979],\n",
      "         [0.2013],\n",
      "         [0.9974],\n",
      "         [0.9968],\n",
      "         [0.2299],\n",
      "         [0.5080],\n",
      "         [0.4570],\n",
      "         [0.9912],\n",
      "         [0.9935],\n",
      "         [0.3749],\n",
      "         [0.7375],\n",
      "         [0.5130],\n",
      "         [0.7160],\n",
      "         [0.9935],\n",
      "         [0.9941],\n",
      "         [0.9963],\n",
      "         [0.2531],\n",
      "         [0.9973],\n",
      "         [0.9975],\n",
      "         [0.7688],\n",
      "         [0.0497],\n",
      "         [0.9945],\n",
      "         [0.9953],\n",
      "         [0.4955],\n",
      "         [0.3547],\n",
      "         [0.4556],\n",
      "         [0.9960],\n",
      "         [0.9958],\n",
      "         [0.3718],\n",
      "         [0.9655],\n",
      "         [1.0025],\n",
      "         [1.0023],\n",
      "         [0.9431],\n",
      "         [1.0014],\n",
      "         [1.0019],\n",
      "         [0.9994],\n",
      "         [0.9968],\n",
      "         [0.3396],\n",
      "         [0.9933],\n",
      "         [0.9918],\n",
      "         [0.9933],\n",
      "         [0.9919],\n",
      "         [0.9961],\n",
      "         [0.9944],\n",
      "         [0.9043],\n",
      "         [0.0500],\n",
      "         [1.0013],\n",
      "         [0.8631],\n",
      "         [1.0000],\n",
      "         [0.9983],\n",
      "         [0.9976],\n",
      "         [0.5415],\n",
      "         [0.3665],\n",
      "         [0.3404],\n",
      "         [0.2414],\n",
      "         [0.9963],\n",
      "         [0.9958],\n",
      "         [0.8448],\n",
      "         [0.9962],\n",
      "         [0.9970],\n",
      "         [0.9960],\n",
      "         [0.4460],\n",
      "         [0.9953],\n",
      "         [0.9843],\n",
      "         [0.9965],\n",
      "         [0.9962],\n",
      "         [0.9144],\n",
      "         [0.9958],\n",
      "         [0.9944],\n",
      "         [0.4512],\n",
      "         [0.0192],\n",
      "         [0.9927],\n",
      "         [0.9916],\n",
      "         [0.5227],\n",
      "         [0.4341],\n",
      "         [0.9952],\n",
      "         [0.6875],\n",
      "         [0.9978],\n",
      "         [0.9946],\n",
      "         [0.5148],\n",
      "         [0.8585],\n",
      "         [0.9995],\n",
      "         [0.9985],\n",
      "         [0.2594],\n",
      "         [0.6542],\n",
      "         [0.9939],\n",
      "         [0.9951],\n",
      "         [0.9947],\n",
      "         [0.9947],\n",
      "         [0.4502],\n",
      "         [0.2505],\n",
      "         [0.9951],\n",
      "         [0.9954],\n",
      "         [0.9244],\n",
      "         [0.9986],\n",
      "         [0.0499],\n",
      "         [0.9972],\n",
      "         [0.9238],\n",
      "         [0.9975],\n",
      "         [0.9962],\n",
      "         [0.8645],\n",
      "         [0.4618],\n",
      "         [0.9563],\n",
      "         [0.1657],\n",
      "         [0.9983],\n",
      "         [0.9870],\n",
      "         [0.9984],\n",
      "         [0.9996],\n",
      "         [0.5222],\n",
      "         [0.9633],\n",
      "         [0.9979],\n",
      "         [0.5027],\n",
      "         [0.5044],\n",
      "         [0.9962],\n",
      "         [0.9979],\n",
      "         [0.9966],\n",
      "         [0.9988],\n",
      "         [0.9987],\n",
      "         [0.2360],\n",
      "         [0.9999],\n",
      "         [0.9868],\n",
      "         [1.0001],\n",
      "         [1.0011],\n",
      "         [1.0009],\n",
      "         [1.0019],\n",
      "         [0.8205],\n",
      "         [1.0013],\n",
      "         [1.0023],\n",
      "         [0.6165],\n",
      "         [0.5086],\n",
      "         [1.0026],\n",
      "         [1.0005],\n",
      "         [0.3645],\n",
      "         [0.3776],\n",
      "         [0.5182],\n",
      "         [0.9986],\n",
      "         [1.0002],\n",
      "         [1.0002],\n",
      "         [0.3833],\n",
      "         [0.9961],\n",
      "         [0.9986]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.2577],\n",
      "        [0.9814],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.4552],\n",
      "        [0.9994],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4454],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.0288],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [0.0209],\n",
      "        [0.5463],\n",
      "        [0.0247],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9490],\n",
      "        [0.3747],\n",
      "        [0.4988],\n",
      "        [0.2646],\n",
      "        [0.0142],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.2518],\n",
      "        [0.5108],\n",
      "        [0.4642],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.7129],\n",
      "        [0.5151],\n",
      "        [0.6920],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.0335],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [0.3728],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.3840],\n",
      "        [0.9520],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.5334],\n",
      "        [0.3808],\n",
      "        [0.3573],\n",
      "        [0.2610],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9997],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.9999],\n",
      "        [0.9956],\n",
      "        [0.5080],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.6327],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.8379],\n",
      "        [0.4668],\n",
      "        [0.9420],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9515],\n",
      "        [0.9997],\n",
      "        [0.5030],\n",
      "        [0.5054],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.9999],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.5945],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.3875],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9998]])\n",
      "######### Epoch: 93  ######### Train Loss: 0.00013594070333056152  ######### Relative L2 Test Norm: 14.035595893859863\n",
      "Output batch pred: tensor([[[0.9965],\n",
      "         [0.6545],\n",
      "         [0.4596],\n",
      "         [1.0021],\n",
      "         [0.9911],\n",
      "         [0.0319],\n",
      "         [1.0048],\n",
      "         [1.0045],\n",
      "         [0.5489],\n",
      "         [0.5235],\n",
      "         [1.0000],\n",
      "         [0.9995],\n",
      "         [0.9854],\n",
      "         [0.9978],\n",
      "         [0.9964],\n",
      "         [0.2513],\n",
      "         [0.8137],\n",
      "         [0.4446],\n",
      "         [0.9988],\n",
      "         [0.9643],\n",
      "         [0.9984],\n",
      "         [0.7239],\n",
      "         [0.9192],\n",
      "         [0.0410],\n",
      "         [0.9936],\n",
      "         [0.9954],\n",
      "         [0.9939],\n",
      "         [0.8981],\n",
      "         [0.9943],\n",
      "         [0.3688],\n",
      "         [0.3562],\n",
      "         [0.9939],\n",
      "         [0.9794],\n",
      "         [0.0342],\n",
      "         [0.9590],\n",
      "         [0.9964],\n",
      "         [0.7817],\n",
      "         [0.9963],\n",
      "         [0.9961],\n",
      "         [0.9962],\n",
      "         [0.9960],\n",
      "         [0.8418],\n",
      "         [0.3573],\n",
      "         [0.9946],\n",
      "         [0.9955],\n",
      "         [0.9943],\n",
      "         [0.5280],\n",
      "         [0.4612],\n",
      "         [0.2444],\n",
      "         [0.5516],\n",
      "         [0.5022],\n",
      "         [0.9968],\n",
      "         [0.3418],\n",
      "         [0.9963],\n",
      "         [0.9979],\n",
      "         [0.9619],\n",
      "         [0.3722],\n",
      "         [0.9993],\n",
      "         [0.4627],\n",
      "         [0.3831],\n",
      "         [0.4989],\n",
      "         [0.9980],\n",
      "         [0.0489],\n",
      "         [0.9959],\n",
      "         [0.6101],\n",
      "         [0.9963],\n",
      "         [0.5116],\n",
      "         [0.5008],\n",
      "         [0.9962],\n",
      "         [0.2369],\n",
      "         [0.6814],\n",
      "         [1.0004],\n",
      "         [0.7748],\n",
      "         [1.0009],\n",
      "         [0.4549],\n",
      "         [0.8577],\n",
      "         [1.0001],\n",
      "         [0.9995],\n",
      "         [0.9241],\n",
      "         [0.1623],\n",
      "         [0.9960],\n",
      "         [0.9960],\n",
      "         [0.9948],\n",
      "         [0.9942],\n",
      "         [0.3620],\n",
      "         [0.9922],\n",
      "         [0.4349],\n",
      "         [0.9940],\n",
      "         [0.3593],\n",
      "         [0.9960],\n",
      "         [0.9961],\n",
      "         [0.9219],\n",
      "         [0.9982],\n",
      "         [0.9975],\n",
      "         [0.9969],\n",
      "         [0.9970],\n",
      "         [0.9974],\n",
      "         [0.4615],\n",
      "         [0.9974],\n",
      "         [0.5051],\n",
      "         [0.9972],\n",
      "         [0.9969],\n",
      "         [0.9971],\n",
      "         [0.9992],\n",
      "         [0.9997],\n",
      "         [0.9978],\n",
      "         [0.9994],\n",
      "         [0.5065],\n",
      "         [0.9981],\n",
      "         [0.9938],\n",
      "         [0.9943],\n",
      "         [0.9933],\n",
      "         [0.2428],\n",
      "         [0.9906],\n",
      "         [0.9930],\n",
      "         [0.9928],\n",
      "         [0.4417],\n",
      "         [0.3598],\n",
      "         [0.0255],\n",
      "         [0.9985],\n",
      "         [0.5229],\n",
      "         [1.0010],\n",
      "         [1.0018],\n",
      "         [0.5177],\n",
      "         [0.2141],\n",
      "         [1.0018],\n",
      "         [0.9992],\n",
      "         [0.0552],\n",
      "         [0.0466],\n",
      "         [0.9362],\n",
      "         [0.9979],\n",
      "         [0.9975],\n",
      "         [0.3440],\n",
      "         [0.9940],\n",
      "         [0.9955],\n",
      "         [0.0444],\n",
      "         [0.9964],\n",
      "         [0.8634],\n",
      "         [0.9959],\n",
      "         [0.9950],\n",
      "         [0.9940],\n",
      "         [0.4457],\n",
      "         [0.9928],\n",
      "         [0.9912],\n",
      "         [0.9917],\n",
      "         [0.4305],\n",
      "         [0.9921],\n",
      "         [0.9910],\n",
      "         [0.9930],\n",
      "         [0.9752],\n",
      "         [0.2539],\n",
      "         [0.9947],\n",
      "         [0.7413],\n",
      "         [0.6872],\n",
      "         [0.9925],\n",
      "         [0.9942],\n",
      "         [0.2469],\n",
      "         [0.9922],\n",
      "         [0.9930],\n",
      "         [0.9930],\n",
      "         [0.9932],\n",
      "         [0.9933],\n",
      "         [0.9957],\n",
      "         [0.2404],\n",
      "         [0.9857],\n",
      "         [0.0397],\n",
      "         [1.0002],\n",
      "         [1.0006],\n",
      "         [0.9974],\n",
      "         [0.5212],\n",
      "         [0.9983],\n",
      "         [0.9969],\n",
      "         [0.8567],\n",
      "         [0.3751],\n",
      "         [0.9520],\n",
      "         [0.9932],\n",
      "         [0.2346],\n",
      "         [0.9951]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9994],\n",
      "        [0.6327],\n",
      "        [0.4611],\n",
      "        [0.9998],\n",
      "        [0.9819],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [0.7820],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9997],\n",
      "        [0.6920],\n",
      "        [0.8933],\n",
      "        [0.0247],\n",
      "        [0.9956],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.8761],\n",
      "        [0.9999],\n",
      "        [0.3875],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.0174],\n",
      "        [0.9520],\n",
      "        [0.9998],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.4668],\n",
      "        [0.2610],\n",
      "        [0.5463],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.3930],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [0.0335],\n",
      "        [0.9999],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.9997],\n",
      "        [0.4552],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.1762],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.9999],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.4503],\n",
      "        [0.3728],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.2208],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.0288],\n",
      "        [0.9164],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [0.3575],\n",
      "        [0.9962],\n",
      "        [0.9999],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.4580],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.2735],\n",
      "        [0.9999],\n",
      "        [0.7129],\n",
      "        [0.6628],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.2577],\n",
      "        [0.9820],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.3912],\n",
      "        [0.9420],\n",
      "        [0.9996],\n",
      "        [0.2547],\n",
      "        [0.9997]])\n",
      "######### Epoch: 94  ######### Train Loss: 0.0001416653540218249  ######### Relative L2 Test Norm: 14.343123435974121\n",
      "Output batch pred: tensor([[[0.9180],\n",
      "         [0.9935],\n",
      "         [0.9916],\n",
      "         [0.5325],\n",
      "         [0.9804],\n",
      "         [0.9910],\n",
      "         [0.6067],\n",
      "         [0.9940],\n",
      "         [0.0501],\n",
      "         [0.9974],\n",
      "         [0.3777],\n",
      "         [0.9594],\n",
      "         [0.0410],\n",
      "         [0.5006],\n",
      "         [0.9926],\n",
      "         [0.4921],\n",
      "         [0.9939],\n",
      "         [0.9942],\n",
      "         [0.9960],\n",
      "         [0.9858],\n",
      "         [0.9956],\n",
      "         [0.2627],\n",
      "         [0.5117],\n",
      "         [1.0010],\n",
      "         [0.9994],\n",
      "         [0.5202],\n",
      "         [0.7679],\n",
      "         [0.9941],\n",
      "         [0.4517],\n",
      "         [0.4392],\n",
      "         [0.9575],\n",
      "         [0.9927],\n",
      "         [0.9950],\n",
      "         [0.9945],\n",
      "         [0.9959],\n",
      "         [0.9939],\n",
      "         [0.9950],\n",
      "         [0.9943],\n",
      "         [0.8415],\n",
      "         [0.9524],\n",
      "         [0.9952],\n",
      "         [0.4622],\n",
      "         [0.4990],\n",
      "         [0.9958],\n",
      "         [0.4584],\n",
      "         [0.3712],\n",
      "         [1.0005],\n",
      "         [0.9997],\n",
      "         [0.9987],\n",
      "         [0.9971],\n",
      "         [0.9024],\n",
      "         [0.9962],\n",
      "         [0.9961],\n",
      "         [0.9981],\n",
      "         [1.0006],\n",
      "         [0.9673],\n",
      "         [1.0018],\n",
      "         [1.0017],\n",
      "         [1.0021],\n",
      "         [0.9816],\n",
      "         [0.9970],\n",
      "         [0.9966],\n",
      "         [0.9934],\n",
      "         [0.9922],\n",
      "         [0.9894],\n",
      "         [0.2291],\n",
      "         [0.9911],\n",
      "         [0.9922],\n",
      "         [0.4464],\n",
      "         [0.5519],\n",
      "         [0.9943],\n",
      "         [0.9944],\n",
      "         [0.0408],\n",
      "         [0.8590],\n",
      "         [0.9965],\n",
      "         [0.9972],\n",
      "         [0.9976],\n",
      "         [0.9976],\n",
      "         [0.5199],\n",
      "         [0.5181],\n",
      "         [0.5347],\n",
      "         [0.9972],\n",
      "         [0.2577],\n",
      "         [0.9830],\n",
      "         [0.9951],\n",
      "         [0.9919],\n",
      "         [0.9184],\n",
      "         [0.9914],\n",
      "         [0.1631],\n",
      "         [0.9927],\n",
      "         [0.9942],\n",
      "         [0.9955],\n",
      "         [0.5097],\n",
      "         [0.9981],\n",
      "         [0.9982],\n",
      "         [0.3649],\n",
      "         [0.9957],\n",
      "         [0.9959],\n",
      "         [0.3577],\n",
      "         [0.9941],\n",
      "         [0.9940],\n",
      "         [0.2453],\n",
      "         [0.8616],\n",
      "         [0.9804],\n",
      "         [0.9938],\n",
      "         [0.4489],\n",
      "         [0.3456],\n",
      "         [0.9994],\n",
      "         [1.0000],\n",
      "         [0.9990],\n",
      "         [1.0004],\n",
      "         [0.8205],\n",
      "         [1.0014],\n",
      "         [1.0014],\n",
      "         [0.0259],\n",
      "         [0.9991],\n",
      "         [0.2576],\n",
      "         [0.9953],\n",
      "         [0.3387],\n",
      "         [0.9898],\n",
      "         [0.7739],\n",
      "         [0.9880],\n",
      "         [0.9915],\n",
      "         [0.9919],\n",
      "         [0.6722],\n",
      "         [0.9342],\n",
      "         [0.9991],\n",
      "         [0.4643],\n",
      "         [1.0007],\n",
      "         [0.4453],\n",
      "         [0.6539],\n",
      "         [0.9968],\n",
      "         [0.9956],\n",
      "         [0.9939],\n",
      "         [0.8458],\n",
      "         [0.0394],\n",
      "         [0.9926],\n",
      "         [0.9941],\n",
      "         [0.7187],\n",
      "         [0.2445],\n",
      "         [0.6930],\n",
      "         [1.0003],\n",
      "         [1.0034],\n",
      "         [1.0030],\n",
      "         [1.0028],\n",
      "         [1.0000],\n",
      "         [1.0017],\n",
      "         [1.0014],\n",
      "         [0.9999],\n",
      "         [0.2030],\n",
      "         [0.0505],\n",
      "         [0.4977],\n",
      "         [0.9937],\n",
      "         [0.5040],\n",
      "         [0.0304],\n",
      "         [0.9904],\n",
      "         [0.2232],\n",
      "         [0.9892],\n",
      "         [0.9922],\n",
      "         [0.9953],\n",
      "         [0.9976],\n",
      "         [0.3712],\n",
      "         [0.3718],\n",
      "         [0.4448],\n",
      "         [1.0013],\n",
      "         [0.4670],\n",
      "         [0.7441],\n",
      "         [0.0464],\n",
      "         [0.0337],\n",
      "         [0.9931],\n",
      "         [0.9939],\n",
      "         [0.9945],\n",
      "         [0.9126],\n",
      "         [0.3752],\n",
      "         [0.3758],\n",
      "         [0.2371],\n",
      "         [0.3617],\n",
      "         [0.9968]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9009],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.5334],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [0.3875],\n",
      "        [0.9490],\n",
      "        [0.0288],\n",
      "        [0.5054],\n",
      "        [0.9999],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.9956],\n",
      "        [0.2729],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.4503],\n",
      "        [0.9520],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.4988],\n",
      "        [0.9962],\n",
      "        [0.4580],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9999],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.0209],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5151],\n",
      "        [0.5139],\n",
      "        [0.5245],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9044],\n",
      "        [0.9999],\n",
      "        [0.1762],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.8379],\n",
      "        [0.9814],\n",
      "        [0.9967],\n",
      "        [0.4527],\n",
      "        [0.3573],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.9966],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.9164],\n",
      "        [0.9996],\n",
      "        [0.4645],\n",
      "        [0.9999],\n",
      "        [0.4480],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.2610],\n",
      "        [0.6628],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.2208],\n",
      "        [0.0368],\n",
      "        [0.5030],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [0.0174],\n",
      "        [0.9996],\n",
      "        [0.2518],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.3808],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [0.7129],\n",
      "        [0.0247],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.8933],\n",
      "        [0.3930],\n",
      "        [0.3912],\n",
      "        [0.2547],\n",
      "        [0.3753],\n",
      "        [1.0000]])\n",
      "######### Epoch: 95  ######### Train Loss: 0.00012877261906396598  ######### Relative L2 Test Norm: 14.055331230163574\n",
      "Output batch pred: tensor([[[0.4503],\n",
      "         [0.9944],\n",
      "         [0.3655],\n",
      "         [0.9921],\n",
      "         [0.4580],\n",
      "         [0.3694],\n",
      "         [0.4451],\n",
      "         [0.9950],\n",
      "         [0.9955],\n",
      "         [0.6525],\n",
      "         [0.0496],\n",
      "         [0.9966],\n",
      "         [0.9955],\n",
      "         [0.9936],\n",
      "         [0.1664],\n",
      "         [0.9593],\n",
      "         [0.9965],\n",
      "         [0.8562],\n",
      "         [0.3717],\n",
      "         [0.5145],\n",
      "         [0.9965],\n",
      "         [0.9608],\n",
      "         [0.4414],\n",
      "         [0.9967],\n",
      "         [0.9967],\n",
      "         [0.9340],\n",
      "         [0.9926],\n",
      "         [0.7415],\n",
      "         [0.9762],\n",
      "         [0.0245],\n",
      "         [0.9954],\n",
      "         [0.9935],\n",
      "         [0.9961],\n",
      "         [0.9974],\n",
      "         [0.9989],\n",
      "         [1.0002],\n",
      "         [0.9999],\n",
      "         [0.9988],\n",
      "         [0.2602],\n",
      "         [0.9990],\n",
      "         [0.3665],\n",
      "         [0.6097],\n",
      "         [0.0365],\n",
      "         [0.9935],\n",
      "         [0.3380],\n",
      "         [0.5003],\n",
      "         [0.9777],\n",
      "         [0.4915],\n",
      "         [0.9858],\n",
      "         [0.9915],\n",
      "         [0.9907],\n",
      "         [0.9910],\n",
      "         [0.2393],\n",
      "         [0.2502],\n",
      "         [0.9938],\n",
      "         [0.4935],\n",
      "         [0.9931],\n",
      "         [0.9952],\n",
      "         [0.9924],\n",
      "         [0.9950],\n",
      "         [0.3590],\n",
      "         [0.9962],\n",
      "         [0.9963],\n",
      "         [0.3784],\n",
      "         [0.9959],\n",
      "         [0.9006],\n",
      "         [0.5186],\n",
      "         [0.2458],\n",
      "         [0.9980],\n",
      "         [0.9995],\n",
      "         [1.0007],\n",
      "         [1.0023],\n",
      "         [0.4597],\n",
      "         [1.0043],\n",
      "         [1.0040],\n",
      "         [1.0047],\n",
      "         [0.5630],\n",
      "         [0.4492],\n",
      "         [0.8495],\n",
      "         [0.9982],\n",
      "         [0.9963],\n",
      "         [0.4603],\n",
      "         [0.7655],\n",
      "         [0.9934],\n",
      "         [0.7781],\n",
      "         [0.9920],\n",
      "         [0.6848],\n",
      "         [0.9936],\n",
      "         [0.5114],\n",
      "         [0.9936],\n",
      "         [0.9914],\n",
      "         [0.8080],\n",
      "         [0.0341],\n",
      "         [0.9925],\n",
      "         [0.9928],\n",
      "         [0.9936],\n",
      "         [0.5372],\n",
      "         [0.0466],\n",
      "         [0.9973],\n",
      "         [0.9979],\n",
      "         [0.9976],\n",
      "         [0.9221],\n",
      "         [0.9225],\n",
      "         [0.9949],\n",
      "         [0.2351],\n",
      "         [0.9923],\n",
      "         [0.9936],\n",
      "         [0.9939],\n",
      "         [0.9939],\n",
      "         [0.9929],\n",
      "         [0.9935],\n",
      "         [0.9965],\n",
      "         [0.9975],\n",
      "         [0.9976],\n",
      "         [0.9957],\n",
      "         [0.2080],\n",
      "         [0.9962],\n",
      "         [0.9940],\n",
      "         [0.0399],\n",
      "         [0.9919],\n",
      "         [0.5003],\n",
      "         [0.9813],\n",
      "         [0.2435],\n",
      "         [0.9962],\n",
      "         [0.7218],\n",
      "         [0.4403],\n",
      "         [0.4631],\n",
      "         [0.9972],\n",
      "         [0.9982],\n",
      "         [0.9970],\n",
      "         [0.2596],\n",
      "         [0.5310],\n",
      "         [0.9959],\n",
      "         [0.9950],\n",
      "         [0.9131],\n",
      "         [0.0421],\n",
      "         [0.8494],\n",
      "         [0.0472],\n",
      "         [0.3577],\n",
      "         [0.9943],\n",
      "         [0.9943],\n",
      "         [0.8615],\n",
      "         [0.9932],\n",
      "         [0.9961],\n",
      "         [0.9949],\n",
      "         [0.6758],\n",
      "         [0.5051],\n",
      "         [0.9606],\n",
      "         [0.9961],\n",
      "         [0.9962],\n",
      "         [0.9971],\n",
      "         [0.9962],\n",
      "         [0.9968],\n",
      "         [0.4532],\n",
      "         [0.3772],\n",
      "         [0.9546],\n",
      "         [0.5080],\n",
      "         [0.9967],\n",
      "         [0.9972],\n",
      "         [0.9988],\n",
      "         [0.9993],\n",
      "         [0.9984],\n",
      "         [0.9998],\n",
      "         [0.9993],\n",
      "         [0.9980],\n",
      "         [0.9987],\n",
      "         [0.3463],\n",
      "         [0.3618],\n",
      "         [0.9956],\n",
      "         [0.9830],\n",
      "         [0.2373],\n",
      "         [0.9976],\n",
      "         [0.9962],\n",
      "         [0.9977],\n",
      "         [0.9849],\n",
      "         [0.5018],\n",
      "         [0.9964],\n",
      "         [0.0253]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.4580],\n",
      "        [0.9997],\n",
      "        [0.3808],\n",
      "        [0.9966],\n",
      "        [0.4642],\n",
      "        [0.3840],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6327],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.1762],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.3875],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.9515],\n",
      "        [0.4503],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.9724],\n",
      "        [0.0142],\n",
      "        [0.9994],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.2729],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.5945],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.5080],\n",
      "        [0.9820],\n",
      "        [0.5009],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.5165],\n",
      "        [0.2610],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [0.5463],\n",
      "        [0.4480],\n",
      "        [0.8139],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.4668],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.9998],\n",
      "        [0.5139],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.5334],\n",
      "        [0.0368],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.9044],\n",
      "        [0.9996],\n",
      "        [0.2518],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.9804],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.4454],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2735],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [0.0288],\n",
      "        [0.8223],\n",
      "        [0.0383],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.8379],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.5054],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [0.3930],\n",
      "        [0.9420],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.3573],\n",
      "        [0.3728],\n",
      "        [0.9967],\n",
      "        [0.9814],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.0000]])\n",
      "######### Epoch: 96  ######### Train Loss: 0.00011899243691004813  ######### Relative L2 Test Norm: 14.172813415527344\n",
      "Output batch pred: tensor([[[0.6726],\n",
      "         [0.9976],\n",
      "         [0.9982],\n",
      "         [1.0008],\n",
      "         [0.9994],\n",
      "         [0.5487],\n",
      "         [0.2421],\n",
      "         [0.0412],\n",
      "         [0.9621],\n",
      "         [0.9960],\n",
      "         [0.9932],\n",
      "         [0.9940],\n",
      "         [0.9928],\n",
      "         [0.9934],\n",
      "         [0.9907],\n",
      "         [0.9936],\n",
      "         [0.9814],\n",
      "         [0.9955],\n",
      "         [0.9935],\n",
      "         [0.9928],\n",
      "         [0.4570],\n",
      "         [0.0486],\n",
      "         [0.9946],\n",
      "         [0.9946],\n",
      "         [0.3784],\n",
      "         [0.9950],\n",
      "         [0.9960],\n",
      "         [0.4497],\n",
      "         [0.4618],\n",
      "         [0.4477],\n",
      "         [0.3760],\n",
      "         [0.9961],\n",
      "         [0.9957],\n",
      "         [0.9948],\n",
      "         [0.9957],\n",
      "         [0.9942],\n",
      "         [0.7437],\n",
      "         [0.9977],\n",
      "         [0.9229],\n",
      "         [0.9862],\n",
      "         [0.9983],\n",
      "         [0.9955],\n",
      "         [0.9960],\n",
      "         [0.9927],\n",
      "         [0.0455],\n",
      "         [0.3594],\n",
      "         [0.9907],\n",
      "         [0.9901],\n",
      "         [0.5024],\n",
      "         [0.9926],\n",
      "         [0.9951],\n",
      "         [0.9960],\n",
      "         [0.9992],\n",
      "         [0.9969],\n",
      "         [0.4476],\n",
      "         [0.9984],\n",
      "         [0.9988],\n",
      "         [0.9928],\n",
      "         [0.6107],\n",
      "         [0.2561],\n",
      "         [0.9949],\n",
      "         [0.9941],\n",
      "         [0.9954],\n",
      "         [0.9962],\n",
      "         [0.9963],\n",
      "         [0.9983],\n",
      "         [0.8178],\n",
      "         [0.5101],\n",
      "         [0.9988],\n",
      "         [0.9965],\n",
      "         [0.9966],\n",
      "         [0.9965],\n",
      "         [0.8624],\n",
      "         [0.0242],\n",
      "         [0.5010],\n",
      "         [0.9804],\n",
      "         [0.2395],\n",
      "         [0.0384],\n",
      "         [0.9151],\n",
      "         [0.9929],\n",
      "         [0.9947],\n",
      "         [0.8505],\n",
      "         [0.6850],\n",
      "         [0.3389],\n",
      "         [0.9921],\n",
      "         [0.5112],\n",
      "         [0.9711],\n",
      "         [0.3659],\n",
      "         [0.9923],\n",
      "         [0.9919],\n",
      "         [0.1642],\n",
      "         [0.9957],\n",
      "         [0.5004],\n",
      "         [0.9985],\n",
      "         [0.9985],\n",
      "         [1.0001],\n",
      "         [0.9972],\n",
      "         [0.9975],\n",
      "         [0.3666],\n",
      "         [0.4474],\n",
      "         [0.3815],\n",
      "         [0.9972],\n",
      "         [0.4960],\n",
      "         [0.9936],\n",
      "         [0.9924],\n",
      "         [0.9933],\n",
      "         [0.9921],\n",
      "         [0.9559],\n",
      "         [0.3584],\n",
      "         [0.4366],\n",
      "         [0.9944],\n",
      "         [0.9933],\n",
      "         [0.9936],\n",
      "         [0.9937],\n",
      "         [0.9937],\n",
      "         [0.9946],\n",
      "         [0.5135],\n",
      "         [0.8550],\n",
      "         [0.2059],\n",
      "         [0.3434],\n",
      "         [0.9550],\n",
      "         [0.2573],\n",
      "         [1.0002],\n",
      "         [0.8498],\n",
      "         [1.0029],\n",
      "         [1.0028],\n",
      "         [0.5174],\n",
      "         [1.0014],\n",
      "         [0.5105],\n",
      "         [1.0009],\n",
      "         [0.9977],\n",
      "         [0.0332],\n",
      "         [0.7190],\n",
      "         [0.9943],\n",
      "         [0.9925],\n",
      "         [0.6461],\n",
      "         [0.9917],\n",
      "         [0.9797],\n",
      "         [0.9942],\n",
      "         [0.9951],\n",
      "         [0.9944],\n",
      "         [0.9969],\n",
      "         [0.5531],\n",
      "         [0.9987],\n",
      "         [0.5205],\n",
      "         [0.2427],\n",
      "         [0.9968],\n",
      "         [0.0369],\n",
      "         [0.2521],\n",
      "         [0.2460],\n",
      "         [0.9955],\n",
      "         [0.9947],\n",
      "         [0.0374],\n",
      "         [0.9963],\n",
      "         [0.9217],\n",
      "         [0.9970],\n",
      "         [0.9975],\n",
      "         [0.9992],\n",
      "         [0.9627],\n",
      "         [0.4582],\n",
      "         [0.7850],\n",
      "         [0.0540],\n",
      "         [0.9976],\n",
      "         [0.7679],\n",
      "         [0.9957],\n",
      "         [0.2390],\n",
      "         [0.9943],\n",
      "         [0.9941],\n",
      "         [0.9934],\n",
      "         [0.8969],\n",
      "         [0.4520],\n",
      "         [0.9908],\n",
      "         [0.3587],\n",
      "         [0.3550],\n",
      "         [0.4557],\n",
      "         [0.5223],\n",
      "         [0.9267],\n",
      "         [0.9917]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.6555],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [0.2518],\n",
      "        [0.0209],\n",
      "        [0.9515],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.9995],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.4645],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3930],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.4642],\n",
      "        [0.4527],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9967],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.9819],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.0335],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [0.5945],\n",
      "        [0.2735],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.0000],\n",
      "        [0.5038],\n",
      "        [0.9814],\n",
      "        [0.2577],\n",
      "        [0.0247],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.6628],\n",
      "        [0.3573],\n",
      "        [0.9999],\n",
      "        [0.5151],\n",
      "        [0.9724],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.4503],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.9490],\n",
      "        [0.3780],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.8296],\n",
      "        [0.2208],\n",
      "        [0.3575],\n",
      "        [0.9420],\n",
      "        [0.2729],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.5080],\n",
      "        [0.9997],\n",
      "        [0.5030],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.5463],\n",
      "        [0.9998],\n",
      "        [0.5165],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.2686],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.4580],\n",
      "        [0.7540],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.8761],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.3728],\n",
      "        [0.4668],\n",
      "        [0.5245],\n",
      "        [0.9164],\n",
      "        [0.9997]])\n",
      "######### Epoch: 97  ######### Train Loss: 0.00012888947094324976  ######### Relative L2 Test Norm: 14.20162582397461\n",
      "Output batch pred: tensor([[[0.3670],\n",
      "         [0.9978],\n",
      "         [0.9968],\n",
      "         [0.9968],\n",
      "         [0.9934],\n",
      "         [0.9941],\n",
      "         [0.6520],\n",
      "         [0.9952],\n",
      "         [0.9944],\n",
      "         [0.0436],\n",
      "         [0.4995],\n",
      "         [0.3723],\n",
      "         [0.9886],\n",
      "         [0.9883],\n",
      "         [0.9869],\n",
      "         [0.7999],\n",
      "         [0.2227],\n",
      "         [0.9831],\n",
      "         [0.9857],\n",
      "         [0.9855],\n",
      "         [0.3529],\n",
      "         [0.9877],\n",
      "         [0.9904],\n",
      "         [0.0412],\n",
      "         [0.3801],\n",
      "         [0.9914],\n",
      "         [0.9936],\n",
      "         [0.9953],\n",
      "         [0.5424],\n",
      "         [0.9974],\n",
      "         [0.9570],\n",
      "         [1.0000],\n",
      "         [1.0013],\n",
      "         [0.3513],\n",
      "         [0.5401],\n",
      "         [1.0031],\n",
      "         [0.9996],\n",
      "         [0.9397],\n",
      "         [0.9988],\n",
      "         [0.9962],\n",
      "         [0.9958],\n",
      "         [0.9935],\n",
      "         [0.9924],\n",
      "         [0.9927],\n",
      "         [0.4323],\n",
      "         [0.0414],\n",
      "         [0.9938],\n",
      "         [0.3374],\n",
      "         [0.9203],\n",
      "         [0.9960],\n",
      "         [0.9967],\n",
      "         [0.9016],\n",
      "         [0.9949],\n",
      "         [0.6107],\n",
      "         [0.9959],\n",
      "         [0.9944],\n",
      "         [0.2412],\n",
      "         [0.2473],\n",
      "         [0.5137],\n",
      "         [0.4982],\n",
      "         [0.9914],\n",
      "         [0.9922],\n",
      "         [0.9918],\n",
      "         [0.9924],\n",
      "         [0.0373],\n",
      "         [0.9179],\n",
      "         [0.2021],\n",
      "         [0.9961],\n",
      "         [0.9973],\n",
      "         [0.9975],\n",
      "         [0.9966],\n",
      "         [0.9985],\n",
      "         [0.9979],\n",
      "         [0.9968],\n",
      "         [0.9973],\n",
      "         [0.3678],\n",
      "         [0.7678],\n",
      "         [0.9951],\n",
      "         [0.9975],\n",
      "         [0.4433],\n",
      "         [0.9983],\n",
      "         [0.9969],\n",
      "         [0.9970],\n",
      "         [0.9623],\n",
      "         [0.9978],\n",
      "         [0.9773],\n",
      "         [0.5005],\n",
      "         [0.9849],\n",
      "         [0.9947],\n",
      "         [0.9987],\n",
      "         [0.9986],\n",
      "         [0.2407],\n",
      "         [0.0248],\n",
      "         [0.3631],\n",
      "         [0.9870],\n",
      "         [0.7244],\n",
      "         [0.1665],\n",
      "         [0.4430],\n",
      "         [0.9958],\n",
      "         [0.5510],\n",
      "         [0.9919],\n",
      "         [0.9914],\n",
      "         [0.0339],\n",
      "         [0.9555],\n",
      "         [0.8469],\n",
      "         [0.9932],\n",
      "         [0.0434],\n",
      "         [0.5151],\n",
      "         [0.4949],\n",
      "         [0.9938],\n",
      "         [0.0538],\n",
      "         [0.0413],\n",
      "         [0.5108],\n",
      "         [0.3714],\n",
      "         [0.4488],\n",
      "         [0.9943],\n",
      "         [0.9129],\n",
      "         [0.9889],\n",
      "         [0.9939],\n",
      "         [0.9939],\n",
      "         [0.2545],\n",
      "         [0.6735],\n",
      "         [0.9927],\n",
      "         [0.9930],\n",
      "         [0.7802],\n",
      "         [0.9961],\n",
      "         [0.9961],\n",
      "         [0.9974],\n",
      "         [0.9982],\n",
      "         [0.9972],\n",
      "         [0.9959],\n",
      "         [0.9962],\n",
      "         [0.9952],\n",
      "         [0.3687],\n",
      "         [0.7389],\n",
      "         [0.9941],\n",
      "         [0.5058],\n",
      "         [0.9822],\n",
      "         [0.4626],\n",
      "         [0.9984],\n",
      "         [1.0004],\n",
      "         [1.0021],\n",
      "         [0.8668],\n",
      "         [0.4718],\n",
      "         [1.0026],\n",
      "         [1.0007],\n",
      "         [0.9985],\n",
      "         [0.4559],\n",
      "         [1.0002],\n",
      "         [0.9840],\n",
      "         [0.9976],\n",
      "         [0.9982],\n",
      "         [0.9973],\n",
      "         [0.4641],\n",
      "         [0.4572],\n",
      "         [0.5023],\n",
      "         [0.9913],\n",
      "         [0.2563],\n",
      "         [0.9565],\n",
      "         [0.9919],\n",
      "         [0.3593],\n",
      "         [0.9949],\n",
      "         [0.9942],\n",
      "         [0.5128],\n",
      "         [0.9994],\n",
      "         [1.0003],\n",
      "         [0.8688],\n",
      "         [0.6952],\n",
      "         [0.4550],\n",
      "         [0.2522],\n",
      "         [0.2576],\n",
      "         [0.9981],\n",
      "         [0.9956],\n",
      "         [0.8448],\n",
      "         [0.9968],\n",
      "         [0.9961],\n",
      "         [0.9960],\n",
      "         [0.9964]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.3780],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.5054],\n",
      "        [0.3912],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.2518],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.3930],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.3575],\n",
      "        [0.5245],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.9998],\n",
      "        [0.5945],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.2646],\n",
      "        [0.5165],\n",
      "        [0.5038],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.9009],\n",
      "        [0.2208],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3808],\n",
      "        [0.7391],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [0.5009],\n",
      "        [0.9819],\n",
      "        [0.9959],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.0000],\n",
      "        [0.3728],\n",
      "        [0.9820],\n",
      "        [0.6920],\n",
      "        [0.1762],\n",
      "        [0.4480],\n",
      "        [0.9997],\n",
      "        [0.5463],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.0142],\n",
      "        [0.9520],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.5151],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.0247],\n",
      "        [0.5139],\n",
      "        [0.3875],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.9956],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9804],\n",
      "        [0.4642],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.4645],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9962],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.4668],\n",
      "        [0.4611],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.8379],\n",
      "        [0.6628],\n",
      "        [0.4527],\n",
      "        [0.2610],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.8139],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998]])\n",
      "######### Epoch: 98  ######### Train Loss: 0.00013706267054658383  ######### Relative L2 Test Norm: 14.120138168334961\n",
      "Output batch pred: tensor([[[0.9908],\n",
      "         [0.9921],\n",
      "         [0.9926],\n",
      "         [0.9774],\n",
      "         [0.9940],\n",
      "         [0.0355],\n",
      "         [0.9944],\n",
      "         [0.9941],\n",
      "         [0.9941],\n",
      "         [0.3449],\n",
      "         [0.8611],\n",
      "         [0.8118],\n",
      "         [0.4997],\n",
      "         [0.9944],\n",
      "         [0.9962],\n",
      "         [0.9600],\n",
      "         [0.9964],\n",
      "         [0.9968],\n",
      "         [0.9966],\n",
      "         [0.6545],\n",
      "         [0.3659],\n",
      "         [0.9822],\n",
      "         [0.5178],\n",
      "         [0.9963],\n",
      "         [0.9974],\n",
      "         [0.9977],\n",
      "         [0.8490],\n",
      "         [0.9586],\n",
      "         [0.9989],\n",
      "         [0.9976],\n",
      "         [0.9035],\n",
      "         [0.4587],\n",
      "         [0.8509],\n",
      "         [0.9897],\n",
      "         [0.9895],\n",
      "         [0.9888],\n",
      "         [0.2389],\n",
      "         [0.9912],\n",
      "         [0.9932],\n",
      "         [0.4458],\n",
      "         [0.9950],\n",
      "         [0.9956],\n",
      "         [0.0406],\n",
      "         [0.9949],\n",
      "         [0.3792],\n",
      "         [0.9298],\n",
      "         [0.9788],\n",
      "         [0.6712],\n",
      "         [0.7638],\n",
      "         [0.9911],\n",
      "         [0.9939],\n",
      "         [0.9959],\n",
      "         [0.1684],\n",
      "         [0.9986],\n",
      "         [0.9981],\n",
      "         [0.9195],\n",
      "         [0.9801],\n",
      "         [0.9981],\n",
      "         [0.9971],\n",
      "         [0.9955],\n",
      "         [0.9943],\n",
      "         [0.5239],\n",
      "         [0.9547],\n",
      "         [0.9895],\n",
      "         [0.9899],\n",
      "         [0.9913],\n",
      "         [0.9898],\n",
      "         [0.4361],\n",
      "         [0.2455],\n",
      "         [0.2400],\n",
      "         [0.9917],\n",
      "         [0.9942],\n",
      "         [0.9951],\n",
      "         [0.9971],\n",
      "         [0.9963],\n",
      "         [0.3807],\n",
      "         [0.9980],\n",
      "         [0.9978],\n",
      "         [0.2623],\n",
      "         [0.9947],\n",
      "         [0.9961],\n",
      "         [0.9959],\n",
      "         [0.7416],\n",
      "         [0.0486],\n",
      "         [0.9984],\n",
      "         [0.0527],\n",
      "         [0.9991],\n",
      "         [0.9997],\n",
      "         [1.0014],\n",
      "         [0.5233],\n",
      "         [0.3766],\n",
      "         [0.9979],\n",
      "         [0.9959],\n",
      "         [0.9939],\n",
      "         [0.4432],\n",
      "         [0.0353],\n",
      "         [0.9946],\n",
      "         [0.9953],\n",
      "         [0.5022],\n",
      "         [0.4385],\n",
      "         [0.5058],\n",
      "         [0.9965],\n",
      "         [0.9978],\n",
      "         [0.2381],\n",
      "         [0.3585],\n",
      "         [0.9827],\n",
      "         [0.9936],\n",
      "         [0.9938],\n",
      "         [0.9930],\n",
      "         [0.7760],\n",
      "         [0.9934],\n",
      "         [0.9949],\n",
      "         [0.0464],\n",
      "         [0.5374],\n",
      "         [0.0355],\n",
      "         [0.9969],\n",
      "         [0.3774],\n",
      "         [0.9970],\n",
      "         [0.9217],\n",
      "         [0.5171],\n",
      "         [0.9963],\n",
      "         [0.9965],\n",
      "         [0.4468],\n",
      "         [0.9959],\n",
      "         [0.4530],\n",
      "         [0.9960],\n",
      "         [0.2529],\n",
      "         [0.9939],\n",
      "         [0.2352],\n",
      "         [0.9935],\n",
      "         [0.5488],\n",
      "         [0.9578],\n",
      "         [0.9943],\n",
      "         [0.4601],\n",
      "         [0.5055],\n",
      "         [0.9950],\n",
      "         [0.9945],\n",
      "         [0.6868],\n",
      "         [0.9939],\n",
      "         [0.9974],\n",
      "         [0.0458],\n",
      "         [0.9977],\n",
      "         [0.5122],\n",
      "         [0.3695],\n",
      "         [0.9972],\n",
      "         [0.9981],\n",
      "         [0.3676],\n",
      "         [0.3649],\n",
      "         [0.9968],\n",
      "         [0.9971],\n",
      "         [0.9936],\n",
      "         [0.9954],\n",
      "         [0.4974],\n",
      "         [0.7201],\n",
      "         [0.9970],\n",
      "         [0.9977],\n",
      "         [0.9978],\n",
      "         [0.9989],\n",
      "         [0.6148],\n",
      "         [0.2094],\n",
      "         [0.2601],\n",
      "         [0.0232],\n",
      "         [0.9996],\n",
      "         [0.9995],\n",
      "         [0.9957],\n",
      "         [0.9979],\n",
      "         [0.9982],\n",
      "         [0.5038],\n",
      "         [0.4620],\n",
      "         [0.9221],\n",
      "         [0.9973],\n",
      "         [0.3459],\n",
      "         [0.9950],\n",
      "         [0.8570],\n",
      "         [0.9941],\n",
      "         [0.4585],\n",
      "         [0.9875],\n",
      "         [0.9916]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.3575],\n",
      "        [0.8379],\n",
      "        [0.7820],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9520],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.6327],\n",
      "        [0.3753],\n",
      "        [0.9804],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.4611],\n",
      "        [0.8223],\n",
      "        [0.9959],\n",
      "        [0.9966],\n",
      "        [0.9997],\n",
      "        [0.2610],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9164],\n",
      "        [0.9820],\n",
      "        [0.6555],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.1762],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.9490],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.4480],\n",
      "        [0.2646],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.3875],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.3840],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4503],\n",
      "        [0.0142],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.4454],\n",
      "        [0.5054],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.3728],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.5334],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.9995],\n",
      "        [0.2518],\n",
      "        [0.9999],\n",
      "        [0.5463],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.5080],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.9997],\n",
      "        [0.5108],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.3747],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.4988],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.2208],\n",
      "        [0.2729],\n",
      "        [0.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5030],\n",
      "        [0.4645],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [0.9956],\n",
      "        [1.0000]])\n",
      "######### Epoch: 99  ######### Train Loss: 0.00011785849346779287  ######### Relative L2 Test Norm: 14.072036743164062\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "optimizer = Adam(fno.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "l = torch.nn.MSELoss()\n",
    "freq_print = 1\n",
    "for epoch in range(epochs):\n",
    "    train_mse = 0.0\n",
    "    for step, (input_batch, output_batch) in enumerate(training_set_tf0):\n",
    "        optimizer.zero_grad()\n",
    "        # print(input_batch.shape)\n",
    "        # print(fno(input_batch).shape)\n",
    "        output_pred_batch = fno(input_batch)\n",
    "        print(\"Output batch pred: {}\".format(output_pred_batch))\n",
    "        print(\"Output batch: {}\".format(output_batch))\n",
    "        loss_f = l(output_pred_batch, output_batch)\n",
    "        loss_f.backward()\n",
    "        optimizer.step()\n",
    "        train_mse += loss_f.item()\n",
    "    train_mse /= len(training_set_tf0)\n",
    "    # print(train_mse)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # print(\"=========\")\n",
    "        # print(\"Testing Set\")\n",
    "        fno.eval()\n",
    "        test_relative_l2 = 0.0\n",
    "        for step, (input_batch, output_batch) in enumerate(testing_set_tf0):\n",
    "            output_pred_batch = fno(input_batch)\n",
    "            loss_f = (torch.mean((output_pred_batch - output_batch) ** 2) / torch.mean(output_batch ** 2)) ** 0.5 * 100\n",
    "            test_relative_l2 += loss_f.item()\n",
    "        test_relative_l2 /= len(testing_set_tf0)\n",
    "\n",
    "    if epoch % freq_print == 0: print(\"######### Epoch:\", epoch, \" ######### Train Loss:\", train_mse, \" ######### Relative L2 Test Norm:\", test_relative_l2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_data = 4\n",
    "input_function_train_n = input_train\n",
    "output_function_train_tf = Tf0_train\n",
    "\n",
    "\n",
    "output_function_train_pred_n = fno(input_function_train_n)\n",
    "# print(output_function_test_pred_n.shape)\n",
    "output_function_train_pred_n = output_function_train_pred_n.detach()[0,:,0]\n",
    "print(output_function_train_pred_n.shape)\n",
    "print(input_function_train_n[:,0].shape)\n",
    "# print(input_function_test_n[0,:,1])\n",
    "plt.figure(dpi=250)\n",
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.scatter(input_function_train_n[:,0], output_function_train_pred_n, label=\"Approximate Solution\", s=2, c=\"red\")\n",
    "plt.plot(input_function_train_n, output_function_train_tf, label=\"True Solution\", c=\"C0\", lw=2)\n",
    "p = 2\n",
    "err = (torch.mean(abs(output_function_train_tf.detach().reshape(-1, ) - output_function_train_pred_n.detach().reshape(-1, )) ** p) / torch.mean(abs(output_function_train_tf.detach()) ** p)) ** (1 / p) * 100\n",
    "print(\"Relative L2 error: \", err.item())\n",
    "plt.legend()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer with 1D Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(fno.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "l = torch.nn.MSELoss()\n",
    "freq_print = 1\n",
    "for epoch in range(epochs):\n",
    "    train_mse = 0.0\n",
    "    for step, (input_batch, output_batch) in enumerate(training_set_tf0):\n",
    "        optimizer.zero_grad()\n",
    "        # print(input_batch.shape)\n",
    "        # print(fno(input_batch).shape)\n",
    "        output_pred_batch = fno(input_batch).squeeze(2) # gives you the prediction of T_s or T_f\n",
    "        print(output_pred_batch)\n",
    "        print(output_batch)\n",
    "        loss_f = l(output_pred_batch, output_batch)\n",
    "        loss_f.backward()\n",
    "        optimizer.step()\n",
    "        train_mse += loss_f.item()\n",
    "    train_mse /= len(training_set_tf0)\n",
    "    # print(train_mse)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # print(\"=========\")\n",
    "        # print(\"Testing Set\")\n",
    "        fno.eval()\n",
    "        test_relative_l2 = 0.0\n",
    "        for step, (input_batch, output_batch) in enumerate(testing_set_tf0):\n",
    "            output_pred_batch = fno(input_batch).squeeze(2)\n",
    "            loss_f = (torch.mean((output_pred_batch - output_batch) ** 2) / torch.mean(output_batch ** 2)) ** 0.5 * 100\n",
    "            test_relative_l2 += loss_f.item()\n",
    "        test_relative_l2 /= len(testing_set_tf0)\n",
    "\n",
    "    if epoch % freq_print == 0: print(\"######### Epoch:\", epoch, \" ######### Train Loss:\", train_mse, \" ######### Relative L2 Test Norm:\", test_relative_l2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_data = 4\n",
    "input_function_train_n = input_data_train\n",
    "output_function_train_tf = Tf0_train\n",
    "\n",
    "plt.plot(input_function_train_n, output_function_train_tf, label=\"True Solution\", c=\"C0\", lw=2)\n",
    "output_function_train_pred_n = fno(input_function_train_n)\n",
    "# print(output_function_test_pred_n.shape)\n",
    "output_function_train_pred_n = output_function_train_pred_n.detach()[0,:,0]\n",
    "print(output_function_train_pred_n.shape)\n",
    "print(input_function_train_n[:,0].shape)\n",
    "# print(input_function_test_n[0,:,1])\n",
    "plt.figure(dpi=250)\n",
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.scatter(input_function_train_n[:,0], output_function_train_pred_n, label=\"Approximate Solution\", s=8, c=\"C0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_function_test_n = input_data_test\n",
    "output_function_test_tf = Tf0_test\n",
    "\n",
    "plt.plot(input_function_test_n, output_function_test_tf, label=\"True Solution\", c=\"C0\", lw=2)\n",
    "output_function_test_pred_n = fno(input_function_test_n)\n",
    "# print(output_function_test_pred_n.shape)\n",
    "output_function_test_pred_n = output_function_test_pred_n.detach()[0,:,0]\n",
    "print(output_function_test_pred_n.shape)\n",
    "print(input_function_test_n[:,0].shape)\n",
    "# print(input_function_test_n[0,:,1])\n",
    "plt.figure(dpi=250)\n",
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.scatter(input_function_test_n[:,0], output_function_test_pred_n, label=\"Approximate Solution\", s=8, c=\"C0\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNO 2D Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "#  2d fourier layer\n",
    "################################################################\n",
    "class SpectralConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
    "        super(SpectralConv2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1  # Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = modes2\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul2d(self, input, weights):\n",
    "        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
    "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        # Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfft2(x)\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-2), x.size(-1) // 2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
    "\n",
    "        # Return to physical space\n",
    "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class FNO2d(nn.Module):\n",
    "    def __init__(self, fno_architecture, device=None, padding_frac=1 / 4):\n",
    "        super(FNO2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "\n",
    "        input: the solution of the coefficient function and locations (a(x, y), x, y)\n",
    "        input shape: (batchsize, x=s, y=s, c=3)\n",
    "        output: the solution \n",
    "        output shape: (batchsize, x=s, y=s, c=1)\n",
    "        \"\"\"\n",
    "        self.modes1 = fno_architecture[\"modes\"]\n",
    "        self.modes2 = fno_architecture[\"modes\"]\n",
    "        self.width = fno_architecture[\"width\"]\n",
    "        self.n_layers = fno_architecture[\"n_layers\"]\n",
    "        self.retrain_fno = fno_architecture[\"retrain_fno\"]\n",
    "\n",
    "        torch.manual_seed(self.retrain_fno)\n",
    "        # self.padding = 9 # pad the domain if input is non-periodic\n",
    "        self.padding_frac = padding_frac\n",
    "        self.fc0 = nn.Linear(3, self.width)  # input channel is 3: (a(x, y), x, y)\n",
    "        \n",
    "        self.conv_list = nn.ModuleList(\n",
    "            [nn.Conv2d(self.width, self.width, 1) for _ in range(self.n_layers)])\n",
    "        self.spectral_list = nn.ModuleList(\n",
    "            [SpectralConv2d(self.width, self.width, self.modes1, self.modes2) for _ in range(self.n_layers)])\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc0(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        x1_padding = int(round(x.shape[-1] * self.padding_frac))\n",
    "        x2_padding = int(round(x.shape[-2] * self.padding_frac))\n",
    "        x = F.pad(x, [0, x1_padding, 0, x2_padding])\n",
    "\n",
    "        for k, (s, c) in enumerate(zip(self.spectral_list, self.conv_list)):\n",
    "\n",
    "            x1 = s(x)\n",
    "            x2 = c(x)\n",
    "            x = x1 + x2\n",
    "            if k != self.n_layers - 1:\n",
    "                x = F.gelu(x)\n",
    "        x = x[..., :-x1_padding, :-x2_padding]\n",
    "\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
