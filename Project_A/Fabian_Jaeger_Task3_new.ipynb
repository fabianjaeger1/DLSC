{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from Common import NeuralNet, MultiVariatePoly\n",
    "import time\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "torch.manual_seed(128)\n",
    "# torch.manual_seed\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>tf0</th>\n",
       "      <th>ts0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>873.000000</td>\n",
       "      <td>293.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2478.06</td>\n",
       "      <td>873.000000</td>\n",
       "      <td>655.920736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4956.12</td>\n",
       "      <td>873.000000</td>\n",
       "      <td>792.106226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7434.18</td>\n",
       "      <td>873.000000</td>\n",
       "      <td>842.176577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9912.24</td>\n",
       "      <td>873.000000</td>\n",
       "      <td>861.040655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>508002.30</td>\n",
       "      <td>730.794575</td>\n",
       "      <td>730.514961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>510480.36</td>\n",
       "      <td>730.053663</td>\n",
       "      <td>729.797475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>512958.42</td>\n",
       "      <td>729.371039</td>\n",
       "      <td>729.133162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>515436.48</td>\n",
       "      <td>728.734400</td>\n",
       "      <td>728.511278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>517914.54</td>\n",
       "      <td>728.135229</td>\n",
       "      <td>727.924326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             t         tf0         ts0\n",
       "0         0.00  873.000000  293.000000\n",
       "1      2478.06  873.000000  655.920736\n",
       "2      4956.12  873.000000  792.106226\n",
       "3      7434.18  873.000000  842.176577\n",
       "4      9912.24  873.000000  861.040655\n",
       "..         ...         ...         ...\n",
       "205  508002.30  730.794575  730.514961\n",
       "206  510480.36  730.053663  729.797475\n",
       "207  512958.42  729.371039  729.133162\n",
       "208  515436.48  728.734400  728.511278\n",
       "209  517914.54  728.135229  727.924326\n",
       "\n",
       "[210 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"Task3/TrainingData.txt\")\n",
    "test_data = pd.read_csv(\"Task3/TestingData.txt\")\n",
    "display(train_data)\n",
    "\n",
    "t_train_import = torch.from_numpy(train_data['t'].to_numpy()).type(torch.float32)\n",
    "t_pred = torch.from_numpy(test_data['t'].to_numpy()).type(torch.float32)\n",
    "\n",
    "Tf0 = torch.from_numpy(train_data['tf0'].to_numpy()).type(torch.float32)\n",
    "Ts0 = torch.from_numpy(train_data['ts0'].to_numpy()).type(torch.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# load data\n",
    "# create scaler\n",
    "scaler_t = MinMaxScaler()\n",
    "scaler_tf = MinMaxScaler()\n",
    "scaler_ts = MinMaxScaler()\n",
    "\n",
    "# # fit scaler on data\n",
    "# scaler_t.fit(data)\n",
    "# # apply transform\n",
    "# normalized = scaler.transform(data)\n",
    "# # inverse transform\n",
    "# inverse = scaler.inverse_transform(normalized)\n",
    "\n",
    "t_train_norm = scaler_t.fit_transform(train_data['t'].to_numpy().reshape(-1, 1))\n",
    "t_test_norm = scaler_t.transform(test_data['t'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "Tf0_norm = scaler_tf.fit_transform(train_data['tf0'].to_numpy().reshape(-1, 1))\n",
    "Ts0_norm = scaler_ts.fit_transform(train_data['ts0'].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split T_f and T_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([178, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([178, 1])\n",
      "torch.Size([178, 1])\n"
     ]
    }
   ],
   "source": [
    "n_train = 178\n",
    "# Input set\n",
    "t_train = t_train_norm[:n_train].reshape(-1,1)\n",
    "t_test =  t_train_norm[n_train:].reshape(-1,1)\n",
    "\n",
    "t_train = torch.from_numpy(t_train).type(torch.float32)\n",
    "t_test = torch.from_numpy(t_test).type(torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "################\n",
    "#! Training with x\n",
    "x_train = torch.zeros_like(t_train).reshape(-1,1)\n",
    "x_test = torch.zeros_like(t_test).reshape(-1,1)\n",
    "\n",
    "input_train = torch.cat((t_train, x_train), 1)\n",
    "input_test = torch.cat((t_test, x_test), 1)\n",
    "\n",
    "################\n",
    "\n",
    "print(t_train.shape)\n",
    "print(t_test.shape)\n",
    "\n",
    "Tf0_norm_torch = torch.from_numpy(Tf0_norm).type(torch.float32)\n",
    "Ts0_norm_torch = torch.from_numpy(Ts0_norm).type(torch.float32)\n",
    "\n",
    "# Output Set\n",
    "Tf0_train = Tf0_norm_torch[:n_train]\n",
    "Ts0_train = Ts0_norm_torch[:n_train]\n",
    "\n",
    "Tf0_test = Tf0_norm_torch[n_train:]\n",
    "Ts0_test = Ts0_norm_torch[n_train:]\n",
    "\n",
    "print(Ts0_train.shape)\n",
    "print(Tf0_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 178\n",
    "\n",
    "training_set_tf0 = DataLoader(TensorDataset(t_train, Tf0_train), batch_size=batch_size, shuffle=True)\n",
    "training_set_ts0 = DataLoader(TensorDataset(t_train, Ts0_train), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testing_set_tf0 = DataLoader(TensorDataset(t_test, Tf0_test), batch_size=batch_size, shuffle=True)\n",
    "testing_set_ts0 = DataLoader(TensorDataset(t_test, Ts0_test), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 178\n",
    "\n",
    "training_set_tf0_2d = DataLoader(TensorDataset(input_train, Tf0_train), batch_size=batch_size, shuffle=True)\n",
    "training_set_ts0_2d = DataLoader(TensorDataset(input_train, Ts0_train), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testing_set_tf0_2d = DataLoader(TensorDataset(input_test, Tf0_test), batch_size=batch_size, shuffle=True)\n",
    "testing_set_ts0_2d = DataLoader(TensorDataset(input_test, Ts0_test), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Training and Testing Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16c1c8e20>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(t_train, Ts0_train, label=\"Ts0\")\n",
    "plt.plot(t_train, Tf0_train, label=\"Tf0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x16c2ab940>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxW0lEQVR4nO3dfXTU1YH/8c/MkCeFjIIlDxBjZLdCTLUlLEiQs2uP5aGWh7a7YLuKWu0RdVeR1QrHtSw+IWo9PtSkFWGVyk98tqGHRnNOV0RCmxVhT+mgnkJ4ECZkgTYTVnmaub8/xkSHmUnm+WYy79c5czi5c+987xX5zif3e7/36zDGGAEAAFjitN0BAACQ2wgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwaZLsDsQgEAjpw4ICGDBkih8NhuzsAACAGxhh1dXWpvLxcTmf0+Y+sCCMHDhxQRUWF7W4AAIAE7Nu3TyNHjoz6flaEkSFDhkgKDqa4uNhybwAAQCx8Pp8qKip6vsejyYow0n1ppri4mDACAECW6WuJBQtYAQCAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFZlxaZnaRHwS3tapKMHpcElUmWd5HSlt62NYybR1n/qlD78w1v67C/7VXT2CI2eMFWuQbH9L+MPGLW2HVFH1zENH1Ko8VVD5XL2/VyhRNvl0jEBYKCJO4y8++67euSRR7RlyxZ5vV698cYbmj17dq9tNmzYoIULF+pPf/qTysvL9ZOf/ETz589PtM/J8zRKTXdJvgNflBWXS9OWS9Uz09PW0yjTdJccX2pnisvliPGYmW679a3nVb55qS7U4Z6yg83DdGDiEn1j6jW9HrJpu1f3Nf5RFUf/R8P1V3XoLO0bfLHumfk1TaspS3m7XDqmlHhITCpcWgimAHKHwxhj4mnw29/+Vps2bdLYsWP1/e9/v88w0tbWppqaGv34xz/WjTfeqE2bNunmm2/Wiy++qO9///sxHdPn88ntdquzszP57eA9jdLL8ySdPuzPT45zVkf/kk60radR5uV5MjIh18UCkhxyyNHHMTPddutbz+villslSV/+zgh8Puz/qXsyaiBp2u7Vm//vF/pp3mqVO470lB8wQ3XvyXma/cP5Eb9wE22XS8eUvgiJJV8Oieo7JCbaLtm2Tdu9WrrOI2/nsZ6yMnehlsyojil4AchusX5/x71mZPr06br//vv1ve99L6b6v/jFL3Tuuefq8ccf15gxY3TDDTfoRz/6kR599NF4D528gD84qxEWJvRFWdOiYL1UtQ349dm6O2WMCfuP7VTw8cqfrbsz6jEz3dZ/6pTKNy8N1jvtl9fun8s2L5X/1KmwQ/oDRu+8uUr1eY+rVEdC3ivVEdXnPa533lwlf8CkpF0uHVP6IiR+xRwOKf+KOayLW27V1reeT2m7ZNs2bffqphc+CAkiktTeeUw3vfCBmrZ7o7YFkFvSvoB18+bNmjJlSkjZ1KlT9f777+vkyZMR2xw/flw+ny/klRJ7WkIvr4Qxkm9/sF6K2vp3b1LRZ+1hX+zdnA6p6LN2+XdvCnvPRtsP//CWSnS413alOqwP//BW2HutO/9Xt558tqfe6e0k6daTK9W6839T0i6XjploSEwqXCYZTJeu88hIciqgS5wezXS26BKnRw4FJElL13miBq/uz9i887B+vW2/Nu883GtdANkt7WGkvb1dJSUlIWUlJSU6deqUDh06FLHNsmXL5Ha7e14VFRWp6czRg4nXS7Dtzl07Y2oWqZ6Ntp/9ZX9M7SLV8+/epHLHkV6DTLnjcFgASrRdLh0z0ZCYTLhMKpi2HZG385imOlv1XsGtWpt/v57M/7nW5t+v9wpu1RRnq7ydx9TadiTCJwdnVS5d/jv9YMXvddvabfrBit/r0uW/YzYFGKAycmvv6Y8O7l6mEu2RwosXL1ZnZ2fPa9++fanpyOCSvutEqec/c3hMTU+v12HOiqldpHo22hadPSKmdpHqDXf8Naa2p9dLtF0uHTPRkJhMuEymbUdXMIg0RLkk1ZD3uKY6W9XRdSysLZd3gNyT9jBSWlqq9vb2kLKOjg4NGjRIw4YNi9imoKBAxcXFIa+UqKyTistlFDkEGTmk4hHBeqdp9Y/WATNU0WaKA0Y6YIap1T86pNx13qSY2rnOmxT2no22oydM1UEN67Vdu4Zp9ISpYe+NOn9U5EZ91Eu0XS4dM9GQmEy4TCqYnpmnJXmrJUW/xLMk71cafmZeyHtfvrxzuu6yvi7vAMg+aQ8jEydOVHNzc0jZ22+/rXHjxikvLy9KqzRxurT1wkUyxoR92QZMcMZm64V3RdyDo+P/TmrpyXk9dU9vK0lLT16tjv8LXQczftRX9GTeDb22ezLveo0f9ZWwY9po6xo0SAcmLum1nXfikoi3dbrOm6TPikp7DTKfFZWGBaBE2+XSMRMNicmEy2Tajnd9GNMlqfGuD0PKuy/vRGOkXi/vAMhOcYeRo0ePatu2bdq2bZuk4K2727Zt0969eyUFL7HMmzevp/78+fO1Z88eLVy4UDt27NCqVau0cuVK3XHHHakZQRz8AaObPxipm04uULuGhrzXrmG6+eQC3fzByIi/dQ0fUqi3AuOjtr3p5AK9FRiv4UMKQ95zOR36h9k/0s29HPMfZv8o4r4Lttp+Y+o1+p+6J/W/jtCZqw7HsF5v65XTpaIZj8jh6F6i+IWAgpflimY8Eh72Em2XQ8dMNCQmFS6Taft/HWFlkZxeL9Jlm0hirQcgO8S9z8g777yjyy67LKz8mmuu0XPPPadrr71Wu3fv1jvvvNPz3oYNG3T77bf3bHp21113xbXpWar2Gdm887B+sOL3koIr/Mc7P+zZdKo1MFqBz7PZiz++RBNHhX4R+wNGly7/ndo7j8kRoa2RU6XuQr131zcjfsHb2Fwr2bYJb3QVcaO1EXJMeyiBjeFiaJdDx4y050e7hsmbwD4jsbRLuG3bRun57/T6uZKka34jVU3u+fHL/0Z7E+nfKID+J9bv77jDiA2pCiO/3rZft63d1me9J678umZ9Pfw6ePfCOil0t5Hu6NFw1dhev+BtbDuebNuEZdOW+Vl2zKzYgTXglx6vkXxeRd6bxxHcuXjBH0PG/eXQH6VVr6H/y5/Drq+AfYSRCFLxWxc7SgIx6tmxWIoY36PsAJxs6OffKNB/EEYi4LcuIMMiPstphNTHJalEA0V3kInywIY+gwyA1CKMRJHsb10A4pToU6PjDP3dv2xEuxsn1l82AKROrN/fcT+1N9tNqylTw1Vjw37rKmUaF0gPpytkkWqsXApootMjuQ5KzhJJdZKih5h4bgtm8SvQv+RcGJGCgeRb1aVcagH6q4iXd8qlacujXt7htmAge+VkGJGC+3Dw2xHQD/UsfD3tCrLPGyyPsvD19D1+oom1HoDMycizaQAgJgF/cEaktw3hmxYF651mfNVQlbkLozzsIbhmpMwdnAUF0L8QRgD0H3taQi/NhDGSb3+w3mlcToeWzKiWpLBA0v3zkhnVXI4F+iHCCID+4+jBpOp1L1AvdYdeiil1F3KnHNCP5eyaEQD90OCSpOuxQB3IPoQRAP1HZV3wrpm+tpGvrOv1Y1igDmQXLtMA6D+cruDtu5KirvyY9lDszw4CkBUIIwD6l+qZwdt3i09b31FcHvW23lTxB4w27zysX2/br807D8sf6PcbVAMDApdpAPQ/1TOl0Vck/jTlBPCAPcCenHs2DQCcjgfsAekR6/c3l2kA5DR/wGjpOk9v26xp6ToPl2yANCKMAMhp8TxgD0B6EEYA5DQesAfYRxgBkNN4wB5gH2EEQE7jAXuAfYQRADmNB+wB9hFGAOQ8HrAH2MWmZwAgHrAH2EQYAYDP8YA9wA7CCICBJ+DP6FbyAJJDGAEwsHgapaa7JN+BL8qKy4NPA07jQ/YAJI4FrAAGDk+j9PK80CAiST5vsNzTaKdfAHpFGAEwMAT8wRmR3p4y07QoWA9Av0IYATAw7GkJnxEJYSTf/mA9AP0KYQTAwHD0YGrrAcgYwgiAgWFwSWrrAcgYwgiAgaGyLnjXTG9PmSkeEawHoF8hjAAYGJyu4O27kqI+ZWbaQ2nbb8QfMNq887B+vW2/Nu88LH8g0kJaAJGwzwiAgaN6pjRndZR9Rh5K2z4jTdu9WrrOI2/nsZ6yMnehlsyo5rk2QAwcxph+H999Pp/cbrc6OztVXFxsuzsA+rsM7sDatN2rm174IOyG4u65GR60h1wW6/c3MyMABh6nS6qanPbD+ANGS9d5ou5s4pC0dJ1H36ou5YF7QC9YMwIACWptOxJyaeZ0RpK385ha245krlNAFiKMAECCOrqiB5FE6gG5ijACAAkaPqQwpfWAXEUYAYAEja8aqjJ3YW87m6jMXajxVUMz2S0g6xBGACBBLqdDS2ZUS4q6s4mWzKhm8SrQB8IIACRhWk2ZGq4aq1J36KWYUncht/UCMeLWXgBI0rSaMn2rulStbUfU0XVMw4cEL80wIwLEhjACACngcjo0cdQw290AshKXaQAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFU8tRcAugX80p4W6ehBaXCJVFknOV1pPaQ/YNTadkQdXcc0fEihxlcNlcvpSOsxgf6GMAIAkuRplJruknwHvigrLpemLZeqZ6blkE3bvVq6ziNv57GesjJ3oZbMqNa0mrK0HBPoj7hMAwCeRunleaFBRJJ83mC5pzHlh2za7tVNL3wQEkQkqb3zmG564QM1bfem/JhAf0UYAZDbAv7gjIhMhDc/L2taFKyXIv6A0dJ1nt6OqKXrPPIHItUABp6Ewkh9fb2qqqpUWFio2tpabdy4sdf6Tz/9tMaMGaOioiJdcMEFWr16dUKdBYCU29MSPiMSwki+/cF6KdLadiRsRuS0I8rbeUytbUdSdkygP4t7zchLL72kBQsWqL6+XpMmTdIvf/lLTZ8+XR6PR+eee25Y/YaGBi1evFgrVqzQ3/3d36m1tVU//vGPdfbZZ2vGjBkpGQQAJOzowdTWi0FHV/Qgkkg9INvFPTPy2GOP6frrr9cNN9ygMWPG6PHHH1dFRYUaGhoi1v/Vr36lG2+8UXPnztX555+vK6+8Utdff72WL1+edOcBIGmDS1JbLwbDhxSmtB6Q7eIKIydOnNCWLVs0ZcqUkPIpU6aopSXyFObx48dVWBj6D6qoqEitra06efJknN0FgBSrrAveNaNot9M6pOIRwXopMr5qqMrchb0dUWXu4G2+QC6IK4wcOnRIfr9fJSWhvyGUlJSovb09YpupU6fq2Wef1ZYtW2SM0fvvv69Vq1bp5MmTOnToUMQ2x48fl8/nC3kBQFo4XcHbdyWFB5LPf572UEr3G3E5HVoyo7q3I2rJjGr2G0HOSGgBq8MR+g/EGBNW1u2ee+7R9OnTdckllygvL0+zZs3StddeK0lyuSL/4162bJncbnfPq6KiIpFuAkBsqmdKc1ZLxaft7VFcHixPwz4j02rK1HDVWJW6Q2eOS92FarhqLPuMIKc4jDEx3zt24sQJnXHGGXrllVf03e9+t6f8tttu07Zt27Rhw4aobU+ePKmDBw+qrKxMzzzzjO666y799a9/ldMZnoeOHz+u48eP9/zs8/lUUVGhzs5OFRcXx9pdAIgPO7ACKeXz+eR2u/v8/o7rbpr8/HzV1taqubk5JIw0Nzdr1qxZvbbNy8vTyJEjJUlr167Vd77znYhBRJIKCgpUUFAQT9cAIHlOl1Q1OaOHdDkdmjhqWEaPCfQ3cd/au3DhQl199dUaN26cJk6cqGeeeUZ79+7V/PnzJUmLFy/W/v37e/YS+fjjj9Xa2qoJEyboL3/5ix577DFt375dzz//fGpHAgAAslLcYWTu3Lk6fPiw7r33Xnm9XtXU1Gj9+vWqrKyUJHm9Xu3du7envt/v189+9jN99NFHysvL02WXXaaWlhadd955KRsEAADIXnGtGbEl1mtOAACg/4j1+5tn0wAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwbZ7gAAIDH+gFFr2xF1dB3T8CGFGl81VC6nw3a3gLgRRgAgCzVt92rpOo+8ncd6ysrchVoyo1rTasos9gyIH5dpACDLNG336qYXPggJIpLU3nlMN73wgZq2ey31DEgMYQQAsog/YLR0nUcmwnvdZUvXeeQPRKoB9E+EEQDIIq1tR8JmRL7MSPJ2HlNr25HMdQpIEmEEALJIR1f0IJJIPaA/IIwAQBYZPqQwpfWA/oAwAgBZZHzVUJW5CxXtBl6HgnfVjK8amsluAUkhjABAFnE5HVoyo1qSwgJJ989LZlSz3wiyCmEEALLMtJoyNVw1VqXu0Esxpe5CNVw1ln1GkHXY9AwAstC0mjJ9q7qUHVgxIBBGACBLuZwOTRw1zHY3gKRxmQYAAFhFGAEAAFZxmQYAUiHgl/a0SEcPSoNLpMo6yemy3SsgKxBGACBZnkap6S7Jd+CLsuJyadpyqXqmvX4BWYLLNACQDE+j9PK80CAiST5vsNzTaKdfQBYhjABAogL+4IxIb8/QbVoUrAcgKsIIACRqT0v4jEgII/n2B+sBiIowAgCJOnowtfWAHEUYAYBEDS5JbT0gRxFGACBRlXXBu2Z6e4Zu8YhgPQBREUYAIFFOV/D2XUlRn6E77SH2GwH6QBgBgGRUz5TmrJaKT3tSbnF5sJx9RoA+sekZACSreqY0+gp2YAUSRBgBgFRwuqSqybZ7AWQlLtMAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwimfTAECO8QeMWtuOqKPrmIYPKdT4qqFyOR22u4UcRhgBgBzStN2rpes88nYe6ykrcxdqyYxqTasps9gz5DIu0wBAjmja7tVNL3wQEkQkqb3zmG564QM1bfda6hlyHWEEAHKAP2C0dJ1HJsJ73WVL13nkD0SqAaQXYQQAckBr25GwGZEvM5K8ncfU2nYkc50CPkcYAYAc0NEVPYgkUg9IJcIIAOSA4UMKU1oPSCXCCADkgPFVQ1XmLlS0G3gdCt5VM75qaCa7BUhKMIzU19erqqpKhYWFqq2t1caNG3utv2bNGl188cU644wzVFZWpuuuu06HDx9OqMMAgPi5nA4tmVEtSWGBpPvnJTOq2W8EVsQdRl566SUtWLBAd999t7Zu3arJkydr+vTp2rt3b8T67733nubNm6frr79ef/rTn/TKK6/ov//7v3XDDTck3XkAQOym1ZSp4aqxKnWHXoopdReq4aqx7DMCaxzGmLju45owYYLGjh2rhoaGnrIxY8Zo9uzZWrZsWVj9Rx99VA0NDdq5c2dP2VNPPaWHH35Y+/bti+mYPp9PbrdbnZ2dKi4ujqe7AIDTsAMrMiXW7++4ZkZOnDihLVu2aMqUKSHlU6ZMUUtLS8Q2dXV1+uSTT7R+/XoZY3Tw4EG9+uqruuKKK6Ie5/jx4/L5fCEvAEBquJwOTRw1TLO+PkITRw0jiMC6uMLIoUOH5Pf7VVJSElJeUlKi9vb2iG3q6uq0Zs0azZ07V/n5+SotLdVZZ52lp556Kupxli1bJrfb3fOqqKiIp5sAACCLJLSA1eEITdHGmLCybh6PR7feeqt++tOfasuWLWpqalJbW5vmz58f9fMXL16szs7Onlesl3MAAED2ietBeeecc45cLlfYLEhHR0fYbEm3ZcuWadKkSbrzzjslSRdddJHOPPNMTZ48Wffff7/KysIXTBUUFKigoCCergEAgCwV18xIfn6+amtr1dzcHFLe3Nysurq6iG0+/fRTOZ2hh3G5XJKCMyoAACC3xX2ZZuHChXr22We1atUq7dixQ7fffrv27t3bc9ll8eLFmjdvXk/9GTNm6PXXX1dDQ4N27dqlTZs26dZbb9X48eNVXl6eupEAAICsFNdlGkmaO3euDh8+rHvvvVder1c1NTVav369KisrJUlerzdkz5Frr71WXV1d+vnPf65/+7d/01lnnaVvfvObWr58eepGAQAAslbc+4zYwD4jAABkn7TsMwIAAJBqhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWxf3UXgBA7vIHjFrbjqij65iGDynU+KqhcjkdtruFLEcYAQDEpGm7V0vXeeTtPNZTVuYu1JIZ1ZpWU2axZ8h2XKYBAPSpabtXN73wQUgQkaT2zmO66YUP1LTda6lnGAgIIwBgU8AvtW2U/vhq8M+A33aPwvgDRkvXeWQivNddtnSdR/5ApBpA37hMAwC2eBqlprsk34EvyorLpWnLpeqZ9vp1mta2I2EzIl9mJHk7j6m17YgmjhqWuY5hwGBmBABs8DRKL88LDSKS5PMGyz2NdvoVQUdX9CASaz1/wGjzzsP69bb92rzzMLMoCMHMCABkWsAfnBGJeuHDITUtkkZfITldGe5cuOFDCpOqx8JX9IWZEQDItD0t4TMiIYzk2x+s1w+MrxqqMnehot3A61AwXIyvGhr2XioWvjKrMvAxMwIAmXb0YGrrpZnL6dCSGdW66YUP5FDofE53QFkyozpsv5G+Fr46FFz4+q3q0qh7lSQ7q8K+KNmBMAIAmTa4JLX1MmBaTZkarhobFgxKewkGyS587Z5VOT3MdM+qNFw1ttdAkkyQIcRkFmEEADKtsi5414zPq8jrRhzB9yvrMt2zXk2rKdO3qktj/pJOZuFrsrMqyQQZW7MxuRyACCMAkGlOV/D23ZfnSdEufEx7qF8sXj2dy+mI+fbdZBa+JjOrkkyQsTUbk+uXo1jACgA2VM+U5qyWik/7oikuD5b3o31GEpXMwtdkZlXiCTJfluzmboku1k12kW/Tdq8uXf47/WDF73Xb2m36wYrf69Llv8uqxcHMjACALdUzg7fv7mkJLlYdXBK8NNMPZ0QSkejCVym5WZVEg4yN2ZhsvhyVSsyMAIBNTpdUNVn62j8G/xwgQaRb98LXUndoaCh1F/b6RZnMrEqiQcbGbEyi7aTkZnL627OGmBkBAKRVvAtfpeRmVbqDTHvnsWjLg1UaIcjYmI3JVAD68kxOKm65TjVmRgAAade98HXW10do4qhhMX3JJTqr0h1kJIXNrPQWZGzMxvT3y1GZwswIAKDfSmRWpbtdvPui2JiNSbSdZOdyVLoQRgAA/Vo8txN/WSJBJpEQ093HRIJMtl2OSheHMabfb/Lv8/nkdrvV2dmp4uJi290BAAxwie7bkel9RroXokqRg0yky1n+gNGly3/XZ4h5765vJr1mJNbvb8IIAAAplOkdWBMJMomEmEQQRgAAyBGJBJlM7DNCGAEAAL1K9zbysX5/s4AVAIAcleji4FRjnxEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGBVQmGkvr5eVVVVKiwsVG1trTZu3Bi17rXXXiuHwxH2uvDCCxPuNAAAGDjiDiMvvfSSFixYoLvvvltbt27V5MmTNX36dO3duzdi/SeeeEJer7fntW/fPg0dOlT/9E//lHTnAQBA9nMYY0w8DSZMmKCxY8eqoaGhp2zMmDGaPXu2li1b1mf7N998U9/73vfU1tamysrKmI7p8/nkdrvV2dmp4uLieLoLAAAsifX7O66ZkRMnTmjLli2aMmVKSPmUKVPU0tIS02esXLlSl19+ea9B5Pjx4/L5fCEvAAAwMMUVRg4dOiS/36+SkpKQ8pKSErW3t/fZ3uv16re//a1uuOGGXustW7ZMbre751VRURFPNwEAQBZJaAGrw+EI+dkYE1YWyXPPPaezzjpLs2fP7rXe4sWL1dnZ2fPat29fIt0EAABZYFA8lc855xy5XK6wWZCOjo6w2ZLTGWO0atUqXX311crPz++1bkFBgQoKCuLpGgAAyFJxzYzk5+ertrZWzc3NIeXNzc2qq6vrte2GDRv05z//Wddff338vQQAAANWXDMjkrRw4UJdffXVGjdunCZOnKhnnnlGe/fu1fz58yUFL7Hs379fq1evDmm3cuVKTZgwQTU1NanpOQAAGBDiDiNz587V4cOHde+998rr9aqmpkbr16/vuTvG6/WG7TnS2dmp1157TU888URqeg0AAAaMuPcZsYF9RgAAyD5p2WcEAAAg1QgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwKq4n00DAOgnAn5pT4t09KA0uESqrJOcLtu9AuJGGAGAbORplJruknwHvigrLpemLZeqZ9rrF5AALtMAQLbxNEovzwsNIpLk8wbLPY12+gUkiDACANkk4A/OiCjSA9c/L2taFKwHZAnCCABkkz0t4TMiIYzk2x+sB2QJwggAZJOjB1NbD+gHCCMAkE0Gl6S2HtAPEEYAIJtU1gXvmpEjSgWHVDwiWA/IEoQRAMgmTlfw9l1J4YHk85+nPcR+I8gqhBEAyDbVM6U5q6XistDy4vJgOfuMIMuw6RkAZKPqmdLoK9iBFQMCYQQAspXTJVVNtt0LIGlcpgEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYFVCYaS+vl5VVVUqLCxUbW2tNm7c2Gv948eP6+6771ZlZaUKCgo0atQorVq1KqEOAwCAgWVQvA1eeuklLViwQPX19Zo0aZJ++ctfavr06fJ4PDr33HMjtpkzZ44OHjyolStX6m/+5m/U0dGhU6dOJd15AACQ/RzGGBNPgwkTJmjs2LFqaGjoKRszZoxmz56tZcuWhdVvamrSlVdeqV27dmno0KEJddLn88ntdquzs1PFxcUJfQYAAMisWL+/47pMc+LECW3ZskVTpkwJKZ8yZYpaWloitmlsbNS4ceP08MMPa8SIEfrqV7+qO+64Q5999lnU4xw/flw+ny/kBQAABqa4LtMcOnRIfr9fJSUlIeUlJSVqb2+P2GbXrl167733VFhYqDfeeEOHDh3SzTffrCNHjkRdN7Js2TItXbo0nq4BAIAsldACVofDEfKzMSasrFsgEJDD4dCaNWs0fvx4ffvb39Zjjz2m5557LursyOLFi9XZ2dnz2rdvXyLdBAAAWSCumZFzzjlHLpcrbBako6MjbLakW1lZmUaMGCG3291TNmbMGBlj9Mknn+hv//Zvw9oUFBSooKAgnq4BAIAsFdfMSH5+vmpra9Xc3BxS3tzcrLq6uohtJk2apAMHDujo0aM9ZR9//LGcTqdGjhyZQJcBAMBAEvdlmoULF+rZZ5/VqlWrtGPHDt1+++3au3ev5s+fLyl4iWXevHk99X/4wx9q2LBhuu666+TxePTuu+/qzjvv1I9+9CMVFRWlbiQAACArxb3PyNy5c3X48GHde++98nq9qqmp0fr161VZWSlJ8nq92rt3b0/9wYMHq7m5Wf/6r/+qcePGadiwYZozZ47uv//+1I0CAABkrbj3GbGBfUYAAMg+adlnBAAAINUIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsG2e4AACDDAn5pT4t09KA0uESqrJOcLtu9Qg4jjABALvE0Sk13Sb4DX5QVl0vTlkvVM+31CzmNyzQAkCs8jdLL80KDiCT5vMFyT6OdfiHnEUYAIBcE/MEZEZkIb35e1rQoWA/IMMIIAOSCPS3hMyIhjOTbH6wHZBhhBABywdGDqa0HpBBhBAByweCS1NYDUogwAgC5oLIueNeMHFEqOKTiEcF6QIYRRgAgFzhdwdt3JYUHks9/nvYQ+43ACsIIAOSK6pnSnNVScVloeXF5sJx9RmAJm54BQC6pnimNviLzO7Cy6yt6QRgBgFzjdElVkzN3PHZ9RR+4TAMASJ9U7Poa8EttG6U/vhr8k43ZBhxmRgAA6dHnrq+O4K6vo6+IfsmGWZWcwMwIACA9kt31lVmVnMHMCAAgPZLZ9ZVZlZzCzAgAIHbxzDQks+ur7VkVZlQyipkRAEBs4p1p6N711edV5BkOR/D9SLu+2pxVYUYl45gZAQD0LZGZhmR2fbU1q8I6FSsIIwCA3vU506DgTEOkL91Ed31N5lk6ic6qJDPObp5G6fEa6fnvSK9dH/zz8ZrYQkwO4zINAKB38cw0RNpMLZFdX7tnVV6ep2Ag+XJASNOsSrLj7J5VOT3MdM+q9LXlfg7vUksYAQD0Lpn1G90S2fW1e1Yl4vqNh/qeVYl3rUo2r1PJ8iBDGAEA9C6Z9RvJyuSsSqbWqZweypKdUUkmyPSTEEMYAQD0Lpm7YlIhU7MqNu7+ScWMSqJBph/dNcQCVgBA75K5K8am6pnSgu3SNb+Rvr8y+OeCP0b/orVx908yd/4ks+A2FXcNpRBhBADQt0TvirGte1bla/8Y/LOvwJTpu3+SWaeSaJBJxV1DKcZlGgBAbBJZv5GNsmWdSqJBJtm7htKAMAIAiF0i6zeyUTasU0k0yKTi7qgUI4wAAJAq8c6qJLOfSqJBxubdUVGwZgQAgFTK1DqVRBfcJrO7bZo4jDGR4lS/4vP55Ha71dnZqeLiYtvdAQAg9RLd8yPiLbojet8YrueWYCnibEyKFiXH+v1NGAEAINslEmQSCTFxivX7mzUjAABku0QX3PaTu6MIIwAA5Kp+cncUC1gBAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVVmxA2v343N8Pp/lngAAgFh1f2/39Ri8rAgjXV1dkqSKigrLPQEAAPHq6uqS2+2O+n5WPLU3EAjowIEDGjJkiBwOh+3uxM3n86miokL79u3LmacO59qYc228EmNmzANXro05neM1xqirq0vl5eVyOqOvDMmKmRGn06mRI0fa7kbSiouLc+J/7C/LtTHn2nglxpwrGPPAl67x9jYj0o0FrAAAwCrCCAAAsIowkgEFBQVasmSJCgoKbHclY3JtzLk2Xokx5wrGPPD1h/FmxQJWAAAwcDEzAgAArCKMAAAAqwgjAADAKsIIAACwijCSgPr6elVVVamwsFC1tbXauHFjr/XXrFmjiy++WGeccYbKysp03XXX6fDhwyF1/vrXv+qWW25RWVmZCgsLNWbMGK1fvz6dw4hLOsb8+OOP64ILLlBRUZEqKip0++2369ixY+kcRlziHfPTTz+tMWPGqKioSBdccIFWr14dVue1115TdXW1CgoKVF1drTfeeCNd3Y9bqse7YsUKTZ48WWeffbbOPvtsXX755WptbU3nEOKWjr/jbmvXrpXD4dDs2bNT3OvkpGPMA+38FcuY++v5691339WMGTNUXl4uh8OhN998s882GzZsUG1trQoLC3X++efrF7/4RVidtJ+7DOKydu1ak5eXZ1asWGE8Ho+57bbbzJlnnmn27NkTsf7GjRuN0+k0TzzxhNm1a5fZuHGjufDCC83s2bN76hw/ftyMGzfOfPvb3zbvvfee2b17t9m4caPZtm1bpobVq3SM+YUXXjAFBQVmzZo1pq2tzbz11lumrKzMLFiwIFPD6lW8Y66vrzdDhgwxa9euNTt37jQvvviiGTx4sGlsbOyp09LSYlwul3nwwQfNjh07zIMPPmgGDRpkfv/732dqWFGlY7w//OEPzdNPP222bt1qduzYYa677jrjdrvNJ598kqlh9SodY+62e/duM2LECDN58mQza9asNI8kdukY80A7f8Uy5v58/lq/fr25++67zWuvvWYkmTfeeKPX+rt27TJnnHGGue2224zH4zErVqwweXl55tVXX+2pk4lzF2EkTuPHjzfz588PKRs9erRZtGhRxPqPPPKIOf/880PKnnzySTNy5MienxsaGsz5559vTpw4kfoOp0A6xnzLLbeYb37zmyF1Fi5caC699NIU9To58Y554sSJ5o477ggpu+2228ykSZN6fp4zZ46ZNm1aSJ2pU6eaK6+8MkW9Tlw6xnu6U6dOmSFDhpjnn38++Q6nQLrGfOrUKTNp0iTz7LPPmmuuuaZfhZF0jHmgnb9iGXN/P391iyWM/OQnPzGjR48OKbvxxhvNJZdc0vNzJs5dXKaJw4kTJ7RlyxZNmTIlpHzKlClqaWmJ2Kaurk6ffPKJ1q9fL2OMDh48qFdffVVXXHFFT53GxkZNnDhRt9xyi0pKSlRTU6MHH3xQfr8/reOJRbrGfOmll2rLli090/a7du3S+vXrQ+rYksiYjx8/rsLCwpCyoqIitba26uTJk5KkzZs3h33m1KlTo35mpqRrvKf79NNPdfLkSQ0dOjQ1HU9COsd877336itf+Yquv/761Hc8Ceka80A7f8Uy5v58/opXtPPS+++/n9FzF2EkDocOHZLf71dJSUlIeUlJidrb2yO2qaur05o1azR37lzl5+ertLRUZ511lp566qmeOrt27dKrr74qv9+v9evX69///d/1s5/9TA888EBaxxOLdI35yiuv1H333adLL71UeXl5GjVqlC677DItWrQoreOJRSJjnjp1qp599llt2bJFxhi9//77WrVqlU6ePKlDhw5Jktrb2+P6zExJ13hPt2jRIo0YMUKXX355yscQr3SNedOmTVq5cqVWrFiR9jHEK11jHmjnr1jG3J/PX/GKdl46depURs9dhJEEOByOkJ+NMWFl3Twej2699Vb99Kc/1ZYtW9TU1KS2tjbNnz+/p04gENDw4cP1zDPPqLa2VldeeaXuvvtuNTQ0pHUc8Uj1mN955x098MADqq+v1wcffKDXX39dv/nNb3TfffeldRzxiGfM99xzj6ZPn65LLrlEeXl5mjVrlq699lpJksvlSugzMy0d4+328MMP68UXX9Trr78e9lunTakcc1dXl6666iqtWLFC55xzTrq7nrBU/z0PtPNXLGPOhvNXPCL99zm9PN3nLsJIHM455xy5XK6wNNjR0RGWGrstW7ZMkyZN0p133qmLLrpIU6dOVX19vVatWiWv1ytJKisr01e/+tWQk/iYMWPU3t6uEydOpG9AMUjXmO+55x5dffXVuuGGG/S1r31N3/3ud/Xggw9q2bJlCgQCaR9XbxIZc1FRkVatWqVPP/1Uu3fv1t69e3XeeedpyJAhPV9MpaWlcX1mpqRrvN0effRRPfjgg3r77bd10UUXpW0c8UjHmHfu3Kndu3drxowZGjRokAYNGqTVq1ersbFRgwYN0s6dOzMxtKjS9fc80M5fsYy5P5+/4hXtvDRo0CANGzas1zqpPHcRRuKQn5+v2tpaNTc3h5Q3Nzerrq4uYptPP/1UTmfof+buf7Td6XPSpEn685//HPI/8ccff6yysjLl5+encghxS9eYo9UxwUXVqep+QhIZc7e8vDyNHDlSLpdLa9eu1Xe+852ecU6cODHsM99+++0+PzPd0jVeSXrkkUd03333qampSePGjUtL/xORjjGPHj1af/zjH7Vt27ae18yZM3XZZZdp27ZtqqioSOeQ+pSuv+eBdv7q1tuY+/P5K17Rzkvjxo1TXl5er3VSeu5K2VLYHNF9m9jKlSuNx+MxCxYsMGeeeabZvXu3McaYRYsWmauvvrqn/n/+53+aQYMGmfr6erNz507z3nvvmXHjxpnx48f31Nm7d68ZPHiw+Zd/+Rfz0Ucfmd/85jdm+PDh5v7778/4+CJJx5iXLFlihgwZYl588UWza9cu8/bbb5tRo0aZOXPmZHx8kcQ75o8++sj86le/Mh9//LH5wx/+YObOnWuGDh1q2traeups2rTJuFwu89BDD5kdO3aYhx56qN/d2pvK8S5fvtzk5+ebV1991Xi93p5XV1dXpocXUTrGfLr+djdNOsY80M5fsYy5P5+/urq6zNatW83WrVuNJPPYY4+ZrVu39tzKfPp4u2/tvf32243H4zErV64Mu7U3E+cuwkgCnn76aVNZWWny8/PN2LFjzYYNG3reu+aaa8zf//3fh9R/8sknTXV1tSkqKjJlZWXmn//5n8P2WmhpaTETJkwwBQUF5vzzzzcPPPCAOXXqVCaGE5NUj/nkyZPmP/7jP8yoUaNMYWGhqaioMDfffLP5y1/+kqER9S2eMXs8HvP1r3/dFBUVmeLiYjNr1izz4Ycfhn3mK6+8Yi644AKTl5dnRo8ebV577bVMDCUmqR5vZWWlkRT2WrJkSYZG1Ld0/B1/WX8LI8akZ8wD6fwVy5j78/nrv/7rvyL+u7vmmmuMMZHP1++88475xje+YfLz8815551nGhoawj433ecuhzFZNqcEAAAGFNaMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArPr/huDUd7vbT7YAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(t_test, Ts0_test, label=\"Ts0\")\n",
    "plt.scatter(t_test, Tf0_test, label=\"Tf0\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNO1D Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(name):\n",
    "    if name in ['tanh', 'Tanh']:\n",
    "        return nn.Tanh()\n",
    "    elif name in ['relu', 'ReLU']:\n",
    "        return nn.ReLU(inplace=True)\n",
    "    elif name in ['lrelu', 'LReLU']:\n",
    "        return nn.LeakyReLU(inplace=True)\n",
    "    elif name in ['sigmoid', 'Sigmoid']:\n",
    "        return nn.Sigmoid()\n",
    "    elif name in ['softplus', 'Softplus']:\n",
    "        return nn.Softplus(beta=4)\n",
    "    elif name in ['celu', 'CeLU']:\n",
    "        return nn.CELU()\n",
    "    elif name in ['elu']:\n",
    "        return nn.ELU()\n",
    "    elif name in ['mish']:\n",
    "        return nn.Mish()\n",
    "    else:\n",
    "        raise ValueError('Unknown activation function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "#  1d fourier layer\n",
    "################################################################\n",
    "class SpectralConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1):\n",
    "        super(SpectralConv1d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        1D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul1d(self, input, weights):\n",
    "        # print(\"Input shape complx_mul1d: {}\".format(input.shape))\n",
    "        # print(\"Weights shape complx_mul1d: {}\".format(weights.shape))\n",
    "        # (batch, in_channel, x ), (in_channel, out_channel, x) -> (batch, out_channel, x)\n",
    "        # return torch.einsum(\"bi,io->bo\", input, weights)\n",
    "        return torch.einsum(\"bix,iox->box\", input, weights)\n",
    "\n",
    "\n",
    "######################### TO DO ####################################\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        # print(\"x Shape: {}\".format(x.shape))\n",
    "        # print(\"========\")\n",
    "        # print(\"Forward Pass\")\n",
    "        # x.shape in our case will be [batch_size,\n",
    "        # x.shape == [batch_size, in_channels, number of grid points]\n",
    "        # hint: use torch.fft library torch.fft.rfft\n",
    "        # use DFT to approximate the fourier transform\n",
    "        \n",
    "        # Compute Fourier coefficients\n",
    "        x_ft = torch.fft.rfft(x)\n",
    "        #print(x_ft.shape)\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-1) // 2 + 1, device=x.device, dtype=torch.cfloat)\n",
    "        # out_ft[:, :self.modes1] = self.compl_mul1d(x_ft[:, :self.modes1], self.weights1)\n",
    "        out_ft[:, :, :self.modes1] = self.compl_mul1d(x_ft[:, :, :self.modes1], self.weights1)\n",
    "\n",
    "        # Return to physical space\n",
    "        x = torch.fft.irfft(out_ft, n=x.size(-1))\n",
    "        return x\n",
    "\n",
    "\n",
    "####################################################################\n",
    "\n",
    "\n",
    "class FNO1d(nn.Module):\n",
    "    def __init__(self, modes, width):\n",
    "        super(FNO1d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "\n",
    "        ### Our case\n",
    "        input: the solution of the initial condition and location (a(x), x)\n",
    "        input_shape: (batchsize, nr_samples=209, columns = 2 (x,t))\n",
    "        output: the solution of a later timestep\n",
    "        output_shape: (batchsize, nr_samples=209, columns = 1 (u))\n",
    "\n",
    "\n",
    "        ### Example\n",
    "        input: the solution of the initial condition and location (a(x), x)\n",
    "        input shape: (batchsize, x=s, c=2)\n",
    "        output: the solution of a later timestep\n",
    "        output shape: (batchsize, x=s, c=1)\n",
    "        \"\"\"\n",
    "\n",
    "        self.modes1 = modes\n",
    "        self.width = width\n",
    "        self.padding = 1  # pad the domain if input is non-periodic\n",
    "        self.linear_p = nn.Linear(2, self.width)  # input channel is 2: (u0(x), x)\n",
    "\n",
    "        self.spect1 = SpectralConv1d(self.width, self.width, self.modes1)\n",
    "        self.spect2 = SpectralConv1d(self.width, self.width, self.modes1)\n",
    "        self.spect3 = SpectralConv1d(self.width, self.width, self.modes1)\n",
    "        self.lin0 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.lin1 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.lin2 = nn.Conv1d(self.width, self.width, 1)\n",
    "\n",
    "        self.linear_q = nn.Linear(self.width, 32)\n",
    "        self.output_layer = nn.Linear(32, 1)\n",
    "\n",
    "        self.activation = torch.nn.Tanh()\n",
    "\n",
    "    def fourier_layer(self, x, spectral_layer, conv_layer):\n",
    "        return self.activation(spectral_layer(x) + conv_layer(x))\n",
    "\n",
    "    def linear_layer(self, x, linear_transformation):\n",
    "        return self.activation(linear_transformation(x))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # grid = self.get_grid(x.shape, x.device)\n",
    "        # x = torch.cat((x, grid), dim=-1)\n",
    "\n",
    "        # print(\"Before Linear: {}\".format(x.shape))\n",
    "        x = self.linear_p(x)\n",
    "        # x = x.permute(1,0)\n",
    "        # print(\"After Linear: {}\".format(x.shape))\n",
    "        #!  Add a batch size dimension at the first position\n",
    "        x = x.unsqueeze(0)\n",
    "        # print(\"X after unsequenze: {}\".format(x.shape))\n",
    "        x = x.permute(0,2,1)\n",
    "        # print(\"X after permute: {}\".format(x.shape))\n",
    "        # x = F.pad(x, [0, self.padding])  # pad the domain if input is non-periodic\n",
    "\n",
    "        x = self.fourier_layer(x, self.spect1, self.lin0)\n",
    "        x = self.fourier_layer(x, self.spect2, self.lin1)\n",
    "        x = self.fourier_layer(x, self.spect3, self.lin2)\n",
    "\n",
    "        # x = x[..., :-self.padding]  # pad the domain if input is non-periodic\n",
    "        # x = x.permute(1,0)\n",
    "\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        x = self.linear_layer(x, self.linear_q)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "# epochs = 250\n",
    "epochs = 1000\n",
    "step_size = 50\n",
    "gamma = 0.5\n",
    "\n",
    "modes = 16\n",
    "width = 64\n",
    "\n",
    "# model\n",
    "\n",
    "fno = FNO1d(modes, width)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer with 2D Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(fno.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "l = torch.nn.MSELoss()\n",
    "freq_print = 1\n",
    "for epoch in range(epochs):\n",
    "    train_mse = 0.0\n",
    "    for step, (input_batch, output_batch) in enumerate(training_set_tf0_2d):\n",
    "        optimizer.zero_grad()\n",
    "        # print(input_batch.shape)\n",
    "        # print(fno(input_batch).shape)\n",
    "        output_pred_batch = fno(input_batch).squeeze(2) # gives you the prediction of T_s or T_f\n",
    "        print(output_pred_batch)\n",
    "        print(output_batch)\n",
    "        loss_f = l(output_pred_batch, output_batch)\n",
    "        loss_f.backward()\n",
    "        optimizer.step()\n",
    "        train_mse += loss_f.item()\n",
    "    train_mse /= len(training_set_tf0_2d)\n",
    "    # print(train_mse)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # print(\"=========\")\n",
    "        # print(\"Testing Set\")\n",
    "        fno.eval()\n",
    "        test_relative_l2 = 0.0\n",
    "        for step, (input_batch, output_batch) in enumerate(testing_set_tf0_2d):\n",
    "            output_pred_batch = fno(input_batch).squeeze(2)\n",
    "            loss_f = (torch.mean((output_pred_batch - output_batch) ** 2) / torch.mean(output_batch ** 2)) ** 0.5 * 100\n",
    "            test_relative_l2 += loss_f.item()\n",
    "        test_relative_l2 /= len(testing_set_tf0_2d)\n",
    "\n",
    "    if epoch % freq_print == 0: print(\"######### Epoch:\", epoch, \" ######### Train Loss:\", train_mse, \" ######### Relative L2 Test Norm:\", test_relative_l2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get prediction with 2D Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_data = 4\n",
    "input_function_train_n = input_train\n",
    "output_function_train_tf = Tf0_train\n",
    "\n",
    "\n",
    "output_function_train_pred_n = fno(input_function_train_n)\n",
    "# print(output_function_test_pred_n.shape)\n",
    "output_function_train_pred_n = output_function_train_pred_n.detach()[0,:,0]\n",
    "print(output_function_train_pred_n.shape)\n",
    "print(input_function_train_n[:,0].shape)\n",
    "# print(input_function_test_n[0,:,1])\n",
    "plt.figure(dpi=250)\n",
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.scatter(input_function_train_n[:,0], output_function_train_pred_n, label=\"Approximate Solution\", s=2, c=\"red\")\n",
    "plt.plot(input_function_train_n, output_function_train_tf, label=\"True Solution\", c=\"C0\", lw=2)\n",
    "p = 2\n",
    "err = (torch.mean(abs(output_function_train_tf.detach().reshape(-1, ) - output_function_train_pred_n.detach().reshape(-1, )) ** p) / torch.mean(abs(output_function_train_tf.detach()) ** p)) ** (1 / p) * 100\n",
    "print(\"Relative L2 error: \", err.item())\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_function_test_n = input_test\n",
    "# print(len(input_function_test_n))\n",
    "output_function_test_tf = Tf0_test\n",
    "\n",
    "\n",
    "output_function_test_pred_n = fno(input_function_test_n)\n",
    "# print(output_function_test_pred_n.shape)\n",
    "output_function_test_pred_n = output_function_test_pred_n.detach()[0,:,0]\n",
    "print(output_function_test_pred_n.shape)\n",
    "print(input_function_test_n[:,0].shape)\n",
    "# print(input_function_test_n[0,:,1])\n",
    "plt.figure(dpi=250)\n",
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.scatter(input_function_test_n[:,0], output_function_test_pred_n, label=\"Approximate Solution\", s=8, c=\"C0\")\n",
    "plt.plot(input_function_test_n, output_function_test_tf, label=\"True Solution\", c=\"C0\", lw=2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer with (t, T_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 178\n",
    "# Input set\n",
    "t_train = t_train_norm[:n_train].reshape(-1,1)\n",
    "t_test =  t_train_norm[n_train:].reshape(-1,1)\n",
    "\n",
    "t_train = torch.from_numpy(t_train).type(torch.float32)\n",
    "t_test = torch.from_numpy(t_test).type(torch.float32)\n",
    "\n",
    "\n",
    "Tf0_norm_torch = torch.from_numpy(Tf0_norm).type(torch.float32)\n",
    "Ts0_norm_torch = torch.from_numpy(Ts0_norm).type(torch.float32)\n",
    "\n",
    "# Output Set\n",
    "Tf0_train = Tf0_norm_torch[:n_train]\n",
    "Ts0_train = Ts0_norm_torch[:n_train]\n",
    "\n",
    "Tf0_test = Tf0_norm_torch[n_train:]\n",
    "Ts0_test = Ts0_norm_torch[n_train:]\n",
    "\n",
    "\n",
    "input_train_tf0 = torch.cat((t_train, Tf0_train), 1)\n",
    "input_test_tf0 = torch.cat((t_test, Tf0_test), 1)\n",
    "\n",
    "\n",
    "print(input_train_tf0.shape)\n",
    "\n",
    "training_set_tf0 = DataLoader(TensorDataset(input_train_tf0, Tf0_train), batch_size=batch_size, shuffle=True)\n",
    "testing_set_tf0 =  DataLoader(TensorDataset(input_test_tf0, Ts0_test), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "batch_size = 178\n",
    "\n",
    "# training_set_tf0 = DataLoader(TensorDataset(t_train, Tf0_train), batch_size=batch_size, shuffle=True)\n",
    "# training_set_ts0 = DataLoader(TensorDataset(t_train, Ts0_train), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# testing_set_tf0 = DataLoader(TensorDataset(t_test, Tf0_test), batch_size=batch_size, shuffle=True)\n",
    "# testing_set_ts0 = DataLoader(TensorDataset(t_test, Ts0_test), batch_size=batch_size, shuffle=True)\n",
    "# batch_size = 178\n",
    "\n",
    "# training_set_tf0_2d = DataLoader(TensorDataset(input_train, Tf0_train), batch_size=batch_size, shuffle=True)\n",
    "# training_set_ts0_2d = DataLoader(TensorDataset(input_train, Ts0_train), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# testing_set_tf0_2d = DataLoader(TensorDataset(input_test, Tf0_test), batch_size=batch_size, shuffle=True)\n",
    "# testing_set_ts0_2d = DataLoader(TensorDataset(input_test, Ts0_test), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output batch pred: tensor([[[0.3863],\n",
      "         [0.7175],\n",
      "         [0.9902],\n",
      "         [0.9276],\n",
      "         [0.9932],\n",
      "         [0.5004],\n",
      "         [0.0226],\n",
      "         [0.9939],\n",
      "         [0.9962],\n",
      "         [0.9946],\n",
      "         [0.9851],\n",
      "         [0.9977],\n",
      "         [0.9970],\n",
      "         [0.9968],\n",
      "         [0.2532],\n",
      "         [0.9980],\n",
      "         [0.9825],\n",
      "         [0.9959],\n",
      "         [0.9945],\n",
      "         [0.9932],\n",
      "         [0.9899],\n",
      "         [0.9905],\n",
      "         [0.9932],\n",
      "         [0.9941],\n",
      "         [0.9961],\n",
      "         [0.5064],\n",
      "         [0.9986],\n",
      "         [0.9983],\n",
      "         [1.0013],\n",
      "         [1.0013],\n",
      "         [0.9996],\n",
      "         [0.9990],\n",
      "         [0.4468],\n",
      "         [0.4495],\n",
      "         [0.9949],\n",
      "         [0.9962],\n",
      "         [0.9598],\n",
      "         [0.8452],\n",
      "         [0.9980],\n",
      "         [0.0400],\n",
      "         [0.9856],\n",
      "         [0.0603],\n",
      "         [0.6574],\n",
      "         [0.9953],\n",
      "         [0.9939],\n",
      "         [0.4651],\n",
      "         [0.9937],\n",
      "         [0.9179],\n",
      "         [0.3422],\n",
      "         [0.4632],\n",
      "         [0.9974],\n",
      "         [0.9997],\n",
      "         [0.9191],\n",
      "         [1.0017],\n",
      "         [1.0004],\n",
      "         [0.9977],\n",
      "         [0.3615],\n",
      "         [0.9954],\n",
      "         [0.9934],\n",
      "         [0.4533],\n",
      "         [0.9912],\n",
      "         [0.9908],\n",
      "         [0.9919],\n",
      "         [0.5294],\n",
      "         [0.1995],\n",
      "         [0.9949],\n",
      "         [0.9978],\n",
      "         [0.9964],\n",
      "         [0.9989],\n",
      "         [0.9978],\n",
      "         [0.3715],\n",
      "         [0.9799],\n",
      "         [0.3633],\n",
      "         [0.5027],\n",
      "         [0.9897],\n",
      "         [0.9880],\n",
      "         [0.9895],\n",
      "         [0.1586],\n",
      "         [0.9954],\n",
      "         [0.9759],\n",
      "         [0.9983],\n",
      "         [0.9955],\n",
      "         [0.9995],\n",
      "         [0.9992],\n",
      "         [0.9993],\n",
      "         [0.2424],\n",
      "         [0.9950],\n",
      "         [0.8601],\n",
      "         [0.9925],\n",
      "         [0.3739],\n",
      "         [0.9157],\n",
      "         [0.3777],\n",
      "         [0.6096],\n",
      "         [0.4531],\n",
      "         [0.9968],\n",
      "         [0.9957],\n",
      "         [0.9981],\n",
      "         [0.9969],\n",
      "         [0.8159],\n",
      "         [0.7700],\n",
      "         [0.9970],\n",
      "         [0.5185],\n",
      "         [0.9966],\n",
      "         [0.9965],\n",
      "         [0.9960],\n",
      "         [0.2540],\n",
      "         [0.9978],\n",
      "         [0.6922],\n",
      "         [0.9978],\n",
      "         [1.0005],\n",
      "         [0.5127],\n",
      "         [0.5539],\n",
      "         [0.9960],\n",
      "         [0.2589],\n",
      "         [0.8485],\n",
      "         [0.9935],\n",
      "         [0.6735],\n",
      "         [0.9920],\n",
      "         [0.5023],\n",
      "         [0.0545],\n",
      "         [0.0291],\n",
      "         [0.8997],\n",
      "         [0.9963],\n",
      "         [0.9958],\n",
      "         [0.4618],\n",
      "         [0.9946],\n",
      "         [0.9941],\n",
      "         [0.9897],\n",
      "         [0.0450],\n",
      "         [0.3657],\n",
      "         [0.9945],\n",
      "         [0.9966],\n",
      "         [0.2385],\n",
      "         [0.9992],\n",
      "         [0.9996],\n",
      "         [0.9979],\n",
      "         [0.9970],\n",
      "         [0.5150],\n",
      "         [0.9930],\n",
      "         [0.0409],\n",
      "         [0.9897],\n",
      "         [0.4478],\n",
      "         [0.7718],\n",
      "         [0.4939],\n",
      "         [0.4390],\n",
      "         [0.5167],\n",
      "         [0.9555],\n",
      "         [0.5466],\n",
      "         [0.3840],\n",
      "         [0.9928],\n",
      "         [0.7423],\n",
      "         [0.5037],\n",
      "         [0.9926],\n",
      "         [0.9927],\n",
      "         [0.3611],\n",
      "         [0.9954],\n",
      "         [0.9970],\n",
      "         [0.9971],\n",
      "         [0.9987],\n",
      "         [0.9558],\n",
      "         [0.9988],\n",
      "         [0.9973],\n",
      "         [0.3588],\n",
      "         [0.2573],\n",
      "         [0.2534],\n",
      "         [0.0601],\n",
      "         [0.2740],\n",
      "         [0.0642],\n",
      "         [0.9884],\n",
      "         [0.4464],\n",
      "         [0.9943],\n",
      "         [0.9948],\n",
      "         [0.9616],\n",
      "         [0.8586],\n",
      "         [0.9976],\n",
      "         [0.9966],\n",
      "         [0.9958],\n",
      "         [0.9937]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.3930],\n",
      "        [0.6920],\n",
      "        [0.9998],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [0.5030],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9819],\n",
      "        [0.0383],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.3573],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.2208],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.9804],\n",
      "        [0.3753],\n",
      "        [0.5054],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.1762],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.9044],\n",
      "        [0.3875],\n",
      "        [0.5945],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [0.5151],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.9997],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5108],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.0288],\n",
      "        [0.0000],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.4645],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.0368],\n",
      "        [0.3780],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.9995],\n",
      "        [0.5139],\n",
      "        [0.9996],\n",
      "        [0.0247],\n",
      "        [0.9997],\n",
      "        [0.4552],\n",
      "        [0.7540],\n",
      "        [0.4988],\n",
      "        [0.4454],\n",
      "        [0.5165],\n",
      "        [0.9520],\n",
      "        [0.5334],\n",
      "        [0.3912],\n",
      "        [0.9997],\n",
      "        [0.7129],\n",
      "        [0.5038],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9420],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.3575],\n",
      "        [0.2577],\n",
      "        [0.2518],\n",
      "        [0.0209],\n",
      "        [0.2735],\n",
      "        [0.0335],\n",
      "        [0.9997],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [0.9999]])\n",
      "######### Epoch: 0  ######### Train Loss: 0.00012840265117119998  ######### Relative L2 Test Norm: 28.201135635375977\n",
      "Output batch pred: tensor([[[ 0.8912],\n",
      "         [ 0.8861],\n",
      "         [-0.2456],\n",
      "         [ 0.8728],\n",
      "         [ 0.8800],\n",
      "         [ 0.8820],\n",
      "         [-0.0218],\n",
      "         [ 0.8949],\n",
      "         [ 0.9002],\n",
      "         [ 0.9145],\n",
      "         [ 0.0298],\n",
      "         [ 0.9189],\n",
      "         [ 0.0102],\n",
      "         [ 0.9204],\n",
      "         [ 0.9168],\n",
      "         [ 0.9129],\n",
      "         [ 0.6108],\n",
      "         [ 0.9004],\n",
      "         [ 0.9078],\n",
      "         [-0.0053],\n",
      "         [ 0.9108],\n",
      "         [ 0.3387],\n",
      "         [ 0.9102],\n",
      "         [ 0.7206],\n",
      "         [ 0.9111],\n",
      "         [ 0.0237],\n",
      "         [ 0.5104],\n",
      "         [ 0.7868],\n",
      "         [ 0.2995],\n",
      "         [ 0.9201],\n",
      "         [ 0.9226],\n",
      "         [ 0.9237],\n",
      "         [ 0.9190],\n",
      "         [ 0.1623],\n",
      "         [ 0.9133],\n",
      "         [ 0.9071],\n",
      "         [ 0.1270],\n",
      "         [ 0.1023],\n",
      "         [ 0.7833],\n",
      "         [ 0.8911],\n",
      "         [ 0.2220],\n",
      "         [ 0.8896],\n",
      "         [ 0.2851],\n",
      "         [ 0.9055],\n",
      "         [ 0.9064],\n",
      "         [ 0.1571],\n",
      "         [ 0.9120],\n",
      "         [ 0.3511],\n",
      "         [ 0.9012],\n",
      "         [ 0.8928],\n",
      "         [ 0.8881],\n",
      "         [ 0.8844],\n",
      "         [ 0.1827],\n",
      "         [ 0.5145],\n",
      "         [ 0.8896],\n",
      "         [ 0.8044],\n",
      "         [ 0.8855],\n",
      "         [ 0.9049],\n",
      "         [-0.2325],\n",
      "         [ 0.9135],\n",
      "         [ 0.8656],\n",
      "         [ 0.9056],\n",
      "         [ 0.9068],\n",
      "         [ 0.8960],\n",
      "         [ 0.9013],\n",
      "         [ 0.4030],\n",
      "         [ 0.1260],\n",
      "         [ 0.8854],\n",
      "         [ 0.9038],\n",
      "         [ 0.8064],\n",
      "         [ 0.3069],\n",
      "         [ 0.9049],\n",
      "         [ 0.9012],\n",
      "         [-0.1070],\n",
      "         [ 0.8884],\n",
      "         [ 0.8857],\n",
      "         [ 0.8790],\n",
      "         [ 0.8801],\n",
      "         [-0.0749],\n",
      "         [ 0.6958],\n",
      "         [ 0.8873],\n",
      "         [-0.0049],\n",
      "         [ 0.8836],\n",
      "         [ 0.3077],\n",
      "         [ 0.2328],\n",
      "         [ 0.2277],\n",
      "         [ 0.7894],\n",
      "         [ 0.8661],\n",
      "         [-0.2274],\n",
      "         [ 0.8843],\n",
      "         [ 0.1304],\n",
      "         [ 0.8997],\n",
      "         [ 0.1255],\n",
      "         [ 0.9012],\n",
      "         [ 0.9094],\n",
      "         [ 0.9023],\n",
      "         [ 0.9083],\n",
      "         [ 0.3136],\n",
      "         [ 0.9113],\n",
      "         [ 0.8785],\n",
      "         [-0.0054],\n",
      "         [ 0.9050],\n",
      "         [-0.2336],\n",
      "         [ 0.9087],\n",
      "         [ 0.9126],\n",
      "         [ 0.9151],\n",
      "         [ 0.9146],\n",
      "         [ 0.9111],\n",
      "         [ 0.9067],\n",
      "         [-0.2345],\n",
      "         [ 0.6467],\n",
      "         [ 0.8828],\n",
      "         [ 0.2130],\n",
      "         [ 0.8843],\n",
      "         [ 0.8845],\n",
      "         [ 0.2614],\n",
      "         [ 0.6791],\n",
      "         [-0.2131],\n",
      "         [ 0.8358],\n",
      "         [ 0.2835],\n",
      "         [ 0.1248],\n",
      "         [-0.2253],\n",
      "         [ 0.2794],\n",
      "         [ 0.1194],\n",
      "         [ 0.8890],\n",
      "         [ 0.8882],\n",
      "         [ 0.8922],\n",
      "         [ 0.6209],\n",
      "         [ 0.2234],\n",
      "         [ 0.1137],\n",
      "         [ 0.8998],\n",
      "         [-0.2013],\n",
      "         [ 0.2964],\n",
      "         [ 0.8953],\n",
      "         [ 0.8921],\n",
      "         [ 0.2099],\n",
      "         [ 0.8876],\n",
      "         [ 0.8865],\n",
      "         [ 0.4824],\n",
      "         [ 0.8847],\n",
      "         [ 0.8823],\n",
      "         [ 0.2023],\n",
      "         [ 0.8908],\n",
      "         [ 0.8931],\n",
      "         [ 0.2941],\n",
      "         [ 0.8987],\n",
      "         [ 0.9035],\n",
      "         [ 0.9080],\n",
      "         [ 0.9137],\n",
      "         [ 0.9105],\n",
      "         [ 0.9166],\n",
      "         [ 0.9086],\n",
      "         [-0.0151],\n",
      "         [ 0.9038],\n",
      "         [ 0.8919],\n",
      "         [ 0.8815],\n",
      "         [ 0.0969],\n",
      "         [ 0.8176],\n",
      "         [ 0.8726],\n",
      "         [ 0.2590],\n",
      "         [ 0.7143],\n",
      "         [ 0.8945],\n",
      "         [ 0.8991],\n",
      "         [ 0.5786],\n",
      "         [ 0.2350],\n",
      "         [ 0.8640],\n",
      "         [ 0.9056],\n",
      "         [ 0.8959],\n",
      "         [ 0.8716],\n",
      "         [ 0.4304],\n",
      "         [ 0.8777],\n",
      "         [ 0.8739],\n",
      "         [ 0.8774],\n",
      "         [ 0.1832],\n",
      "         [ 0.8881],\n",
      "         [ 0.8913],\n",
      "         [ 0.8889],\n",
      "         [-0.2423]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.9999],\n",
      "        [0.8223],\n",
      "        [0.9956],\n",
      "        [0.2735],\n",
      "        [0.6555],\n",
      "        [0.8761],\n",
      "        [0.5009],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.3573],\n",
      "        [0.8933],\n",
      "        [0.9999],\n",
      "        [0.4611],\n",
      "        [0.9995],\n",
      "        [0.5030],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9997],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.4454],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.9820],\n",
      "        [0.9997],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9966],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.5945],\n",
      "        [0.3840],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.4668],\n",
      "        [0.4642],\n",
      "        [0.9044],\n",
      "        [0.9804],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.9999],\n",
      "        [0.3747],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.9999],\n",
      "        [0.9724],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0288],\n",
      "        [0.7820],\n",
      "        [0.9995],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.8139],\n",
      "        [0.0368],\n",
      "        [0.9490],\n",
      "        [0.5080],\n",
      "        [0.3808],\n",
      "        [0.0247],\n",
      "        [0.5054],\n",
      "        [0.3780],\n",
      "        [0.9996],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.4503],\n",
      "        [0.3575],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.7129],\n",
      "        [0.4580],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0000]])\n",
      "######### Epoch: 1  ######### Train Loss: 0.026137156412005424  ######### Relative L2 Test Norm: 13.871691703796387\n",
      "Output batch pred: tensor([[[ 1.0356],\n",
      "         [ 1.0336],\n",
      "         [ 1.0275],\n",
      "         [ 1.0274],\n",
      "         [ 0.4017],\n",
      "         [ 0.3135],\n",
      "         [ 1.0230],\n",
      "         [ 0.1870],\n",
      "         [ 1.0394],\n",
      "         [ 0.4974],\n",
      "         [ 0.8487],\n",
      "         [ 1.0489],\n",
      "         [ 1.0536],\n",
      "         [ 1.0567],\n",
      "         [ 0.3713],\n",
      "         [ 0.3554],\n",
      "         [-0.0281],\n",
      "         [ 1.0381],\n",
      "         [-0.0246],\n",
      "         [ 1.0389],\n",
      "         [ 1.0348],\n",
      "         [ 0.5591],\n",
      "         [ 0.2067],\n",
      "         [ 0.5179],\n",
      "         [ 0.8380],\n",
      "         [ 1.0618],\n",
      "         [ 1.0639],\n",
      "         [ 0.7276],\n",
      "         [ 1.0405],\n",
      "         [ 1.0428],\n",
      "         [ 0.2037],\n",
      "         [-0.0300],\n",
      "         [ 1.0209],\n",
      "         [ 1.0192],\n",
      "         [ 0.3239],\n",
      "         [ 0.1281],\n",
      "         [ 1.0228],\n",
      "         [ 0.4239],\n",
      "         [ 0.7411],\n",
      "         [ 1.0249],\n",
      "         [ 1.0246],\n",
      "         [ 0.9792],\n",
      "         [ 1.0035],\n",
      "         [ 1.0274],\n",
      "         [ 1.0370],\n",
      "         [ 1.0448],\n",
      "         [ 1.0488],\n",
      "         [ 1.0446],\n",
      "         [ 1.0628],\n",
      "         [ 1.0645],\n",
      "         [ 1.0640],\n",
      "         [ 1.0574],\n",
      "         [-0.0468],\n",
      "         [ 0.4810],\n",
      "         [ 1.0208],\n",
      "         [ 0.4550],\n",
      "         [-0.0716],\n",
      "         [ 0.4701],\n",
      "         [ 0.9953],\n",
      "         [ 1.0075],\n",
      "         [ 1.0170],\n",
      "         [ 1.0258],\n",
      "         [ 1.0339],\n",
      "         [ 0.4972],\n",
      "         [-0.0610],\n",
      "         [ 1.0351],\n",
      "         [ 0.4364],\n",
      "         [ 1.0270],\n",
      "         [ 1.0050],\n",
      "         [ 1.0174],\n",
      "         [ 0.9190],\n",
      "         [ 0.9711],\n",
      "         [ 1.0144],\n",
      "         [ 1.0206],\n",
      "         [ 1.0306],\n",
      "         [ 0.7806],\n",
      "         [ 0.1691],\n",
      "         [ 0.8970],\n",
      "         [ 1.0355],\n",
      "         [ 1.0319],\n",
      "         [ 1.0293],\n",
      "         [ 1.0212],\n",
      "         [ 1.0134],\n",
      "         [ 0.1483],\n",
      "         [ 1.0144],\n",
      "         [ 1.0090],\n",
      "         [ 0.1722],\n",
      "         [ 1.0181],\n",
      "         [ 1.0258],\n",
      "         [ 1.0300],\n",
      "         [ 0.2976],\n",
      "         [ 0.4238],\n",
      "         [ 1.0374],\n",
      "         [ 1.0452],\n",
      "         [ 1.0459],\n",
      "         [ 1.0456],\n",
      "         [ 1.0430],\n",
      "         [ 1.0421],\n",
      "         [ 1.0386],\n",
      "         [ 0.9595],\n",
      "         [ 1.0391],\n",
      "         [ 1.0398],\n",
      "         [ 0.5147],\n",
      "         [ 0.4313],\n",
      "         [ 0.3383],\n",
      "         [ 1.0333],\n",
      "         [ 0.3304],\n",
      "         [ 0.1076],\n",
      "         [ 0.1985],\n",
      "         [ 1.0304],\n",
      "         [ 1.0227],\n",
      "         [ 1.0148],\n",
      "         [ 0.2675],\n",
      "         [ 1.0144],\n",
      "         [ 1.0166],\n",
      "         [ 1.0198],\n",
      "         [ 0.8538],\n",
      "         [ 0.5041],\n",
      "         [ 0.4547],\n",
      "         [ 0.3576],\n",
      "         [ 0.0053],\n",
      "         [ 1.0554],\n",
      "         [ 0.6394],\n",
      "         [ 0.9040],\n",
      "         [ 0.5154],\n",
      "         [ 1.0376],\n",
      "         [ 1.0248],\n",
      "         [ 1.0254],\n",
      "         [ 1.0175],\n",
      "         [ 1.0251],\n",
      "         [ 1.0307],\n",
      "         [ 1.0380],\n",
      "         [ 1.0322],\n",
      "         [ 1.0485],\n",
      "         [ 0.2319],\n",
      "         [ 0.4617],\n",
      "         [ 1.0633],\n",
      "         [ 1.0605],\n",
      "         [ 1.0545],\n",
      "         [ 1.0500],\n",
      "         [ 1.0442],\n",
      "         [ 0.8708],\n",
      "         [ 1.0353],\n",
      "         [ 0.9468],\n",
      "         [ 0.4136],\n",
      "         [ 0.3948],\n",
      "         [ 1.0235],\n",
      "         [ 1.0296],\n",
      "         [ 0.3116],\n",
      "         [ 1.0288],\n",
      "         [ 1.0286],\n",
      "         [ 0.9895],\n",
      "         [ 0.6410],\n",
      "         [ 1.0288],\n",
      "         [ 1.0283],\n",
      "         [ 1.0336],\n",
      "         [ 0.4207],\n",
      "         [ 0.5057],\n",
      "         [ 0.7303],\n",
      "         [ 1.0313],\n",
      "         [ 1.0309],\n",
      "         [-0.0633],\n",
      "         [ 1.0239],\n",
      "         [ 1.0152],\n",
      "         [ 1.0131],\n",
      "         [ 0.9687],\n",
      "         [ 0.8934],\n",
      "         [ 0.4343],\n",
      "         [ 0.4523],\n",
      "         [ 1.0147],\n",
      "         [-0.0675],\n",
      "         [ 1.0226],\n",
      "         [ 1.0304],\n",
      "         [ 0.3364],\n",
      "         [ 1.0388],\n",
      "         [ 0.9667],\n",
      "         [ 0.6853],\n",
      "         [ 1.0396]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.7820],\n",
      "        [0.9995],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.3840],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.2577],\n",
      "        [0.5009],\n",
      "        [0.7540],\n",
      "        [0.9962],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.7129],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.0383],\n",
      "        [0.5334],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.9997],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.7391],\n",
      "        [0.2518],\n",
      "        [0.8379],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.2547],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.4580],\n",
      "        [0.3808],\n",
      "        [0.9995],\n",
      "        [0.3728],\n",
      "        [0.1762],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.9996],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.8139],\n",
      "        [0.5151],\n",
      "        [0.4645],\n",
      "        [0.3753],\n",
      "        [0.0288],\n",
      "        [0.9999],\n",
      "        [0.5945],\n",
      "        [0.8296],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [0.9967],\n",
      "        [0.2729],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.4611],\n",
      "        [0.4454],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [0.3780],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9520],\n",
      "        [0.6327],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.4503],\n",
      "        [0.5139],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.8761],\n",
      "        [0.4988],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [0.0174],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.6555],\n",
      "        [1.0000]])\n",
      "######### Epoch: 2  ######### Train Loss: 0.001981517765671015  ######### Relative L2 Test Norm: 9.930020332336426\n",
      "Output batch pred: tensor([[[1.1198],\n",
      "         [0.6130],\n",
      "         [1.1255],\n",
      "         [1.1258],\n",
      "         [1.1241],\n",
      "         [1.1203],\n",
      "         [0.4850],\n",
      "         [0.9024],\n",
      "         [0.9843],\n",
      "         [1.1111],\n",
      "         [0.7842],\n",
      "         [1.1026],\n",
      "         [1.1180],\n",
      "         [1.0878],\n",
      "         [1.1202],\n",
      "         [0.3274],\n",
      "         [1.1296],\n",
      "         [0.9941],\n",
      "         [0.6758],\n",
      "         [0.8723],\n",
      "         [1.1249],\n",
      "         [1.1221],\n",
      "         [1.1186],\n",
      "         [0.4809],\n",
      "         [0.9737],\n",
      "         [1.1060],\n",
      "         [1.0985],\n",
      "         [1.0977],\n",
      "         [1.0859],\n",
      "         [1.0960],\n",
      "         [1.0905],\n",
      "         [1.0962],\n",
      "         [1.0976],\n",
      "         [1.0955],\n",
      "         [1.1018],\n",
      "         [1.0996],\n",
      "         [1.0902],\n",
      "         [1.0710],\n",
      "         [0.7912],\n",
      "         [1.0956],\n",
      "         [1.0886],\n",
      "         [1.0881],\n",
      "         [1.0837],\n",
      "         [1.0799],\n",
      "         [1.0773],\n",
      "         [1.0823],\n",
      "         [1.0854],\n",
      "         [0.0856],\n",
      "         [1.0934],\n",
      "         [0.6575],\n",
      "         [1.0961],\n",
      "         [1.0998],\n",
      "         [1.0987],\n",
      "         [0.6136],\n",
      "         [0.9801],\n",
      "         [0.6127],\n",
      "         [1.1083],\n",
      "         [0.5801],\n",
      "         [1.1141],\n",
      "         [1.1163],\n",
      "         [0.3532],\n",
      "         [1.1231],\n",
      "         [1.1219],\n",
      "         [1.0886],\n",
      "         [1.1156],\n",
      "         [0.1118],\n",
      "         [1.0808],\n",
      "         [1.0946],\n",
      "         [1.0914],\n",
      "         [1.0858],\n",
      "         [1.0917],\n",
      "         [1.0015],\n",
      "         [1.0991],\n",
      "         [0.4812],\n",
      "         [1.1080],\n",
      "         [0.3745],\n",
      "         [1.1184],\n",
      "         [0.6598],\n",
      "         [0.1338],\n",
      "         [0.1052],\n",
      "         [1.1151],\n",
      "         [0.8698],\n",
      "         [1.1071],\n",
      "         [1.1049],\n",
      "         [1.1011],\n",
      "         [0.6563],\n",
      "         [0.3552],\n",
      "         [1.1118],\n",
      "         [1.1117],\n",
      "         [1.0522],\n",
      "         [0.5229],\n",
      "         [0.5215],\n",
      "         [0.6870],\n",
      "         [1.1271],\n",
      "         [0.5070],\n",
      "         [1.1158],\n",
      "         [0.4960],\n",
      "         [0.6388],\n",
      "         [1.0605],\n",
      "         [0.4710],\n",
      "         [1.0953],\n",
      "         [1.0953],\n",
      "         [1.0977],\n",
      "         [1.0901],\n",
      "         [1.1089],\n",
      "         [0.6332],\n",
      "         [1.1178],\n",
      "         [1.1218],\n",
      "         [0.1263],\n",
      "         [1.1229],\n",
      "         [0.6598],\n",
      "         [0.8189],\n",
      "         [0.5524],\n",
      "         [0.3232],\n",
      "         [1.0931],\n",
      "         [1.0913],\n",
      "         [0.6039],\n",
      "         [1.0941],\n",
      "         [0.6247],\n",
      "         [1.0450],\n",
      "         [1.1106],\n",
      "         [0.3578],\n",
      "         [0.1355],\n",
      "         [0.3586],\n",
      "         [1.1014],\n",
      "         [1.0924],\n",
      "         [0.5300],\n",
      "         [1.0795],\n",
      "         [1.0707],\n",
      "         [1.0727],\n",
      "         [1.0773],\n",
      "         [1.0845],\n",
      "         [1.0228],\n",
      "         [0.5570],\n",
      "         [1.1100],\n",
      "         [0.5643],\n",
      "         [1.1184],\n",
      "         [1.1175],\n",
      "         [1.1134],\n",
      "         [1.1114],\n",
      "         [1.1065],\n",
      "         [1.1021],\n",
      "         [0.7178],\n",
      "         [1.0970],\n",
      "         [0.4368],\n",
      "         [1.0979],\n",
      "         [1.0230],\n",
      "         [0.1098],\n",
      "         [0.6215],\n",
      "         [0.9067],\n",
      "         [0.1214],\n",
      "         [1.1048],\n",
      "         [1.1022],\n",
      "         [0.5823],\n",
      "         [0.5658],\n",
      "         [0.3549],\n",
      "         [1.1035],\n",
      "         [1.1049],\n",
      "         [1.1055],\n",
      "         [0.4608],\n",
      "         [1.1168],\n",
      "         [0.5822],\n",
      "         [1.1202],\n",
      "         [1.1196],\n",
      "         [1.1209],\n",
      "         [1.1239],\n",
      "         [0.4934],\n",
      "         [0.2678],\n",
      "         [0.1244],\n",
      "         [1.1062],\n",
      "         [1.1032],\n",
      "         [1.0959],\n",
      "         [1.0903],\n",
      "         [1.0935],\n",
      "         [0.9171],\n",
      "         [0.5558],\n",
      "         [0.3365],\n",
      "         [1.1026]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.4668],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [0.7391],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.9996],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.5151],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9999],\n",
      "        [0.9820],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9804],\n",
      "        [0.9515],\n",
      "        [0.6555],\n",
      "        [0.9996],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0383],\n",
      "        [0.9997],\n",
      "        [0.5463],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.8379],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.9724],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.8761],\n",
      "        [0.9997],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [0.0247],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.5334],\n",
      "        [0.2735],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9009],\n",
      "        [0.3930],\n",
      "        [0.3875],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.9967],\n",
      "        [0.3840],\n",
      "        [0.5139],\n",
      "        [0.9420],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9819],\n",
      "        [0.9998],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0174],\n",
      "        [0.9999],\n",
      "        [0.5165],\n",
      "        [0.6628],\n",
      "        [0.4454],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [0.5080],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [0.2547],\n",
      "        [0.0288],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.5945],\n",
      "        [0.9998],\n",
      "        [0.3575],\n",
      "        [0.9999],\n",
      "        [0.8933],\n",
      "        [0.0142],\n",
      "        [0.4988],\n",
      "        [0.7540],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.4645],\n",
      "        [0.4527],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.1762],\n",
      "        [0.0368],\n",
      "        [0.9962],\n",
      "        [0.9999],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.4580],\n",
      "        [0.2610],\n",
      "        [0.9959]])\n",
      "######### Epoch: 3  ######### Train Loss: 0.012664025649428368  ######### Relative L2 Test Norm: 7.447413444519043\n",
      "Output batch pred: tensor([[[0.5957],\n",
      "         [1.0842],\n",
      "         [0.6380],\n",
      "         [0.5583],\n",
      "         [0.5789],\n",
      "         [1.0768],\n",
      "         [1.0134],\n",
      "         [0.5823],\n",
      "         [1.0866],\n",
      "         [1.0884],\n",
      "         [1.0877],\n",
      "         [1.0860],\n",
      "         [1.0826],\n",
      "         [1.0774],\n",
      "         [1.0753],\n",
      "         [1.0737],\n",
      "         [0.1243],\n",
      "         [1.0764],\n",
      "         [1.0775],\n",
      "         [1.0834],\n",
      "         [0.6503],\n",
      "         [1.0902],\n",
      "         [1.0906],\n",
      "         [1.0904],\n",
      "         [0.3635],\n",
      "         [1.0852],\n",
      "         [1.0509],\n",
      "         [1.0820],\n",
      "         [1.0815],\n",
      "         [1.0812],\n",
      "         [1.0868],\n",
      "         [0.5148],\n",
      "         [1.0175],\n",
      "         [0.9720],\n",
      "         [1.0826],\n",
      "         [0.3129],\n",
      "         [1.0725],\n",
      "         [1.0653],\n",
      "         [1.0594],\n",
      "         [1.0612],\n",
      "         [1.0655],\n",
      "         [0.6101],\n",
      "         [1.0813],\n",
      "         [1.0878],\n",
      "         [0.6637],\n",
      "         [0.6103],\n",
      "         [1.1046],\n",
      "         [0.5336],\n",
      "         [0.6559],\n",
      "         [0.8199],\n",
      "         [1.0801],\n",
      "         [1.0766],\n",
      "         [0.5707],\n",
      "         [0.9422],\n",
      "         [1.0018],\n",
      "         [1.0710],\n",
      "         [1.0762],\n",
      "         [0.9962],\n",
      "         [1.0846],\n",
      "         [1.0896],\n",
      "         [0.1829],\n",
      "         [0.1740],\n",
      "         [0.9444],\n",
      "         [1.1026],\n",
      "         [0.8314],\n",
      "         [1.0762],\n",
      "         [0.1913],\n",
      "         [1.1077],\n",
      "         [1.1075],\n",
      "         [1.1063],\n",
      "         [1.0953],\n",
      "         [0.4083],\n",
      "         [1.1054],\n",
      "         [0.5426],\n",
      "         [1.1031],\n",
      "         [1.0928],\n",
      "         [1.1045],\n",
      "         [1.1051],\n",
      "         [0.5118],\n",
      "         [1.0957],\n",
      "         [0.3271],\n",
      "         [1.1033],\n",
      "         [0.4031],\n",
      "         [1.0987],\n",
      "         [1.0953],\n",
      "         [0.1555],\n",
      "         [1.0924],\n",
      "         [1.0945],\n",
      "         [1.0933],\n",
      "         [1.0994],\n",
      "         [1.1019],\n",
      "         [0.6622],\n",
      "         [0.1565],\n",
      "         [1.1007],\n",
      "         [1.0663],\n",
      "         [0.7452],\n",
      "         [1.0841],\n",
      "         [1.0784],\n",
      "         [1.0764],\n",
      "         [1.0716],\n",
      "         [1.0798],\n",
      "         [1.0828],\n",
      "         [0.6694],\n",
      "         [1.0944],\n",
      "         [0.6599],\n",
      "         [0.8032],\n",
      "         [1.0999],\n",
      "         [1.0937],\n",
      "         [1.0856],\n",
      "         [0.4996],\n",
      "         [1.0730],\n",
      "         [1.0728],\n",
      "         [1.0708],\n",
      "         [0.3594],\n",
      "         [1.0761],\n",
      "         [1.0600],\n",
      "         [0.5956],\n",
      "         [1.0893],\n",
      "         [1.0916],\n",
      "         [1.0866],\n",
      "         [0.4943],\n",
      "         [1.0778],\n",
      "         [1.0836],\n",
      "         [1.0281],\n",
      "         [1.0838],\n",
      "         [0.6800],\n",
      "         [1.0860],\n",
      "         [1.0855],\n",
      "         [0.1643],\n",
      "         [1.0903],\n",
      "         [1.0860],\n",
      "         [0.5030],\n",
      "         [0.6760],\n",
      "         [1.0815],\n",
      "         [1.0801],\n",
      "         [1.0806],\n",
      "         [0.6433],\n",
      "         [0.3785],\n",
      "         [0.8913],\n",
      "         [0.8707],\n",
      "         [0.4064],\n",
      "         [0.8539],\n",
      "         [0.5125],\n",
      "         [1.0954],\n",
      "         [1.0924],\n",
      "         [1.0869],\n",
      "         [1.0858],\n",
      "         [1.0834],\n",
      "         [0.6444],\n",
      "         [1.0823],\n",
      "         [0.5665],\n",
      "         [1.0778],\n",
      "         [1.0740],\n",
      "         [1.0747],\n",
      "         [0.9346],\n",
      "         [1.0701],\n",
      "         [0.9396],\n",
      "         [1.0744],\n",
      "         [0.4731],\n",
      "         [0.3958],\n",
      "         [0.1901],\n",
      "         [0.2017],\n",
      "         [1.1029],\n",
      "         [1.0693],\n",
      "         [0.4043],\n",
      "         [0.6681],\n",
      "         [1.0943],\n",
      "         [1.0895],\n",
      "         [0.4931],\n",
      "         [0.8814],\n",
      "         [1.0694],\n",
      "         [1.0711],\n",
      "         [1.0746],\n",
      "         [0.4882],\n",
      "         [0.5826],\n",
      "         [1.0897],\n",
      "         [0.5891],\n",
      "         [1.0888]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.4611],\n",
      "        [0.9998],\n",
      "        [0.5139],\n",
      "        [0.4454],\n",
      "        [0.4642],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [0.4580],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.8933],\n",
      "        [0.8379],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [0.3808],\n",
      "        [0.5009],\n",
      "        [0.6628],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.4645],\n",
      "        [0.8296],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.8761],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.0335],\n",
      "        [0.0174],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.9520],\n",
      "        [0.0247],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.2646],\n",
      "        [0.9999],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [0.9820],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.0000],\n",
      "        [0.9998],\n",
      "        [0.9515],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5245],\n",
      "        [0.9998],\n",
      "        [0.5038],\n",
      "        [0.6327],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.3875],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.3728],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.9966],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.5334],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.2547],\n",
      "        [0.7391],\n",
      "        [0.7129],\n",
      "        [0.2729],\n",
      "        [0.6920],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.9996],\n",
      "        [0.9997],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.8139],\n",
      "        [0.9995],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.2735],\n",
      "        [0.0368],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.2518],\n",
      "        [0.5054],\n",
      "        [0.9956],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.3780],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [1.0000]])\n",
      "######### Epoch: 4  ######### Train Loss: 0.012143086642026901  ######### Relative L2 Test Norm: 7.770647048950195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabianjaeger/miniconda/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([178, 1])) that is different to the input size (torch.Size([1, 178, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output batch pred: tensor([[[1.0265],\n",
      "         [0.6272],\n",
      "         [0.3549],\n",
      "         [0.3140],\n",
      "         [1.0247],\n",
      "         [0.8705],\n",
      "         [1.0311],\n",
      "         [1.0301],\n",
      "         [0.5422],\n",
      "         [0.4806],\n",
      "         [0.9545],\n",
      "         [1.0228],\n",
      "         [1.0192],\n",
      "         [1.0157],\n",
      "         [1.0149],\n",
      "         [0.3490],\n",
      "         [0.7352],\n",
      "         [0.5920],\n",
      "         [1.0273],\n",
      "         [0.6023],\n",
      "         [0.4778],\n",
      "         [0.7411],\n",
      "         [0.6073],\n",
      "         [1.0328],\n",
      "         [0.4686],\n",
      "         [1.0208],\n",
      "         [1.0152],\n",
      "         [1.0125],\n",
      "         [0.4147],\n",
      "         [1.0121],\n",
      "         [1.0164],\n",
      "         [1.0216],\n",
      "         [1.0277],\n",
      "         [1.0322],\n",
      "         [0.5490],\n",
      "         [0.5494],\n",
      "         [1.0362],\n",
      "         [1.0348],\n",
      "         [0.5408],\n",
      "         [1.0310],\n",
      "         [0.9982],\n",
      "         [0.1599],\n",
      "         [0.5929],\n",
      "         [1.0284],\n",
      "         [1.0279],\n",
      "         [0.9980],\n",
      "         [0.1439],\n",
      "         [0.6097],\n",
      "         [1.0260],\n",
      "         [1.0223],\n",
      "         [1.0187],\n",
      "         [1.0173],\n",
      "         [1.0096],\n",
      "         [0.7532],\n",
      "         [0.6086],\n",
      "         [0.4737],\n",
      "         [0.1629],\n",
      "         [0.3628],\n",
      "         [0.8550],\n",
      "         [1.0326],\n",
      "         [0.8359],\n",
      "         [0.9705],\n",
      "         [1.0228],\n",
      "         [1.0184],\n",
      "         [0.1040],\n",
      "         [1.0159],\n",
      "         [0.8827],\n",
      "         [1.0224],\n",
      "         [1.0104],\n",
      "         [0.7035],\n",
      "         [0.4934],\n",
      "         [1.0419],\n",
      "         [0.5841],\n",
      "         [1.0301],\n",
      "         [0.1754],\n",
      "         [1.0344],\n",
      "         [0.3750],\n",
      "         [1.0330],\n",
      "         [1.0308],\n",
      "         [1.0380],\n",
      "         [0.5778],\n",
      "         [1.0493],\n",
      "         [1.0550],\n",
      "         [0.1991],\n",
      "         [0.4986],\n",
      "         [1.0546],\n",
      "         [1.0525],\n",
      "         [1.0454],\n",
      "         [1.0364],\n",
      "         [1.0281],\n",
      "         [1.0178],\n",
      "         [1.0038],\n",
      "         [1.0138],\n",
      "         [1.0130],\n",
      "         [1.0170],\n",
      "         [0.5888],\n",
      "         [0.4654],\n",
      "         [1.0219],\n",
      "         [1.0271],\n",
      "         [1.0260],\n",
      "         [0.4551],\n",
      "         [0.5244],\n",
      "         [1.0154],\n",
      "         [0.8975],\n",
      "         [1.0099],\n",
      "         [1.0128],\n",
      "         [0.9493],\n",
      "         [0.9891],\n",
      "         [1.0249],\n",
      "         [1.0289],\n",
      "         [1.0328],\n",
      "         [1.0345],\n",
      "         [1.0311],\n",
      "         [1.0236],\n",
      "         [1.0322],\n",
      "         [1.0294],\n",
      "         [1.0267],\n",
      "         [1.0237],\n",
      "         [1.0206],\n",
      "         [1.0222],\n",
      "         [1.0213],\n",
      "         [1.0207],\n",
      "         [0.5431],\n",
      "         [0.3508],\n",
      "         [0.9106],\n",
      "         [1.0332],\n",
      "         [1.0358],\n",
      "         [0.1603],\n",
      "         [1.0397],\n",
      "         [0.9583],\n",
      "         [0.6103],\n",
      "         [1.0395],\n",
      "         [0.3655],\n",
      "         [1.0350],\n",
      "         [0.9944],\n",
      "         [0.2787],\n",
      "         [1.0238],\n",
      "         [1.0223],\n",
      "         [1.0213],\n",
      "         [1.0175],\n",
      "         [1.0188],\n",
      "         [0.4614],\n",
      "         [1.0288],\n",
      "         [1.0305],\n",
      "         [1.0368],\n",
      "         [1.0378],\n",
      "         [0.3640],\n",
      "         [1.0427],\n",
      "         [0.4965],\n",
      "         [1.0323],\n",
      "         [0.9656],\n",
      "         [1.0214],\n",
      "         [1.0152],\n",
      "         [1.0107],\n",
      "         [1.0072],\n",
      "         [1.0119],\n",
      "         [0.7710],\n",
      "         [0.3556],\n",
      "         [1.0337],\n",
      "         [1.0420],\n",
      "         [1.0492],\n",
      "         [0.6368],\n",
      "         [0.2056],\n",
      "         [0.2128],\n",
      "         [0.6785],\n",
      "         [1.0408],\n",
      "         [0.6353],\n",
      "         [1.0230],\n",
      "         [0.5907],\n",
      "         [0.5350],\n",
      "         [1.0091],\n",
      "         [1.0079],\n",
      "         [0.5303],\n",
      "         [1.0093],\n",
      "         [1.0176],\n",
      "         [0.7948],\n",
      "         [1.0187],\n",
      "         [0.8960]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.5334],\n",
      "        [0.2646],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.3930],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.6555],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.3753],\n",
      "        [0.6327],\n",
      "        [0.5054],\n",
      "        [0.9997],\n",
      "        [0.3840],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.0383],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.0142],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.6628],\n",
      "        [0.5165],\n",
      "        [0.3747],\n",
      "        [0.0174],\n",
      "        [0.2547],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.9164],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.5945],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.9804],\n",
      "        [0.0288],\n",
      "        [0.9966],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.0335],\n",
      "        [0.3573],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [0.9814],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.3728],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9009],\n",
      "        [0.9515],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.4580],\n",
      "        [0.2610],\n",
      "        [0.8296],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.1762],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9998],\n",
      "        [0.3912],\n",
      "        [0.9995],\n",
      "        [0.9044],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.6920],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.0247],\n",
      "        [0.0368],\n",
      "        [0.5463],\n",
      "        [0.9967],\n",
      "        [0.5245],\n",
      "        [0.9996],\n",
      "        [0.5108],\n",
      "        [0.4642],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7129],\n",
      "        [0.9959],\n",
      "        [0.8223]])\n",
      "######### Epoch: 5  ######### Train Loss: 0.004650959279388189  ######### Relative L2 Test Norm: 12.456080436706543\n",
      "Output batch pred: tensor([[[0.0936],\n",
      "         [0.9471],\n",
      "         [0.9486],\n",
      "         [0.9475],\n",
      "         [0.3043],\n",
      "         [0.9452],\n",
      "         [0.9419],\n",
      "         [0.9399],\n",
      "         [0.2918],\n",
      "         [0.9398],\n",
      "         [0.2859],\n",
      "         [0.9415],\n",
      "         [0.9439],\n",
      "         [0.9481],\n",
      "         [0.9530],\n",
      "         [0.9562],\n",
      "         [0.1067],\n",
      "         [0.9503],\n",
      "         [0.9611],\n",
      "         [0.9625],\n",
      "         [0.9606],\n",
      "         [0.9579],\n",
      "         [0.9548],\n",
      "         [0.6816],\n",
      "         [0.9558],\n",
      "         [0.9563],\n",
      "         [0.9621],\n",
      "         [0.5021],\n",
      "         [0.9317],\n",
      "         [0.4978],\n",
      "         [0.4382],\n",
      "         [0.5521],\n",
      "         [0.4339],\n",
      "         [0.9551],\n",
      "         [0.8744],\n",
      "         [0.5276],\n",
      "         [0.9522],\n",
      "         [0.5320],\n",
      "         [0.9511],\n",
      "         [0.7265],\n",
      "         [0.4051],\n",
      "         [0.9595],\n",
      "         [0.5672],\n",
      "         [0.9621],\n",
      "         [0.9654],\n",
      "         [0.9656],\n",
      "         [0.9641],\n",
      "         [0.9582],\n",
      "         [0.9577],\n",
      "         [0.3819],\n",
      "         [0.9557],\n",
      "         [0.7917],\n",
      "         [0.9350],\n",
      "         [0.9559],\n",
      "         [0.9531],\n",
      "         [0.5244],\n",
      "         [0.9559],\n",
      "         [0.9534],\n",
      "         [0.9531],\n",
      "         [0.4743],\n",
      "         [0.9476],\n",
      "         [0.9470],\n",
      "         [0.9489],\n",
      "         [0.1148],\n",
      "         [0.4762],\n",
      "         [0.9509],\n",
      "         [0.4799],\n",
      "         [0.9577],\n",
      "         [0.2703],\n",
      "         [0.9611],\n",
      "         [0.9569],\n",
      "         [0.1170],\n",
      "         [0.9554],\n",
      "         [0.9487],\n",
      "         [0.8935],\n",
      "         [0.4132],\n",
      "         [0.9544],\n",
      "         [0.8216],\n",
      "         [0.4986],\n",
      "         [0.9670],\n",
      "         [0.4403],\n",
      "         [0.9739],\n",
      "         [0.5183],\n",
      "         [0.7058],\n",
      "         [0.9766],\n",
      "         [0.1437],\n",
      "         [0.5917],\n",
      "         [0.9372],\n",
      "         [0.9655],\n",
      "         [0.9603],\n",
      "         [0.9627],\n",
      "         [0.5466],\n",
      "         [0.5026],\n",
      "         [0.4309],\n",
      "         [0.9685],\n",
      "         [0.9704],\n",
      "         [0.9706],\n",
      "         [0.9698],\n",
      "         [0.9692],\n",
      "         [0.9642],\n",
      "         [0.5447],\n",
      "         [0.9598],\n",
      "         [0.9582],\n",
      "         [0.7536],\n",
      "         [0.4663],\n",
      "         [0.9532],\n",
      "         [0.7613],\n",
      "         [0.9529],\n",
      "         [0.9517],\n",
      "         [0.9528],\n",
      "         [0.9525],\n",
      "         [0.8843],\n",
      "         [0.9407],\n",
      "         [0.2168],\n",
      "         [0.9437],\n",
      "         [0.5484],\n",
      "         [0.9612],\n",
      "         [0.9316],\n",
      "         [0.6344],\n",
      "         [0.8443],\n",
      "         [0.9705],\n",
      "         [0.7385],\n",
      "         [0.9716],\n",
      "         [0.1334],\n",
      "         [0.1413],\n",
      "         [0.9717],\n",
      "         [0.9682],\n",
      "         [0.5030],\n",
      "         [0.9715],\n",
      "         [0.9443],\n",
      "         [0.4377],\n",
      "         [0.9791],\n",
      "         [0.1581],\n",
      "         [0.3493],\n",
      "         [0.3394],\n",
      "         [0.3449],\n",
      "         [0.9684],\n",
      "         [0.5510],\n",
      "         [0.5291],\n",
      "         [0.8804],\n",
      "         [0.9518],\n",
      "         [0.5159],\n",
      "         [0.9498],\n",
      "         [0.9563],\n",
      "         [0.3029],\n",
      "         [0.3121],\n",
      "         [0.9656],\n",
      "         [0.9664],\n",
      "         [0.8441],\n",
      "         [0.4163],\n",
      "         [0.9592],\n",
      "         [0.9578],\n",
      "         [0.9557],\n",
      "         [0.9576],\n",
      "         [0.9613],\n",
      "         [0.9635],\n",
      "         [0.9719],\n",
      "         [0.9767],\n",
      "         [0.4445],\n",
      "         [0.9887],\n",
      "         [0.9878],\n",
      "         [0.9864],\n",
      "         [0.9820],\n",
      "         [0.9744],\n",
      "         [0.9722],\n",
      "         [0.3959],\n",
      "         [0.8980],\n",
      "         [0.9576],\n",
      "         [0.9610],\n",
      "         [0.9623],\n",
      "         [0.6660],\n",
      "         [0.1357],\n",
      "         [0.8514],\n",
      "         [0.9670],\n",
      "         [0.9623],\n",
      "         [0.5463],\n",
      "         [0.9599],\n",
      "         [0.9565]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.0000],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.9997],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.0142],\n",
      "        [0.9804],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.9420],\n",
      "        [0.4454],\n",
      "        [0.3808],\n",
      "        [0.5038],\n",
      "        [0.3840],\n",
      "        [0.9820],\n",
      "        [0.8761],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.7129],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.9997],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.5030],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.4580],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.4527],\n",
      "        [0.9995],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.0368],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [0.9164],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.4668],\n",
      "        [0.9997],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.6555],\n",
      "        [0.9997],\n",
      "        [0.0288],\n",
      "        [0.5463],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.4642],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9967],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.9814],\n",
      "        [0.1762],\n",
      "        [0.9819],\n",
      "        [0.5245],\n",
      "        [0.9998],\n",
      "        [0.9490],\n",
      "        [0.5945],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.3728],\n",
      "        [0.9999],\n",
      "        [0.0174],\n",
      "        [0.2610],\n",
      "        [0.2518],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.4988],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.2547],\n",
      "        [0.2577],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.3747],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.6327],\n",
      "        [0.0383],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [1.0000]])\n",
      "######### Epoch: 6  ######### Train Loss: 0.0020430777221918106  ######### Relative L2 Test Norm: 17.44108009338379\n",
      "Output batch pred: tensor([[[0.9115],\n",
      "         [0.9181],\n",
      "         [0.2221],\n",
      "         [0.9329],\n",
      "         [0.9350],\n",
      "         [0.1226],\n",
      "         [0.9283],\n",
      "         [0.2929],\n",
      "         [0.8940],\n",
      "         [0.8909],\n",
      "         [0.8746],\n",
      "         [0.8659],\n",
      "         [0.6559],\n",
      "         [0.8642],\n",
      "         [0.4221],\n",
      "         [0.8831],\n",
      "         [0.8840],\n",
      "         [0.7865],\n",
      "         [0.4966],\n",
      "         [0.9193],\n",
      "         [0.9068],\n",
      "         [0.4878],\n",
      "         [0.9082],\n",
      "         [0.8668],\n",
      "         [0.4225],\n",
      "         [0.8946],\n",
      "         [0.8954],\n",
      "         [0.0972],\n",
      "         [0.2841],\n",
      "         [0.9218],\n",
      "         [0.9304],\n",
      "         [0.3028],\n",
      "         [0.9442],\n",
      "         [0.9430],\n",
      "         [0.9428],\n",
      "         [0.4150],\n",
      "         [0.9347],\n",
      "         [0.9266],\n",
      "         [0.7310],\n",
      "         [0.5193],\n",
      "         [0.9266],\n",
      "         [0.9243],\n",
      "         [0.1142],\n",
      "         [0.9297],\n",
      "         [0.1207],\n",
      "         [0.4561],\n",
      "         [0.3833],\n",
      "         [0.9135],\n",
      "         [0.9109],\n",
      "         [0.9097],\n",
      "         [0.5741],\n",
      "         [0.3543],\n",
      "         [0.0973],\n",
      "         [0.4524],\n",
      "         [0.9082],\n",
      "         [0.9065],\n",
      "         [0.9053],\n",
      "         [0.9023],\n",
      "         [0.9018],\n",
      "         [0.8970],\n",
      "         [0.8948],\n",
      "         [0.8948],\n",
      "         [0.8980],\n",
      "         [0.4250],\n",
      "         [0.9039],\n",
      "         [0.2639],\n",
      "         [0.9166],\n",
      "         [0.9178],\n",
      "         [0.9192],\n",
      "         [0.6703],\n",
      "         [0.9083],\n",
      "         [0.9054],\n",
      "         [0.8982],\n",
      "         [0.8964],\n",
      "         [0.9012],\n",
      "         [0.8396],\n",
      "         [0.9153],\n",
      "         [0.9252],\n",
      "         [0.9344],\n",
      "         [0.9419],\n",
      "         [0.9453],\n",
      "         [0.3113],\n",
      "         [0.8142],\n",
      "         [0.9301],\n",
      "         [0.4962],\n",
      "         [0.0958],\n",
      "         [0.9040],\n",
      "         [0.8971],\n",
      "         [0.3467],\n",
      "         [0.8970],\n",
      "         [0.4170],\n",
      "         [0.9039],\n",
      "         [0.9085],\n",
      "         [0.9076],\n",
      "         [0.9089],\n",
      "         [0.3586],\n",
      "         [0.8983],\n",
      "         [0.8884],\n",
      "         [0.7125],\n",
      "         [0.8777],\n",
      "         [0.8763],\n",
      "         [0.3921],\n",
      "         [0.8810],\n",
      "         [0.8858],\n",
      "         [0.0526],\n",
      "         [0.8990],\n",
      "         [0.9017],\n",
      "         [0.2584],\n",
      "         [0.9061],\n",
      "         [0.9050],\n",
      "         [0.7746],\n",
      "         [0.4673],\n",
      "         [0.8969],\n",
      "         [0.8969],\n",
      "         [0.8997],\n",
      "         [0.5163],\n",
      "         [0.4405],\n",
      "         [0.4893],\n",
      "         [0.7802],\n",
      "         [0.9186],\n",
      "         [0.9192],\n",
      "         [0.9197],\n",
      "         [0.9189],\n",
      "         [0.4557],\n",
      "         [0.9135],\n",
      "         [0.2406],\n",
      "         [0.3864],\n",
      "         [0.9097],\n",
      "         [0.3570],\n",
      "         [0.4569],\n",
      "         [0.3853],\n",
      "         [0.6457],\n",
      "         [0.4915],\n",
      "         [0.4976],\n",
      "         [0.9105],\n",
      "         [0.9096],\n",
      "         [0.8958],\n",
      "         [0.5088],\n",
      "         [0.8254],\n",
      "         [0.6923],\n",
      "         [0.2724],\n",
      "         [0.3831],\n",
      "         [0.4537],\n",
      "         [0.9194],\n",
      "         [0.9128],\n",
      "         [0.8379],\n",
      "         [0.3605],\n",
      "         [0.8849],\n",
      "         [0.8803],\n",
      "         [0.8751],\n",
      "         [0.8744],\n",
      "         [0.8784],\n",
      "         [0.8525],\n",
      "         [0.8980],\n",
      "         [0.8716],\n",
      "         [0.9236],\n",
      "         [0.9328],\n",
      "         [0.9353],\n",
      "         [0.1063],\n",
      "         [0.9330],\n",
      "         [0.8577],\n",
      "         [0.5052],\n",
      "         [0.9091],\n",
      "         [0.9026],\n",
      "         [0.8640],\n",
      "         [0.8969],\n",
      "         [0.8978],\n",
      "         [0.9064],\n",
      "         [0.8557],\n",
      "         [0.5325],\n",
      "         [0.6525],\n",
      "         [0.1325],\n",
      "         [0.3986],\n",
      "         [0.2865],\n",
      "         [0.6205],\n",
      "         [0.9110],\n",
      "         [0.9041],\n",
      "         [0.8846]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.9997],\n",
      "        [0.1762],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9997],\n",
      "        [0.2735],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.9998],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [0.9819],\n",
      "        [0.8379],\n",
      "        [0.5108],\n",
      "        [0.9997],\n",
      "        [0.9814],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.2729],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.9998],\n",
      "        [0.3930],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9999],\n",
      "        [0.0335],\n",
      "        [0.4480],\n",
      "        [0.3753],\n",
      "        [0.9959],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.3575],\n",
      "        [0.0247],\n",
      "        [0.4668],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [0.8223],\n",
      "        [0.9995],\n",
      "        [0.5009],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.9998],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5463],\n",
      "        [0.4611],\n",
      "        [0.5080],\n",
      "        [0.8139],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.3912],\n",
      "        [0.9994],\n",
      "        [0.3573],\n",
      "        [0.4642],\n",
      "        [0.3875],\n",
      "        [0.6628],\n",
      "        [0.5054],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9804],\n",
      "        [0.5245],\n",
      "        [0.8761],\n",
      "        [0.7129],\n",
      "        [0.2518],\n",
      "        [0.3747],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9009],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.0209],\n",
      "        [0.9956],\n",
      "        [0.8933],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9164],\n",
      "        [0.5334],\n",
      "        [0.6555],\n",
      "        [0.0368],\n",
      "        [0.3780],\n",
      "        [0.2547],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9724]])\n",
      "######### Epoch: 7  ######### Train Loss: 0.005908578168600798  ######### Relative L2 Test Norm: 19.78685760498047\n",
      "Output batch pred: tensor([[[0.8878],\n",
      "         [0.8265],\n",
      "         [0.8844],\n",
      "         [0.8835],\n",
      "         [0.6309],\n",
      "         [0.8814],\n",
      "         [0.8809],\n",
      "         [0.8845],\n",
      "         [0.8891],\n",
      "         [0.8908],\n",
      "         [0.3404],\n",
      "         [0.2307],\n",
      "         [0.5709],\n",
      "         [0.8979],\n",
      "         [0.4296],\n",
      "         [0.9076],\n",
      "         [0.4943],\n",
      "         [0.8233],\n",
      "         [0.8936],\n",
      "         [0.8889],\n",
      "         [0.8856],\n",
      "         [0.8847],\n",
      "         [0.8867],\n",
      "         [0.3447],\n",
      "         [0.8921],\n",
      "         [0.8811],\n",
      "         [0.8948],\n",
      "         [0.8931],\n",
      "         [0.8563],\n",
      "         [0.8870],\n",
      "         [0.8816],\n",
      "         [0.2108],\n",
      "         [0.8697],\n",
      "         [0.8640],\n",
      "         [0.8643],\n",
      "         [0.2128],\n",
      "         [0.8643],\n",
      "         [0.2180],\n",
      "         [0.0663],\n",
      "         [0.6698],\n",
      "         [0.8676],\n",
      "         [0.8686],\n",
      "         [0.0724],\n",
      "         [0.8728],\n",
      "         [0.0676],\n",
      "         [0.3398],\n",
      "         [0.0527],\n",
      "         [0.8213],\n",
      "         [0.8937],\n",
      "         [0.8961],\n",
      "         [0.9006],\n",
      "         [0.9002],\n",
      "         [0.8978],\n",
      "         [0.8934],\n",
      "         [0.8877],\n",
      "         [0.7441],\n",
      "         [0.8717],\n",
      "         [0.8669],\n",
      "         [0.3834],\n",
      "         [0.4223],\n",
      "         [0.4188],\n",
      "         [0.8641],\n",
      "         [0.8571],\n",
      "         [0.4353],\n",
      "         [0.7493],\n",
      "         [0.2402],\n",
      "         [0.2503],\n",
      "         [0.4708],\n",
      "         [0.8934],\n",
      "         [0.8080],\n",
      "         [0.8937],\n",
      "         [0.5067],\n",
      "         [0.8933],\n",
      "         [0.8929],\n",
      "         [0.8909],\n",
      "         [0.2459],\n",
      "         [0.8892],\n",
      "         [0.7664],\n",
      "         [0.3495],\n",
      "         [0.8864],\n",
      "         [0.8886],\n",
      "         [0.8904],\n",
      "         [0.0781],\n",
      "         [0.8886],\n",
      "         [0.4103],\n",
      "         [0.8911],\n",
      "         [0.8892],\n",
      "         [0.4120],\n",
      "         [0.8882],\n",
      "         [0.8871],\n",
      "         [0.5950],\n",
      "         [0.6051],\n",
      "         [0.4539],\n",
      "         [0.8837],\n",
      "         [0.4501],\n",
      "         [0.8769],\n",
      "         [0.8049],\n",
      "         [0.0435],\n",
      "         [0.8351],\n",
      "         [0.8660],\n",
      "         [0.4565],\n",
      "         [0.3695],\n",
      "         [0.3092],\n",
      "         [0.8664],\n",
      "         [0.6638],\n",
      "         [0.4596],\n",
      "         [0.8867],\n",
      "         [0.7545],\n",
      "         [0.6735],\n",
      "         [0.9034],\n",
      "         [0.4315],\n",
      "         [0.9072],\n",
      "         [0.3671],\n",
      "         [0.4504],\n",
      "         [0.4505],\n",
      "         [0.0928],\n",
      "         [0.2711],\n",
      "         [0.9025],\n",
      "         [0.9027],\n",
      "         [0.3640],\n",
      "         [0.9098],\n",
      "         [0.8752],\n",
      "         [0.9159],\n",
      "         [0.9187],\n",
      "         [0.9214],\n",
      "         [0.9233],\n",
      "         [0.9203],\n",
      "         [0.9212],\n",
      "         [0.9198],\n",
      "         [0.9126],\n",
      "         [0.0826],\n",
      "         [0.9042],\n",
      "         [0.8977],\n",
      "         [0.8920],\n",
      "         [0.8853],\n",
      "         [0.8810],\n",
      "         [0.8857],\n",
      "         [0.8673],\n",
      "         [0.2352],\n",
      "         [0.4240],\n",
      "         [0.8882],\n",
      "         [0.6053],\n",
      "         [0.9069],\n",
      "         [0.9049],\n",
      "         [0.9046],\n",
      "         [0.8989],\n",
      "         [0.8905],\n",
      "         [0.3281],\n",
      "         [0.8749],\n",
      "         [0.8745],\n",
      "         [0.8737],\n",
      "         [0.8748],\n",
      "         [0.8834],\n",
      "         [0.8914],\n",
      "         [0.1860],\n",
      "         [0.3476],\n",
      "         [0.4830],\n",
      "         [0.9146],\n",
      "         [0.3717],\n",
      "         [0.9077],\n",
      "         [0.9021],\n",
      "         [0.8936],\n",
      "         [0.8848],\n",
      "         [0.0688],\n",
      "         [0.8781],\n",
      "         [0.4577],\n",
      "         [0.8786],\n",
      "         [0.8825],\n",
      "         [0.8864],\n",
      "         [0.8576],\n",
      "         [0.8929],\n",
      "         [0.4619],\n",
      "         [0.3612],\n",
      "         [0.4172],\n",
      "         [0.8930],\n",
      "         [0.8936],\n",
      "         [0.8926],\n",
      "         [0.7243]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.9164],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.6920],\n",
      "        [0.9996],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.2208],\n",
      "        [0.5945],\n",
      "        [0.9819],\n",
      "        [0.4503],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.0383],\n",
      "        [0.7540],\n",
      "        [0.9995],\n",
      "        [0.9996],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.3808],\n",
      "        [0.0000],\n",
      "        [0.9044],\n",
      "        [0.9997],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.5038],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.5054],\n",
      "        [0.8296],\n",
      "        [0.2686],\n",
      "        [0.2729],\n",
      "        [0.5139],\n",
      "        [0.9995],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.3875],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [0.6628],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.0209],\n",
      "        [0.9520],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [0.4454],\n",
      "        [0.3753],\n",
      "        [0.9966],\n",
      "        [0.7391],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.7129],\n",
      "        [0.9999],\n",
      "        [0.4480],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.4645],\n",
      "        [0.4642],\n",
      "        [0.0174],\n",
      "        [0.2646],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.2610],\n",
      "        [0.4611],\n",
      "        [0.9804],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.3575],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9515],\n",
      "        [0.9999],\n",
      "        [0.5030],\n",
      "        [0.3930],\n",
      "        [0.4527],\n",
      "        [0.9967],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7820]])\n",
      "######### Epoch: 8  ######### Train Loss: 0.00824643298983574  ######### Relative L2 Test Norm: 20.51417350769043\n",
      "Output batch pred: tensor([[[0.2411],\n",
      "         [0.6868],\n",
      "         [0.8949],\n",
      "         [0.8954],\n",
      "         [0.1998],\n",
      "         [0.6499],\n",
      "         [0.9046],\n",
      "         [0.9092],\n",
      "         [0.9132],\n",
      "         [0.9159],\n",
      "         [0.9210],\n",
      "         [0.4390],\n",
      "         [0.9245],\n",
      "         [0.9208],\n",
      "         [0.9212],\n",
      "         [0.9153],\n",
      "         [0.9117],\n",
      "         [0.9105],\n",
      "         [0.9063],\n",
      "         [0.9019],\n",
      "         [0.8996],\n",
      "         [0.4113],\n",
      "         [0.8988],\n",
      "         [0.8963],\n",
      "         [0.0407],\n",
      "         [0.3472],\n",
      "         [0.8911],\n",
      "         [0.8887],\n",
      "         [0.8887],\n",
      "         [0.4434],\n",
      "         [0.7613],\n",
      "         [0.6122],\n",
      "         [0.8391],\n",
      "         [0.9021],\n",
      "         [0.0621],\n",
      "         [0.9094],\n",
      "         [0.9120],\n",
      "         [0.2495],\n",
      "         [0.9074],\n",
      "         [0.8902],\n",
      "         [0.4524],\n",
      "         [0.4551],\n",
      "         [0.0507],\n",
      "         [0.7356],\n",
      "         [0.8739],\n",
      "         [0.8756],\n",
      "         [0.7339],\n",
      "         [0.8843],\n",
      "         [0.7237],\n",
      "         [0.9021],\n",
      "         [0.4149],\n",
      "         [0.8228],\n",
      "         [0.5158],\n",
      "         [0.9093],\n",
      "         [0.9059],\n",
      "         [0.8996],\n",
      "         [0.6574],\n",
      "         [0.8843],\n",
      "         [0.2232],\n",
      "         [0.8447],\n",
      "         [0.8799],\n",
      "         [0.2242],\n",
      "         [0.8827],\n",
      "         [0.8878],\n",
      "         [0.4412],\n",
      "         [0.0468],\n",
      "         [0.4813],\n",
      "         [0.8913],\n",
      "         [0.3391],\n",
      "         [0.8914],\n",
      "         [0.8800],\n",
      "         [0.7722],\n",
      "         [0.8987],\n",
      "         [0.9014],\n",
      "         [0.3458],\n",
      "         [0.9028],\n",
      "         [0.4730],\n",
      "         [0.4638],\n",
      "         [0.8829],\n",
      "         [0.8970],\n",
      "         [0.8958],\n",
      "         [0.8918],\n",
      "         [0.5365],\n",
      "         [0.8934],\n",
      "         [0.8943],\n",
      "         [0.4029],\n",
      "         [0.4813],\n",
      "         [0.9138],\n",
      "         [0.6316],\n",
      "         [0.9177],\n",
      "         [0.9159],\n",
      "         [0.8355],\n",
      "         [0.7056],\n",
      "         [0.8937],\n",
      "         [0.8849],\n",
      "         [0.8789],\n",
      "         [0.8743],\n",
      "         [0.8725],\n",
      "         [0.5539],\n",
      "         [0.3927],\n",
      "         [0.0482],\n",
      "         [0.8859],\n",
      "         [0.8899],\n",
      "         [0.4472],\n",
      "         [0.8823],\n",
      "         [0.0547],\n",
      "         [0.8923],\n",
      "         [0.8924],\n",
      "         [0.8917],\n",
      "         [0.8898],\n",
      "         [0.3293],\n",
      "         [0.0529],\n",
      "         [0.9015],\n",
      "         [0.9050],\n",
      "         [0.9109],\n",
      "         [0.9153],\n",
      "         [0.9177],\n",
      "         [0.8784],\n",
      "         [0.3383],\n",
      "         [0.3595],\n",
      "         [0.9110],\n",
      "         [0.3610],\n",
      "         [0.9034],\n",
      "         [0.8699],\n",
      "         [0.8319],\n",
      "         [0.8977],\n",
      "         [0.2459],\n",
      "         [0.8979],\n",
      "         [0.9007],\n",
      "         [0.4266],\n",
      "         [0.9045],\n",
      "         [0.9071],\n",
      "         [0.3384],\n",
      "         [0.9088],\n",
      "         [0.4326],\n",
      "         [0.9123],\n",
      "         [0.9109],\n",
      "         [0.2618],\n",
      "         [0.9041],\n",
      "         [0.4226],\n",
      "         [0.8980],\n",
      "         [0.8953],\n",
      "         [0.4701],\n",
      "         [0.8916],\n",
      "         [0.8914],\n",
      "         [0.8928],\n",
      "         [0.8954],\n",
      "         [0.8983],\n",
      "         [0.8878],\n",
      "         [0.4080],\n",
      "         [0.9027],\n",
      "         [0.8344],\n",
      "         [0.4709],\n",
      "         [0.9020],\n",
      "         [0.8964],\n",
      "         [0.3263],\n",
      "         [0.4520],\n",
      "         [0.8941],\n",
      "         [0.8934],\n",
      "         [0.8934],\n",
      "         [0.8957],\n",
      "         [0.8969],\n",
      "         [0.0472],\n",
      "         [0.8973],\n",
      "         [0.8641],\n",
      "         [0.2427],\n",
      "         [0.3510],\n",
      "         [0.1766],\n",
      "         [0.8959],\n",
      "         [0.3440],\n",
      "         [0.8973],\n",
      "         [0.2399],\n",
      "         [0.9001],\n",
      "         [0.9023],\n",
      "         [0.9028],\n",
      "         [0.0856],\n",
      "         [0.9022],\n",
      "         [0.4325]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2547],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.0000],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.5038],\n",
      "        [0.8296],\n",
      "        [0.6628],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.2518],\n",
      "        [0.9998],\n",
      "        [0.9819],\n",
      "        [0.5030],\n",
      "        [0.5165],\n",
      "        [0.0368],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [0.9995],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [0.8761],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.9967],\n",
      "        [0.2686],\n",
      "        [0.9490],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.0209],\n",
      "        [0.5334],\n",
      "        [0.9997],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.8379],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.3747],\n",
      "        [0.9959],\n",
      "        [0.5108],\n",
      "        [0.5054],\n",
      "        [0.9724],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.6327],\n",
      "        [0.4645],\n",
      "        [0.0288],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9820],\n",
      "        [0.0247],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.3753],\n",
      "        [0.0335],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.3573],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [0.3875],\n",
      "        [0.9966],\n",
      "        [0.9515],\n",
      "        [0.9044],\n",
      "        [0.9994],\n",
      "        [0.2735],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5245],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.4503],\n",
      "        [0.9994],\n",
      "        [0.9009],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [0.3728],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.2610],\n",
      "        [0.3840],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0383],\n",
      "        [0.9999],\n",
      "        [0.4642]])\n",
      "######### Epoch: 9  ######### Train Loss: 0.006860088557004929  ######### Relative L2 Test Norm: 18.182964324951172\n",
      "Output batch pred: tensor([[[0.9159],\n",
      "         [0.9222],\n",
      "         [0.9299],\n",
      "         [0.9376],\n",
      "         [0.9439],\n",
      "         [0.9377],\n",
      "         [0.5038],\n",
      "         [0.9438],\n",
      "         [0.5129],\n",
      "         [0.4685],\n",
      "         [0.9142],\n",
      "         [0.6410],\n",
      "         [0.2122],\n",
      "         [0.4761],\n",
      "         [0.2201],\n",
      "         [0.2175],\n",
      "         [0.6578],\n",
      "         [0.9075],\n",
      "         [0.9156],\n",
      "         [0.9228],\n",
      "         [0.2542],\n",
      "         [0.9305],\n",
      "         [0.0854],\n",
      "         [0.3584],\n",
      "         [0.5112],\n",
      "         [0.8457],\n",
      "         [0.6288],\n",
      "         [0.9118],\n",
      "         [0.9160],\n",
      "         [0.9193],\n",
      "         [0.9268],\n",
      "         [0.9220],\n",
      "         [0.4274],\n",
      "         [0.9434],\n",
      "         [0.9461],\n",
      "         [0.9409],\n",
      "         [0.9348],\n",
      "         [0.7978],\n",
      "         [0.7151],\n",
      "         [0.8286],\n",
      "         [0.3924],\n",
      "         [0.0151],\n",
      "         [0.8949],\n",
      "         [0.7483],\n",
      "         [0.9043],\n",
      "         [0.9121],\n",
      "         [0.9188],\n",
      "         [0.3462],\n",
      "         [0.9312],\n",
      "         [0.9323],\n",
      "         [0.9304],\n",
      "         [0.9256],\n",
      "         [0.0457],\n",
      "         [0.9123],\n",
      "         [0.3272],\n",
      "         [0.3879],\n",
      "         [0.9030],\n",
      "         [0.9042],\n",
      "         [0.4465],\n",
      "         [0.9194],\n",
      "         [0.9275],\n",
      "         [0.2048],\n",
      "         [0.9380],\n",
      "         [0.9473],\n",
      "         [0.9494],\n",
      "         [0.9494],\n",
      "         [0.9466],\n",
      "         [0.4507],\n",
      "         [0.4862],\n",
      "         [0.9348],\n",
      "         [0.9313],\n",
      "         [0.9283],\n",
      "         [0.9275],\n",
      "         [0.9253],\n",
      "         [0.4307],\n",
      "         [0.9261],\n",
      "         [0.2543],\n",
      "         [0.9248],\n",
      "         [0.9236],\n",
      "         [0.3576],\n",
      "         [0.9190],\n",
      "         [0.9178],\n",
      "         [0.8278],\n",
      "         [0.4776],\n",
      "         [0.9200],\n",
      "         [0.4803],\n",
      "         [0.9304],\n",
      "         [0.9348],\n",
      "         [0.9393],\n",
      "         [0.9301],\n",
      "         [0.9311],\n",
      "         [0.3487],\n",
      "         [0.9376],\n",
      "         [0.7195],\n",
      "         [0.9234],\n",
      "         [0.9125],\n",
      "         [0.4419],\n",
      "         [0.3101],\n",
      "         [0.4428],\n",
      "         [0.9031],\n",
      "         [0.8747],\n",
      "         [0.9183],\n",
      "         [0.4789],\n",
      "         [0.9376],\n",
      "         [0.4507],\n",
      "         [0.4731],\n",
      "         [0.9473],\n",
      "         [0.3923],\n",
      "         [0.2638],\n",
      "         [0.9327],\n",
      "         [0.9272],\n",
      "         [0.1775],\n",
      "         [0.9179],\n",
      "         [0.9204],\n",
      "         [0.8901],\n",
      "         [0.6153],\n",
      "         [0.8994],\n",
      "         [0.2734],\n",
      "         [0.3589],\n",
      "         [0.9394],\n",
      "         [0.9346],\n",
      "         [0.5886],\n",
      "         [0.9269],\n",
      "         [0.0721],\n",
      "         [0.9232],\n",
      "         [0.2430],\n",
      "         [0.9222],\n",
      "         [0.9246],\n",
      "         [0.3654],\n",
      "         [0.9289],\n",
      "         [0.9290],\n",
      "         [0.3647],\n",
      "         [0.9226],\n",
      "         [0.4075],\n",
      "         [0.6149],\n",
      "         [0.9101],\n",
      "         [0.9099],\n",
      "         [0.3302],\n",
      "         [0.4766],\n",
      "         [0.9268],\n",
      "         [0.9356],\n",
      "         [0.9462],\n",
      "         [0.9524],\n",
      "         [0.9415],\n",
      "         [0.9629],\n",
      "         [0.9627],\n",
      "         [0.9596],\n",
      "         [0.9552],\n",
      "         [0.9512],\n",
      "         [0.9462],\n",
      "         [0.0752],\n",
      "         [0.9506],\n",
      "         [0.8367],\n",
      "         [0.9597],\n",
      "         [0.9615],\n",
      "         [0.9657],\n",
      "         [0.9655],\n",
      "         [0.0970],\n",
      "         [0.0779],\n",
      "         [0.7834],\n",
      "         [0.9370],\n",
      "         [0.9290],\n",
      "         [0.8525],\n",
      "         [0.9199],\n",
      "         [0.4204],\n",
      "         [0.0602],\n",
      "         [0.9310],\n",
      "         [0.9024],\n",
      "         [0.8190],\n",
      "         [0.9534],\n",
      "         [0.9010],\n",
      "         [0.0969],\n",
      "         [0.9513],\n",
      "         [0.9422],\n",
      "         [0.4472],\n",
      "         [0.9266],\n",
      "         [0.9193],\n",
      "         [0.9129]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9820],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.2547],\n",
      "        [0.5463],\n",
      "        [0.2686],\n",
      "        [0.2610],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.9998],\n",
      "        [0.0368],\n",
      "        [0.3753],\n",
      "        [0.5334],\n",
      "        [0.9009],\n",
      "        [0.6628],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9995],\n",
      "        [0.8296],\n",
      "        [0.7540],\n",
      "        [0.8933],\n",
      "        [0.4580],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.4645],\n",
      "        [0.9997],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.9804],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.5009],\n",
      "        [0.3728],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.4668],\n",
      "        [0.9999],\n",
      "        [0.3840],\n",
      "        [0.2518],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9520],\n",
      "        [0.6327],\n",
      "        [0.9490],\n",
      "        [0.2729],\n",
      "        [0.3575],\n",
      "        [0.9998],\n",
      "        [0.9967],\n",
      "        [0.5945],\n",
      "        [0.9962],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.3912],\n",
      "        [0.9997],\n",
      "        [0.4454],\n",
      "        [0.6555],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3747],\n",
      "        [0.5151],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9724],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [0.0335],\n",
      "        [0.9999],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0209],\n",
      "        [0.0000],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.8223],\n",
      "        [0.9998],\n",
      "        [0.9164],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000]])\n",
      "######### Epoch: 10  ######### Train Loss: 0.0034920175094157457  ######### Relative L2 Test Norm: 15.954229354858398\n",
      "Output batch pred: tensor([[[0.9395],\n",
      "         [0.2209],\n",
      "         [0.9471],\n",
      "         [0.9545],\n",
      "         [0.5382],\n",
      "         [0.9716],\n",
      "         [0.8400],\n",
      "         [0.9853],\n",
      "         [0.9872],\n",
      "         [0.9900],\n",
      "         [0.5539],\n",
      "         [0.9862],\n",
      "         [0.9852],\n",
      "         [0.9159],\n",
      "         [0.9781],\n",
      "         [0.9784],\n",
      "         [0.9764],\n",
      "         [0.0783],\n",
      "         [0.9757],\n",
      "         [0.9730],\n",
      "         [0.6877],\n",
      "         [0.9727],\n",
      "         [0.5409],\n",
      "         [0.9736],\n",
      "         [0.3685],\n",
      "         [0.9792],\n",
      "         [0.9855],\n",
      "         [0.9903],\n",
      "         [0.8337],\n",
      "         [0.9980],\n",
      "         [0.9862],\n",
      "         [0.9939],\n",
      "         [0.9901],\n",
      "         [0.9482],\n",
      "         [0.9700],\n",
      "         [0.9375],\n",
      "         [0.0596],\n",
      "         [0.9388],\n",
      "         [0.3394],\n",
      "         [0.9332],\n",
      "         [0.0407],\n",
      "         [0.2538],\n",
      "         [0.4996],\n",
      "         [0.9613],\n",
      "         [0.9704],\n",
      "         [0.8405],\n",
      "         [0.9739],\n",
      "         [0.2657],\n",
      "         [0.9708],\n",
      "         [0.9665],\n",
      "         [0.9625],\n",
      "         [0.9589],\n",
      "         [0.8971],\n",
      "         [0.5085],\n",
      "         [0.3644],\n",
      "         [0.9617],\n",
      "         [0.9638],\n",
      "         [0.5023],\n",
      "         [0.4358],\n",
      "         [0.9616],\n",
      "         [0.4932],\n",
      "         [0.4460],\n",
      "         [0.9548],\n",
      "         [0.9514],\n",
      "         [0.9568],\n",
      "         [0.4998],\n",
      "         [0.2691],\n",
      "         [0.9698],\n",
      "         [0.9747],\n",
      "         [0.9788],\n",
      "         [0.5216],\n",
      "         [0.9803],\n",
      "         [0.9782],\n",
      "         [0.0917],\n",
      "         [0.9727],\n",
      "         [0.6490],\n",
      "         [0.9660],\n",
      "         [0.9303],\n",
      "         [0.2624],\n",
      "         [0.2543],\n",
      "         [0.9597],\n",
      "         [0.9628],\n",
      "         [0.2593],\n",
      "         [0.9659],\n",
      "         [0.2777],\n",
      "         [0.9691],\n",
      "         [0.9650],\n",
      "         [0.9803],\n",
      "         [0.9857],\n",
      "         [0.9883],\n",
      "         [0.0815],\n",
      "         [0.2505],\n",
      "         [0.9903],\n",
      "         [0.9855],\n",
      "         [0.9790],\n",
      "         [0.9707],\n",
      "         [0.9645],\n",
      "         [0.3431],\n",
      "         [0.6485],\n",
      "         [0.4802],\n",
      "         [0.9460],\n",
      "         [0.9460],\n",
      "         [0.9463],\n",
      "         [0.4348],\n",
      "         [0.8742],\n",
      "         [0.9090],\n",
      "         [0.4374],\n",
      "         [0.5035],\n",
      "         [0.8403],\n",
      "         [0.7171],\n",
      "         [0.7862],\n",
      "         [0.9880],\n",
      "         [0.8746],\n",
      "         [0.0971],\n",
      "         [0.9993],\n",
      "         [0.9967],\n",
      "         [0.9896],\n",
      "         [0.9820],\n",
      "         [0.9695],\n",
      "         [0.9543],\n",
      "         [0.3628],\n",
      "         [0.0308],\n",
      "         [0.9355],\n",
      "         [0.4262],\n",
      "         [0.1755],\n",
      "         [0.3677],\n",
      "         [0.9700],\n",
      "         [0.9829],\n",
      "         [0.9914],\n",
      "         [0.9969],\n",
      "         [0.5131],\n",
      "         [0.9921],\n",
      "         [0.4131],\n",
      "         [0.4683],\n",
      "         [0.9736],\n",
      "         [0.9665],\n",
      "         [0.9627],\n",
      "         [0.9249],\n",
      "         [0.4373],\n",
      "         [0.9591],\n",
      "         [0.9573],\n",
      "         [0.5957],\n",
      "         [0.4523],\n",
      "         [0.9591],\n",
      "         [0.9604],\n",
      "         [0.8853],\n",
      "         [0.5473],\n",
      "         [0.9709],\n",
      "         [0.9673],\n",
      "         [0.9867],\n",
      "         [0.9940],\n",
      "         [0.7724],\n",
      "         [1.0017],\n",
      "         [1.0005],\n",
      "         [0.9838],\n",
      "         [0.4034],\n",
      "         [0.9730],\n",
      "         [0.4992],\n",
      "         [0.0612],\n",
      "         [0.9363],\n",
      "         [0.0494],\n",
      "         [0.9291],\n",
      "         [0.4136],\n",
      "         [0.9447],\n",
      "         [0.3740],\n",
      "         [0.9670],\n",
      "         [0.9787],\n",
      "         [0.9879],\n",
      "         [0.9951],\n",
      "         [0.9966],\n",
      "         [0.9979],\n",
      "         [0.7922],\n",
      "         [0.4077],\n",
      "         [0.8917],\n",
      "         [0.9698],\n",
      "         [0.9593],\n",
      "         [0.3680],\n",
      "         [0.9424]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.9962],\n",
      "        [0.9998],\n",
      "        [0.9044],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.9996],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.9520],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.9999],\n",
      "        [0.0142],\n",
      "        [0.2735],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.5165],\n",
      "        [0.3753],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.4611],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.2686],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [0.6327],\n",
      "        [0.9997],\n",
      "        [0.9515],\n",
      "        [0.2646],\n",
      "        [0.2577],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.2610],\n",
      "        [0.9999],\n",
      "        [0.2729],\n",
      "        [0.9959],\n",
      "        [0.9804],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.6555],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [0.9009],\n",
      "        [0.9420],\n",
      "        [0.4580],\n",
      "        [0.5139],\n",
      "        [0.8379],\n",
      "        [0.6920],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.3875],\n",
      "        [0.0000],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.1762],\n",
      "        [0.3728],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9819],\n",
      "        [0.3747],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.3780],\n",
      "        [0.8761],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.3912],\n",
      "        [1.0000]])\n",
      "######### Epoch: 11  ######### Train Loss: 0.0009110596147365868  ######### Relative L2 Test Norm: 14.444889068603516\n",
      "Output batch pred: tensor([[[0.9347],\n",
      "         [0.9925],\n",
      "         [0.4535],\n",
      "         [0.4630],\n",
      "         [0.0602],\n",
      "         [0.4639],\n",
      "         [0.9851],\n",
      "         [0.8554],\n",
      "         [1.0006],\n",
      "         [1.0045],\n",
      "         [0.0672],\n",
      "         [1.0103],\n",
      "         [1.0084],\n",
      "         [1.0056],\n",
      "         [1.0013],\n",
      "         [0.5492],\n",
      "         [0.9984],\n",
      "         [0.0916],\n",
      "         [0.2934],\n",
      "         [1.0112],\n",
      "         [1.0157],\n",
      "         [0.8982],\n",
      "         [1.0198],\n",
      "         [0.2580],\n",
      "         [0.7314],\n",
      "         [0.3085],\n",
      "         [0.9779],\n",
      "         [0.4347],\n",
      "         [0.5166],\n",
      "         [1.0155],\n",
      "         [0.8991],\n",
      "         [1.0234],\n",
      "         [1.0228],\n",
      "         [0.9877],\n",
      "         [1.0208],\n",
      "         [0.2931],\n",
      "         [1.0089],\n",
      "         [0.9950],\n",
      "         [1.0089],\n",
      "         [0.3900],\n",
      "         [1.0243],\n",
      "         [1.0343],\n",
      "         [1.0459],\n",
      "         [1.0548],\n",
      "         [1.0603],\n",
      "         [1.0586],\n",
      "         [1.0490],\n",
      "         [0.5158],\n",
      "         [1.0143],\n",
      "         [0.9919],\n",
      "         [0.5017],\n",
      "         [0.9658],\n",
      "         [0.0275],\n",
      "         [0.9663],\n",
      "         [0.0630],\n",
      "         [0.5273],\n",
      "         [0.3912],\n",
      "         [1.0133],\n",
      "         [1.0182],\n",
      "         [1.0183],\n",
      "         [0.2835],\n",
      "         [0.5886],\n",
      "         [0.4001],\n",
      "         [0.6320],\n",
      "         [0.9955],\n",
      "         [0.2767],\n",
      "         [1.0026],\n",
      "         [0.4187],\n",
      "         [1.0082],\n",
      "         [1.0091],\n",
      "         [1.0030],\n",
      "         [0.5166],\n",
      "         [0.9826],\n",
      "         [0.3608],\n",
      "         [0.1604],\n",
      "         [0.4251],\n",
      "         [0.7262],\n",
      "         [0.9840],\n",
      "         [1.0018],\n",
      "         [1.0142],\n",
      "         [1.0261],\n",
      "         [1.0326],\n",
      "         [0.3036],\n",
      "         [0.6023],\n",
      "         [1.0075],\n",
      "         [0.9889],\n",
      "         [0.9661],\n",
      "         [0.2405],\n",
      "         [0.9391],\n",
      "         [0.0223],\n",
      "         [0.0174],\n",
      "         [0.3110],\n",
      "         [0.9669],\n",
      "         [0.5265],\n",
      "         [0.9923],\n",
      "         [1.0006],\n",
      "         [1.0061],\n",
      "         [0.5383],\n",
      "         [1.0115],\n",
      "         [1.0141],\n",
      "         [1.0183],\n",
      "         [1.0220],\n",
      "         [1.0293],\n",
      "         [1.0332],\n",
      "         [1.0364],\n",
      "         [1.0360],\n",
      "         [1.0325],\n",
      "         [1.0258],\n",
      "         [0.6973],\n",
      "         [1.0118],\n",
      "         [0.4938],\n",
      "         [0.5457],\n",
      "         [0.8110],\n",
      "         [1.0142],\n",
      "         [0.5572],\n",
      "         [0.5772],\n",
      "         [1.0363],\n",
      "         [1.0252],\n",
      "         [0.9691],\n",
      "         [1.0242],\n",
      "         [0.9972],\n",
      "         [0.9166],\n",
      "         [0.9944],\n",
      "         [0.9886],\n",
      "         [0.0709],\n",
      "         [0.9897],\n",
      "         [0.9626],\n",
      "         [1.0050],\n",
      "         [0.9378],\n",
      "         [0.0800],\n",
      "         [0.8808],\n",
      "         [1.0170],\n",
      "         [0.4060],\n",
      "         [1.0063],\n",
      "         [1.0033],\n",
      "         [0.7033],\n",
      "         [1.0064],\n",
      "         [1.0102],\n",
      "         [1.0155],\n",
      "         [1.0185],\n",
      "         [1.0230],\n",
      "         [0.5592],\n",
      "         [1.0193],\n",
      "         [0.8434],\n",
      "         [1.0046],\n",
      "         [0.9970],\n",
      "         [0.9621],\n",
      "         [0.9965],\n",
      "         [1.0019],\n",
      "         [0.8023],\n",
      "         [0.5062],\n",
      "         [0.5321],\n",
      "         [1.0323],\n",
      "         [1.0445],\n",
      "         [0.9906],\n",
      "         [1.0270],\n",
      "         [0.5263],\n",
      "         [1.0157],\n",
      "         [1.0075],\n",
      "         [1.0011],\n",
      "         [0.2861],\n",
      "         [0.5416],\n",
      "         [0.4240],\n",
      "         [1.0227],\n",
      "         [1.0303],\n",
      "         [1.0359],\n",
      "         [1.0371],\n",
      "         [1.0366],\n",
      "         [0.4327],\n",
      "         [1.0257],\n",
      "         [0.4301],\n",
      "         [1.0161],\n",
      "         [1.0141],\n",
      "         [1.0147],\n",
      "         [1.0160],\n",
      "         [0.7628],\n",
      "         [1.0185],\n",
      "         [1.0174]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9044],\n",
      "        [0.9997],\n",
      "        [0.4454],\n",
      "        [0.4611],\n",
      "        [0.0209],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [0.0335],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.6628],\n",
      "        [0.2729],\n",
      "        [0.9490],\n",
      "        [0.3930],\n",
      "        [0.4642],\n",
      "        [0.9967],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.9420],\n",
      "        [0.9997],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [0.3575],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.5151],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.5463],\n",
      "        [0.3780],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.5030],\n",
      "        [0.9997],\n",
      "        [0.3808],\n",
      "        [0.1762],\n",
      "        [0.4480],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.2547],\n",
      "        [0.5334],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.0142],\n",
      "        [0.3573],\n",
      "        [0.9997],\n",
      "        [0.5245],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.5139],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.5054],\n",
      "        [0.9997],\n",
      "        [0.9814],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.8761],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.9997],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.0247],\n",
      "        [0.8139],\n",
      "        [0.9999],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [0.9515],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.4503],\n",
      "        [0.4580],\n",
      "        [0.9819],\n",
      "        [0.9995],\n",
      "        [0.9164],\n",
      "        [0.9820],\n",
      "        [0.4552],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.2610],\n",
      "        [0.5038],\n",
      "        [0.3875],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000]])\n",
      "######### Epoch: 12  ######### Train Loss: 0.0011462982511147857  ######### Relative L2 Test Norm: 12.827704429626465\n",
      "Output batch pred: tensor([[[0.2596],\n",
      "         [0.4496],\n",
      "         [0.9962],\n",
      "         [0.3580],\n",
      "         [0.3282],\n",
      "         [0.9889],\n",
      "         [0.9936],\n",
      "         [1.0004],\n",
      "         [0.2482],\n",
      "         [0.4668],\n",
      "         [1.0244],\n",
      "         [1.0265],\n",
      "         [0.5655],\n",
      "         [1.0275],\n",
      "         [0.0895],\n",
      "         [0.8479],\n",
      "         [1.0182],\n",
      "         [0.0655],\n",
      "         [1.0147],\n",
      "         [1.0194],\n",
      "         [0.4009],\n",
      "         [1.0308],\n",
      "         [0.5123],\n",
      "         [1.0426],\n",
      "         [1.0502],\n",
      "         [0.5969],\n",
      "         [1.0551],\n",
      "         [1.0547],\n",
      "         [1.0534],\n",
      "         [0.7549],\n",
      "         [1.0445],\n",
      "         [1.0383],\n",
      "         [0.4935],\n",
      "         [1.0328],\n",
      "         [1.0332],\n",
      "         [1.0353],\n",
      "         [0.2469],\n",
      "         [1.0475],\n",
      "         [1.0451],\n",
      "         [1.0632],\n",
      "         [1.0702],\n",
      "         [1.0752],\n",
      "         [1.0770],\n",
      "         [0.9622],\n",
      "         [1.0678],\n",
      "         [1.0583],\n",
      "         [0.9136],\n",
      "         [1.0342],\n",
      "         [0.5770],\n",
      "         [0.9844],\n",
      "         [0.2731],\n",
      "         [0.9641],\n",
      "         [1.0349],\n",
      "         [0.5117],\n",
      "         [1.0575],\n",
      "         [0.5610],\n",
      "         [1.0723],\n",
      "         [1.0710],\n",
      "         [1.0666],\n",
      "         [1.0565],\n",
      "         [0.3125],\n",
      "         [1.0334],\n",
      "         [0.0458],\n",
      "         [0.5428],\n",
      "         [1.0277],\n",
      "         [0.7767],\n",
      "         [0.9211],\n",
      "         [1.0569],\n",
      "         [1.0635],\n",
      "         [0.5986],\n",
      "         [1.0574],\n",
      "         [1.0475],\n",
      "         [0.4196],\n",
      "         [1.0088],\n",
      "         [0.0363],\n",
      "         [0.9756],\n",
      "         [0.3330],\n",
      "         [0.4374],\n",
      "         [0.4950],\n",
      "         [1.0119],\n",
      "         [0.2973],\n",
      "         [1.0545],\n",
      "         [1.0687],\n",
      "         [1.0756],\n",
      "         [1.0748],\n",
      "         [1.0522],\n",
      "         [1.0557],\n",
      "         [1.0420],\n",
      "         [1.0277],\n",
      "         [0.4071],\n",
      "         [0.1781],\n",
      "         [1.0145],\n",
      "         [0.6873],\n",
      "         [1.0329],\n",
      "         [1.0436],\n",
      "         [1.0557],\n",
      "         [1.0636],\n",
      "         [0.6557],\n",
      "         [1.0533],\n",
      "         [1.0594],\n",
      "         [0.5767],\n",
      "         [1.0413],\n",
      "         [0.3003],\n",
      "         [0.4186],\n",
      "         [1.0275],\n",
      "         [0.9949],\n",
      "         [0.5644],\n",
      "         [0.0771],\n",
      "         [0.7479],\n",
      "         [1.0371],\n",
      "         [0.4398],\n",
      "         [1.0380],\n",
      "         [0.5080],\n",
      "         [0.5625],\n",
      "         [1.0310],\n",
      "         [0.9605],\n",
      "         [0.0755],\n",
      "         [0.5088],\n",
      "         [0.8929],\n",
      "         [1.0346],\n",
      "         [1.0270],\n",
      "         [1.0410],\n",
      "         [1.0420],\n",
      "         [1.0433],\n",
      "         [0.8323],\n",
      "         [0.5166],\n",
      "         [0.3978],\n",
      "         [1.0362],\n",
      "         [1.0335],\n",
      "         [0.0699],\n",
      "         [1.0282],\n",
      "         [0.7881],\n",
      "         [1.0234],\n",
      "         [1.0233],\n",
      "         [0.6545],\n",
      "         [0.0581],\n",
      "         [1.0186],\n",
      "         [1.0164],\n",
      "         [1.0121],\n",
      "         [0.2504],\n",
      "         [0.9727],\n",
      "         [1.0132],\n",
      "         [1.0135],\n",
      "         [0.0544],\n",
      "         [1.0177],\n",
      "         [0.9905],\n",
      "         [0.2807],\n",
      "         [1.0375],\n",
      "         [0.9607],\n",
      "         [0.6176],\n",
      "         [1.0554],\n",
      "         [1.0614],\n",
      "         [0.8749],\n",
      "         [1.0659],\n",
      "         [1.0647],\n",
      "         [0.4560],\n",
      "         [0.6137],\n",
      "         [1.0599],\n",
      "         [1.0616],\n",
      "         [1.0647],\n",
      "         [1.0695],\n",
      "         [1.0741],\n",
      "         [1.0807],\n",
      "         [1.0856],\n",
      "         [1.0862],\n",
      "         [1.0266],\n",
      "         [1.0744],\n",
      "         [1.0792],\n",
      "         [1.0697],\n",
      "         [1.0642],\n",
      "         [0.5942],\n",
      "         [1.0487],\n",
      "         [0.4310],\n",
      "         [1.0425],\n",
      "         [1.0390],\n",
      "         [1.0364],\n",
      "         [0.9598],\n",
      "         [1.0293]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2577],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.4503],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.5165],\n",
      "        [0.9996],\n",
      "        [0.0383],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.9997],\n",
      "        [0.4552],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9998],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.9490],\n",
      "        [0.2729],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.9994],\n",
      "        [0.0000],\n",
      "        [0.5038],\n",
      "        [0.9999],\n",
      "        [0.6920],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.4668],\n",
      "        [0.5030],\n",
      "        [0.9997],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.3840],\n",
      "        [0.9999],\n",
      "        [0.9515],\n",
      "        [0.5139],\n",
      "        [0.0209],\n",
      "        [0.6628],\n",
      "        [0.9994],\n",
      "        [0.3912],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.9044],\n",
      "        [0.0288],\n",
      "        [0.4645],\n",
      "        [0.8139],\n",
      "        [0.9995],\n",
      "        [0.9814],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.4611],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.9995],\n",
      "        [0.9996],\n",
      "        [0.5945],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [0.2518],\n",
      "        [0.9420],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.2547],\n",
      "        [0.9999],\n",
      "        [0.8761],\n",
      "        [0.5245],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.3780],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [0.9009],\n",
      "        [0.9820],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [1.0000]])\n",
      "######### Epoch: 13  ######### Train Loss: 0.0030587040819227695  ######### Relative L2 Test Norm: 13.042001724243164\n",
      "Output batch pred: tensor([[[1.0251],\n",
      "         [0.7368],\n",
      "         [1.0466],\n",
      "         [1.0566],\n",
      "         [1.0618],\n",
      "         [1.0649],\n",
      "         [1.0625],\n",
      "         [0.9888],\n",
      "         [1.0466],\n",
      "         [0.4937],\n",
      "         [1.0298],\n",
      "         [0.0499],\n",
      "         [1.0276],\n",
      "         [0.8871],\n",
      "         [1.0373],\n",
      "         [0.9214],\n",
      "         [1.0500],\n",
      "         [0.6020],\n",
      "         [0.5752],\n",
      "         [1.0541],\n",
      "         [1.0530],\n",
      "         [1.0517],\n",
      "         [0.2944],\n",
      "         [1.0486],\n",
      "         [0.6151],\n",
      "         [1.0514],\n",
      "         [1.0528],\n",
      "         [0.0762],\n",
      "         [0.9298],\n",
      "         [1.0532],\n",
      "         [1.0542],\n",
      "         [1.0548],\n",
      "         [1.0556],\n",
      "         [0.0881],\n",
      "         [1.0660],\n",
      "         [1.0725],\n",
      "         [1.0673],\n",
      "         [1.0792],\n",
      "         [1.0818],\n",
      "         [1.0676],\n",
      "         [1.0691],\n",
      "         [1.0592],\n",
      "         [0.3863],\n",
      "         [0.8582],\n",
      "         [1.0251],\n",
      "         [0.4618],\n",
      "         [1.0244],\n",
      "         [1.0319],\n",
      "         [1.0468],\n",
      "         [1.0596],\n",
      "         [1.0739],\n",
      "         [1.0712],\n",
      "         [1.0865],\n",
      "         [1.0879],\n",
      "         [1.0826],\n",
      "         [1.0714],\n",
      "         [1.0602],\n",
      "         [0.5633],\n",
      "         [1.0421],\n",
      "         [0.9604],\n",
      "         [0.5009],\n",
      "         [1.0398],\n",
      "         [0.2360],\n",
      "         [1.0517],\n",
      "         [1.0572],\n",
      "         [1.0617],\n",
      "         [1.0625],\n",
      "         [0.0760],\n",
      "         [1.0625],\n",
      "         [0.5272],\n",
      "         [1.0676],\n",
      "         [1.0711],\n",
      "         [1.0749],\n",
      "         [1.0791],\n",
      "         [1.0839],\n",
      "         [1.0868],\n",
      "         [1.0903],\n",
      "         [1.0902],\n",
      "         [1.0871],\n",
      "         [0.9607],\n",
      "         [0.6250],\n",
      "         [1.0810],\n",
      "         [1.0792],\n",
      "         [0.3460],\n",
      "         [1.0761],\n",
      "         [1.0748],\n",
      "         [1.0668],\n",
      "         [0.4330],\n",
      "         [1.0558],\n",
      "         [0.6674],\n",
      "         [0.4137],\n",
      "         [0.9679],\n",
      "         [0.4659],\n",
      "         [0.3868],\n",
      "         [1.0337],\n",
      "         [1.0428],\n",
      "         [1.0525],\n",
      "         [1.0414],\n",
      "         [1.0646],\n",
      "         [1.0622],\n",
      "         [0.5237],\n",
      "         [0.2027],\n",
      "         [1.0371],\n",
      "         [0.0427],\n",
      "         [0.0423],\n",
      "         [1.0134],\n",
      "         [1.0170],\n",
      "         [1.0274],\n",
      "         [1.0389],\n",
      "         [0.2827],\n",
      "         [0.5147],\n",
      "         [1.0665],\n",
      "         [0.0898],\n",
      "         [1.0551],\n",
      "         [0.5663],\n",
      "         [0.9861],\n",
      "         [1.0114],\n",
      "         [0.4523],\n",
      "         [0.0332],\n",
      "         [0.3547],\n",
      "         [0.4727],\n",
      "         [0.9914],\n",
      "         [0.7346],\n",
      "         [0.3113],\n",
      "         [1.0646],\n",
      "         [1.0731],\n",
      "         [0.4709],\n",
      "         [1.0677],\n",
      "         [1.0599],\n",
      "         [1.0488],\n",
      "         [1.0417],\n",
      "         [0.5407],\n",
      "         [0.2583],\n",
      "         [0.5429],\n",
      "         [0.4008],\n",
      "         [1.0386],\n",
      "         [1.0584],\n",
      "         [1.0649],\n",
      "         [1.0691],\n",
      "         [1.0714],\n",
      "         [1.0755],\n",
      "         [1.0762],\n",
      "         [1.0442],\n",
      "         [1.0431],\n",
      "         [0.9856],\n",
      "         [1.0660],\n",
      "         [0.2941],\n",
      "         [0.5189],\n",
      "         [1.0451],\n",
      "         [1.0406],\n",
      "         [0.8264],\n",
      "         [0.5872],\n",
      "         [0.2785],\n",
      "         [0.9651],\n",
      "         [0.4173],\n",
      "         [0.5754],\n",
      "         [1.0525],\n",
      "         [0.4070],\n",
      "         [0.4338],\n",
      "         [1.0535],\n",
      "         [1.0461],\n",
      "         [0.4056],\n",
      "         [1.0303],\n",
      "         [0.2571],\n",
      "         [0.7524],\n",
      "         [0.6890],\n",
      "         [0.5511],\n",
      "         [0.5621],\n",
      "         [0.8221],\n",
      "         [1.0696],\n",
      "         [1.0750],\n",
      "         [1.0730],\n",
      "         [0.6077],\n",
      "         [1.0587],\n",
      "         [0.8292],\n",
      "         [1.0323],\n",
      "         [1.0217],\n",
      "         [0.0187]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.6628],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [0.9996],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.9997],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9997],\n",
      "        [0.5245],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.0368],\n",
      "        [0.8296],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9820],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.3573],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0142],\n",
      "        [0.9967],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.8223],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.3753],\n",
      "        [0.9997],\n",
      "        [0.5945],\n",
      "        [0.3930],\n",
      "        [0.9164],\n",
      "        [0.4503],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.0247],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2547],\n",
      "        [0.4480],\n",
      "        [0.9999],\n",
      "        [0.0335],\n",
      "        [0.9997],\n",
      "        [0.5139],\n",
      "        [0.9420],\n",
      "        [0.9999],\n",
      "        [0.4611],\n",
      "        [0.0209],\n",
      "        [0.3728],\n",
      "        [0.4668],\n",
      "        [0.9490],\n",
      "        [0.6555],\n",
      "        [0.2686],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.2518],\n",
      "        [0.5030],\n",
      "        [0.3747],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9520],\n",
      "        [0.9515],\n",
      "        [0.8761],\n",
      "        [0.9997],\n",
      "        [0.2646],\n",
      "        [0.4645],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.5463],\n",
      "        [0.2729],\n",
      "        [0.9044],\n",
      "        [0.3875],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.6920],\n",
      "        [0.6327],\n",
      "        [0.5080],\n",
      "        [0.5038],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.0000]])\n",
      "######### Epoch: 14  ######### Train Loss: 0.0037140846252441406  ######### Relative L2 Test Norm: 14.390786170959473\n",
      "Output batch pred: tensor([[[0.2445],\n",
      "         [1.0381],\n",
      "         [1.0510],\n",
      "         [1.0620],\n",
      "         [1.0697],\n",
      "         [1.0639],\n",
      "         [1.0752],\n",
      "         [0.7898],\n",
      "         [1.0662],\n",
      "         [1.0216],\n",
      "         [0.4288],\n",
      "         [0.9714],\n",
      "         [1.0377],\n",
      "         [0.0214],\n",
      "         [0.8096],\n",
      "         [1.0372],\n",
      "         [0.5435],\n",
      "         [1.0460],\n",
      "         [0.4018],\n",
      "         [1.0583],\n",
      "         [1.0601],\n",
      "         [1.0636],\n",
      "         [0.5738],\n",
      "         [1.0626],\n",
      "         [1.0638],\n",
      "         [1.0627],\n",
      "         [1.0618],\n",
      "         [1.0610],\n",
      "         [1.0622],\n",
      "         [1.0619],\n",
      "         [1.0629],\n",
      "         [1.0628],\n",
      "         [0.3051],\n",
      "         [1.0576],\n",
      "         [0.9194],\n",
      "         [1.0492],\n",
      "         [0.9661],\n",
      "         [0.0446],\n",
      "         [0.4822],\n",
      "         [0.0145],\n",
      "         [1.0210],\n",
      "         [0.9494],\n",
      "         [0.0148],\n",
      "         [1.0265],\n",
      "         [1.0316],\n",
      "         [0.8640],\n",
      "         [0.2212],\n",
      "         [1.0545],\n",
      "         [1.0589],\n",
      "         [1.0653],\n",
      "         [1.0660],\n",
      "         [1.0718],\n",
      "         [1.0724],\n",
      "         [1.0390],\n",
      "         [1.0693],\n",
      "         [0.5137],\n",
      "         [0.8205],\n",
      "         [0.4295],\n",
      "         [1.0528],\n",
      "         [1.0482],\n",
      "         [0.2895],\n",
      "         [0.7338],\n",
      "         [1.0506],\n",
      "         [0.1923],\n",
      "         [1.0545],\n",
      "         [1.0581],\n",
      "         [0.5077],\n",
      "         [0.7977],\n",
      "         [1.0455],\n",
      "         [1.0534],\n",
      "         [1.0474],\n",
      "         [0.6564],\n",
      "         [1.0358],\n",
      "         [1.0312],\n",
      "         [0.2341],\n",
      "         [1.0176],\n",
      "         [0.4603],\n",
      "         [1.0396],\n",
      "         [0.9129],\n",
      "         [1.0501],\n",
      "         [0.5807],\n",
      "         [1.0566],\n",
      "         [0.4009],\n",
      "         [0.5724],\n",
      "         [1.0470],\n",
      "         [0.4955],\n",
      "         [1.0357],\n",
      "         [0.0427],\n",
      "         [1.0272],\n",
      "         [0.4640],\n",
      "         [0.4628],\n",
      "         [1.0324],\n",
      "         [1.0370],\n",
      "         [0.3918],\n",
      "         [1.0464],\n",
      "         [0.4141],\n",
      "         [0.4097],\n",
      "         [1.0482],\n",
      "         [0.4924],\n",
      "         [1.0446],\n",
      "         [0.5426],\n",
      "         [0.8301],\n",
      "         [0.8901],\n",
      "         [1.0367],\n",
      "         [1.0384],\n",
      "         [0.0617],\n",
      "         [0.5521],\n",
      "         [0.4098],\n",
      "         [0.5751],\n",
      "         [1.0528],\n",
      "         [1.0542],\n",
      "         [1.0554],\n",
      "         [1.0523],\n",
      "         [1.0522],\n",
      "         [1.0515],\n",
      "         [0.2602],\n",
      "         [0.5526],\n",
      "         [0.4178],\n",
      "         [1.0485],\n",
      "         [1.0494],\n",
      "         [1.0522],\n",
      "         [1.0565],\n",
      "         [1.0601],\n",
      "         [1.0666],\n",
      "         [0.6276],\n",
      "         [1.0572],\n",
      "         [0.9597],\n",
      "         [1.0734],\n",
      "         [1.0676],\n",
      "         [1.0596],\n",
      "         [1.0475],\n",
      "         [1.0344],\n",
      "         [1.0180],\n",
      "         [0.5098],\n",
      "         [0.2141],\n",
      "         [0.3139],\n",
      "         [0.5340],\n",
      "         [0.0262],\n",
      "         [0.4698],\n",
      "         [1.0333],\n",
      "         [0.9604],\n",
      "         [1.0282],\n",
      "         [1.0684],\n",
      "         [1.0737],\n",
      "         [0.0730],\n",
      "         [1.0745],\n",
      "         [1.0705],\n",
      "         [1.0649],\n",
      "         [1.0618],\n",
      "         [0.2929],\n",
      "         [1.0253],\n",
      "         [1.0573],\n",
      "         [1.0572],\n",
      "         [1.0600],\n",
      "         [1.0603],\n",
      "         [0.7272],\n",
      "         [1.0544],\n",
      "         [1.0489],\n",
      "         [0.5039],\n",
      "         [0.5822],\n",
      "         [0.0297],\n",
      "         [1.0280],\n",
      "         [1.0295],\n",
      "         [1.0324],\n",
      "         [0.4118],\n",
      "         [1.0568],\n",
      "         [1.0650],\n",
      "         [1.0726],\n",
      "         [1.0768],\n",
      "         [1.0682],\n",
      "         [1.0730],\n",
      "         [1.0102],\n",
      "         [1.0512],\n",
      "         [0.2553],\n",
      "         [1.0250],\n",
      "         [0.5053],\n",
      "         [1.0090],\n",
      "         [1.0081]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2686],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.3912],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9997],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.9999],\n",
      "        [0.8933],\n",
      "        [0.0335],\n",
      "        [0.4645],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.0247],\n",
      "        [0.9999],\n",
      "        [0.9967],\n",
      "        [0.7820],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.7129],\n",
      "        [0.3875],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [0.2735],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.6920],\n",
      "        [0.9820],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.9997],\n",
      "        [0.9995],\n",
      "        [0.2518],\n",
      "        [0.9814],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9997],\n",
      "        [0.3575],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.9999],\n",
      "        [0.4580],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3747],\n",
      "        [0.9997],\n",
      "        [0.3840],\n",
      "        [0.3780],\n",
      "        [0.9995],\n",
      "        [0.4503],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [0.7540],\n",
      "        [0.8139],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0288],\n",
      "        [0.5030],\n",
      "        [0.3753],\n",
      "        [0.5139],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.5038],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.9724],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.5151],\n",
      "        [0.2577],\n",
      "        [0.3573],\n",
      "        [0.5463],\n",
      "        [0.0383],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.9520],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.5334],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.9996],\n",
      "        [0.9164],\n",
      "        [0.9962],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [1.0000]])\n",
      "######### Epoch: 15  ######### Train Loss: 0.003137006890028715  ######### Relative L2 Test Norm: 15.042296409606934\n",
      "Output batch pred: tensor([[[ 1.0220],\n",
      "         [ 0.8962],\n",
      "         [ 1.0219],\n",
      "         [ 1.0416],\n",
      "         [ 1.0468],\n",
      "         [ 1.0491],\n",
      "         [ 1.0474],\n",
      "         [ 1.0461],\n",
      "         [ 1.0408],\n",
      "         [ 1.0344],\n",
      "         [ 1.0229],\n",
      "         [ 0.5126],\n",
      "         [ 0.1880],\n",
      "         [ 0.6873],\n",
      "         [ 0.7837],\n",
      "         [ 0.9796],\n",
      "         [ 0.0051],\n",
      "         [ 1.0184],\n",
      "         [ 0.0241],\n",
      "         [ 0.9502],\n",
      "         [ 1.0252],\n",
      "         [ 0.5198],\n",
      "         [ 0.3846],\n",
      "         [ 1.0347],\n",
      "         [ 1.0410],\n",
      "         [ 0.7824],\n",
      "         [ 1.0163],\n",
      "         [ 1.0503],\n",
      "         [ 1.0516],\n",
      "         [ 1.0487],\n",
      "         [ 0.5692],\n",
      "         [ 1.0395],\n",
      "         [ 0.7871],\n",
      "         [ 0.5252],\n",
      "         [ 1.0253],\n",
      "         [ 0.3742],\n",
      "         [ 0.4638],\n",
      "         [ 1.0089],\n",
      "         [ 1.0316],\n",
      "         [ 1.0359],\n",
      "         [ 1.0388],\n",
      "         [ 1.0393],\n",
      "         [ 1.0409],\n",
      "         [ 0.0302],\n",
      "         [ 1.0369],\n",
      "         [ 1.0329],\n",
      "         [ 1.0270],\n",
      "         [ 1.0242],\n",
      "         [ 1.0209],\n",
      "         [ 0.8866],\n",
      "         [ 0.0247],\n",
      "         [ 0.2463],\n",
      "         [ 0.5235],\n",
      "         [ 1.0235],\n",
      "         [ 0.3576],\n",
      "         [ 1.0328],\n",
      "         [ 1.0364],\n",
      "         [ 1.0423],\n",
      "         [ 0.4926],\n",
      "         [ 1.0518],\n",
      "         [ 1.0561],\n",
      "         [ 1.0580],\n",
      "         [ 1.0600],\n",
      "         [ 0.9303],\n",
      "         [ 1.0603],\n",
      "         [ 1.0539],\n",
      "         [ 1.0501],\n",
      "         [ 0.3968],\n",
      "         [ 0.3633],\n",
      "         [ 1.0293],\n",
      "         [ 1.0253],\n",
      "         [ 0.2434],\n",
      "         [ 1.0156],\n",
      "         [ 0.0027],\n",
      "         [ 0.2272],\n",
      "         [ 1.0226],\n",
      "         [ 0.9932],\n",
      "         [ 1.0208],\n",
      "         [ 1.0379],\n",
      "         [ 0.9735],\n",
      "         [ 0.2689],\n",
      "         [ 1.0473],\n",
      "         [ 1.0509],\n",
      "         [ 1.0498],\n",
      "         [ 0.9720],\n",
      "         [ 0.8677],\n",
      "         [ 1.0357],\n",
      "         [ 0.2295],\n",
      "         [ 1.0199],\n",
      "         [ 0.6559],\n",
      "         [ 0.3345],\n",
      "         [ 0.3517],\n",
      "         [ 1.0027],\n",
      "         [-0.0153],\n",
      "         [ 1.0095],\n",
      "         [ 0.5396],\n",
      "         [ 0.6345],\n",
      "         [ 0.5194],\n",
      "         [ 1.0311],\n",
      "         [ 0.2491],\n",
      "         [ 1.0311],\n",
      "         [ 1.0308],\n",
      "         [ 1.0269],\n",
      "         [ 0.0288],\n",
      "         [ 1.0187],\n",
      "         [ 0.2477],\n",
      "         [ 1.0112],\n",
      "         [ 1.0148],\n",
      "         [ 0.1541],\n",
      "         [ 0.3612],\n",
      "         [ 1.0237],\n",
      "         [ 0.4797],\n",
      "         [ 0.8842],\n",
      "         [ 0.4010],\n",
      "         [ 1.0384],\n",
      "         [ 1.0404],\n",
      "         [ 1.0441],\n",
      "         [ 1.0496],\n",
      "         [ 1.0525],\n",
      "         [ 0.5168],\n",
      "         [ 0.7660],\n",
      "         [ 1.0544],\n",
      "         [ 1.0529],\n",
      "         [ 1.0510],\n",
      "         [ 1.0456],\n",
      "         [ 1.0430],\n",
      "         [ 1.0370],\n",
      "         [ 1.0369],\n",
      "         [ 1.0335],\n",
      "         [ 1.0334],\n",
      "         [ 0.9965],\n",
      "         [ 0.4864],\n",
      "         [ 1.0376],\n",
      "         [ 0.9805],\n",
      "         [ 0.4683],\n",
      "         [ 1.0350],\n",
      "         [ 1.0334],\n",
      "         [ 1.0177],\n",
      "         [ 0.4711],\n",
      "         [ 1.0228],\n",
      "         [ 0.2224],\n",
      "         [ 0.4395],\n",
      "         [ 1.0217],\n",
      "         [ 0.5113],\n",
      "         [ 0.5606],\n",
      "         [ 1.0130],\n",
      "         [ 1.0245],\n",
      "         [ 1.0230],\n",
      "         [ 0.9300],\n",
      "         [-0.0086],\n",
      "         [ 0.5161],\n",
      "         [ 0.4518],\n",
      "         [ 0.5283],\n",
      "         [ 1.0252],\n",
      "         [ 1.0304],\n",
      "         [ 1.0347],\n",
      "         [ 1.0373],\n",
      "         [ 0.5550],\n",
      "         [ 0.3882],\n",
      "         [ 0.5820],\n",
      "         [ 1.0250],\n",
      "         [ 0.4541],\n",
      "         [ 1.0112],\n",
      "         [ 0.3646],\n",
      "         [ 1.0102],\n",
      "         [ 0.0252],\n",
      "         [ 1.0225],\n",
      "         [ 1.0316],\n",
      "         [ 1.0417],\n",
      "         [ 1.0501],\n",
      "         [ 1.0542],\n",
      "         [ 1.0568],\n",
      "         [ 1.0545],\n",
      "         [ 0.8483],\n",
      "         [ 1.0423],\n",
      "         [ 1.0329],\n",
      "         [ 1.0269],\n",
      "         [ 1.0219]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9997],\n",
      "        [0.8296],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.5054],\n",
      "        [0.2208],\n",
      "        [0.6555],\n",
      "        [0.7391],\n",
      "        [0.9515],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.6920],\n",
      "        [0.9520],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.4580],\n",
      "        [0.9724],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.0288],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.8379],\n",
      "        [0.0383],\n",
      "        [0.2735],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.3575],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.8223],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.3573],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.8933],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.3753],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [0.5945],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [0.3728],\n",
      "        [0.9999],\n",
      "        [0.4642],\n",
      "        [0.8139],\n",
      "        [0.3912],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9420],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.4480],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.4645],\n",
      "        [0.9997],\n",
      "        [0.2547],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.5334],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.8761],\n",
      "        [0.0000],\n",
      "        [0.5080],\n",
      "        [0.4527],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.3780],\n",
      "        [0.5463],\n",
      "        [0.9997],\n",
      "        [0.4552],\n",
      "        [0.9997],\n",
      "        [0.3875],\n",
      "        [0.9997],\n",
      "        [0.0368],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998]])\n",
      "######### Epoch: 16  ######### Train Loss: 0.001559231779538095  ######### Relative L2 Test Norm: 15.79310131072998\n",
      "Output batch pred: tensor([[[ 0.9593],\n",
      "         [ 0.9977],\n",
      "         [ 0.7711],\n",
      "         [ 1.0035],\n",
      "         [ 0.4341],\n",
      "         [ 1.0061],\n",
      "         [ 1.0074],\n",
      "         [ 1.0081],\n",
      "         [ 0.0101],\n",
      "         [ 0.9344],\n",
      "         [ 1.0048],\n",
      "         [ 0.9713],\n",
      "         [ 0.4545],\n",
      "         [ 0.5535],\n",
      "         [ 1.0100],\n",
      "         [ 0.6936],\n",
      "         [ 1.0146],\n",
      "         [ 0.7159],\n",
      "         [ 1.0158],\n",
      "         [ 0.5191],\n",
      "         [ 1.0180],\n",
      "         [ 1.0191],\n",
      "         [ 0.8797],\n",
      "         [ 1.0163],\n",
      "         [ 1.0151],\n",
      "         [ 0.3756],\n",
      "         [ 1.0123],\n",
      "         [ 1.0167],\n",
      "         [ 1.0207],\n",
      "         [ 1.0243],\n",
      "         [ 1.0286],\n",
      "         [ 0.2509],\n",
      "         [ 0.9015],\n",
      "         [ 1.0276],\n",
      "         [ 1.0240],\n",
      "         [ 1.0171],\n",
      "         [ 0.4413],\n",
      "         [ 1.0005],\n",
      "         [ 0.9963],\n",
      "         [ 0.1555],\n",
      "         [ 0.9933],\n",
      "         [ 0.5131],\n",
      "         [-0.0131],\n",
      "         [ 1.0052],\n",
      "         [ 1.0103],\n",
      "         [ 1.0125],\n",
      "         [ 1.0132],\n",
      "         [ 1.0124],\n",
      "         [ 1.0090],\n",
      "         [ 0.4313],\n",
      "         [ 1.0007],\n",
      "         [ 0.9972],\n",
      "         [ 0.3357],\n",
      "         [ 1.0010],\n",
      "         [ 0.4859],\n",
      "         [ 0.5071],\n",
      "         [ 1.0117],\n",
      "         [ 1.0150],\n",
      "         [ 0.5197],\n",
      "         [ 1.0144],\n",
      "         [ 0.6626],\n",
      "         [ 1.0097],\n",
      "         [ 1.0062],\n",
      "         [ 0.8251],\n",
      "         [ 1.0088],\n",
      "         [ 0.2140],\n",
      "         [ 1.0152],\n",
      "         [ 1.0194],\n",
      "         [ 0.4687],\n",
      "         [ 1.0275],\n",
      "         [ 1.0258],\n",
      "         [ 1.0219],\n",
      "         [ 1.0167],\n",
      "         [ 0.8630],\n",
      "         [-0.0039],\n",
      "         [ 0.2085],\n",
      "         [ 0.9977],\n",
      "         [ 0.9977],\n",
      "         [ 1.0026],\n",
      "         [ 0.2328],\n",
      "         [ 1.0104],\n",
      "         [ 0.9386],\n",
      "         [ 1.0117],\n",
      "         [ 0.0083],\n",
      "         [ 0.2353],\n",
      "         [ 0.9377],\n",
      "         [ 0.5003],\n",
      "         [ 0.2083],\n",
      "         [ 0.4377],\n",
      "         [ 0.9077],\n",
      "         [ 1.0087],\n",
      "         [ 1.0165],\n",
      "         [ 1.0257],\n",
      "         [ 1.0303],\n",
      "         [ 0.8288],\n",
      "         [ 1.0309],\n",
      "         [ 1.0252],\n",
      "         [ 0.4635],\n",
      "         [ 0.1314],\n",
      "         [ 1.0052],\n",
      "         [ 1.0006],\n",
      "         [ 0.9983],\n",
      "         [ 1.0017],\n",
      "         [ 1.0055],\n",
      "         [ 0.3239],\n",
      "         [ 1.0125],\n",
      "         [ 0.9998],\n",
      "         [ 0.9716],\n",
      "         [-0.0214],\n",
      "         [ 0.9989],\n",
      "         [-0.0041],\n",
      "         [ 0.9831],\n",
      "         [ 0.3275],\n",
      "         [ 0.4512],\n",
      "         [ 0.9825],\n",
      "         [ 0.9767],\n",
      "         [ 0.9960],\n",
      "         [ 0.7267],\n",
      "         [ 0.9334],\n",
      "         [ 0.7651],\n",
      "         [ 0.2409],\n",
      "         [ 1.0163],\n",
      "         [ 0.6276],\n",
      "         [ 1.0130],\n",
      "         [ 0.3339],\n",
      "         [ 1.0117],\n",
      "         [ 1.0156],\n",
      "         [ 1.0192],\n",
      "         [ 0.4470],\n",
      "         [ 0.9923],\n",
      "         [ 1.0273],\n",
      "         [ 1.0264],\n",
      "         [ 0.5258],\n",
      "         [ 1.0211],\n",
      "         [ 0.4660],\n",
      "         [ 1.0113],\n",
      "         [ 1.0082],\n",
      "         [ 0.4325],\n",
      "         [ 1.0113],\n",
      "         [ 0.3548],\n",
      "         [ 1.0205],\n",
      "         [ 1.0252],\n",
      "         [ 1.0266],\n",
      "         [ 1.0263],\n",
      "         [ 1.0232],\n",
      "         [ 0.2246],\n",
      "         [ 0.3560],\n",
      "         [ 0.9781],\n",
      "         [-0.0130],\n",
      "         [ 0.9733],\n",
      "         [ 0.9881],\n",
      "         [-0.0026],\n",
      "         [ 0.4851],\n",
      "         [ 0.3508],\n",
      "         [ 1.0161],\n",
      "         [ 1.0191],\n",
      "         [ 1.0213],\n",
      "         [ 1.0082],\n",
      "         [ 1.0165],\n",
      "         [ 1.0079],\n",
      "         [ 1.0005],\n",
      "         [ 0.8583],\n",
      "         [-0.0260],\n",
      "         [ 0.4786],\n",
      "         [ 0.4624],\n",
      "         [ 0.9897],\n",
      "         [ 0.9946],\n",
      "         [ 0.9983],\n",
      "         [ 0.3402],\n",
      "         [ 1.0048],\n",
      "         [ 0.5446],\n",
      "         [ 1.0055],\n",
      "         [ 0.3555],\n",
      "         [ 1.0008],\n",
      "         [ 0.9919],\n",
      "         [ 0.3257],\n",
      "         [ 0.9903],\n",
      "         [ 0.9915]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9515],\n",
      "        [0.9997],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.9044],\n",
      "        [0.9967],\n",
      "        [0.9520],\n",
      "        [0.4668],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.9959],\n",
      "        [0.5054],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2646],\n",
      "        [0.8296],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.5108],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.8139],\n",
      "        [0.0142],\n",
      "        [0.2547],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.2729],\n",
      "        [0.9164],\n",
      "        [0.5165],\n",
      "        [0.2610],\n",
      "        [0.4645],\n",
      "        [0.8761],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.7540],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.1762],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.9420],\n",
      "        [0.0000],\n",
      "        [0.9998],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [0.3912],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.9999],\n",
      "        [0.6920],\n",
      "        [0.8933],\n",
      "        [0.7129],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.9997],\n",
      "        [0.3573],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.3840],\n",
      "        [0.9724],\n",
      "        [0.0174],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.5030],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.8379],\n",
      "        [0.0209],\n",
      "        [0.5151],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [0.3753],\n",
      "        [0.9998],\n",
      "        [0.9999]])\n",
      "######### Epoch: 17  ######### Train Loss: 0.0006447633495554328  ######### Relative L2 Test Norm: 17.535913467407227\n",
      "Output batch pred: tensor([[[ 0.8490],\n",
      "         [ 0.9118],\n",
      "         [ 0.9878],\n",
      "         [ 0.3303],\n",
      "         [ 0.4884],\n",
      "         [ 0.9985],\n",
      "         [ 1.0011],\n",
      "         [ 1.0039],\n",
      "         [ 1.0060],\n",
      "         [ 1.0032],\n",
      "         [ 0.9732],\n",
      "         [ 0.7027],\n",
      "         [ 1.0034],\n",
      "         [ 0.2149],\n",
      "         [ 0.9994],\n",
      "         [ 0.7257],\n",
      "         [ 0.9923],\n",
      "         [ 0.9939],\n",
      "         [ 0.9903],\n",
      "         [ 0.9902],\n",
      "         [ 0.9751],\n",
      "         [ 0.9827],\n",
      "         [ 0.9798],\n",
      "         [ 0.4108],\n",
      "         [ 0.4613],\n",
      "         [ 0.3177],\n",
      "         [ 0.1925],\n",
      "         [ 0.3068],\n",
      "         [ 0.9572],\n",
      "         [-0.0082],\n",
      "         [ 0.4548],\n",
      "         [ 0.6304],\n",
      "         [ 0.9855],\n",
      "         [ 0.9871],\n",
      "         [ 0.2156],\n",
      "         [ 0.3501],\n",
      "         [ 0.9943],\n",
      "         [ 0.5358],\n",
      "         [ 0.9874],\n",
      "         [ 0.9809],\n",
      "         [ 0.9822],\n",
      "         [ 0.9830],\n",
      "         [ 0.9651],\n",
      "         [ 0.8052],\n",
      "         [ 0.8382],\n",
      "         [ 0.9904],\n",
      "         [ 0.9895],\n",
      "         [ 0.9881],\n",
      "         [ 0.4054],\n",
      "         [ 0.9787],\n",
      "         [ 0.8930],\n",
      "         [ 0.4660],\n",
      "         [ 0.1673],\n",
      "         [ 0.9667],\n",
      "         [ 0.9681],\n",
      "         [ 0.9732],\n",
      "         [ 0.9759],\n",
      "         [ 0.9791],\n",
      "         [-0.0366],\n",
      "         [ 0.9832],\n",
      "         [ 0.9822],\n",
      "         [ 0.9789],\n",
      "         [ 0.9769],\n",
      "         [ 0.9601],\n",
      "         [ 0.9709],\n",
      "         [ 0.4062],\n",
      "         [ 0.9340],\n",
      "         [ 0.2845],\n",
      "         [ 0.8997],\n",
      "         [ 0.4927],\n",
      "         [ 0.9785],\n",
      "         [ 0.9817],\n",
      "         [ 0.9811],\n",
      "         [-0.0281],\n",
      "         [ 0.9784],\n",
      "         [ 0.9767],\n",
      "         [ 0.9761],\n",
      "         [ 0.9749],\n",
      "         [ 0.1793],\n",
      "         [ 0.9776],\n",
      "         [ 0.9829],\n",
      "         [ 0.9838],\n",
      "         [ 0.4161],\n",
      "         [ 0.9896],\n",
      "         [ 0.9906],\n",
      "         [ 0.9875],\n",
      "         [ 0.6009],\n",
      "         [ 0.4949],\n",
      "         [ 0.9928],\n",
      "         [ 0.9982],\n",
      "         [ 0.4568],\n",
      "         [ 1.0052],\n",
      "         [ 1.0097],\n",
      "         [ 1.0117],\n",
      "         [ 1.0142],\n",
      "         [ 1.0138],\n",
      "         [ 0.3728],\n",
      "         [ 1.0101],\n",
      "         [ 1.0095],\n",
      "         [ 1.0069],\n",
      "         [ 1.0073],\n",
      "         [ 1.0075],\n",
      "         [ 1.0075],\n",
      "         [ 0.9175],\n",
      "         [ 1.0058],\n",
      "         [ 1.0029],\n",
      "         [ 1.0009],\n",
      "         [ 0.9977],\n",
      "         [ 0.9929],\n",
      "         [ 0.9877],\n",
      "         [-0.0160],\n",
      "         [ 0.9776],\n",
      "         [ 0.3260],\n",
      "         [ 0.4610],\n",
      "         [ 0.4202],\n",
      "         [ 0.2213],\n",
      "         [ 0.9969],\n",
      "         [ 0.9948],\n",
      "         [ 1.0101],\n",
      "         [ 1.0100],\n",
      "         [ 0.0063],\n",
      "         [ 1.0042],\n",
      "         [ 0.9957],\n",
      "         [ 0.9910],\n",
      "         [ 0.7252],\n",
      "         [ 0.4143],\n",
      "         [ 0.9127],\n",
      "         [-0.0260],\n",
      "         [ 0.9772],\n",
      "         [ 0.9782],\n",
      "         [ 0.7566],\n",
      "         [-0.0319],\n",
      "         [ 0.9798],\n",
      "         [ 0.9798],\n",
      "         [ 0.2885],\n",
      "         [ 0.3223],\n",
      "         [ 0.9708],\n",
      "         [ 0.1647],\n",
      "         [ 0.2875],\n",
      "         [ 0.9266],\n",
      "         [ 0.9645],\n",
      "         [ 0.0844],\n",
      "         [ 0.3799],\n",
      "         [ 0.9650],\n",
      "         [ 0.9663],\n",
      "         [ 0.6299],\n",
      "         [ 0.9639],\n",
      "         [-0.0225],\n",
      "         [ 0.9622],\n",
      "         [ 0.9485],\n",
      "         [-0.0263],\n",
      "         [ 0.3868],\n",
      "         [ 0.7289],\n",
      "         [ 0.9688],\n",
      "         [ 0.9701],\n",
      "         [ 0.4562],\n",
      "         [ 0.1431],\n",
      "         [ 0.4600],\n",
      "         [ 0.4656],\n",
      "         [ 0.9818],\n",
      "         [ 0.9455],\n",
      "         [ 0.3268],\n",
      "         [ 0.8605],\n",
      "         [ 0.9966],\n",
      "         [ 1.0009],\n",
      "         [ 1.0004],\n",
      "         [ 0.9993],\n",
      "         [ 0.9977],\n",
      "         [ 0.9930],\n",
      "         [ 0.9882],\n",
      "         [ 0.1927],\n",
      "         [ 0.9778],\n",
      "         [ 0.3866],\n",
      "         [ 0.4689],\n",
      "         [ 0.9739],\n",
      "         [ 0.5039],\n",
      "         [ 0.8290],\n",
      "         [ 0.9789]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.8379],\n",
      "        [0.9044],\n",
      "        [0.9999],\n",
      "        [0.3747],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.6628],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.5165],\n",
      "        [0.3930],\n",
      "        [0.2735],\n",
      "        [0.3840],\n",
      "        [0.9999],\n",
      "        [0.0288],\n",
      "        [0.4988],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.2577],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.7820],\n",
      "        [0.8139],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.5139],\n",
      "        [0.2518],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.9996],\n",
      "        [0.4645],\n",
      "        [0.9490],\n",
      "        [0.3575],\n",
      "        [0.9009],\n",
      "        [0.5245],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.5945],\n",
      "        [0.5108],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.4668],\n",
      "        [0.9995],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.8761],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.5009],\n",
      "        [0.4580],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.9997],\n",
      "        [0.9995],\n",
      "        [0.0247],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.7129],\n",
      "        [0.4611],\n",
      "        [0.9164],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7540],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.3728],\n",
      "        [0.9520],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.9994],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [0.0174],\n",
      "        [0.4527],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.2208],\n",
      "        [0.5030],\n",
      "        [0.5038],\n",
      "        [0.9999],\n",
      "        [0.9420],\n",
      "        [0.3753],\n",
      "        [0.8296],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9999],\n",
      "        [0.4454],\n",
      "        [0.5151],\n",
      "        [0.9999],\n",
      "        [0.5463],\n",
      "        [0.8223],\n",
      "        [0.9998]])\n",
      "######### Epoch: 18  ######### Train Loss: 0.0011588691268116236  ######### Relative L2 Test Norm: 17.90843391418457\n",
      "Output batch pred: tensor([[[ 0.1575],\n",
      "         [-0.0026],\n",
      "         [ 0.3209],\n",
      "         [ 0.9680],\n",
      "         [ 0.9707],\n",
      "         [ 0.9718],\n",
      "         [ 0.9735],\n",
      "         [ 0.9741],\n",
      "         [-0.0249],\n",
      "         [-0.0060],\n",
      "         [ 0.9707],\n",
      "         [ 0.9668],\n",
      "         [ 0.9672],\n",
      "         [ 0.9676],\n",
      "         [ 0.9329],\n",
      "         [-0.0251],\n",
      "         [ 0.9606],\n",
      "         [ 0.9757],\n",
      "         [ 0.3957],\n",
      "         [ 0.9786],\n",
      "         [ 0.9790],\n",
      "         [ 0.9745],\n",
      "         [ 0.9741],\n",
      "         [-0.0459],\n",
      "         [ 0.7857],\n",
      "         [ 0.9659],\n",
      "         [ 0.9614],\n",
      "         [ 0.2828],\n",
      "         [ 0.8709],\n",
      "         [ 0.9685],\n",
      "         [ 0.9711],\n",
      "         [ 0.9739],\n",
      "         [ 0.9753],\n",
      "         [ 0.8351],\n",
      "         [ 0.2068],\n",
      "         [ 0.9678],\n",
      "         [ 0.3190],\n",
      "         [ 0.1769],\n",
      "         [ 0.9524],\n",
      "         [ 0.3841],\n",
      "         [ 0.9437],\n",
      "         [ 0.3784],\n",
      "         [ 0.9425],\n",
      "         [ 0.1591],\n",
      "         [ 0.4507],\n",
      "         [ 0.9616],\n",
      "         [ 0.3989],\n",
      "         [ 0.4679],\n",
      "         [ 0.9761],\n",
      "         [ 0.9754],\n",
      "         [ 0.9753],\n",
      "         [ 0.9716],\n",
      "         [ 0.9256],\n",
      "         [ 0.9607],\n",
      "         [ 0.4432],\n",
      "         [ 0.9534],\n",
      "         [ 0.4859],\n",
      "         [ 0.1759],\n",
      "         [ 0.6032],\n",
      "         [ 0.9634],\n",
      "         [ 0.4188],\n",
      "         [ 0.9734],\n",
      "         [ 0.9775],\n",
      "         [ 0.9620],\n",
      "         [ 0.4733],\n",
      "         [ 0.9801],\n",
      "         [ 0.9782],\n",
      "         [ 0.9751],\n",
      "         [ 0.9725],\n",
      "         [ 0.0961],\n",
      "         [ 0.4927],\n",
      "         [ 0.9674],\n",
      "         [ 0.9309],\n",
      "         [ 0.9649],\n",
      "         [ 0.9655],\n",
      "         [ 0.4691],\n",
      "         [-0.0416],\n",
      "         [ 0.9650],\n",
      "         [ 0.9488],\n",
      "         [ 0.9650],\n",
      "         [ 0.9642],\n",
      "         [ 0.9682],\n",
      "         [ 0.9686],\n",
      "         [ 0.9733],\n",
      "         [ 0.4778],\n",
      "         [ 0.9767],\n",
      "         [ 0.1906],\n",
      "         [ 0.4718],\n",
      "         [ 0.9762],\n",
      "         [ 0.9619],\n",
      "         [ 0.2008],\n",
      "         [ 0.4042],\n",
      "         [ 0.9698],\n",
      "         [ 0.9697],\n",
      "         [ 0.9697],\n",
      "         [ 0.9718],\n",
      "         [ 0.9738],\n",
      "         [ 0.9766],\n",
      "         [ 0.9770],\n",
      "         [ 0.9782],\n",
      "         [ 0.9731],\n",
      "         [ 0.9754],\n",
      "         [ 0.9713],\n",
      "         [ 0.9692],\n",
      "         [ 0.8910],\n",
      "         [ 0.5659],\n",
      "         [ 0.9021],\n",
      "         [ 0.1837],\n",
      "         [ 0.9688],\n",
      "         [ 0.9702],\n",
      "         [ 0.9708],\n",
      "         [ 0.3286],\n",
      "         [ 0.9756],\n",
      "         [ 0.7198],\n",
      "         [ 0.6653],\n",
      "         [ 0.5124],\n",
      "         [ 0.9388],\n",
      "         [-0.0091],\n",
      "         [ 0.9037],\n",
      "         [ 0.9770],\n",
      "         [ 0.9787],\n",
      "         [ 0.9791],\n",
      "         [ 0.7687],\n",
      "         [ 0.9797],\n",
      "         [-0.0271],\n",
      "         [ 0.3260],\n",
      "         [ 0.9636],\n",
      "         [ 0.8772],\n",
      "         [ 0.2816],\n",
      "         [ 0.9496],\n",
      "         [ 0.2993],\n",
      "         [ 0.3013],\n",
      "         [ 0.2005],\n",
      "         [ 0.9593],\n",
      "         [ 0.4654],\n",
      "         [ 0.3411],\n",
      "         [ 0.9715],\n",
      "         [ 0.9723],\n",
      "         [ 0.9692],\n",
      "         [ 0.3973],\n",
      "         [ 0.7285],\n",
      "         [ 0.3032],\n",
      "         [ 0.9551],\n",
      "         [ 0.7976],\n",
      "         [ 0.9545],\n",
      "         [ 0.3765],\n",
      "         [-0.0381],\n",
      "         [ 0.9574],\n",
      "         [ 0.9603],\n",
      "         [ 0.9593],\n",
      "         [ 0.3796],\n",
      "         [ 0.9552],\n",
      "         [ 0.9519],\n",
      "         [ 0.9513],\n",
      "         [ 0.6651],\n",
      "         [ 0.9501],\n",
      "         [ 0.4345],\n",
      "         [ 0.2963],\n",
      "         [ 0.9549],\n",
      "         [ 0.9715],\n",
      "         [ 0.9754],\n",
      "         [ 0.9763],\n",
      "         [ 0.9752],\n",
      "         [ 0.9727],\n",
      "         [ 0.4708],\n",
      "         [ 0.9683],\n",
      "         [ 0.3973],\n",
      "         [ 0.9655],\n",
      "         [ 0.9646],\n",
      "         [ 0.8356],\n",
      "         [ 0.9705],\n",
      "         [ 0.9737],\n",
      "         [ 0.8449],\n",
      "         [ 0.6619],\n",
      "         [ 0.9841],\n",
      "         [ 0.9836],\n",
      "         [ 0.9815],\n",
      "         [ 0.9741]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2208],\n",
      "        [0.0335],\n",
      "        [0.3840],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9515],\n",
      "        [0.0209],\n",
      "        [0.9804],\n",
      "        [0.9995],\n",
      "        [0.4454],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [0.2646],\n",
      "        [0.9998],\n",
      "        [0.3808],\n",
      "        [0.2547],\n",
      "        [0.9998],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.9999],\n",
      "        [0.2577],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.5030],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9994],\n",
      "        [0.5463],\n",
      "        [0.2686],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9724],\n",
      "        [0.5009],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.5151],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.5038],\n",
      "        [0.9999],\n",
      "        [0.9819],\n",
      "        [0.2729],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9044],\n",
      "        [0.5945],\n",
      "        [0.9164],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9997],\n",
      "        [0.7129],\n",
      "        [0.6628],\n",
      "        [0.5334],\n",
      "        [0.9520],\n",
      "        [0.0368],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.3875],\n",
      "        [0.9999],\n",
      "        [0.8933],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.3753],\n",
      "        [0.2735],\n",
      "        [0.9956],\n",
      "        [0.5054],\n",
      "        [0.3930],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.7391],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.9997],\n",
      "        [0.4480],\n",
      "        [0.0247],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.3728],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8296],\n",
      "        [0.6555],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9962]])\n",
      "######### Epoch: 19  ######### Train Loss: 0.0017350227572023869  ######### Relative L2 Test Norm: 17.419876098632812\n",
      "Output batch pred: tensor([[[ 0.7139],\n",
      "         [ 0.9628],\n",
      "         [ 0.9627],\n",
      "         [ 0.8830],\n",
      "         [ 0.9565],\n",
      "         [ 0.9554],\n",
      "         [ 0.4700],\n",
      "         [ 0.9575],\n",
      "         [ 0.9581],\n",
      "         [ 0.9631],\n",
      "         [ 0.8344],\n",
      "         [ 0.9315],\n",
      "         [ 0.9640],\n",
      "         [ 0.9644],\n",
      "         [ 0.9618],\n",
      "         [ 0.3148],\n",
      "         [ 0.9471],\n",
      "         [-0.0227],\n",
      "         [ 0.4382],\n",
      "         [ 0.8656],\n",
      "         [ 0.3787],\n",
      "         [ 0.9555],\n",
      "         [ 0.9600],\n",
      "         [ 0.9690],\n",
      "         [ 0.9751],\n",
      "         [ 0.9660],\n",
      "         [ 0.9765],\n",
      "         [ 0.9761],\n",
      "         [ 0.9117],\n",
      "         [ 0.9641],\n",
      "         [ 0.9552],\n",
      "         [ 0.9504],\n",
      "         [ 0.2876],\n",
      "         [ 0.9467],\n",
      "         [ 0.9485],\n",
      "         [ 0.1910],\n",
      "         [ 0.9624],\n",
      "         [ 0.7892],\n",
      "         [ 0.9697],\n",
      "         [ 0.9545],\n",
      "         [ 0.4076],\n",
      "         [ 0.9663],\n",
      "         [ 0.2054],\n",
      "         [ 0.7348],\n",
      "         [ 0.9507],\n",
      "         [ 0.9494],\n",
      "         [ 0.3940],\n",
      "         [ 0.2974],\n",
      "         [ 0.3162],\n",
      "         [ 0.8279],\n",
      "         [ 0.9754],\n",
      "         [ 0.9807],\n",
      "         [-0.0027],\n",
      "         [ 0.7626],\n",
      "         [ 0.6413],\n",
      "         [ 0.9733],\n",
      "         [ 0.4788],\n",
      "         [ 0.9439],\n",
      "         [ 0.4023],\n",
      "         [ 0.9493],\n",
      "         [ 0.9463],\n",
      "         [ 0.9457],\n",
      "         [ 0.9471],\n",
      "         [ 0.6687],\n",
      "         [ 0.9489],\n",
      "         [ 0.4581],\n",
      "         [ 0.3283],\n",
      "         [ 0.4158],\n",
      "         [ 0.0340],\n",
      "         [ 0.1783],\n",
      "         [ 0.8900],\n",
      "         [ 0.0101],\n",
      "         [ 0.9731],\n",
      "         [ 0.3137],\n",
      "         [ 0.9738],\n",
      "         [ 0.9722],\n",
      "         [ 0.9670],\n",
      "         [ 0.9623],\n",
      "         [ 0.9545],\n",
      "         [ 0.9501],\n",
      "         [ 0.9452],\n",
      "         [ 0.8456],\n",
      "         [ 0.9416],\n",
      "         [ 0.9431],\n",
      "         [ 0.9492],\n",
      "         [ 0.9560],\n",
      "         [ 0.9630],\n",
      "         [ 0.9291],\n",
      "         [ 0.4209],\n",
      "         [ 0.9735],\n",
      "         [ 0.0029],\n",
      "         [ 0.3296],\n",
      "         [ 0.3388],\n",
      "         [ 0.3879],\n",
      "         [ 0.9492],\n",
      "         [ 0.4645],\n",
      "         [ 0.4254],\n",
      "         [ 0.1692],\n",
      "         [ 0.9426],\n",
      "         [ 0.9474],\n",
      "         [ 0.9537],\n",
      "         [-0.0166],\n",
      "         [ 0.9324],\n",
      "         [ 0.9688],\n",
      "         [ 0.9714],\n",
      "         [ 0.2002],\n",
      "         [ 0.9748],\n",
      "         [ 0.9726],\n",
      "         [ 0.6635],\n",
      "         [ 0.9647],\n",
      "         [ 0.4597],\n",
      "         [ 0.9519],\n",
      "         [ 0.9640],\n",
      "         [ 0.9645],\n",
      "         [ 0.9680],\n",
      "         [-0.0124],\n",
      "         [ 0.5281],\n",
      "         [ 0.9774],\n",
      "         [ 0.9784],\n",
      "         [ 0.9779],\n",
      "         [ 0.9781],\n",
      "         [ 0.9764],\n",
      "         [ 0.9733],\n",
      "         [ 0.9690],\n",
      "         [ 0.5763],\n",
      "         [ 0.9619],\n",
      "         [-0.0442],\n",
      "         [ 0.4442],\n",
      "         [ 0.9504],\n",
      "         [ 0.9543],\n",
      "         [ 0.6265],\n",
      "         [ 0.9570],\n",
      "         [ 0.1010],\n",
      "         [ 0.9626],\n",
      "         [ 0.4018],\n",
      "         [ 0.9675],\n",
      "         [ 0.8241],\n",
      "         [ 0.9722],\n",
      "         [ 0.9607],\n",
      "         [ 0.9726],\n",
      "         [ 0.9704],\n",
      "         [ 0.9663],\n",
      "         [ 0.9599],\n",
      "         [ 0.8161],\n",
      "         [ 0.9517],\n",
      "         [ 0.1617],\n",
      "         [ 0.9448],\n",
      "         [ 0.3853],\n",
      "         [ 0.9459],\n",
      "         [ 0.9498],\n",
      "         [ 0.4400],\n",
      "         [ 0.1766],\n",
      "         [ 0.9658],\n",
      "         [ 0.9699],\n",
      "         [ 0.9753],\n",
      "         [ 0.9760],\n",
      "         [ 0.5262],\n",
      "         [ 0.9725],\n",
      "         [ 0.4132],\n",
      "         [ 0.2995],\n",
      "         [ 0.9561],\n",
      "         [ 0.3126],\n",
      "         [ 0.4504],\n",
      "         [ 0.9188],\n",
      "         [ 0.9545],\n",
      "         [ 0.9536],\n",
      "         [ 0.9528],\n",
      "         [ 0.9544],\n",
      "         [ 0.9530],\n",
      "         [-0.0176],\n",
      "         [ 0.9491],\n",
      "         [ 0.1806],\n",
      "         [ 0.9460],\n",
      "         [ 0.9463],\n",
      "         [ 0.1788],\n",
      "         [ 0.4618],\n",
      "         [ 0.3238],\n",
      "         [ 0.9612]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.7129],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.8933],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [0.5165],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9490],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.9998],\n",
      "        [0.0247],\n",
      "        [0.5108],\n",
      "        [0.9044],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9966],\n",
      "        [0.9724],\n",
      "        [0.4454],\n",
      "        [0.9996],\n",
      "        [0.2686],\n",
      "        [0.7540],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.3780],\n",
      "        [0.3875],\n",
      "        [0.8223],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.7391],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.9814],\n",
      "        [0.4645],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.3808],\n",
      "        [0.4611],\n",
      "        [0.0368],\n",
      "        [0.2208],\n",
      "        [0.9009],\n",
      "        [0.0288],\n",
      "        [0.9994],\n",
      "        [0.3575],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [0.0174],\n",
      "        [0.3747],\n",
      "        [0.3930],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.5038],\n",
      "        [0.2729],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.9515],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.9998],\n",
      "        [0.5054],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0142],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.5463],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.3573],\n",
      "        [0.9956],\n",
      "        [0.3728],\n",
      "        [0.4988],\n",
      "        [0.9520],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.9996],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.5151],\n",
      "        [0.3912],\n",
      "        [0.9999]])\n",
      "######### Epoch: 20  ######### Train Loss: 0.002004764275625348  ######### Relative L2 Test Norm: 16.984609603881836\n",
      "Output batch pred: tensor([[[ 9.5641e-01],\n",
      "         [ 6.5634e-01],\n",
      "         [ 9.6414e-01],\n",
      "         [ 9.6800e-01],\n",
      "         [ 9.7341e-01],\n",
      "         [ 9.7718e-01],\n",
      "         [ 9.8073e-01],\n",
      "         [ 9.7983e-01],\n",
      "         [ 4.8977e-01],\n",
      "         [ 9.7338e-01],\n",
      "         [ 4.8381e-01],\n",
      "         [ 8.1610e-01],\n",
      "         [ 9.5657e-01],\n",
      "         [ 9.4855e-01],\n",
      "         [ 4.5577e-01],\n",
      "         [ 9.4424e-01],\n",
      "         [ 9.4698e-01],\n",
      "         [ 9.5251e-01],\n",
      "         [ 8.5068e-04],\n",
      "         [ 9.6598e-01],\n",
      "         [ 9.7302e-01],\n",
      "         [ 9.7682e-01],\n",
      "         [ 9.7930e-01],\n",
      "         [ 9.7891e-01],\n",
      "         [ 9.3733e-01],\n",
      "         [ 4.1673e-01],\n",
      "         [ 9.6536e-01],\n",
      "         [ 9.5963e-01],\n",
      "         [ 4.5547e-01],\n",
      "         [ 8.6390e-01],\n",
      "         [ 3.1331e-01],\n",
      "         [ 5.0479e-01],\n",
      "         [ 9.6364e-01],\n",
      "         [ 4.1473e-01],\n",
      "         [ 9.6902e-01],\n",
      "         [ 6.5569e-01],\n",
      "         [ 9.7049e-01],\n",
      "         [ 8.9901e-01],\n",
      "         [ 9.6745e-01],\n",
      "         [ 9.6712e-01],\n",
      "         [ 8.3098e-01],\n",
      "         [ 8.3445e-01],\n",
      "         [ 2.0040e-02],\n",
      "         [ 2.3771e-01],\n",
      "         [ 8.9284e-01],\n",
      "         [ 5.3437e-01],\n",
      "         [ 9.7271e-01],\n",
      "         [ 4.3447e-01],\n",
      "         [ 6.3499e-01],\n",
      "         [ 2.0838e-02],\n",
      "         [ 9.6560e-01],\n",
      "         [ 3.3856e-01],\n",
      "         [ 9.6345e-01],\n",
      "         [ 4.6337e-01],\n",
      "         [ 9.6097e-01],\n",
      "         [ 4.2497e-01],\n",
      "         [ 9.5930e-01],\n",
      "         [ 9.5615e-01],\n",
      "         [ 9.5669e-01],\n",
      "         [ 9.5268e-01],\n",
      "         [ 9.5277e-01],\n",
      "         [ 4.1074e-01],\n",
      "         [ 9.5435e-01],\n",
      "         [ 1.9295e-01],\n",
      "         [ 9.5661e-01],\n",
      "         [ 4.2095e-01],\n",
      "         [ 9.5988e-01],\n",
      "         [ 4.3019e-01],\n",
      "         [ 4.9346e-01],\n",
      "         [ 9.7009e-01],\n",
      "         [ 9.7157e-01],\n",
      "         [ 9.6991e-01],\n",
      "         [ 4.8390e-01],\n",
      "         [ 9.6357e-01],\n",
      "         [ 9.5951e-01],\n",
      "         [ 9.5439e-01],\n",
      "         [ 9.5360e-01],\n",
      "         [ 9.3772e-01],\n",
      "         [ 3.1063e-01],\n",
      "         [ 9.5220e-01],\n",
      "         [ 9.5486e-01],\n",
      "         [ 9.5699e-01],\n",
      "         [ 1.9359e-01],\n",
      "         [ 9.6191e-01],\n",
      "         [ 9.4759e-01],\n",
      "         [ 3.2054e-01],\n",
      "         [ 9.6835e-01],\n",
      "         [ 9.6371e-01],\n",
      "         [ 9.5092e-01],\n",
      "         [ 9.6238e-01],\n",
      "         [ 3.3697e-01],\n",
      "         [ 7.8950e-03],\n",
      "         [ 9.5758e-01],\n",
      "         [ 9.5614e-01],\n",
      "         [ 9.5127e-01],\n",
      "         [ 9.5653e-01],\n",
      "         [ 9.6118e-01],\n",
      "         [-8.8909e-03],\n",
      "         [ 9.6897e-01],\n",
      "         [ 8.4396e-01],\n",
      "         [ 9.4342e-01],\n",
      "         [ 9.8185e-01],\n",
      "         [ 2.3093e-02],\n",
      "         [ 5.3095e-01],\n",
      "         [ 9.8184e-01],\n",
      "         [ 1.0333e-02],\n",
      "         [ 9.6249e-01],\n",
      "         [ 9.6721e-01],\n",
      "         [ 9.5948e-01],\n",
      "         [ 9.5270e-01],\n",
      "         [ 9.5002e-01],\n",
      "         [ 9.4898e-01],\n",
      "         [ 7.3143e-01],\n",
      "         [ 9.5317e-01],\n",
      "         [ 9.5743e-01],\n",
      "         [ 1.3425e-01],\n",
      "         [ 2.3734e-01],\n",
      "         [ 9.7630e-01],\n",
      "         [ 9.8137e-01],\n",
      "         [ 5.2278e-01],\n",
      "         [ 9.8467e-01],\n",
      "         [ 9.8320e-01],\n",
      "         [ 2.3486e-01],\n",
      "         [ 3.2942e-01],\n",
      "         [ 9.3316e-01],\n",
      "         [ 9.6311e-01],\n",
      "         [ 9.5669e-01],\n",
      "         [ 3.3712e-03],\n",
      "         [ 9.4753e-01],\n",
      "         [ 3.9138e-01],\n",
      "         [ 1.9521e-01],\n",
      "         [ 9.5349e-01],\n",
      "         [ 9.6127e-01],\n",
      "         [ 4.8071e-01],\n",
      "         [ 2.1428e-01],\n",
      "         [ 9.7489e-01],\n",
      "         [ 9.7681e-01],\n",
      "         [ 9.7542e-01],\n",
      "         [ 9.6998e-01],\n",
      "         [ 3.2500e-01],\n",
      "         [ 9.5964e-01],\n",
      "         [ 9.5540e-01],\n",
      "         [ 6.9752e-01],\n",
      "         [ 8.7390e-01],\n",
      "         [ 4.4531e-01],\n",
      "         [ 9.5083e-01],\n",
      "         [ 9.2006e-01],\n",
      "         [ 9.6090e-01],\n",
      "         [ 9.6592e-01],\n",
      "         [ 9.7008e-01],\n",
      "         [ 9.1488e-01],\n",
      "         [ 9.7446e-01],\n",
      "         [ 9.7354e-01],\n",
      "         [ 3.1185e-01],\n",
      "         [ 7.4027e-01],\n",
      "         [ 9.6218e-01],\n",
      "         [ 3.9072e-01],\n",
      "         [-3.2266e-02],\n",
      "         [ 9.5785e-01],\n",
      "         [ 6.8907e-01],\n",
      "         [ 1.5959e-01],\n",
      "         [ 3.3064e-01],\n",
      "         [ 9.6879e-01],\n",
      "         [ 9.6906e-01],\n",
      "         [ 4.2362e-01],\n",
      "         [ 9.6740e-01],\n",
      "         [ 9.6572e-01],\n",
      "         [ 9.6267e-01],\n",
      "         [ 3.2891e-01],\n",
      "         [ 9.5717e-01],\n",
      "         [ 9.5586e-01],\n",
      "         [ 9.5493e-01],\n",
      "         [ 9.4301e-01],\n",
      "         [ 5.6828e-01],\n",
      "         [ 3.3549e-01],\n",
      "         [ 9.5775e-01],\n",
      "         [ 7.7784e-01],\n",
      "         [ 2.0877e-01]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9962],\n",
      "        [0.6628],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.0335],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9420],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.5038],\n",
      "        [0.8761],\n",
      "        [0.3780],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.9999],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [0.8296],\n",
      "        [0.0247],\n",
      "        [0.2729],\n",
      "        [0.8933],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.6327],\n",
      "        [0.0368],\n",
      "        [0.9999],\n",
      "        [0.3840],\n",
      "        [0.9994],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9996],\n",
      "        [0.4645],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [0.5139],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.2577],\n",
      "        [0.9966],\n",
      "        [0.9724],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.8379],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.1762],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.5151],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.2646],\n",
      "        [0.3575],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.2547],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.9009],\n",
      "        [0.5030],\n",
      "        [0.9998],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [0.4454],\n",
      "        [0.0000],\n",
      "        [0.9996],\n",
      "        [0.6920],\n",
      "        [0.2208],\n",
      "        [0.3747],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.5945],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.2686]])\n",
      "######### Epoch: 21  ######### Train Loss: 0.0013441063929349184  ######### Relative L2 Test Norm: 14.811101913452148\n",
      "Output batch pred: tensor([[[0.9921],\n",
      "         [0.9697],\n",
      "         [0.9773],\n",
      "         [0.9722],\n",
      "         [0.2085],\n",
      "         [0.9687],\n",
      "         [0.7599],\n",
      "         [0.9414],\n",
      "         [0.0402],\n",
      "         [0.9882],\n",
      "         [0.0770],\n",
      "         [0.4707],\n",
      "         [0.9936],\n",
      "         [0.2279],\n",
      "         [0.0543],\n",
      "         [0.9782],\n",
      "         [0.2321],\n",
      "         [0.9666],\n",
      "         [0.9086],\n",
      "         [0.9695],\n",
      "         [0.9727],\n",
      "         [0.9781],\n",
      "         [0.3388],\n",
      "         [0.9836],\n",
      "         [0.0329],\n",
      "         [0.9823],\n",
      "         [0.9802],\n",
      "         [0.9716],\n",
      "         [0.9623],\n",
      "         [0.3982],\n",
      "         [0.9521],\n",
      "         [0.9497],\n",
      "         [0.9185],\n",
      "         [0.5188],\n",
      "         [0.7284],\n",
      "         [0.9825],\n",
      "         [0.9892],\n",
      "         [0.9947],\n",
      "         [0.9969],\n",
      "         [0.4842],\n",
      "         [0.4750],\n",
      "         [0.9782],\n",
      "         [0.4789],\n",
      "         [0.9553],\n",
      "         [0.9514],\n",
      "         [0.6240],\n",
      "         [0.9490],\n",
      "         [0.8212],\n",
      "         [0.9589],\n",
      "         [0.9647],\n",
      "         [0.9734],\n",
      "         [0.5287],\n",
      "         [0.9803],\n",
      "         [0.3592],\n",
      "         [0.9781],\n",
      "         [0.9761],\n",
      "         [0.4475],\n",
      "         [0.9687],\n",
      "         [0.3548],\n",
      "         [0.9667],\n",
      "         [0.9716],\n",
      "         [0.5013],\n",
      "         [0.9759],\n",
      "         [0.8880],\n",
      "         [0.0449],\n",
      "         [0.8430],\n",
      "         [0.3647],\n",
      "         [0.9743],\n",
      "         [0.4834],\n",
      "         [0.9728],\n",
      "         [0.9716],\n",
      "         [0.5041],\n",
      "         [0.9698],\n",
      "         [0.9708],\n",
      "         [0.9546],\n",
      "         [0.5995],\n",
      "         [0.8387],\n",
      "         [0.9659],\n",
      "         [0.9659],\n",
      "         [0.9626],\n",
      "         [0.9489],\n",
      "         [0.3523],\n",
      "         [0.9622],\n",
      "         [0.9641],\n",
      "         [0.9543],\n",
      "         [0.9693],\n",
      "         [0.9700],\n",
      "         [0.9599],\n",
      "         [0.9654],\n",
      "         [0.9698],\n",
      "         [0.2368],\n",
      "         [0.9627],\n",
      "         [0.9600],\n",
      "         [0.9568],\n",
      "         [0.0222],\n",
      "         [0.4147],\n",
      "         [0.7812],\n",
      "         [0.9623],\n",
      "         [0.9653],\n",
      "         [0.9698],\n",
      "         [0.9719],\n",
      "         [0.3482],\n",
      "         [0.9751],\n",
      "         [0.9738],\n",
      "         [0.4868],\n",
      "         [0.9650],\n",
      "         [0.9619],\n",
      "         [0.9562],\n",
      "         [0.9537],\n",
      "         [0.9519],\n",
      "         [0.9523],\n",
      "         [0.8799],\n",
      "         [0.9600],\n",
      "         [0.9671],\n",
      "         [0.0133],\n",
      "         [0.9865],\n",
      "         [0.9957],\n",
      "         [1.0026],\n",
      "         [0.2718],\n",
      "         [0.9377],\n",
      "         [1.0033],\n",
      "         [0.4879],\n",
      "         [0.3649],\n",
      "         [0.5039],\n",
      "         [0.8345],\n",
      "         [0.7509],\n",
      "         [0.9660],\n",
      "         [0.9664],\n",
      "         [0.9689],\n",
      "         [0.9731],\n",
      "         [0.0541],\n",
      "         [0.3842],\n",
      "         [0.5697],\n",
      "         [0.2881],\n",
      "         [0.5308],\n",
      "         [0.9954],\n",
      "         [0.9552],\n",
      "         [0.9793],\n",
      "         [0.9687],\n",
      "         [0.6901],\n",
      "         [0.2023],\n",
      "         [0.9506],\n",
      "         [0.9479],\n",
      "         [0.4134],\n",
      "         [0.8908],\n",
      "         [0.2398],\n",
      "         [0.9816],\n",
      "         [0.9872],\n",
      "         [0.6650],\n",
      "         [0.9915],\n",
      "         [0.9885],\n",
      "         [0.9821],\n",
      "         [0.3387],\n",
      "         [0.9702],\n",
      "         [0.9246],\n",
      "         [0.9618],\n",
      "         [0.9602],\n",
      "         [0.9624],\n",
      "         [0.2224],\n",
      "         [0.5051],\n",
      "         [0.1651],\n",
      "         [0.6962],\n",
      "         [0.9887],\n",
      "         [0.9885],\n",
      "         [0.9870],\n",
      "         [0.9803],\n",
      "         [0.9777],\n",
      "         [0.4851],\n",
      "         [0.9689],\n",
      "         [0.3479],\n",
      "         [0.9667],\n",
      "         [0.4214],\n",
      "         [0.3493],\n",
      "         [0.4348],\n",
      "         [0.5195],\n",
      "         [0.9971],\n",
      "         [0.9985],\n",
      "         [0.0275]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.9490],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9997],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.9998],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [0.4480],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9520],\n",
      "        [0.5463],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4645],\n",
      "        [0.4642],\n",
      "        [0.9995],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.4668],\n",
      "        [0.9998],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.0368],\n",
      "        [0.8223],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.5945],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9820],\n",
      "        [0.3930],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9819],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.0288],\n",
      "        [0.4552],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.8933],\n",
      "        [0.9962],\n",
      "        [0.4611],\n",
      "        [0.3575],\n",
      "        [0.5009],\n",
      "        [0.8139],\n",
      "        [0.7391],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.3808],\n",
      "        [0.5334],\n",
      "        [0.2735],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [0.9515],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.9044],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.6327],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.5165],\n",
      "        [0.1762],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.5080],\n",
      "        [0.9999],\n",
      "        [0.3912],\n",
      "        [0.9995],\n",
      "        [0.4527],\n",
      "        [0.3780],\n",
      "        [0.4454],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.9967],\n",
      "        [0.0000]])\n",
      "######### Epoch: 22  ######### Train Loss: 0.0007770885131321847  ######### Relative L2 Test Norm: 12.15826416015625\n",
      "Output batch pred: tensor([[[0.9962],\n",
      "         [0.7434],\n",
      "         [0.9981],\n",
      "         [0.9952],\n",
      "         [0.0452],\n",
      "         [0.5257],\n",
      "         [0.9986],\n",
      "         [0.4049],\n",
      "         [0.9880],\n",
      "         [0.9986],\n",
      "         [0.9964],\n",
      "         [0.9915],\n",
      "         [0.9866],\n",
      "         [0.4500],\n",
      "         [0.9730],\n",
      "         [0.9686],\n",
      "         [0.9650],\n",
      "         [0.8338],\n",
      "         [0.9672],\n",
      "         [0.2425],\n",
      "         [0.9830],\n",
      "         [0.9922],\n",
      "         [0.9998],\n",
      "         [1.0046],\n",
      "         [0.5344],\n",
      "         [0.4803],\n",
      "         [0.8402],\n",
      "         [0.9982],\n",
      "         [0.9885],\n",
      "         [0.9865],\n",
      "         [0.9087],\n",
      "         [0.8530],\n",
      "         [0.5021],\n",
      "         [0.9889],\n",
      "         [0.3749],\n",
      "         [0.9962],\n",
      "         [0.9971],\n",
      "         [0.9999],\n",
      "         [0.9972],\n",
      "         [0.9829],\n",
      "         [0.0521],\n",
      "         [0.5058],\n",
      "         [0.9846],\n",
      "         [0.9822],\n",
      "         [0.9136],\n",
      "         [0.3839],\n",
      "         [0.3960],\n",
      "         [0.0634],\n",
      "         [0.8720],\n",
      "         [0.2816],\n",
      "         [0.9180],\n",
      "         [0.9968],\n",
      "         [0.9938],\n",
      "         [0.2585],\n",
      "         [0.9841],\n",
      "         [0.9805],\n",
      "         [0.9780],\n",
      "         [0.9781],\n",
      "         [0.9805],\n",
      "         [0.0516],\n",
      "         [0.9818],\n",
      "         [0.9864],\n",
      "         [0.9892],\n",
      "         [0.9893],\n",
      "         [0.9873],\n",
      "         [0.0477],\n",
      "         [0.9862],\n",
      "         [0.4533],\n",
      "         [0.9752],\n",
      "         [0.4613],\n",
      "         [0.9936],\n",
      "         [0.9928],\n",
      "         [0.9987],\n",
      "         [0.3766],\n",
      "         [0.5814],\n",
      "         [0.9950],\n",
      "         [0.9884],\n",
      "         [0.3753],\n",
      "         [0.9786],\n",
      "         [0.9753],\n",
      "         [0.4926],\n",
      "         [0.9708],\n",
      "         [0.9602],\n",
      "         [0.9733],\n",
      "         [0.8334],\n",
      "         [0.9775],\n",
      "         [0.5360],\n",
      "         [0.9454],\n",
      "         [0.9850],\n",
      "         [0.9863],\n",
      "         [0.9867],\n",
      "         [0.9858],\n",
      "         [0.9868],\n",
      "         [0.9831],\n",
      "         [0.2554],\n",
      "         [0.9841],\n",
      "         [0.5475],\n",
      "         [0.6880],\n",
      "         [0.9776],\n",
      "         [0.9764],\n",
      "         [0.9736],\n",
      "         [0.9763],\n",
      "         [0.9775],\n",
      "         [0.5156],\n",
      "         [0.9848],\n",
      "         [0.9871],\n",
      "         [0.9893],\n",
      "         [0.6275],\n",
      "         [0.9885],\n",
      "         [0.5226],\n",
      "         [0.9829],\n",
      "         [0.4536],\n",
      "         [0.9852],\n",
      "         [0.9491],\n",
      "         [0.9857],\n",
      "         [0.9869],\n",
      "         [0.3580],\n",
      "         [0.9933],\n",
      "         [0.4841],\n",
      "         [0.7972],\n",
      "         [0.9946],\n",
      "         [0.9910],\n",
      "         [0.9873],\n",
      "         [0.9817],\n",
      "         [0.9761],\n",
      "         [0.9724],\n",
      "         [0.4995],\n",
      "         [0.9109],\n",
      "         [0.9708],\n",
      "         [0.5083],\n",
      "         [0.9817],\n",
      "         [0.2720],\n",
      "         [0.2674],\n",
      "         [0.9969],\n",
      "         [0.3986],\n",
      "         [1.0015],\n",
      "         [0.0731],\n",
      "         [0.9981],\n",
      "         [0.9619],\n",
      "         [0.9918],\n",
      "         [0.9860],\n",
      "         [0.2086],\n",
      "         [0.9829],\n",
      "         [0.3803],\n",
      "         [0.9798],\n",
      "         [0.4434],\n",
      "         [0.7582],\n",
      "         [0.9756],\n",
      "         [0.9752],\n",
      "         [0.9794],\n",
      "         [0.3678],\n",
      "         [0.3845],\n",
      "         [0.4669],\n",
      "         [0.9977],\n",
      "         [0.0902],\n",
      "         [0.6895],\n",
      "         [0.7178],\n",
      "         [1.0139],\n",
      "         [0.2253],\n",
      "         [0.5621],\n",
      "         [0.0901],\n",
      "         [0.5080],\n",
      "         [1.0031],\n",
      "         [0.9682],\n",
      "         [0.0672],\n",
      "         [0.9745],\n",
      "         [0.9881],\n",
      "         [0.9843],\n",
      "         [0.9813],\n",
      "         [0.9805],\n",
      "         [0.2370],\n",
      "         [0.9801],\n",
      "         [0.9786],\n",
      "         [0.2596],\n",
      "         [0.9858],\n",
      "         [0.7490],\n",
      "         [0.4778],\n",
      "         [0.9242]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0142],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.4503],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.8296],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [0.0209],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.3808],\n",
      "        [0.3840],\n",
      "        [0.0000],\n",
      "        [0.8223],\n",
      "        [0.2547],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9995],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0174],\n",
      "        [0.9999],\n",
      "        [0.4454],\n",
      "        [0.9814],\n",
      "        [0.4480],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [0.9819],\n",
      "        [0.9997],\n",
      "        [0.8139],\n",
      "        [0.9995],\n",
      "        [0.5245],\n",
      "        [0.9420],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9967],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [0.9956],\n",
      "        [0.4552],\n",
      "        [0.9996],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.7540],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5151],\n",
      "        [0.9164],\n",
      "        [0.9959],\n",
      "        [0.5139],\n",
      "        [0.9966],\n",
      "        [0.2646],\n",
      "        [0.2518],\n",
      "        [0.9999],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9994],\n",
      "        [0.3912],\n",
      "        [0.9998],\n",
      "        [0.4527],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.3875],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [0.0335],\n",
      "        [0.6327],\n",
      "        [0.6555],\n",
      "        [0.9997],\n",
      "        [0.1762],\n",
      "        [0.5080],\n",
      "        [0.0247],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.0368],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.4642],\n",
      "        [0.9009]])\n",
      "######### Epoch: 23  ######### Train Loss: 0.0004802202747669071  ######### Relative L2 Test Norm: 11.258111000061035\n",
      "Output batch pred: tensor([[[0.9967],\n",
      "         [0.1084],\n",
      "         [0.5602],\n",
      "         [1.0120],\n",
      "         [1.0097],\n",
      "         [1.0058],\n",
      "         [0.9997],\n",
      "         [0.9947],\n",
      "         [0.3748],\n",
      "         [0.8177],\n",
      "         [0.9844],\n",
      "         [0.9820],\n",
      "         [0.9852],\n",
      "         [0.9869],\n",
      "         [0.6653],\n",
      "         [0.8529],\n",
      "         [0.5185],\n",
      "         [0.5593],\n",
      "         [0.9974],\n",
      "         [0.9979],\n",
      "         [0.9979],\n",
      "         [0.9978],\n",
      "         [0.9983],\n",
      "         [0.9980],\n",
      "         [0.5787],\n",
      "         [1.0015],\n",
      "         [1.0056],\n",
      "         [1.0065],\n",
      "         [1.0063],\n",
      "         [0.0700],\n",
      "         [0.2944],\n",
      "         [1.0029],\n",
      "         [1.0017],\n",
      "         [1.0011],\n",
      "         [0.9988],\n",
      "         [0.5356],\n",
      "         [0.4809],\n",
      "         [0.8057],\n",
      "         [1.0028],\n",
      "         [0.8808],\n",
      "         [1.0023],\n",
      "         [0.8683],\n",
      "         [0.9962],\n",
      "         [0.9556],\n",
      "         [0.4488],\n",
      "         [0.4602],\n",
      "         [0.9856],\n",
      "         [0.9832],\n",
      "         [0.9835],\n",
      "         [0.9854],\n",
      "         [0.9172],\n",
      "         [0.9898],\n",
      "         [0.9929],\n",
      "         [0.5311],\n",
      "         [1.0022],\n",
      "         [0.9520],\n",
      "         [1.0122],\n",
      "         [0.4113],\n",
      "         [1.0191],\n",
      "         [1.0085],\n",
      "         [0.6674],\n",
      "         [0.5548],\n",
      "         [0.2976],\n",
      "         [0.0930],\n",
      "         [0.5883],\n",
      "         [0.9986],\n",
      "         [0.0931],\n",
      "         [0.9932],\n",
      "         [0.4700],\n",
      "         [0.9924],\n",
      "         [0.9956],\n",
      "         [0.9954],\n",
      "         [0.0777],\n",
      "         [1.0055],\n",
      "         [0.9353],\n",
      "         [0.4141],\n",
      "         [1.0093],\n",
      "         [0.4881],\n",
      "         [0.9885],\n",
      "         [0.7505],\n",
      "         [0.3928],\n",
      "         [0.9691],\n",
      "         [0.5352],\n",
      "         [0.9957],\n",
      "         [0.5423],\n",
      "         [0.5081],\n",
      "         [1.0154],\n",
      "         [1.0187],\n",
      "         [0.3078],\n",
      "         [1.0150],\n",
      "         [1.0127],\n",
      "         [0.0897],\n",
      "         [1.0074],\n",
      "         [0.5543],\n",
      "         [1.0005],\n",
      "         [1.0002],\n",
      "         [0.4983],\n",
      "         [0.3850],\n",
      "         [0.4813],\n",
      "         [0.2975],\n",
      "         [1.0100],\n",
      "         [0.5640],\n",
      "         [0.2220],\n",
      "         [1.0123],\n",
      "         [0.2494],\n",
      "         [1.0067],\n",
      "         [1.0037],\n",
      "         [1.0008],\n",
      "         [0.9957],\n",
      "         [0.9966],\n",
      "         [0.9956],\n",
      "         [0.9952],\n",
      "         [0.4658],\n",
      "         [0.0634],\n",
      "         [1.0048],\n",
      "         [1.0068],\n",
      "         [0.4146],\n",
      "         [1.0040],\n",
      "         [1.0169],\n",
      "         [0.5192],\n",
      "         [1.0155],\n",
      "         [1.0156],\n",
      "         [0.8899],\n",
      "         [1.0075],\n",
      "         [0.2690],\n",
      "         [0.0771],\n",
      "         [1.0019],\n",
      "         [0.9150],\n",
      "         [0.9995],\n",
      "         [0.9967],\n",
      "         [0.4127],\n",
      "         [0.5483],\n",
      "         [0.9964],\n",
      "         [0.9976],\n",
      "         [0.9965],\n",
      "         [0.9959],\n",
      "         [0.9955],\n",
      "         [0.9959],\n",
      "         [0.9926],\n",
      "         [0.9925],\n",
      "         [0.9991],\n",
      "         [0.9966],\n",
      "         [0.3937],\n",
      "         [0.4013],\n",
      "         [0.9922],\n",
      "         [0.9900],\n",
      "         [0.2615],\n",
      "         [0.7746],\n",
      "         [0.9549],\n",
      "         [0.9857],\n",
      "         [0.9938],\n",
      "         [0.9984],\n",
      "         [1.0057],\n",
      "         [1.0104],\n",
      "         [0.7258],\n",
      "         [0.4090],\n",
      "         [0.0729],\n",
      "         [1.0144],\n",
      "         [1.0063],\n",
      "         [0.9976],\n",
      "         [0.9882],\n",
      "         [0.9786],\n",
      "         [0.9716],\n",
      "         [0.9650],\n",
      "         [0.9677],\n",
      "         [0.9715],\n",
      "         [0.9793],\n",
      "         [0.2705],\n",
      "         [0.9965],\n",
      "         [1.0065],\n",
      "         [1.0124],\n",
      "         [1.0124],\n",
      "         [0.9860],\n",
      "         [0.7411],\n",
      "         [0.4350],\n",
      "         [0.7847],\n",
      "         [0.9439],\n",
      "         [0.3056]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9814],\n",
      "        [0.0335],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.7820],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.6327],\n",
      "        [0.8139],\n",
      "        [0.4988],\n",
      "        [0.5245],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5334],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0174],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5038],\n",
      "        [0.4527],\n",
      "        [0.7540],\n",
      "        [0.9994],\n",
      "        [0.8379],\n",
      "        [0.9997],\n",
      "        [0.8223],\n",
      "        [0.9998],\n",
      "        [0.9420],\n",
      "        [0.4480],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [0.9995],\n",
      "        [0.9164],\n",
      "        [0.9999],\n",
      "        [0.3747],\n",
      "        [0.9996],\n",
      "        [0.9820],\n",
      "        [0.5945],\n",
      "        [0.5009],\n",
      "        [0.2547],\n",
      "        [0.0142],\n",
      "        [0.5463],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.0288],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.9724],\n",
      "        [0.6920],\n",
      "        [0.3753],\n",
      "        [0.9520],\n",
      "        [0.5054],\n",
      "        [0.9804],\n",
      "        [0.5030],\n",
      "        [0.4645],\n",
      "        [0.9967],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.3573],\n",
      "        [0.4454],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.1762],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [0.2518],\n",
      "        [0.0368],\n",
      "        [0.9997],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.3808],\n",
      "        [0.3875],\n",
      "        [0.9997],\n",
      "        [0.9959],\n",
      "        [0.2577],\n",
      "        [0.7391],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [0.3575],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.6628],\n",
      "        [0.3912],\n",
      "        [0.7129],\n",
      "        [0.9009],\n",
      "        [0.2686]])\n",
      "######### Epoch: 24  ######### Train Loss: 0.0008157201809808612  ######### Relative L2 Test Norm: 10.106735229492188\n",
      "Output batch pred: tensor([[[1.0101],\n",
      "         [1.0095],\n",
      "         [0.4823],\n",
      "         [1.0074],\n",
      "         [0.4285],\n",
      "         [0.9502],\n",
      "         [1.0190],\n",
      "         [1.0225],\n",
      "         [0.1150],\n",
      "         [0.3258],\n",
      "         [0.3123],\n",
      "         [1.0169],\n",
      "         [1.0161],\n",
      "         [1.0154],\n",
      "         [0.5677],\n",
      "         [0.9428],\n",
      "         [0.4164],\n",
      "         [0.5113],\n",
      "         [0.5503],\n",
      "         [0.5627],\n",
      "         [1.0083],\n",
      "         [1.0022],\n",
      "         [1.0010],\n",
      "         [0.9977],\n",
      "         [0.9959],\n",
      "         [0.9978],\n",
      "         [1.0006],\n",
      "         [0.9686],\n",
      "         [0.5530],\n",
      "         [0.4027],\n",
      "         [0.7757],\n",
      "         [0.3115],\n",
      "         [1.0242],\n",
      "         [1.0229],\n",
      "         [1.0208],\n",
      "         [0.9853],\n",
      "         [1.0116],\n",
      "         [1.0102],\n",
      "         [1.0088],\n",
      "         [0.0632],\n",
      "         [0.3977],\n",
      "         [1.0090],\n",
      "         [1.0071],\n",
      "         [1.0100],\n",
      "         [0.9424],\n",
      "         [1.0091],\n",
      "         [1.0075],\n",
      "         [1.0034],\n",
      "         [1.0042],\n",
      "         [1.0037],\n",
      "         [0.3682],\n",
      "         [1.0011],\n",
      "         [1.0058],\n",
      "         [1.0008],\n",
      "         [1.0071],\n",
      "         [1.0053],\n",
      "         [0.4039],\n",
      "         [0.9969],\n",
      "         [0.8003],\n",
      "         [1.0106],\n",
      "         [0.3060],\n",
      "         [1.0179],\n",
      "         [1.0197],\n",
      "         [0.0927],\n",
      "         [1.0227],\n",
      "         [0.3039],\n",
      "         [1.0142],\n",
      "         [1.0108],\n",
      "         [0.7118],\n",
      "         [0.4812],\n",
      "         [0.9963],\n",
      "         [0.9955],\n",
      "         [0.9945],\n",
      "         [0.9981],\n",
      "         [1.0003],\n",
      "         [0.5912],\n",
      "         [1.0137],\n",
      "         [0.6656],\n",
      "         [0.7079],\n",
      "         [1.0186],\n",
      "         [1.0201],\n",
      "         [1.0185],\n",
      "         [0.5680],\n",
      "         [0.5574],\n",
      "         [0.5087],\n",
      "         [0.5552],\n",
      "         [1.0099],\n",
      "         [1.0243],\n",
      "         [1.0258],\n",
      "         [0.2479],\n",
      "         [1.0280],\n",
      "         [1.0255],\n",
      "         [0.1086],\n",
      "         [1.0191],\n",
      "         [0.3043],\n",
      "         [1.0102],\n",
      "         [0.4843],\n",
      "         [0.9716],\n",
      "         [0.9918],\n",
      "         [1.0034],\n",
      "         [1.0026],\n",
      "         [0.7250],\n",
      "         [1.0052],\n",
      "         [0.9186],\n",
      "         [0.4776],\n",
      "         [0.2393],\n",
      "         [0.9976],\n",
      "         [0.9984],\n",
      "         [0.9996],\n",
      "         [1.0024],\n",
      "         [0.5383],\n",
      "         [0.8860],\n",
      "         [1.0101],\n",
      "         [0.0989],\n",
      "         [0.5814],\n",
      "         [1.0120],\n",
      "         [1.0108],\n",
      "         [1.0083],\n",
      "         [0.4085],\n",
      "         [0.8406],\n",
      "         [1.0028],\n",
      "         [0.4886],\n",
      "         [1.0051],\n",
      "         [1.0038],\n",
      "         [1.0023],\n",
      "         [1.0001],\n",
      "         [0.9976],\n",
      "         [0.9785],\n",
      "         [0.9908],\n",
      "         [0.4697],\n",
      "         [0.9900],\n",
      "         [0.9949],\n",
      "         [1.0008],\n",
      "         [0.3945],\n",
      "         [1.0165],\n",
      "         [0.1027],\n",
      "         [1.0258],\n",
      "         [1.0264],\n",
      "         [0.9001],\n",
      "         [0.4942],\n",
      "         [1.0098],\n",
      "         [1.0015],\n",
      "         [0.9922],\n",
      "         [0.9903],\n",
      "         [0.8608],\n",
      "         [0.9605],\n",
      "         [0.8616],\n",
      "         [0.4082],\n",
      "         [1.0172],\n",
      "         [0.6072],\n",
      "         [1.0229],\n",
      "         [0.8329],\n",
      "         [0.0915],\n",
      "         [1.0169],\n",
      "         [0.2891],\n",
      "         [0.2785],\n",
      "         [1.0050],\n",
      "         [1.0005],\n",
      "         [0.9500],\n",
      "         [1.0057],\n",
      "         [1.0117],\n",
      "         [0.0861],\n",
      "         [0.1045],\n",
      "         [1.0118],\n",
      "         [1.0123],\n",
      "         [0.9924],\n",
      "         [1.0076],\n",
      "         [0.5324],\n",
      "         [1.0071],\n",
      "         [1.0097],\n",
      "         [0.5072],\n",
      "         [0.5544],\n",
      "         [0.4409],\n",
      "         [1.0264],\n",
      "         [0.8024],\n",
      "         [1.0263],\n",
      "         [1.0236],\n",
      "         [0.4389]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.2735],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.8933],\n",
      "        [0.3747],\n",
      "        [0.4645],\n",
      "        [0.5030],\n",
      "        [0.5165],\n",
      "        [0.9994],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9420],\n",
      "        [0.5108],\n",
      "        [0.3575],\n",
      "        [0.6920],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9967],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.0209],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.9044],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.3573],\n",
      "        [0.9962],\n",
      "        [0.9999],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.9819],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.6555],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.9997],\n",
      "        [0.5945],\n",
      "        [0.6327],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.5139],\n",
      "        [0.5054],\n",
      "        [0.4580],\n",
      "        [0.4988],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0247],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.4527],\n",
      "        [0.9490],\n",
      "        [0.9804],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.4503],\n",
      "        [0.2208],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.3840],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.9994],\n",
      "        [0.4668],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [0.4454],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.8296],\n",
      "        [0.9520],\n",
      "        [0.8139],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.9999],\n",
      "        [0.7540],\n",
      "        [0.0000],\n",
      "        [0.9998],\n",
      "        [0.2547],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.5038],\n",
      "        [0.3912],\n",
      "        [0.9998],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3930]])\n",
      "######### Epoch: 25  ######### Train Loss: 0.0012120034079998732  ######### Relative L2 Test Norm: 9.158943176269531\n",
      "Output batch pred: tensor([[[1.0023],\n",
      "         [0.4213],\n",
      "         [1.0165],\n",
      "         [0.8767],\n",
      "         [1.0096],\n",
      "         [1.0038],\n",
      "         [0.6961],\n",
      "         [0.9986],\n",
      "         [0.0661],\n",
      "         [1.0011],\n",
      "         [0.9981],\n",
      "         [0.4131],\n",
      "         [1.0121],\n",
      "         [0.9837],\n",
      "         [1.0176],\n",
      "         [1.0177],\n",
      "         [0.9356],\n",
      "         [1.0155],\n",
      "         [0.5125],\n",
      "         [1.0096],\n",
      "         [1.0115],\n",
      "         [0.9732],\n",
      "         [0.4986],\n",
      "         [1.0132],\n",
      "         [1.0128],\n",
      "         [1.0169],\n",
      "         [0.4250],\n",
      "         [0.9022],\n",
      "         [1.0188],\n",
      "         [0.2929],\n",
      "         [0.4235],\n",
      "         [1.0159],\n",
      "         [0.7843],\n",
      "         [1.0111],\n",
      "         [1.0051],\n",
      "         [1.0085],\n",
      "         [1.0077],\n",
      "         [1.0091],\n",
      "         [0.9960],\n",
      "         [1.0112],\n",
      "         [0.5526],\n",
      "         [0.6595],\n",
      "         [0.8093],\n",
      "         [1.0156],\n",
      "         [1.0149],\n",
      "         [0.4948],\n",
      "         [0.5630],\n",
      "         [0.1059],\n",
      "         [0.5571],\n",
      "         [0.7351],\n",
      "         [1.0168],\n",
      "         [1.0204],\n",
      "         [0.4164],\n",
      "         [1.0214],\n",
      "         [0.3131],\n",
      "         [1.0198],\n",
      "         [0.5536],\n",
      "         [0.4912],\n",
      "         [1.0105],\n",
      "         [1.0100],\n",
      "         [1.0077],\n",
      "         [1.0085],\n",
      "         [0.9361],\n",
      "         [0.5426],\n",
      "         [0.4238],\n",
      "         [1.0106],\n",
      "         [1.0133],\n",
      "         [0.5388],\n",
      "         [1.0135],\n",
      "         [1.0114],\n",
      "         [1.0103],\n",
      "         [0.2031],\n",
      "         [1.0062],\n",
      "         [1.0060],\n",
      "         [0.9956],\n",
      "         [1.0097],\n",
      "         [0.2754],\n",
      "         [1.0144],\n",
      "         [1.0164],\n",
      "         [1.0150],\n",
      "         [1.0158],\n",
      "         [1.0154],\n",
      "         [0.6932],\n",
      "         [0.9525],\n",
      "         [1.0030],\n",
      "         [0.9969],\n",
      "         [0.2741],\n",
      "         [0.9599],\n",
      "         [0.9959],\n",
      "         [0.9260],\n",
      "         [0.3782],\n",
      "         [0.7481],\n",
      "         [1.0100],\n",
      "         [0.8467],\n",
      "         [0.0912],\n",
      "         [0.1004],\n",
      "         [1.0054],\n",
      "         [1.0150],\n",
      "         [0.5755],\n",
      "         [1.0070],\n",
      "         [1.0023],\n",
      "         [0.9988],\n",
      "         [0.5152],\n",
      "         [0.9933],\n",
      "         [0.9925],\n",
      "         [0.9989],\n",
      "         [1.0019],\n",
      "         [1.0059],\n",
      "         [1.0091],\n",
      "         [0.0889],\n",
      "         [0.2889],\n",
      "         [1.0169],\n",
      "         [1.0181],\n",
      "         [0.6007],\n",
      "         [1.0209],\n",
      "         [1.0219],\n",
      "         [1.0221],\n",
      "         [0.2725],\n",
      "         [0.9104],\n",
      "         [1.0332],\n",
      "         [0.4289],\n",
      "         [0.5447],\n",
      "         [0.4558],\n",
      "         [0.6048],\n",
      "         [0.5862],\n",
      "         [0.4414],\n",
      "         [0.5308],\n",
      "         [1.0164],\n",
      "         [0.4885],\n",
      "         [1.0064],\n",
      "         [1.0054],\n",
      "         [1.0022],\n",
      "         [0.9740],\n",
      "         [0.8827],\n",
      "         [1.0153],\n",
      "         [0.5014],\n",
      "         [0.9588],\n",
      "         [0.4517],\n",
      "         [1.0240],\n",
      "         [0.3145],\n",
      "         [0.8233],\n",
      "         [1.0093],\n",
      "         [1.0040],\n",
      "         [0.9982],\n",
      "         [0.4642],\n",
      "         [0.9828],\n",
      "         [0.9962],\n",
      "         [1.0043],\n",
      "         [1.0104],\n",
      "         [1.0181],\n",
      "         [1.0241],\n",
      "         [0.1070],\n",
      "         [0.3140],\n",
      "         [0.5848],\n",
      "         [1.0246],\n",
      "         [1.0169],\n",
      "         [1.0074],\n",
      "         [0.9992],\n",
      "         [0.9921],\n",
      "         [0.9929],\n",
      "         [0.9913],\n",
      "         [1.0013],\n",
      "         [0.5835],\n",
      "         [1.0176],\n",
      "         [0.0873],\n",
      "         [1.0281],\n",
      "         [1.0328],\n",
      "         [1.0333],\n",
      "         [0.1113],\n",
      "         [0.0778],\n",
      "         [1.0190],\n",
      "         [1.0134],\n",
      "         [1.0074],\n",
      "         [0.4834],\n",
      "         [1.0052],\n",
      "         [1.0069],\n",
      "         [1.0103],\n",
      "         [0.3039]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9724],\n",
      "        [0.3780],\n",
      "        [0.9999],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.9997],\n",
      "        [0.9956],\n",
      "        [0.3875],\n",
      "        [0.9997],\n",
      "        [0.9515],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.8761],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.3808],\n",
      "        [0.9997],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.5945],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.5165],\n",
      "        [0.0368],\n",
      "        [0.5108],\n",
      "        [0.6628],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.3728],\n",
      "        [0.9994],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.5038],\n",
      "        [0.3912],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.6327],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.9520],\n",
      "        [0.9996],\n",
      "        [0.9009],\n",
      "        [0.3575],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.0142],\n",
      "        [0.0288],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.4611],\n",
      "        [0.3747],\n",
      "        [0.5151],\n",
      "        [0.5054],\n",
      "        [0.3753],\n",
      "        [0.4668],\n",
      "        [0.9962],\n",
      "        [0.4480],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9490],\n",
      "        [0.8223],\n",
      "        [0.9999],\n",
      "        [0.4503],\n",
      "        [0.9044],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.7540],\n",
      "        [0.9966],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.4552],\n",
      "        [0.9819],\n",
      "        [0.9967],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0247],\n",
      "        [0.2577],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.9998],\n",
      "        [0.0174],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735]])\n",
      "######### Epoch: 26  ######### Train Loss: 0.0013545131077989936  ######### Relative L2 Test Norm: 9.882901191711426\n",
      "Output batch pred: tensor([[[0.7210],\n",
      "         [0.1074],\n",
      "         [1.0152],\n",
      "         [0.1002],\n",
      "         [1.0087],\n",
      "         [1.0086],\n",
      "         [1.0060],\n",
      "         [1.0036],\n",
      "         [1.0029],\n",
      "         [1.0056],\n",
      "         [0.0591],\n",
      "         [1.0103],\n",
      "         [1.0148],\n",
      "         [0.5832],\n",
      "         [1.0209],\n",
      "         [0.0887],\n",
      "         [0.5505],\n",
      "         [1.0134],\n",
      "         [1.0093],\n",
      "         [1.0039],\n",
      "         [1.0056],\n",
      "         [0.8740],\n",
      "         [0.1993],\n",
      "         [1.0120],\n",
      "         [0.0881],\n",
      "         [1.0230],\n",
      "         [0.5289],\n",
      "         [0.5286],\n",
      "         [0.6759],\n",
      "         [1.0105],\n",
      "         [1.0206],\n",
      "         [0.5480],\n",
      "         [1.0121],\n",
      "         [0.4773],\n",
      "         [0.4895],\n",
      "         [0.4643],\n",
      "         [0.9304],\n",
      "         [1.0042],\n",
      "         [1.0034],\n",
      "         [1.0007],\n",
      "         [0.8728],\n",
      "         [0.4570],\n",
      "         [0.7765],\n",
      "         [0.9939],\n",
      "         [0.9956],\n",
      "         [0.5290],\n",
      "         [0.9993],\n",
      "         [1.0065],\n",
      "         [0.9932],\n",
      "         [0.4217],\n",
      "         [1.0033],\n",
      "         [0.2895],\n",
      "         [1.0171],\n",
      "         [1.0160],\n",
      "         [1.0152],\n",
      "         [0.2486],\n",
      "         [0.5534],\n",
      "         [0.5440],\n",
      "         [0.3976],\n",
      "         [1.0206],\n",
      "         [0.7734],\n",
      "         [0.2907],\n",
      "         [1.0193],\n",
      "         [1.0150],\n",
      "         [0.4056],\n",
      "         [1.0066],\n",
      "         [1.0048],\n",
      "         [1.0036],\n",
      "         [0.5279],\n",
      "         [1.0078],\n",
      "         [1.0117],\n",
      "         [0.7873],\n",
      "         [1.0177],\n",
      "         [0.9931],\n",
      "         [0.9594],\n",
      "         [0.1086],\n",
      "         [1.0211],\n",
      "         [0.5951],\n",
      "         [1.0122],\n",
      "         [0.5527],\n",
      "         [0.4879],\n",
      "         [1.0056],\n",
      "         [1.0071],\n",
      "         [0.2926],\n",
      "         [1.0105],\n",
      "         [0.3116],\n",
      "         [0.3146],\n",
      "         [1.0185],\n",
      "         [1.0062],\n",
      "         [1.0147],\n",
      "         [0.5424],\n",
      "         [1.0072],\n",
      "         [1.0035],\n",
      "         [0.9989],\n",
      "         [0.9990],\n",
      "         [0.9970],\n",
      "         [0.9663],\n",
      "         [1.0000],\n",
      "         [1.0044],\n",
      "         [1.0069],\n",
      "         [1.0054],\n",
      "         [1.0124],\n",
      "         [1.0037],\n",
      "         [1.0189],\n",
      "         [0.4347],\n",
      "         [0.4353],\n",
      "         [1.0275],\n",
      "         [0.4297],\n",
      "         [1.0302],\n",
      "         [0.8405],\n",
      "         [1.0265],\n",
      "         [1.0220],\n",
      "         [0.3023],\n",
      "         [0.9779],\n",
      "         [0.5561],\n",
      "         [1.0060],\n",
      "         [1.0037],\n",
      "         [1.0016],\n",
      "         [1.0022],\n",
      "         [1.0027],\n",
      "         [1.0025],\n",
      "         [1.0026],\n",
      "         [0.9997],\n",
      "         [0.9976],\n",
      "         [0.3854],\n",
      "         [0.9970],\n",
      "         [0.9993],\n",
      "         [1.0024],\n",
      "         [0.2655],\n",
      "         [1.0094],\n",
      "         [1.0104],\n",
      "         [1.0161],\n",
      "         [0.2853],\n",
      "         [1.0161],\n",
      "         [1.0103],\n",
      "         [0.9237],\n",
      "         [0.0648],\n",
      "         [0.9974],\n",
      "         [0.9902],\n",
      "         [0.9918],\n",
      "         [0.9911],\n",
      "         [0.9945],\n",
      "         [0.9413],\n",
      "         [1.0002],\n",
      "         [0.3920],\n",
      "         [1.0044],\n",
      "         [1.0041],\n",
      "         [0.9324],\n",
      "         [0.6939],\n",
      "         [0.9982],\n",
      "         [0.8237],\n",
      "         [0.9607],\n",
      "         [0.9927],\n",
      "         [0.6650],\n",
      "         [0.9975],\n",
      "         [0.9995],\n",
      "         [0.9997],\n",
      "         [0.5198],\n",
      "         [1.0029],\n",
      "         [0.8755],\n",
      "         [1.0020],\n",
      "         [1.0049],\n",
      "         [1.0074],\n",
      "         [0.4795],\n",
      "         [0.0764],\n",
      "         [1.0154],\n",
      "         [0.6053],\n",
      "         [0.4980],\n",
      "         [1.0213],\n",
      "         [1.0194],\n",
      "         [0.0773],\n",
      "         [0.3819],\n",
      "         [0.4785],\n",
      "         [0.8527],\n",
      "         [0.3747],\n",
      "         [0.9937],\n",
      "         [0.3867],\n",
      "         [0.9987]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.6628],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.5245],\n",
      "        [0.9998],\n",
      "        [0.0288],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.4645],\n",
      "        [0.5945],\n",
      "        [0.9814],\n",
      "        [0.9998],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.4668],\n",
      "        [0.4480],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.4552],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5165],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.3930],\n",
      "        [0.9820],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.5108],\n",
      "        [0.5009],\n",
      "        [0.3575],\n",
      "        [0.9997],\n",
      "        [0.6920],\n",
      "        [0.2577],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.3840],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.9044],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [0.5151],\n",
      "        [0.4611],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9520],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.3875],\n",
      "        [0.9996],\n",
      "        [0.3753],\n",
      "        [0.9997],\n",
      "        [0.7540],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.2686],\n",
      "        [0.9420],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.9999],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.8761],\n",
      "        [0.0247],\n",
      "        [0.9966],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [0.3747],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.9009],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.0142],\n",
      "        [0.9962],\n",
      "        [0.5463],\n",
      "        [0.4454],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.0000],\n",
      "        [0.3573],\n",
      "        [0.4580],\n",
      "        [0.8139],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.9997]])\n",
      "######### Epoch: 27  ######### Train Loss: 0.0009289705194532871  ######### Relative L2 Test Norm: 12.019472122192383\n",
      "Output batch pred: tensor([[[0.3954],\n",
      "         [1.0084],\n",
      "         [0.9712],\n",
      "         [1.0004],\n",
      "         [0.0453],\n",
      "         [0.9564],\n",
      "         [0.9886],\n",
      "         [0.2656],\n",
      "         [0.9944],\n",
      "         [1.0006],\n",
      "         [1.0018],\n",
      "         [0.3830],\n",
      "         [1.0128],\n",
      "         [0.5522],\n",
      "         [0.8820],\n",
      "         [0.5341],\n",
      "         [1.0059],\n",
      "         [0.4620],\n",
      "         [0.4727],\n",
      "         [0.9928],\n",
      "         [0.9919],\n",
      "         [0.9903],\n",
      "         [0.9923],\n",
      "         [0.9948],\n",
      "         [0.4559],\n",
      "         [0.9944],\n",
      "         [0.4652],\n",
      "         [0.3907],\n",
      "         [0.9953],\n",
      "         [0.9976],\n",
      "         [0.9974],\n",
      "         [0.9980],\n",
      "         [0.3875],\n",
      "         [1.0018],\n",
      "         [0.5433],\n",
      "         [0.4033],\n",
      "         [0.1935],\n",
      "         [1.0052],\n",
      "         [1.0037],\n",
      "         [1.0035],\n",
      "         [1.0025],\n",
      "         [1.0030],\n",
      "         [1.0026],\n",
      "         [0.2783],\n",
      "         [0.2779],\n",
      "         [0.0742],\n",
      "         [0.5337],\n",
      "         [0.2390],\n",
      "         [0.7037],\n",
      "         [1.0042],\n",
      "         [0.9962],\n",
      "         [0.4386],\n",
      "         [0.9851],\n",
      "         [0.9808],\n",
      "         [0.9772],\n",
      "         [0.9805],\n",
      "         [0.9821],\n",
      "         [0.2348],\n",
      "         [1.0013],\n",
      "         [0.5377],\n",
      "         [1.0132],\n",
      "         [1.0149],\n",
      "         [1.0128],\n",
      "         [1.0101],\n",
      "         [0.2687],\n",
      "         [0.5737],\n",
      "         [0.3783],\n",
      "         [0.9126],\n",
      "         [0.9987],\n",
      "         [0.9915],\n",
      "         [1.0065],\n",
      "         [0.0520],\n",
      "         [1.0135],\n",
      "         [0.4041],\n",
      "         [0.4914],\n",
      "         [0.4200],\n",
      "         [1.0094],\n",
      "         [1.0062],\n",
      "         [0.7883],\n",
      "         [1.0018],\n",
      "         [0.4587],\n",
      "         [1.0042],\n",
      "         [0.4826],\n",
      "         [0.2802],\n",
      "         [1.0105],\n",
      "         [0.9547],\n",
      "         [0.3965],\n",
      "         [0.0746],\n",
      "         [0.9974],\n",
      "         [0.9906],\n",
      "         [0.9832],\n",
      "         [0.9775],\n",
      "         [0.9740],\n",
      "         [0.9760],\n",
      "         [0.9410],\n",
      "         [0.9850],\n",
      "         [0.9971],\n",
      "         [0.4828],\n",
      "         [0.9437],\n",
      "         [1.0172],\n",
      "         [0.5435],\n",
      "         [0.5406],\n",
      "         [1.0155],\n",
      "         [0.2671],\n",
      "         [1.0043],\n",
      "         [0.9973],\n",
      "         [0.9923],\n",
      "         [0.9887],\n",
      "         [0.9809],\n",
      "         [0.9874],\n",
      "         [0.3727],\n",
      "         [0.7535],\n",
      "         [0.8731],\n",
      "         [0.9410],\n",
      "         [0.5955],\n",
      "         [0.7474],\n",
      "         [0.5774],\n",
      "         [0.1004],\n",
      "         [0.3108],\n",
      "         [0.5752],\n",
      "         [1.0268],\n",
      "         [1.0193],\n",
      "         [1.0100],\n",
      "         [0.9997],\n",
      "         [0.8254],\n",
      "         [0.9859],\n",
      "         [0.9842],\n",
      "         [0.6032],\n",
      "         [0.9794],\n",
      "         [0.9838],\n",
      "         [0.9860],\n",
      "         [0.9916],\n",
      "         [0.9917],\n",
      "         [1.0011],\n",
      "         [0.8820],\n",
      "         [0.0774],\n",
      "         [1.0139],\n",
      "         [0.0905],\n",
      "         [1.0196],\n",
      "         [1.0041],\n",
      "         [1.0178],\n",
      "         [0.7716],\n",
      "         [0.0703],\n",
      "         [0.9781],\n",
      "         [1.0046],\n",
      "         [0.6721],\n",
      "         [0.9910],\n",
      "         [0.9742],\n",
      "         [0.9798],\n",
      "         [0.9802],\n",
      "         [0.9848],\n",
      "         [0.9760],\n",
      "         [0.9935],\n",
      "         [0.4707],\n",
      "         [1.0041],\n",
      "         [1.0060],\n",
      "         [1.0074],\n",
      "         [0.9924],\n",
      "         [1.0023],\n",
      "         [0.9996],\n",
      "         [0.3503],\n",
      "         [0.7877],\n",
      "         [0.9873],\n",
      "         [0.9860],\n",
      "         [0.9854],\n",
      "         [0.9876],\n",
      "         [0.9892],\n",
      "         [0.9902],\n",
      "         [0.9916],\n",
      "         [0.5219],\n",
      "         [0.9923],\n",
      "         [0.5434],\n",
      "         [0.9959],\n",
      "         [0.0608],\n",
      "         [0.9270],\n",
      "         [0.8646],\n",
      "         [1.0084],\n",
      "         [1.0093]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.3728],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9520],\n",
      "        [0.9999],\n",
      "        [0.2729],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9962],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.8223],\n",
      "        [0.5054],\n",
      "        [0.9997],\n",
      "        [0.4527],\n",
      "        [0.4642],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.9997],\n",
      "        [0.4580],\n",
      "        [0.3912],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.3875],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2735],\n",
      "        [0.2686],\n",
      "        [0.0247],\n",
      "        [0.5038],\n",
      "        [0.2208],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9997],\n",
      "        [0.5108],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.2610],\n",
      "        [0.5463],\n",
      "        [0.3747],\n",
      "        [0.8761],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [0.9998],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.4552],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.9996],\n",
      "        [0.4611],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.3780],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.7129],\n",
      "        [0.8296],\n",
      "        [0.9009],\n",
      "        [0.5334],\n",
      "        [0.6628],\n",
      "        [0.5080],\n",
      "        [0.0174],\n",
      "        [0.2547],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.9966],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.8379],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.0209],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.9994],\n",
      "        [0.9819],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.9994],\n",
      "        [0.4645],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.7540],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.9994],\n",
      "        [0.0335],\n",
      "        [0.8933],\n",
      "        [0.8139],\n",
      "        [0.9995],\n",
      "        [1.0000]])\n",
      "######### Epoch: 28  ######### Train Loss: 0.0006397697143256664  ######### Relative L2 Test Norm: 13.737318992614746\n",
      "Output batch pred: tensor([[[0.7821],\n",
      "         [1.0003],\n",
      "         [0.9976],\n",
      "         [0.9991],\n",
      "         [0.2667],\n",
      "         [0.7357],\n",
      "         [0.0534],\n",
      "         [0.3992],\n",
      "         [1.0054],\n",
      "         [0.4820],\n",
      "         [0.3998],\n",
      "         [1.0115],\n",
      "         [1.0109],\n",
      "         [0.5238],\n",
      "         [1.0055],\n",
      "         [0.2585],\n",
      "         [1.0000],\n",
      "         [0.8655],\n",
      "         [1.0004],\n",
      "         [1.0011],\n",
      "         [1.0012],\n",
      "         [0.0402],\n",
      "         [1.0122],\n",
      "         [1.0124],\n",
      "         [1.0081],\n",
      "         [0.6801],\n",
      "         [0.9943],\n",
      "         [0.9915],\n",
      "         [0.9829],\n",
      "         [0.9764],\n",
      "         [0.4277],\n",
      "         [0.9702],\n",
      "         [0.9734],\n",
      "         [0.9799],\n",
      "         [0.5047],\n",
      "         [0.3637],\n",
      "         [0.4661],\n",
      "         [0.2516],\n",
      "         [0.9899],\n",
      "         [0.9879],\n",
      "         [0.9826],\n",
      "         [0.9771],\n",
      "         [0.9732],\n",
      "         [0.9696],\n",
      "         [0.9685],\n",
      "         [0.4254],\n",
      "         [0.9748],\n",
      "         [0.9663],\n",
      "         [0.9864],\n",
      "         [0.9870],\n",
      "         [0.9889],\n",
      "         [0.8981],\n",
      "         [0.0246],\n",
      "         [0.9838],\n",
      "         [0.9803],\n",
      "         [0.9757],\n",
      "         [0.9781],\n",
      "         [0.9427],\n",
      "         [0.9817],\n",
      "         [0.9864],\n",
      "         [0.6909],\n",
      "         [0.9906],\n",
      "         [0.3696],\n",
      "         [0.0494],\n",
      "         [1.0051],\n",
      "         [0.3675],\n",
      "         [1.0073],\n",
      "         [1.0039],\n",
      "         [0.5742],\n",
      "         [0.5285],\n",
      "         [0.3866],\n",
      "         [0.4502],\n",
      "         [0.9806],\n",
      "         [0.9882],\n",
      "         [0.7736],\n",
      "         [0.3548],\n",
      "         [0.9813],\n",
      "         [0.0430],\n",
      "         [0.9739],\n",
      "         [0.9904],\n",
      "         [0.9953],\n",
      "         [0.0859],\n",
      "         [1.0100],\n",
      "         [0.0783],\n",
      "         [1.0023],\n",
      "         [0.0910],\n",
      "         [0.4762],\n",
      "         [1.0023],\n",
      "         [0.2456],\n",
      "         [0.9478],\n",
      "         [0.9800],\n",
      "         [0.9717],\n",
      "         [0.9718],\n",
      "         [0.9711],\n",
      "         [0.7937],\n",
      "         [0.8974],\n",
      "         [0.8339],\n",
      "         [0.9874],\n",
      "         [0.9928],\n",
      "         [0.9963],\n",
      "         [1.0030],\n",
      "         [1.0023],\n",
      "         [1.0063],\n",
      "         [1.0073],\n",
      "         [0.5280],\n",
      "         [1.0043],\n",
      "         [0.3843],\n",
      "         [0.9989],\n",
      "         [0.9599],\n",
      "         [0.9898],\n",
      "         [0.9861],\n",
      "         [0.8495],\n",
      "         [0.9838],\n",
      "         [0.9857],\n",
      "         [0.9884],\n",
      "         [0.0111],\n",
      "         [0.9999],\n",
      "         [1.0048],\n",
      "         [0.5743],\n",
      "         [0.5254],\n",
      "         [1.0108],\n",
      "         [0.5277],\n",
      "         [0.5569],\n",
      "         [0.4543],\n",
      "         [0.2562],\n",
      "         [0.3795],\n",
      "         [0.4953],\n",
      "         [0.9824],\n",
      "         [0.9750],\n",
      "         [0.9736],\n",
      "         [0.9693],\n",
      "         [0.9628],\n",
      "         [0.1981],\n",
      "         [0.8847],\n",
      "         [0.9639],\n",
      "         [0.9650],\n",
      "         [0.9746],\n",
      "         [0.9835],\n",
      "         [0.9936],\n",
      "         [0.7614],\n",
      "         [0.5484],\n",
      "         [0.2659],\n",
      "         [0.9657],\n",
      "         [0.2743],\n",
      "         [1.0120],\n",
      "         [1.0029],\n",
      "         [0.9899],\n",
      "         [0.9795],\n",
      "         [0.9665],\n",
      "         [0.9623],\n",
      "         [0.9599],\n",
      "         [0.9428],\n",
      "         [0.9679],\n",
      "         [0.9755],\n",
      "         [0.9858],\n",
      "         [0.3683],\n",
      "         [0.1922],\n",
      "         [0.8855],\n",
      "         [1.0113],\n",
      "         [0.2425],\n",
      "         [0.7123],\n",
      "         [0.4937],\n",
      "         [0.9724],\n",
      "         [0.4615],\n",
      "         [0.9935],\n",
      "         [0.4293],\n",
      "         [0.9800],\n",
      "         [0.9757],\n",
      "         [0.4728],\n",
      "         [0.5772],\n",
      "         [0.9681],\n",
      "         [0.9671],\n",
      "         [0.9707],\n",
      "         [0.4887],\n",
      "         [0.9809],\n",
      "         [0.3298],\n",
      "         [0.9914],\n",
      "         [0.9244]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.7391],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.6920],\n",
      "        [0.0209],\n",
      "        [0.3912],\n",
      "        [0.9996],\n",
      "        [0.4580],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9997],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.3747],\n",
      "        [0.4642],\n",
      "        [0.2646],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.9520],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.0288],\n",
      "        [0.9997],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5463],\n",
      "        [0.5108],\n",
      "        [0.3875],\n",
      "        [0.4503],\n",
      "        [0.9819],\n",
      "        [0.9998],\n",
      "        [0.7540],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.9820],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9804],\n",
      "        [0.0368],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [0.2547],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.8933],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.8296],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.5245],\n",
      "        [0.4480],\n",
      "        [0.2686],\n",
      "        [0.3930],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.2577],\n",
      "        [0.9044],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.9994],\n",
      "        [0.7129],\n",
      "        [0.5151],\n",
      "        [0.2518],\n",
      "        [0.9164],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.1762],\n",
      "        [0.8379],\n",
      "        [0.9999],\n",
      "        [0.2208],\n",
      "        [0.6555],\n",
      "        [0.4668],\n",
      "        [0.9515],\n",
      "        [0.4552],\n",
      "        [0.9997],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.5080],\n",
      "        [0.5945],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.5165],\n",
      "        [0.9999],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.9009]])\n",
      "######### Epoch: 29  ######### Train Loss: 0.000515059451572597  ######### Relative L2 Test Norm: 15.511462211608887\n",
      "Output batch pred: tensor([[[ 0.4199],\n",
      "         [ 0.6308],\n",
      "         [ 0.9779],\n",
      "         [ 0.1974],\n",
      "         [ 0.9740],\n",
      "         [ 0.9749],\n",
      "         [ 0.9757],\n",
      "         [ 0.9789],\n",
      "         [ 0.9807],\n",
      "         [ 0.9098],\n",
      "         [ 0.9868],\n",
      "         [ 0.0249],\n",
      "         [ 0.9023],\n",
      "         [ 0.9546],\n",
      "         [ 0.9843],\n",
      "         [ 0.2201],\n",
      "         [ 0.9823],\n",
      "         [ 0.0087],\n",
      "         [ 0.9778],\n",
      "         [ 0.4857],\n",
      "         [ 0.9764],\n",
      "         [ 0.9720],\n",
      "         [ 0.9719],\n",
      "         [ 0.3292],\n",
      "         [ 0.9776],\n",
      "         [ 0.9778],\n",
      "         [ 0.9824],\n",
      "         [ 0.9848],\n",
      "         [ 0.9906],\n",
      "         [ 0.9941],\n",
      "         [ 0.5239],\n",
      "         [ 0.3763],\n",
      "         [ 0.4703],\n",
      "         [ 1.0005],\n",
      "         [ 0.7582],\n",
      "         [ 0.9966],\n",
      "         [ 0.5327],\n",
      "         [ 0.9860],\n",
      "         [ 0.3356],\n",
      "         [ 0.9763],\n",
      "         [ 0.3475],\n",
      "         [ 0.7902],\n",
      "         [ 0.9721],\n",
      "         [ 0.9745],\n",
      "         [ 0.9757],\n",
      "         [ 0.5262],\n",
      "         [ 0.9776],\n",
      "         [ 0.3221],\n",
      "         [ 0.8432],\n",
      "         [ 0.9837],\n",
      "         [ 0.9866],\n",
      "         [ 0.9900],\n",
      "         [ 0.9933],\n",
      "         [ 0.9835],\n",
      "         [ 0.3410],\n",
      "         [ 0.9944],\n",
      "         [ 0.9937],\n",
      "         [ 0.9860],\n",
      "         [ 0.9189],\n",
      "         [ 0.9531],\n",
      "         [ 0.9617],\n",
      "         [ 0.9565],\n",
      "         [ 0.9515],\n",
      "         [ 0.3098],\n",
      "         [ 0.9636],\n",
      "         [ 0.9737],\n",
      "         [ 0.2404],\n",
      "         [ 0.4671],\n",
      "         [ 0.4702],\n",
      "         [ 1.0100],\n",
      "         [ 0.8885],\n",
      "         [ 1.0072],\n",
      "         [ 0.9994],\n",
      "         [ 0.5510],\n",
      "         [ 0.4263],\n",
      "         [ 0.8383],\n",
      "         [ 0.9809],\n",
      "         [ 0.9822],\n",
      "         [ 0.4445],\n",
      "         [ 0.9773],\n",
      "         [ 0.9180],\n",
      "         [ 0.9796],\n",
      "         [ 0.9910],\n",
      "         [ 0.2333],\n",
      "         [ 0.9872],\n",
      "         [ 0.9857],\n",
      "         [ 0.0082],\n",
      "         [ 0.6058],\n",
      "         [ 0.3707],\n",
      "         [ 0.9623],\n",
      "         [ 1.0075],\n",
      "         [ 0.7569],\n",
      "         [ 0.2703],\n",
      "         [ 0.8127],\n",
      "         [ 1.0067],\n",
      "         [ 0.1616],\n",
      "         [ 0.9796],\n",
      "         [ 0.9730],\n",
      "         [ 0.9643],\n",
      "         [ 0.9555],\n",
      "         [ 0.9607],\n",
      "         [ 0.9670],\n",
      "         [ 0.9727],\n",
      "         [ 0.9834],\n",
      "         [ 0.0465],\n",
      "         [ 0.0380],\n",
      "         [ 1.0000],\n",
      "         [ 1.0003],\n",
      "         [ 0.9953],\n",
      "         [ 0.9536],\n",
      "         [ 0.9824],\n",
      "         [ 0.9772],\n",
      "         [ 0.6513],\n",
      "         [ 0.9773],\n",
      "         [ 0.9786],\n",
      "         [ 0.4903],\n",
      "         [ 0.9888],\n",
      "         [ 0.9904],\n",
      "         [ 0.9884],\n",
      "         [ 0.4983],\n",
      "         [ 0.4729],\n",
      "         [ 0.9724],\n",
      "         [ 0.9643],\n",
      "         [ 0.9607],\n",
      "         [ 0.9640],\n",
      "         [-0.0315],\n",
      "         [ 0.9771],\n",
      "         [ 0.9850],\n",
      "         [ 0.5001],\n",
      "         [ 0.8637],\n",
      "         [ 0.2355],\n",
      "         [ 0.2002],\n",
      "         [ 0.4307],\n",
      "         [ 0.9817],\n",
      "         [ 0.9686],\n",
      "         [ 0.9659],\n",
      "         [ 0.9633],\n",
      "         [ 0.9642],\n",
      "         [ 0.4527],\n",
      "         [ 0.7446],\n",
      "         [ 0.4836],\n",
      "         [ 0.9899],\n",
      "         [ 0.0581],\n",
      "         [ 0.0612],\n",
      "         [ 0.9999],\n",
      "         [ 0.2553],\n",
      "         [ 0.9893],\n",
      "         [ 0.9520],\n",
      "         [ 0.9818],\n",
      "         [ 0.2199],\n",
      "         [ 0.4117],\n",
      "         [ 0.9771],\n",
      "         [ 0.6675],\n",
      "         [ 0.3529],\n",
      "         [ 0.3355],\n",
      "         [ 0.3370],\n",
      "         [ 0.9741],\n",
      "         [ 0.8993],\n",
      "         [ 0.9740],\n",
      "         [ 0.9720],\n",
      "         [ 0.9771],\n",
      "         [ 0.9621],\n",
      "         [ 0.4301],\n",
      "         [ 0.9909],\n",
      "         [ 0.5087],\n",
      "         [ 0.0354],\n",
      "         [ 0.9969],\n",
      "         [ 0.9934],\n",
      "         [ 0.9902],\n",
      "         [ 0.9824],\n",
      "         [ 0.9792],\n",
      "         [ 0.9752],\n",
      "         [ 0.4210],\n",
      "         [ 0.4542],\n",
      "         [ 0.9696],\n",
      "         [ 0.9758],\n",
      "         [ 0.9788],\n",
      "         [ 0.9803]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.4527],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [0.8933],\n",
      "        [0.9962],\n",
      "        [0.0247],\n",
      "        [0.8761],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9997],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5165],\n",
      "        [0.3808],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.5463],\n",
      "        [0.9999],\n",
      "        [0.3575],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [0.3573],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9164],\n",
      "        [0.9814],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.9959],\n",
      "        [0.9999],\n",
      "        [0.2735],\n",
      "        [0.4642],\n",
      "        [0.4580],\n",
      "        [0.9995],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.4454],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.4645],\n",
      "        [0.9819],\n",
      "        [0.9009],\n",
      "        [0.9804],\n",
      "        [0.9994],\n",
      "        [0.2646],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.0174],\n",
      "        [0.5945],\n",
      "        [0.3875],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.2577],\n",
      "        [0.7540],\n",
      "        [0.9997],\n",
      "        [0.1762],\n",
      "        [0.9956],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.0335],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5139],\n",
      "        [0.5030],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5080],\n",
      "        [0.8296],\n",
      "        [0.2518],\n",
      "        [0.2208],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.7391],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [0.9998],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.3912],\n",
      "        [0.3753],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.4988],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]])\n",
      "######### Epoch: 30  ######### Train Loss: 0.0006325332797132432  ######### Relative L2 Test Norm: 16.531713485717773\n",
      "Output batch pred: tensor([[[ 0.9740],\n",
      "         [ 0.2045],\n",
      "         [ 0.5015],\n",
      "         [ 0.9680],\n",
      "         [ 0.9639],\n",
      "         [ 0.3279],\n",
      "         [ 0.4025],\n",
      "         [ 0.9811],\n",
      "         [ 0.9816],\n",
      "         [ 0.5283],\n",
      "         [ 0.4794],\n",
      "         [ 0.4159],\n",
      "         [ 0.9753],\n",
      "         [ 0.9725],\n",
      "         [-0.0137],\n",
      "         [ 0.9733],\n",
      "         [ 0.9740],\n",
      "         [ 0.9732],\n",
      "         [ 0.9768],\n",
      "         [ 0.9828],\n",
      "         [ 0.9817],\n",
      "         [ 0.9849],\n",
      "         [ 0.3329],\n",
      "         [ 0.4848],\n",
      "         [ 0.9761],\n",
      "         [ 0.2972],\n",
      "         [ 0.9754],\n",
      "         [ 0.9138],\n",
      "         [ 0.9757],\n",
      "         [ 0.9777],\n",
      "         [ 0.4931],\n",
      "         [ 0.2278],\n",
      "         [ 0.9662],\n",
      "         [ 0.9844],\n",
      "         [ 0.4351],\n",
      "         [ 0.8395],\n",
      "         [ 0.9784],\n",
      "         [ 0.9768],\n",
      "         [ 0.4592],\n",
      "         [ 0.9753],\n",
      "         [-0.0156],\n",
      "         [ 0.9796],\n",
      "         [ 0.9852],\n",
      "         [ 0.3247],\n",
      "         [ 0.7352],\n",
      "         [ 0.9797],\n",
      "         [ 0.9817],\n",
      "         [ 0.9436],\n",
      "         [ 0.9773],\n",
      "         [ 0.9770],\n",
      "         [ 0.9756],\n",
      "         [ 0.9023],\n",
      "         [ 0.9859],\n",
      "         [ 0.9903],\n",
      "         [ 0.9933],\n",
      "         [ 0.0179],\n",
      "         [ 0.9904],\n",
      "         [ 0.9890],\n",
      "         [ 0.9832],\n",
      "         [ 0.4767],\n",
      "         [ 0.9781],\n",
      "         [ 0.9737],\n",
      "         [ 0.9776],\n",
      "         [ 0.0076],\n",
      "         [ 0.9100],\n",
      "         [ 0.9490],\n",
      "         [ 0.3679],\n",
      "         [ 0.9937],\n",
      "         [ 0.9906],\n",
      "         [ 0.4522],\n",
      "         [ 0.9860],\n",
      "         [ 0.9818],\n",
      "         [ 0.9816],\n",
      "         [ 0.9443],\n",
      "         [-0.0073],\n",
      "         [ 0.9903],\n",
      "         [ 0.9964],\n",
      "         [ 1.0017],\n",
      "         [ 0.9911],\n",
      "         [ 0.4598],\n",
      "         [ 0.9972],\n",
      "         [ 0.3519],\n",
      "         [ 0.9791],\n",
      "         [ 0.9720],\n",
      "         [ 0.9628],\n",
      "         [ 0.9610],\n",
      "         [ 0.9623],\n",
      "         [ 0.9683],\n",
      "         [ 0.9764],\n",
      "         [ 0.4423],\n",
      "         [ 0.9925],\n",
      "         [ 0.5351],\n",
      "         [ 0.4352],\n",
      "         [ 0.4876],\n",
      "         [ 0.9816],\n",
      "         [ 0.9714],\n",
      "         [ 0.9600],\n",
      "         [ 0.9555],\n",
      "         [ 0.9540],\n",
      "         [ 0.9584],\n",
      "         [ 0.9654],\n",
      "         [ 0.3233],\n",
      "         [ 0.9870],\n",
      "         [ 0.9948],\n",
      "         [ 0.0434],\n",
      "         [ 0.5050],\n",
      "         [ 0.6538],\n",
      "         [ 0.9888],\n",
      "         [ 0.9818],\n",
      "         [ 0.9746],\n",
      "         [ 0.9691],\n",
      "         [ 0.9683],\n",
      "         [ 0.6589],\n",
      "         [ 0.9626],\n",
      "         [ 0.3469],\n",
      "         [ 0.6704],\n",
      "         [ 0.9939],\n",
      "         [ 0.9927],\n",
      "         [ 0.6026],\n",
      "         [ 0.9841],\n",
      "         [ 0.4743],\n",
      "         [ 0.1877],\n",
      "         [ 0.3950],\n",
      "         [ 0.9668],\n",
      "         [ 0.7826],\n",
      "         [ 0.9749],\n",
      "         [ 0.0149],\n",
      "         [ 0.0179],\n",
      "         [ 0.9169],\n",
      "         [ 0.9919],\n",
      "         [ 0.9800],\n",
      "         [ 0.9876],\n",
      "         [ 0.4854],\n",
      "         [ 0.4149],\n",
      "         [ 0.9813],\n",
      "         [ 0.9800],\n",
      "         [ 0.3482],\n",
      "         [ 0.7112],\n",
      "         [ 0.2251],\n",
      "         [ 0.9774],\n",
      "         [ 0.9895],\n",
      "         [ 0.4390],\n",
      "         [ 0.4938],\n",
      "         [ 0.8434],\n",
      "         [ 0.9743],\n",
      "         [ 0.8258],\n",
      "         [ 0.9681],\n",
      "         [ 0.9676],\n",
      "         [ 0.9712],\n",
      "         [ 0.0023],\n",
      "         [ 0.1650],\n",
      "         [ 0.9804],\n",
      "         [ 0.2212],\n",
      "         [ 0.3310],\n",
      "         [ 0.9797],\n",
      "         [ 0.7566],\n",
      "         [ 0.9709],\n",
      "         [ 0.9669],\n",
      "         [ 0.2960],\n",
      "         [ 0.8738],\n",
      "         [ 0.9717],\n",
      "         [ 0.9774],\n",
      "         [ 0.9761],\n",
      "         [ 0.9839],\n",
      "         [ 0.8345],\n",
      "         [ 0.2085],\n",
      "         [ 0.9818],\n",
      "         [ 0.7447],\n",
      "         [ 0.9703],\n",
      "         [ 0.9690],\n",
      "         [ 0.1804],\n",
      "         [ 0.1070],\n",
      "         [ 0.9764],\n",
      "         [ 0.9792],\n",
      "         [ 0.9463],\n",
      "         [ 0.9810],\n",
      "         [ 0.2032],\n",
      "         [ 0.9811]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.2735],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.3875],\n",
      "        [0.4480],\n",
      "        [0.9996],\n",
      "        [0.9966],\n",
      "        [0.5334],\n",
      "        [0.5030],\n",
      "        [0.4503],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.5139],\n",
      "        [0.9959],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5151],\n",
      "        [0.2729],\n",
      "        [0.9724],\n",
      "        [0.9998],\n",
      "        [0.4645],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.9044],\n",
      "        [0.9420],\n",
      "        [0.3912],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9520],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.4454],\n",
      "        [0.5009],\n",
      "        [0.9996],\n",
      "        [0.9994],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.0383],\n",
      "        [0.5054],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.6628],\n",
      "        [0.9814],\n",
      "        [0.3840],\n",
      "        [0.6555],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.5945],\n",
      "        [0.9997],\n",
      "        [0.5108],\n",
      "        [0.2547],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.0174],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [0.5080],\n",
      "        [0.4527],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.3930],\n",
      "        [0.6920],\n",
      "        [0.2646],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.5165],\n",
      "        [0.8379],\n",
      "        [0.9997],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.3753],\n",
      "        [0.9994],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.8761],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2577],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9490],\n",
      "        [0.9999],\n",
      "        [0.2518],\n",
      "        [0.9998]])\n",
      "######### Epoch: 31  ######### Train Loss: 0.000786172051448375  ######### Relative L2 Test Norm: 16.793785095214844\n",
      "Output batch pred: tensor([[[ 3.3241e-01],\n",
      "         [ 4.9950e-01],\n",
      "         [ 5.8837e-01],\n",
      "         [ 9.8776e-01],\n",
      "         [ 4.7999e-01],\n",
      "         [ 9.9243e-01],\n",
      "         [ 9.9463e-01],\n",
      "         [ 9.9433e-01],\n",
      "         [ 3.4692e-01],\n",
      "         [ 9.9169e-01],\n",
      "         [ 9.9617e-01],\n",
      "         [ 3.4596e-01],\n",
      "         [ 9.9459e-01],\n",
      "         [ 1.3951e-01],\n",
      "         [ 9.9204e-01],\n",
      "         [ 4.3466e-01],\n",
      "         [ 9.8539e-01],\n",
      "         [ 9.8255e-01],\n",
      "         [ 6.5112e-01],\n",
      "         [ 4.5741e-01],\n",
      "         [ 6.1652e-01],\n",
      "         [ 2.9014e-01],\n",
      "         [-1.8871e-03],\n",
      "         [ 9.6305e-01],\n",
      "         [ 9.5774e-01],\n",
      "         [ 9.6069e-01],\n",
      "         [ 9.6091e-01],\n",
      "         [ 9.5888e-01],\n",
      "         [ 9.6348e-01],\n",
      "         [ 9.6856e-01],\n",
      "         [ 9.7391e-01],\n",
      "         [ 4.7477e-01],\n",
      "         [ 9.8429e-01],\n",
      "         [ 9.8917e-01],\n",
      "         [ 9.8862e-01],\n",
      "         [ 9.1805e-01],\n",
      "         [ 9.9123e-01],\n",
      "         [ 4.7376e-01],\n",
      "         [ 9.8473e-01],\n",
      "         [ 8.9772e-01],\n",
      "         [ 7.1126e-01],\n",
      "         [ 9.6712e-01],\n",
      "         [ 4.9055e-01],\n",
      "         [ 9.6238e-01],\n",
      "         [ 9.6160e-01],\n",
      "         [ 9.6597e-01],\n",
      "         [ 9.6865e-01],\n",
      "         [ 9.7562e-01],\n",
      "         [ 9.8286e-01],\n",
      "         [ 3.3388e-01],\n",
      "         [ 4.4336e-01],\n",
      "         [ 2.2449e-01],\n",
      "         [ 9.9801e-01],\n",
      "         [-6.5210e-04],\n",
      "         [ 5.0344e-01],\n",
      "         [ 9.9208e-01],\n",
      "         [ 8.5206e-03],\n",
      "         [ 9.8455e-01],\n",
      "         [ 9.8147e-01],\n",
      "         [ 2.1208e-01],\n",
      "         [ 1.8742e-01],\n",
      "         [ 9.7210e-01],\n",
      "         [ 9.7541e-01],\n",
      "         [ 4.7582e-01],\n",
      "         [ 9.7871e-01],\n",
      "         [-3.7023e-03],\n",
      "         [ 9.8455e-01],\n",
      "         [ 9.8918e-01],\n",
      "         [ 2.1893e-01],\n",
      "         [ 9.9553e-01],\n",
      "         [ 4.4519e-01],\n",
      "         [ 2.5715e-01],\n",
      "         [ 1.0052e+00],\n",
      "         [ 1.0062e+00],\n",
      "         [ 1.0045e+00],\n",
      "         [ 2.3410e-01],\n",
      "         [ 9.6466e-01],\n",
      "         [ 9.8250e-01],\n",
      "         [ 9.8383e-01],\n",
      "         [ 9.7593e-01],\n",
      "         [ 9.0104e-01],\n",
      "         [ 9.7056e-01],\n",
      "         [ 9.7341e-01],\n",
      "         [ 9.7407e-01],\n",
      "         [ 9.7990e-01],\n",
      "         [ 4.8237e-01],\n",
      "         [ 9.9307e-01],\n",
      "         [ 9.9973e-01],\n",
      "         [ 1.3329e-02],\n",
      "         [ 1.0088e+00],\n",
      "         [ 9.5272e-01],\n",
      "         [ 1.0074e+00],\n",
      "         [ 1.0032e+00],\n",
      "         [ 8.6775e-01],\n",
      "         [ 6.8308e-01],\n",
      "         [ 9.7929e-01],\n",
      "         [ 9.7341e-01],\n",
      "         [ 9.7128e-01],\n",
      "         [ 9.6501e-01],\n",
      "         [ 9.6786e-01],\n",
      "         [ 9.6982e-01],\n",
      "         [ 9.7287e-01],\n",
      "         [ 7.5299e-01],\n",
      "         [ 9.7835e-01],\n",
      "         [ 9.7893e-01],\n",
      "         [ 9.8186e-01],\n",
      "         [ 9.8127e-01],\n",
      "         [-1.2185e-02],\n",
      "         [ 9.7786e-01],\n",
      "         [ 4.7132e-01],\n",
      "         [ 8.7889e-01],\n",
      "         [ 9.7077e-01],\n",
      "         [ 9.7377e-01],\n",
      "         [ 9.7420e-01],\n",
      "         [ 3.8731e-01],\n",
      "         [ 9.7170e-01],\n",
      "         [ 7.8790e-01],\n",
      "         [ 9.7161e-01],\n",
      "         [ 9.6747e-01],\n",
      "         [ 3.0865e-01],\n",
      "         [ 4.4737e-01],\n",
      "         [ 3.1823e-01],\n",
      "         [ 9.6673e-01],\n",
      "         [ 8.1789e-01],\n",
      "         [ 3.9117e-01],\n",
      "         [ 9.5262e-01],\n",
      "         [ 9.7540e-01],\n",
      "         [ 9.8128e-01],\n",
      "         [ 3.2505e-01],\n",
      "         [ 4.2821e-01],\n",
      "         [ 4.4385e-01],\n",
      "         [ 4.8992e-01],\n",
      "         [ 9.9106e-01],\n",
      "         [ 9.7958e-01],\n",
      "         [ 9.5447e-01],\n",
      "         [ 4.2407e-01],\n",
      "         [ 9.8318e-01],\n",
      "         [ 7.0261e-01],\n",
      "         [ 9.7381e-01],\n",
      "         [ 9.5909e-01],\n",
      "         [ 8.0201e-03],\n",
      "         [ 9.7580e-01],\n",
      "         [ 7.4255e-01],\n",
      "         [ 9.8048e-01],\n",
      "         [ 9.4017e-01],\n",
      "         [ 2.2668e-01],\n",
      "         [ 9.7108e-01],\n",
      "         [ 3.4858e-01],\n",
      "         [ 2.3290e-02],\n",
      "         [ 3.5474e-01],\n",
      "         [ 1.0635e-02],\n",
      "         [ 8.2682e-01],\n",
      "         [ 9.7377e-01],\n",
      "         [ 8.3178e-01],\n",
      "         [ 9.7137e-01],\n",
      "         [ 9.6919e-01],\n",
      "         [ 2.8658e-01],\n",
      "         [ 9.6784e-01],\n",
      "         [ 9.6733e-01],\n",
      "         [ 9.7155e-01],\n",
      "         [ 9.7385e-01],\n",
      "         [ 1.4854e-01],\n",
      "         [ 9.8283e-01],\n",
      "         [ 9.8745e-01],\n",
      "         [ 9.9031e-01],\n",
      "         [ 9.9156e-01],\n",
      "         [ 2.1736e-01],\n",
      "         [ 4.1904e-01],\n",
      "         [ 5.2975e-01],\n",
      "         [ 9.8763e-01],\n",
      "         [ 9.8700e-01],\n",
      "         [ 9.8334e-01],\n",
      "         [ 9.7981e-01],\n",
      "         [ 9.3954e-01],\n",
      "         [ 4.0834e-01],\n",
      "         [ 9.7266e-01],\n",
      "         [ 9.7351e-01],\n",
      "         [ 9.7423e-01]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.3930],\n",
      "        [0.5245],\n",
      "        [0.5945],\n",
      "        [0.9995],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.4988],\n",
      "        [0.6327],\n",
      "        [0.3573],\n",
      "        [0.0368],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.9996],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.3747],\n",
      "        [0.4645],\n",
      "        [0.2610],\n",
      "        [0.9995],\n",
      "        [0.0000],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [0.2518],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.9520],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.6628],\n",
      "        [0.9999],\n",
      "        [0.9966],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [0.5151],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.5030],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.4527],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.4580],\n",
      "        [0.4642],\n",
      "        [0.5054],\n",
      "        [0.9959],\n",
      "        [0.9804],\n",
      "        [0.9515],\n",
      "        [0.4552],\n",
      "        [0.9997],\n",
      "        [0.6920],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.2686],\n",
      "        [0.9820],\n",
      "        [0.3840],\n",
      "        [0.0288],\n",
      "        [0.3912],\n",
      "        [0.0209],\n",
      "        [0.8139],\n",
      "        [0.9999],\n",
      "        [0.8296],\n",
      "        [0.9994],\n",
      "        [0.9994],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [0.4480],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9490],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]])\n",
      "######### Epoch: 32  ######### Train Loss: 0.0008188996580429375  ######### Relative L2 Test Norm: 15.448026657104492\n",
      "Output batch pred: tensor([[[ 0.9763],\n",
      "         [ 0.9806],\n",
      "         [ 0.3171],\n",
      "         [ 0.9866],\n",
      "         [ 0.1672],\n",
      "         [ 0.9906],\n",
      "         [ 0.9902],\n",
      "         [ 0.3079],\n",
      "         [ 0.9863],\n",
      "         [ 0.4040],\n",
      "         [ 0.9822],\n",
      "         [ 0.9837],\n",
      "         [ 0.9835],\n",
      "         [ 0.9872],\n",
      "         [ 0.9892],\n",
      "         [ 0.9943],\n",
      "         [ 0.9973],\n",
      "         [ 0.9029],\n",
      "         [ 0.6825],\n",
      "         [ 0.9734],\n",
      "         [ 0.4770],\n",
      "         [ 0.2078],\n",
      "         [ 0.4230],\n",
      "         [ 0.3404],\n",
      "         [ 0.9793],\n",
      "         [ 0.9804],\n",
      "         [ 0.5204],\n",
      "         [ 0.9913],\n",
      "         [ 0.9597],\n",
      "         [ 0.5021],\n",
      "         [ 0.2406],\n",
      "         [ 0.3693],\n",
      "         [ 0.0197],\n",
      "         [ 0.9845],\n",
      "         [ 0.0013],\n",
      "         [ 0.5808],\n",
      "         [ 0.9769],\n",
      "         [ 0.8194],\n",
      "         [ 0.9638],\n",
      "         [ 0.4593],\n",
      "         [ 0.9859],\n",
      "         [ 0.3410],\n",
      "         [ 1.0008],\n",
      "         [ 1.0047],\n",
      "         [ 1.0065],\n",
      "         [ 0.4440],\n",
      "         [ 0.9990],\n",
      "         [ 0.9932],\n",
      "         [ 0.4910],\n",
      "         [ 0.9881],\n",
      "         [ 0.4022],\n",
      "         [ 0.3205],\n",
      "         [ 0.7568],\n",
      "         [ 0.5312],\n",
      "         [ 0.9930],\n",
      "         [ 0.9931],\n",
      "         [ 0.8587],\n",
      "         [ 0.9892],\n",
      "         [ 0.9833],\n",
      "         [ 0.9794],\n",
      "         [ 0.1880],\n",
      "         [ 0.9722],\n",
      "         [ 0.9732],\n",
      "         [ 0.9770],\n",
      "         [ 0.9804],\n",
      "         [-0.0175],\n",
      "         [ 0.0113],\n",
      "         [ 1.0048],\n",
      "         [ 0.0396],\n",
      "         [ 1.0104],\n",
      "         [ 1.0045],\n",
      "         [ 1.0002],\n",
      "         [ 0.9936],\n",
      "         [ 0.6537],\n",
      "         [ 0.4572],\n",
      "         [ 0.9740],\n",
      "         [ 0.9723],\n",
      "         [ 0.9730],\n",
      "         [ 0.4865],\n",
      "         [ 0.9806],\n",
      "         [ 0.9813],\n",
      "         [ 0.9897],\n",
      "         [ 0.9878],\n",
      "         [ 0.2227],\n",
      "         [ 0.9909],\n",
      "         [ 0.9751],\n",
      "         [ 0.3253],\n",
      "         [ 0.9832],\n",
      "         [ 0.4154],\n",
      "         [ 0.9765],\n",
      "         [-0.0033],\n",
      "         [ 0.9749],\n",
      "         [ 0.9728],\n",
      "         [ 0.4161],\n",
      "         [ 0.9768],\n",
      "         [ 0.8333],\n",
      "         [ 0.9767],\n",
      "         [ 0.9822],\n",
      "         [ 0.7984],\n",
      "         [ 0.4779],\n",
      "         [ 0.9853],\n",
      "         [ 0.9889],\n",
      "         [ 0.4909],\n",
      "         [ 0.3169],\n",
      "         [ 0.4209],\n",
      "         [ 0.9865],\n",
      "         [ 0.9850],\n",
      "         [ 0.4080],\n",
      "         [ 0.9838],\n",
      "         [ 0.9849],\n",
      "         [ 0.3319],\n",
      "         [ 0.9872],\n",
      "         [ 0.9901],\n",
      "         [ 0.7703],\n",
      "         [ 0.9783],\n",
      "         [ 0.2041],\n",
      "         [ 0.9870],\n",
      "         [ 0.0056],\n",
      "         [ 0.1250],\n",
      "         [ 0.4055],\n",
      "         [ 0.9742],\n",
      "         [ 0.9723],\n",
      "         [ 0.9413],\n",
      "         [ 0.9482],\n",
      "         [ 0.9898],\n",
      "         [ 0.9943],\n",
      "         [ 0.6556],\n",
      "         [ 1.0058],\n",
      "         [ 0.0380],\n",
      "         [ 1.0068],\n",
      "         [ 0.2317],\n",
      "         [ 0.2212],\n",
      "         [ 0.7411],\n",
      "         [ 0.9898],\n",
      "         [ 0.9861],\n",
      "         [ 0.9818],\n",
      "         [ 0.9836],\n",
      "         [ 0.4722],\n",
      "         [ 0.9871],\n",
      "         [ 0.9120],\n",
      "         [ 0.9945],\n",
      "         [ 0.9225],\n",
      "         [ 0.2183],\n",
      "         [ 0.9965],\n",
      "         [ 0.9961],\n",
      "         [ 0.9950],\n",
      "         [ 0.7190],\n",
      "         [ 0.3347],\n",
      "         [ 0.8571],\n",
      "         [ 0.9949],\n",
      "         [ 0.4845],\n",
      "         [ 0.9971],\n",
      "         [ 0.9227],\n",
      "         [ 0.9955],\n",
      "         [ 0.9907],\n",
      "         [ 0.9906],\n",
      "         [ 0.9847],\n",
      "         [ 0.9816],\n",
      "         [ 0.9830],\n",
      "         [ 0.9836],\n",
      "         [ 0.9858],\n",
      "         [ 0.9865],\n",
      "         [-0.0055],\n",
      "         [ 0.9984],\n",
      "         [ 1.0040],\n",
      "         [ 0.4551],\n",
      "         [ 1.0083],\n",
      "         [ 0.9950],\n",
      "         [ 1.0048],\n",
      "         [ 0.9987],\n",
      "         [ 0.9932],\n",
      "         [ 0.3283],\n",
      "         [ 0.9378],\n",
      "         [ 0.9107],\n",
      "         [ 0.9659],\n",
      "         [ 0.9672],\n",
      "         [ 0.4407],\n",
      "         [ 0.9682]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.6628],\n",
      "        [0.9724],\n",
      "        [0.5054],\n",
      "        [0.2610],\n",
      "        [0.4645],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [0.9997],\n",
      "        [0.9490],\n",
      "        [0.5108],\n",
      "        [0.2686],\n",
      "        [0.3912],\n",
      "        [0.0174],\n",
      "        [0.9956],\n",
      "        [0.0142],\n",
      "        [0.5945],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [0.9820],\n",
      "        [0.4988],\n",
      "        [0.9959],\n",
      "        [0.3747],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.3753],\n",
      "        [0.7391],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.0209],\n",
      "        [0.9997],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.5080],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.9999],\n",
      "        [0.9814],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [0.4668],\n",
      "        [0.9999],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [0.9997],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.7820],\n",
      "        [0.5139],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.3575],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.7540],\n",
      "        [0.9819],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.1762],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.2547],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.9967],\n",
      "        [0.8933],\n",
      "        [0.9994],\n",
      "        [0.9044],\n",
      "        [0.2646],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.6920],\n",
      "        [0.3780],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.9420],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.9997]])\n",
      "######### Epoch: 33  ######### Train Loss: 0.0006561555783264339  ######### Relative L2 Test Norm: 15.112585067749023\n",
      "Output batch pred: tensor([[[ 0.7547],\n",
      "         [ 1.0082],\n",
      "         [ 1.0079],\n",
      "         [ 0.4965],\n",
      "         [ 0.1460],\n",
      "         [ 0.4239],\n",
      "         [ 0.9951],\n",
      "         [ 0.9914],\n",
      "         [ 0.9724],\n",
      "         [ 0.4815],\n",
      "         [ 0.9819],\n",
      "         [ 0.3150],\n",
      "         [ 0.1888],\n",
      "         [ 0.9847],\n",
      "         [ 0.9860],\n",
      "         [ 0.9887],\n",
      "         [ 0.8976],\n",
      "         [ 0.9948],\n",
      "         [ 0.9995],\n",
      "         [ 1.0087],\n",
      "         [ 1.0146],\n",
      "         [ 0.0392],\n",
      "         [ 1.0219],\n",
      "         [ 1.0196],\n",
      "         [ 0.4704],\n",
      "         [ 0.5477],\n",
      "         [ 1.0069],\n",
      "         [ 0.7665],\n",
      "         [ 0.9881],\n",
      "         [ 0.9798],\n",
      "         [ 0.9307],\n",
      "         [ 0.9696],\n",
      "         [-0.0178],\n",
      "         [ 0.9770],\n",
      "         [ 0.3437],\n",
      "         [ 0.9760],\n",
      "         [ 0.5456],\n",
      "         [ 0.3686],\n",
      "         [ 1.0156],\n",
      "         [ 0.3837],\n",
      "         [ 0.8080],\n",
      "         [ 0.4413],\n",
      "         [ 1.0054],\n",
      "         [ 0.9875],\n",
      "         [ 0.3447],\n",
      "         [ 0.9902],\n",
      "         [ 0.9883],\n",
      "         [ 0.9853],\n",
      "         [ 0.9891],\n",
      "         [ 0.9950],\n",
      "         [ 0.9968],\n",
      "         [ 1.0040],\n",
      "         [ 1.0058],\n",
      "         [ 0.2348],\n",
      "         [ 1.0023],\n",
      "         [ 1.0013],\n",
      "         [ 1.0013],\n",
      "         [-0.0184],\n",
      "         [ 0.8540],\n",
      "         [ 0.9952],\n",
      "         [ 0.9828],\n",
      "         [ 0.9978],\n",
      "         [ 1.0003],\n",
      "         [ 0.9984],\n",
      "         [ 1.0047],\n",
      "         [ 0.4950],\n",
      "         [ 1.0061],\n",
      "         [ 1.0027],\n",
      "         [ 0.2258],\n",
      "         [ 0.4431],\n",
      "         [ 0.4300],\n",
      "         [ 0.9047],\n",
      "         [ 0.9848],\n",
      "         [ 0.0013],\n",
      "         [ 0.3080],\n",
      "         [ 0.4736],\n",
      "         [ 0.9944],\n",
      "         [ 0.9990],\n",
      "         [ 0.9984],\n",
      "         [ 0.5054],\n",
      "         [ 0.3579],\n",
      "         [ 0.4695],\n",
      "         [ 0.9806],\n",
      "         [ 1.0134],\n",
      "         [ 0.6700],\n",
      "         [ 1.0066],\n",
      "         [ 0.9317],\n",
      "         [ 1.0004],\n",
      "         [ 0.2277],\n",
      "         [ 0.9914],\n",
      "         [ 0.9935],\n",
      "         [ 0.9929],\n",
      "         [ 0.9913],\n",
      "         [ 0.9954],\n",
      "         [ 0.9959],\n",
      "         [ 0.9976],\n",
      "         [ 0.8641],\n",
      "         [ 0.3400],\n",
      "         [ 0.0104],\n",
      "         [ 0.2015],\n",
      "         [ 0.8610],\n",
      "         [ 0.4252],\n",
      "         [ 0.9973],\n",
      "         [ 0.9981],\n",
      "         [ 1.0001],\n",
      "         [ 0.9998],\n",
      "         [ 0.9987],\n",
      "         [ 0.1838],\n",
      "         [ 1.0028],\n",
      "         [ 1.0002],\n",
      "         [ 1.0021],\n",
      "         [ 1.0001],\n",
      "         [ 0.3572],\n",
      "         [ 0.4809],\n",
      "         [ 0.4974],\n",
      "         [ 0.2259],\n",
      "         [ 0.2216],\n",
      "         [ 0.9924],\n",
      "         [ 0.9603],\n",
      "         [ 0.9983],\n",
      "         [ 0.5398],\n",
      "         [-0.0011],\n",
      "         [ 0.9398],\n",
      "         [ 0.9987],\n",
      "         [ 0.9940],\n",
      "         [ 0.9944],\n",
      "         [ 0.9909],\n",
      "         [ 0.4748],\n",
      "         [ 0.9917],\n",
      "         [ 0.9928],\n",
      "         [ 0.9179],\n",
      "         [ 0.9953],\n",
      "         [ 0.9610],\n",
      "         [ 0.9986],\n",
      "         [ 1.0031],\n",
      "         [ 1.0041],\n",
      "         [ 1.0065],\n",
      "         [ 0.6963],\n",
      "         [ 0.4501],\n",
      "         [ 1.0009],\n",
      "         [ 1.0010],\n",
      "         [ 0.3448],\n",
      "         [-0.0114],\n",
      "         [ 0.7131],\n",
      "         [ 0.1990],\n",
      "         [ 0.9878],\n",
      "         [ 0.9744],\n",
      "         [ 0.4723],\n",
      "         [ 0.9851],\n",
      "         [ 0.9838],\n",
      "         [ 0.9864],\n",
      "         [ 0.9886],\n",
      "         [ 0.9894],\n",
      "         [ 0.9903],\n",
      "         [ 0.9979],\n",
      "         [ 1.0015],\n",
      "         [ 0.4363],\n",
      "         [ 0.0306],\n",
      "         [ 0.6166],\n",
      "         [ 0.6811],\n",
      "         [ 1.0044],\n",
      "         [ 1.0007],\n",
      "         [ 0.5000],\n",
      "         [ 0.9922],\n",
      "         [ 0.4148],\n",
      "         [ 0.8278],\n",
      "         [-0.0128],\n",
      "         [ 0.2940],\n",
      "         [ 0.9792],\n",
      "         [ 0.9795],\n",
      "         [ 0.9815],\n",
      "         [ 0.9846],\n",
      "         [ 0.9878],\n",
      "         [ 0.9892],\n",
      "         [ 0.9974],\n",
      "         [ 1.0016],\n",
      "         [ 0.8237],\n",
      "         [ 1.0083]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.7129],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.1762],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9814],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.9967],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9724],\n",
      "        [0.5334],\n",
      "        [0.3780],\n",
      "        [0.9994],\n",
      "        [0.3840],\n",
      "        [0.7540],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9962],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.0142],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.2610],\n",
      "        [0.4642],\n",
      "        [0.4611],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.3575],\n",
      "        [0.5054],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.5080],\n",
      "        [0.3753],\n",
      "        [0.4668],\n",
      "        [0.9490],\n",
      "        [0.9999],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.8379],\n",
      "        [0.3747],\n",
      "        [0.0368],\n",
      "        [0.2518],\n",
      "        [0.8296],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3875],\n",
      "        [0.5009],\n",
      "        [0.5165],\n",
      "        [0.2686],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.0209],\n",
      "        [0.9164],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9009],\n",
      "        [0.9994],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.0000],\n",
      "        [0.6920],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.0288],\n",
      "        [0.5945],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.8139],\n",
      "        [0.0174],\n",
      "        [0.3573],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.7820],\n",
      "        [0.9995]])\n",
      "######### Epoch: 34  ######### Train Loss: 0.0004712696827482432  ######### Relative L2 Test Norm: 14.704902648925781\n",
      "Output batch pred: tensor([[[1.0110],\n",
      "         [1.0087],\n",
      "         [0.9726],\n",
      "         [0.9320],\n",
      "         [0.4930],\n",
      "         [0.9308],\n",
      "         [0.9923],\n",
      "         [0.9900],\n",
      "         [1.0054],\n",
      "         [0.2262],\n",
      "         [0.6928],\n",
      "         [1.0020],\n",
      "         [1.0030],\n",
      "         [0.9831],\n",
      "         [0.3518],\n",
      "         [0.3411],\n",
      "         [0.3556],\n",
      "         [0.7189],\n",
      "         [0.5182],\n",
      "         [0.9973],\n",
      "         [0.9985],\n",
      "         [0.4951],\n",
      "         [0.9962],\n",
      "         [0.9972],\n",
      "         [0.9994],\n",
      "         [0.9989],\n",
      "         [0.9980],\n",
      "         [0.9614],\n",
      "         [0.4233],\n",
      "         [1.0022],\n",
      "         [1.0042],\n",
      "         [1.0096],\n",
      "         [1.0098],\n",
      "         [1.0161],\n",
      "         [0.0410],\n",
      "         [1.0190],\n",
      "         [0.8823],\n",
      "         [1.0132],\n",
      "         [1.0081],\n",
      "         [0.8580],\n",
      "         [0.2023],\n",
      "         [0.9887],\n",
      "         [0.9848],\n",
      "         [0.9823],\n",
      "         [0.7482],\n",
      "         [0.0045],\n",
      "         [0.9957],\n",
      "         [0.1495],\n",
      "         [1.0093],\n",
      "         [0.2410],\n",
      "         [1.0097],\n",
      "         [1.0153],\n",
      "         [1.0128],\n",
      "         [1.0084],\n",
      "         [0.2257],\n",
      "         [0.8446],\n",
      "         [0.3425],\n",
      "         [0.9838],\n",
      "         [0.6745],\n",
      "         [0.0216],\n",
      "         [1.0112],\n",
      "         [1.0211],\n",
      "         [1.0265],\n",
      "         [1.0306],\n",
      "         [0.5540],\n",
      "         [1.0269],\n",
      "         [0.9882],\n",
      "         [1.0120],\n",
      "         [1.0034],\n",
      "         [0.3262],\n",
      "         [0.9964],\n",
      "         [0.8128],\n",
      "         [0.9984],\n",
      "         [0.3503],\n",
      "         [1.0108],\n",
      "         [1.0148],\n",
      "         [1.0236],\n",
      "         [1.0260],\n",
      "         [1.0269],\n",
      "         [1.0233],\n",
      "         [1.0185],\n",
      "         [0.0067],\n",
      "         [1.0032],\n",
      "         [0.4297],\n",
      "         [0.9519],\n",
      "         [0.9910],\n",
      "         [0.9922],\n",
      "         [0.9391],\n",
      "         [1.0044],\n",
      "         [0.5624],\n",
      "         [1.0169],\n",
      "         [0.4654],\n",
      "         [1.0266],\n",
      "         [1.0259],\n",
      "         [1.0238],\n",
      "         [0.5195],\n",
      "         [0.8901],\n",
      "         [0.5077],\n",
      "         [1.0073],\n",
      "         [1.0045],\n",
      "         [1.0021],\n",
      "         [1.0015],\n",
      "         [1.0016],\n",
      "         [1.0032],\n",
      "         [0.3682],\n",
      "         [0.9248],\n",
      "         [1.0027],\n",
      "         [1.0033],\n",
      "         [1.0042],\n",
      "         [0.2133],\n",
      "         [0.2336],\n",
      "         [0.9993],\n",
      "         [0.2266],\n",
      "         [0.1800],\n",
      "         [1.0002],\n",
      "         [1.0034],\n",
      "         [1.0065],\n",
      "         [1.0081],\n",
      "         [1.0150],\n",
      "         [1.0168],\n",
      "         [1.0219],\n",
      "         [1.0245],\n",
      "         [1.0232],\n",
      "         [0.8155],\n",
      "         [1.0187],\n",
      "         [0.5069],\n",
      "         [1.0090],\n",
      "         [0.4383],\n",
      "         [1.0057],\n",
      "         [0.3639],\n",
      "         [0.9108],\n",
      "         [1.0028],\n",
      "         [1.0056],\n",
      "         [1.0075],\n",
      "         [1.0090],\n",
      "         [0.4321],\n",
      "         [0.3589],\n",
      "         [0.5422],\n",
      "         [0.4466],\n",
      "         [0.7410],\n",
      "         [0.4390],\n",
      "         [0.9928],\n",
      "         [0.0226],\n",
      "         [0.9986],\n",
      "         [0.4978],\n",
      "         [1.0005],\n",
      "         [0.4566],\n",
      "         [0.6145],\n",
      "         [1.0087],\n",
      "         [0.0388],\n",
      "         [1.0067],\n",
      "         [1.0041],\n",
      "         [0.3407],\n",
      "         [0.5030],\n",
      "         [0.0098],\n",
      "         [0.9982],\n",
      "         [1.0029],\n",
      "         [1.0053],\n",
      "         [1.0094],\n",
      "         [1.0129],\n",
      "         [1.0016],\n",
      "         [0.0170],\n",
      "         [1.0137],\n",
      "         [1.0115],\n",
      "         [0.4558],\n",
      "         [1.0028],\n",
      "         [0.0180],\n",
      "         [0.9960],\n",
      "         [0.6375],\n",
      "         [0.4305],\n",
      "         [0.9922],\n",
      "         [0.4985],\n",
      "         [1.0030],\n",
      "         [1.0082],\n",
      "         [1.0104],\n",
      "         [0.3413],\n",
      "         [0.5118],\n",
      "         [0.2548]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9009],\n",
      "        [0.5030],\n",
      "        [0.9044],\n",
      "        [0.9804],\n",
      "        [0.9814],\n",
      "        [0.9999],\n",
      "        [0.2547],\n",
      "        [0.6628],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.3840],\n",
      "        [0.3747],\n",
      "        [0.3912],\n",
      "        [0.6920],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.4527],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [0.2646],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7391],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.9956],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.8139],\n",
      "        [0.3780],\n",
      "        [0.9819],\n",
      "        [0.6555],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [0.9490],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.3575],\n",
      "        [0.9997],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.9420],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [0.9164],\n",
      "        [0.9967],\n",
      "        [0.5463],\n",
      "        [0.9997],\n",
      "        [0.4503],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5009],\n",
      "        [0.8379],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.8933],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2518],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.2208],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.9998],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.3808],\n",
      "        [0.5334],\n",
      "        [0.4611],\n",
      "        [0.7129],\n",
      "        [0.4580],\n",
      "        [0.9959],\n",
      "        [0.0209],\n",
      "        [0.9999],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.5945],\n",
      "        [0.9999],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.5151],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.0174],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.4642],\n",
      "        [0.9996],\n",
      "        [0.0368],\n",
      "        [0.9996],\n",
      "        [0.6327],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [0.5054],\n",
      "        [0.2729]])\n",
      "######### Epoch: 35  ######### Train Loss: 0.00039518316043540835  ######### Relative L2 Test Norm: 13.606056213378906\n",
      "Output batch pred: tensor([[[0.9892],\n",
      "         [0.5779],\n",
      "         [0.3911],\n",
      "         [1.0214],\n",
      "         [1.0163],\n",
      "         [1.0146],\n",
      "         [1.0124],\n",
      "         [0.8763],\n",
      "         [1.0062],\n",
      "         [0.2440],\n",
      "         [0.0266],\n",
      "         [0.0378],\n",
      "         [1.0051],\n",
      "         [0.9513],\n",
      "         [0.9791],\n",
      "         [1.0172],\n",
      "         [0.3760],\n",
      "         [0.0611],\n",
      "         [1.0181],\n",
      "         [0.4502],\n",
      "         [1.0115],\n",
      "         [0.3403],\n",
      "         [0.7904],\n",
      "         [1.0027],\n",
      "         [0.4916],\n",
      "         [1.0069],\n",
      "         [0.6889],\n",
      "         [0.4495],\n",
      "         [0.9997],\n",
      "         [1.0190],\n",
      "         [1.0205],\n",
      "         [1.0247],\n",
      "         [1.0251],\n",
      "         [0.5353],\n",
      "         [1.0232],\n",
      "         [1.0228],\n",
      "         [1.0084],\n",
      "         [1.0205],\n",
      "         [1.0176],\n",
      "         [1.0172],\n",
      "         [0.5122],\n",
      "         [0.8328],\n",
      "         [0.0449],\n",
      "         [1.0039],\n",
      "         [0.2223],\n",
      "         [0.9910],\n",
      "         [0.4330],\n",
      "         [0.8578],\n",
      "         [0.4504],\n",
      "         [0.9426],\n",
      "         [0.7204],\n",
      "         [1.0207],\n",
      "         [1.0222],\n",
      "         [0.9954],\n",
      "         [0.6990],\n",
      "         [1.0295],\n",
      "         [1.0249],\n",
      "         [1.0232],\n",
      "         [1.0223],\n",
      "         [1.0191],\n",
      "         [1.0054],\n",
      "         [0.4656],\n",
      "         [0.5163],\n",
      "         [1.0121],\n",
      "         [0.3618],\n",
      "         [1.0102],\n",
      "         [1.0060],\n",
      "         [0.4511],\n",
      "         [1.0073],\n",
      "         [1.0073],\n",
      "         [1.0077],\n",
      "         [1.0096],\n",
      "         [1.0101],\n",
      "         [0.5225],\n",
      "         [1.0104],\n",
      "         [1.0156],\n",
      "         [1.0135],\n",
      "         [1.0128],\n",
      "         [0.2416],\n",
      "         [1.0066],\n",
      "         [0.0281],\n",
      "         [0.4521],\n",
      "         [0.9975],\n",
      "         [0.9985],\n",
      "         [1.0023],\n",
      "         [1.0077],\n",
      "         [0.8752],\n",
      "         [0.5601],\n",
      "         [1.0190],\n",
      "         [0.3856],\n",
      "         [1.0200],\n",
      "         [0.5201],\n",
      "         [0.5178],\n",
      "         [1.0130],\n",
      "         [1.0106],\n",
      "         [1.0089],\n",
      "         [1.0087],\n",
      "         [1.0094],\n",
      "         [0.5398],\n",
      "         [0.0355],\n",
      "         [1.0126],\n",
      "         [1.0131],\n",
      "         [1.0123],\n",
      "         [0.0561],\n",
      "         [1.0073],\n",
      "         [1.0111],\n",
      "         [0.2571],\n",
      "         [1.0118],\n",
      "         [0.8730],\n",
      "         [0.9408],\n",
      "         [1.0168],\n",
      "         [0.0366],\n",
      "         [1.0193],\n",
      "         [0.2528],\n",
      "         [1.0171],\n",
      "         [0.4719],\n",
      "         [0.3576],\n",
      "         [1.0110],\n",
      "         [0.4549],\n",
      "         [0.6287],\n",
      "         [1.0128],\n",
      "         [1.0150],\n",
      "         [1.0165],\n",
      "         [1.0149],\n",
      "         [1.0181],\n",
      "         [1.0173],\n",
      "         [0.5306],\n",
      "         [1.0119],\n",
      "         [0.7808],\n",
      "         [0.4606],\n",
      "         [1.0033],\n",
      "         [0.1935],\n",
      "         [0.0067],\n",
      "         [1.0039],\n",
      "         [0.3585],\n",
      "         [1.0075],\n",
      "         [1.0097],\n",
      "         [1.0085],\n",
      "         [0.2404],\n",
      "         [1.0117],\n",
      "         [1.0099],\n",
      "         [0.9968],\n",
      "         [1.0124],\n",
      "         [1.0097],\n",
      "         [0.7400],\n",
      "         [1.0101],\n",
      "         [1.0134],\n",
      "         [0.3614],\n",
      "         [1.0113],\n",
      "         [0.3603],\n",
      "         [1.0086],\n",
      "         [1.0058],\n",
      "         [0.4881],\n",
      "         [0.2155],\n",
      "         [1.0025],\n",
      "         [1.0046],\n",
      "         [1.0079],\n",
      "         [0.9333],\n",
      "         [1.0160],\n",
      "         [1.0205],\n",
      "         [0.7781],\n",
      "         [0.9364],\n",
      "         [0.4008],\n",
      "         [1.0219],\n",
      "         [1.0185],\n",
      "         [1.0136],\n",
      "         [1.0074],\n",
      "         [1.0073],\n",
      "         [0.2403],\n",
      "         [0.3645],\n",
      "         [1.0036],\n",
      "         [1.0050],\n",
      "         [0.5159],\n",
      "         [1.0098],\n",
      "         [1.0111],\n",
      "         [0.9761],\n",
      "         [0.1689],\n",
      "         [1.0192]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9515],\n",
      "        [0.5463],\n",
      "        [0.3875],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9997],\n",
      "        [0.2686],\n",
      "        [0.0142],\n",
      "        [0.0247],\n",
      "        [0.9999],\n",
      "        [0.9164],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.7540],\n",
      "        [0.9966],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.4503],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.7820],\n",
      "        [0.0383],\n",
      "        [0.9999],\n",
      "        [0.2518],\n",
      "        [0.9804],\n",
      "        [0.4480],\n",
      "        [0.8139],\n",
      "        [0.4552],\n",
      "        [0.9009],\n",
      "        [0.6628],\n",
      "        [0.9962],\n",
      "        [0.9956],\n",
      "        [0.9520],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.4645],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9996],\n",
      "        [0.0209],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5245],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.9044],\n",
      "        [0.9997],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.5945],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.4642],\n",
      "        [0.9994],\n",
      "        [0.2208],\n",
      "        [0.0000],\n",
      "        [0.9999],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6920],\n",
      "        [0.9997],\n",
      "        [0.9995],\n",
      "        [0.3753],\n",
      "        [0.9998],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.5009],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.8761],\n",
      "        [0.3930],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5151],\n",
      "        [0.9997],\n",
      "        [0.9967],\n",
      "        [0.9420],\n",
      "        [0.1762],\n",
      "        [0.9998]])\n",
      "######### Epoch: 36  ######### Train Loss: 0.00046745326835662127  ######### Relative L2 Test Norm: 13.891060829162598\n",
      "Output batch pred: tensor([[[1.0018],\n",
      "         [1.0147],\n",
      "         [0.3697],\n",
      "         [1.0094],\n",
      "         [1.0097],\n",
      "         [0.5230],\n",
      "         [1.0109],\n",
      "         [1.0140],\n",
      "         [0.2406],\n",
      "         [0.4706],\n",
      "         [1.0226],\n",
      "         [1.0276],\n",
      "         [1.0282],\n",
      "         [1.0279],\n",
      "         [1.0248],\n",
      "         [1.0237],\n",
      "         [0.0359],\n",
      "         [0.5645],\n",
      "         [0.9725],\n",
      "         [1.0015],\n",
      "         [0.0488],\n",
      "         [0.0463],\n",
      "         [0.2526],\n",
      "         [1.0034],\n",
      "         [0.5088],\n",
      "         [0.7949],\n",
      "         [1.0078],\n",
      "         [0.2527],\n",
      "         [0.0439],\n",
      "         [0.5625],\n",
      "         [1.0095],\n",
      "         [0.2668],\n",
      "         [0.9738],\n",
      "         [1.0122],\n",
      "         [0.9401],\n",
      "         [1.0187],\n",
      "         [0.3663],\n",
      "         [1.0256],\n",
      "         [0.9550],\n",
      "         [0.4056],\n",
      "         [0.5417],\n",
      "         [1.0207],\n",
      "         [0.7490],\n",
      "         [1.0137],\n",
      "         [0.5276],\n",
      "         [1.0047],\n",
      "         [1.0081],\n",
      "         [1.0081],\n",
      "         [1.0119],\n",
      "         [1.0142],\n",
      "         [1.0157],\n",
      "         [0.0326],\n",
      "         [1.0185],\n",
      "         [1.0197],\n",
      "         [1.0183],\n",
      "         [1.0183],\n",
      "         [0.5157],\n",
      "         [1.0146],\n",
      "         [0.3970],\n",
      "         [0.4603],\n",
      "         [0.2604],\n",
      "         [1.0151],\n",
      "         [0.2451],\n",
      "         [0.5203],\n",
      "         [0.9998],\n",
      "         [1.0121],\n",
      "         [0.4715],\n",
      "         [0.3683],\n",
      "         [1.0157],\n",
      "         [1.0192],\n",
      "         [0.3673],\n",
      "         [1.0230],\n",
      "         [1.0276],\n",
      "         [1.0251],\n",
      "         [0.6531],\n",
      "         [0.4913],\n",
      "         [1.0088],\n",
      "         [0.5181],\n",
      "         [1.0113],\n",
      "         [0.7006],\n",
      "         [0.4591],\n",
      "         [0.9688],\n",
      "         [1.0076],\n",
      "         [1.0116],\n",
      "         [0.3724],\n",
      "         [0.8881],\n",
      "         [1.0228],\n",
      "         [1.0235],\n",
      "         [1.0225],\n",
      "         [0.8813],\n",
      "         [1.0208],\n",
      "         [1.0165],\n",
      "         [1.0128],\n",
      "         [1.0076],\n",
      "         [1.0055],\n",
      "         [0.3564],\n",
      "         [0.0273],\n",
      "         [1.0008],\n",
      "         [1.0049],\n",
      "         [1.0033],\n",
      "         [0.8306],\n",
      "         [0.8798],\n",
      "         [1.0104],\n",
      "         [1.0067],\n",
      "         [0.4618],\n",
      "         [1.0154],\n",
      "         [1.0163],\n",
      "         [1.0161],\n",
      "         [0.5566],\n",
      "         [0.2213],\n",
      "         [0.3941],\n",
      "         [1.0158],\n",
      "         [1.0140],\n",
      "         [1.0154],\n",
      "         [0.0552],\n",
      "         [0.7960],\n",
      "         [1.0152],\n",
      "         [1.0176],\n",
      "         [1.0155],\n",
      "         [0.8852],\n",
      "         [1.0184],\n",
      "         [1.0190],\n",
      "         [1.0174],\n",
      "         [1.0116],\n",
      "         [0.0617],\n",
      "         [0.4443],\n",
      "         [1.0055],\n",
      "         [0.9119],\n",
      "         [1.0049],\n",
      "         [1.0084],\n",
      "         [0.0493],\n",
      "         [1.0152],\n",
      "         [1.0010],\n",
      "         [1.0205],\n",
      "         [0.5303],\n",
      "         [1.0201],\n",
      "         [0.5342],\n",
      "         [0.7714],\n",
      "         [1.0139],\n",
      "         [1.0129],\n",
      "         [0.3774],\n",
      "         [1.0127],\n",
      "         [0.9422],\n",
      "         [0.9822],\n",
      "         [1.0061],\n",
      "         [0.3799],\n",
      "         [1.0172],\n",
      "         [0.9564],\n",
      "         [1.0057],\n",
      "         [1.0043],\n",
      "         [0.1649],\n",
      "         [0.6414],\n",
      "         [0.2299],\n",
      "         [0.4216],\n",
      "         [0.2430],\n",
      "         [0.9988],\n",
      "         [1.0055],\n",
      "         [0.4670],\n",
      "         [1.0175],\n",
      "         [1.0248],\n",
      "         [0.4944],\n",
      "         [1.0293],\n",
      "         [1.0283],\n",
      "         [1.0255],\n",
      "         [1.0217],\n",
      "         [1.0157],\n",
      "         [1.0114],\n",
      "         [1.0119],\n",
      "         [0.6920],\n",
      "         [1.0127],\n",
      "         [1.0145],\n",
      "         [1.0148],\n",
      "         [1.0205],\n",
      "         [1.0223],\n",
      "         [1.0239],\n",
      "         [1.0246],\n",
      "         [0.5239],\n",
      "         [1.0224]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9814],\n",
      "        [0.9998],\n",
      "        [0.3808],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2547],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0000],\n",
      "        [0.5463],\n",
      "        [0.9490],\n",
      "        [0.9998],\n",
      "        [0.0247],\n",
      "        [0.0209],\n",
      "        [0.2686],\n",
      "        [0.9997],\n",
      "        [0.5054],\n",
      "        [0.7540],\n",
      "        [0.9999],\n",
      "        [0.2577],\n",
      "        [0.0142],\n",
      "        [0.5334],\n",
      "        [0.9999],\n",
      "        [0.2729],\n",
      "        [0.9420],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.3912],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.9997],\n",
      "        [0.3930],\n",
      "        [0.4503],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.5080],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [0.4668],\n",
      "        [0.3753],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.5945],\n",
      "        [0.4645],\n",
      "        [0.9820],\n",
      "        [0.5030],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [0.4642],\n",
      "        [0.9520],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.8379],\n",
      "        [0.9999],\n",
      "        [0.9956],\n",
      "        [0.4527],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.2208],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.7391],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.4454],\n",
      "        [0.9996],\n",
      "        [0.8761],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.9998],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.9515],\n",
      "        [0.9819],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [0.6327],\n",
      "        [0.2610],\n",
      "        [0.4480],\n",
      "        [0.2735],\n",
      "        [0.9996],\n",
      "        [0.9994],\n",
      "        [0.4580],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [0.9995]])\n",
      "######### Epoch: 37  ######### Train Loss: 0.0005338542978279293  ######### Relative L2 Test Norm: 13.131793975830078\n",
      "Output batch pred: tensor([[[0.2648],\n",
      "         [1.0081],\n",
      "         [1.0095],\n",
      "         [1.0077],\n",
      "         [0.4729],\n",
      "         [1.0103],\n",
      "         [0.2659],\n",
      "         [0.9314],\n",
      "         [1.0071],\n",
      "         [0.2589],\n",
      "         [0.7616],\n",
      "         [0.3634],\n",
      "         [0.8014],\n",
      "         [1.0084],\n",
      "         [1.0113],\n",
      "         [0.4524],\n",
      "         [1.0105],\n",
      "         [1.0133],\n",
      "         [1.0154],\n",
      "         [1.0160],\n",
      "         [1.0183],\n",
      "         [0.2718],\n",
      "         [0.9493],\n",
      "         [0.5492],\n",
      "         [0.9804],\n",
      "         [1.0167],\n",
      "         [1.0006],\n",
      "         [1.0100],\n",
      "         [0.1676],\n",
      "         [1.0038],\n",
      "         [1.0035],\n",
      "         [0.5116],\n",
      "         [0.4698],\n",
      "         [0.6943],\n",
      "         [0.3894],\n",
      "         [1.0148],\n",
      "         [1.0150],\n",
      "         [1.0185],\n",
      "         [1.0182],\n",
      "         [0.5357],\n",
      "         [1.0156],\n",
      "         [1.0133],\n",
      "         [1.0111],\n",
      "         [0.0434],\n",
      "         [1.0082],\n",
      "         [1.0039],\n",
      "         [0.3976],\n",
      "         [0.5693],\n",
      "         [0.7439],\n",
      "         [0.0696],\n",
      "         [1.0099],\n",
      "         [1.0119],\n",
      "         [0.8854],\n",
      "         [0.5553],\n",
      "         [1.0084],\n",
      "         [1.0073],\n",
      "         [1.0092],\n",
      "         [0.3755],\n",
      "         [0.8640],\n",
      "         [1.0113],\n",
      "         [1.0129],\n",
      "         [0.9252],\n",
      "         [0.6831],\n",
      "         [1.0181],\n",
      "         [1.0168],\n",
      "         [1.0204],\n",
      "         [1.0191],\n",
      "         [1.0193],\n",
      "         [1.0204],\n",
      "         [1.0191],\n",
      "         [1.0183],\n",
      "         [1.0144],\n",
      "         [0.5230],\n",
      "         [1.0109],\n",
      "         [1.0069],\n",
      "         [0.3895],\n",
      "         [1.0037],\n",
      "         [1.0074],\n",
      "         [0.4535],\n",
      "         [0.2485],\n",
      "         [0.9781],\n",
      "         [1.0144],\n",
      "         [1.0152],\n",
      "         [1.0143],\n",
      "         [0.9567],\n",
      "         [0.4604],\n",
      "         [0.3577],\n",
      "         [0.3737],\n",
      "         [1.0072],\n",
      "         [0.2455],\n",
      "         [1.0053],\n",
      "         [1.0101],\n",
      "         [0.4721],\n",
      "         [1.0185],\n",
      "         [1.0216],\n",
      "         [0.8945],\n",
      "         [1.0252],\n",
      "         [0.2393],\n",
      "         [1.0165],\n",
      "         [0.9807],\n",
      "         [0.3809],\n",
      "         [0.5538],\n",
      "         [0.9613],\n",
      "         [0.9965],\n",
      "         [0.9953],\n",
      "         [0.2569],\n",
      "         [1.0010],\n",
      "         [0.7805],\n",
      "         [0.5335],\n",
      "         [0.5329],\n",
      "         [0.4761],\n",
      "         [0.3942],\n",
      "         [1.0075],\n",
      "         [1.0077],\n",
      "         [1.0046],\n",
      "         [1.0038],\n",
      "         [0.9996],\n",
      "         [1.0039],\n",
      "         [0.6233],\n",
      "         [0.0235],\n",
      "         [1.0119],\n",
      "         [0.8408],\n",
      "         [1.0034],\n",
      "         [1.0160],\n",
      "         [1.0138],\n",
      "         [0.4704],\n",
      "         [1.0118],\n",
      "         [1.0093],\n",
      "         [1.0069],\n",
      "         [1.0061],\n",
      "         [1.0034],\n",
      "         [1.0049],\n",
      "         [0.3664],\n",
      "         [1.0086],\n",
      "         [0.0516],\n",
      "         [1.0121],\n",
      "         [1.0130],\n",
      "         [0.0697],\n",
      "         [1.0166],\n",
      "         [0.0517],\n",
      "         [1.0197],\n",
      "         [0.0674],\n",
      "         [1.0212],\n",
      "         [1.0186],\n",
      "         [1.0211],\n",
      "         [1.0198],\n",
      "         [1.0037],\n",
      "         [0.0570],\n",
      "         [0.9434],\n",
      "         [0.7134],\n",
      "         [1.0126],\n",
      "         [0.0649],\n",
      "         [1.0111],\n",
      "         [1.0102],\n",
      "         [1.0106],\n",
      "         [0.5165],\n",
      "         [0.3827],\n",
      "         [0.8772],\n",
      "         [1.0120],\n",
      "         [0.5287],\n",
      "         [1.0131],\n",
      "         [0.5168],\n",
      "         [0.2529],\n",
      "         [0.9977],\n",
      "         [1.0169],\n",
      "         [0.4875],\n",
      "         [1.0052],\n",
      "         [1.0100],\n",
      "         [1.0132],\n",
      "         [0.4587],\n",
      "         [1.0077],\n",
      "         [1.0059],\n",
      "         [0.9998],\n",
      "         [0.9999],\n",
      "         [1.0017],\n",
      "         [1.0005],\n",
      "         [0.5024],\n",
      "         [1.0030]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2686],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.7129],\n",
      "        [0.3575],\n",
      "        [0.7540],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9009],\n",
      "        [0.5165],\n",
      "        [0.9420],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [0.9994],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.4642],\n",
      "        [0.6555],\n",
      "        [0.3840],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.9994],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3930],\n",
      "        [0.5463],\n",
      "        [0.6920],\n",
      "        [0.0247],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.8379],\n",
      "        [0.5245],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.2577],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9164],\n",
      "        [0.4480],\n",
      "        [0.3573],\n",
      "        [0.3753],\n",
      "        [0.9997],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.8223],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.3780],\n",
      "        [0.5334],\n",
      "        [0.9520],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.5151],\n",
      "        [0.5139],\n",
      "        [0.4611],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.9995],\n",
      "        [0.5945],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [0.9967],\n",
      "        [0.4580],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9996],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.0288],\n",
      "        [0.9044],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [0.9997],\n",
      "        [0.5030],\n",
      "        [0.3808],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.2518],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.9819],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9998]])\n",
      "######### Epoch: 38  ######### Train Loss: 0.0004577638756018132  ######### Relative L2 Test Norm: 12.889334678649902\n",
      "Output batch pred: tensor([[[0.9365],\n",
      "         [1.0079],\n",
      "         [1.0078],\n",
      "         [1.0083],\n",
      "         [1.0053],\n",
      "         [0.0550],\n",
      "         [1.0104],\n",
      "         [1.0106],\n",
      "         [0.9403],\n",
      "         [1.0112],\n",
      "         [1.0067],\n",
      "         [0.2716],\n",
      "         [1.0060],\n",
      "         [0.5186],\n",
      "         [0.9255],\n",
      "         [1.0016],\n",
      "         [0.0417],\n",
      "         [1.0032],\n",
      "         [0.4638],\n",
      "         [1.0037],\n",
      "         [1.0059],\n",
      "         [1.0063],\n",
      "         [0.9480],\n",
      "         [1.0036],\n",
      "         [0.5226],\n",
      "         [0.9977],\n",
      "         [0.5032],\n",
      "         [0.9931],\n",
      "         [0.9938],\n",
      "         [0.9952],\n",
      "         [0.9953],\n",
      "         [0.5082],\n",
      "         [0.9114],\n",
      "         [1.0033],\n",
      "         [0.5513],\n",
      "         [0.7416],\n",
      "         [0.9983],\n",
      "         [0.9983],\n",
      "         [0.2663],\n",
      "         [0.9966],\n",
      "         [0.9969],\n",
      "         [0.9972],\n",
      "         [0.9982],\n",
      "         [1.0005],\n",
      "         [1.0037],\n",
      "         [1.0058],\n",
      "         [1.0077],\n",
      "         [0.2845],\n",
      "         [0.5443],\n",
      "         [1.0076],\n",
      "         [1.0068],\n",
      "         [1.0021],\n",
      "         [1.0029],\n",
      "         [0.4555],\n",
      "         [0.9983],\n",
      "         [1.0010],\n",
      "         [1.0009],\n",
      "         [0.0545],\n",
      "         [1.0012],\n",
      "         [0.1845],\n",
      "         [1.0030],\n",
      "         [1.0019],\n",
      "         [0.9863],\n",
      "         [1.0039],\n",
      "         [0.7116],\n",
      "         [1.0034],\n",
      "         [1.0007],\n",
      "         [0.8728],\n",
      "         [1.0004],\n",
      "         [1.0024],\n",
      "         [1.0000],\n",
      "         [1.0006],\n",
      "         [0.7922],\n",
      "         [0.9973],\n",
      "         [0.5602],\n",
      "         [0.9852],\n",
      "         [0.9981],\n",
      "         [0.0533],\n",
      "         [1.0011],\n",
      "         [1.0001],\n",
      "         [1.0034],\n",
      "         [1.0042],\n",
      "         [1.0040],\n",
      "         [0.8758],\n",
      "         [0.9998],\n",
      "         [0.9952],\n",
      "         [0.4673],\n",
      "         [0.2435],\n",
      "         [0.9806],\n",
      "         [0.9566],\n",
      "         [0.4413],\n",
      "         [0.9964],\n",
      "         [0.5233],\n",
      "         [1.0013],\n",
      "         [0.6883],\n",
      "         [0.3583],\n",
      "         [1.0038],\n",
      "         [0.3895],\n",
      "         [1.0066],\n",
      "         [0.9674],\n",
      "         [1.0059],\n",
      "         [1.0056],\n",
      "         [1.0049],\n",
      "         [1.0051],\n",
      "         [0.9703],\n",
      "         [1.0057],\n",
      "         [1.0061],\n",
      "         [1.0032],\n",
      "         [1.0060],\n",
      "         [1.0103],\n",
      "         [0.8676],\n",
      "         [1.0099],\n",
      "         [0.2292],\n",
      "         [1.0140],\n",
      "         [0.5333],\n",
      "         [1.0171],\n",
      "         [1.0156],\n",
      "         [1.0147],\n",
      "         [0.5192],\n",
      "         [0.2565],\n",
      "         [0.3903],\n",
      "         [0.9674],\n",
      "         [0.9984],\n",
      "         [0.2599],\n",
      "         [0.3718],\n",
      "         [0.4729],\n",
      "         [0.3946],\n",
      "         [1.0046],\n",
      "         [0.3856],\n",
      "         [0.3883],\n",
      "         [1.0098],\n",
      "         [0.3715],\n",
      "         [1.0083],\n",
      "         [0.0694],\n",
      "         [0.3854],\n",
      "         [0.8669],\n",
      "         [0.0501],\n",
      "         [0.8312],\n",
      "         [0.9941],\n",
      "         [0.3835],\n",
      "         [0.5353],\n",
      "         [1.0156],\n",
      "         [0.0759],\n",
      "         [1.0161],\n",
      "         [1.0130],\n",
      "         [0.7937],\n",
      "         [1.0051],\n",
      "         [0.6656],\n",
      "         [0.9998],\n",
      "         [0.0377],\n",
      "         [0.9946],\n",
      "         [0.9813],\n",
      "         [0.5059],\n",
      "         [0.9936],\n",
      "         [0.9955],\n",
      "         [0.0537],\n",
      "         [0.5491],\n",
      "         [0.4432],\n",
      "         [0.4524],\n",
      "         [0.9980],\n",
      "         [0.6213],\n",
      "         [0.4698],\n",
      "         [0.4597],\n",
      "         [0.9993],\n",
      "         [1.0018],\n",
      "         [0.2485],\n",
      "         [1.0034],\n",
      "         [0.7585],\n",
      "         [0.3932],\n",
      "         [1.0076],\n",
      "         [1.0090],\n",
      "         [1.0090],\n",
      "         [1.0106],\n",
      "         [1.0093],\n",
      "         [0.2620],\n",
      "         [1.0062],\n",
      "         [0.4765],\n",
      "         [1.0082]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9044],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5030],\n",
      "        [0.8761],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [0.4503],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0247],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.9995],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.4645],\n",
      "        [0.2518],\n",
      "        [0.9804],\n",
      "        [0.9520],\n",
      "        [0.4480],\n",
      "        [0.9997],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.9994],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9998],\n",
      "        [0.5038],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.2547],\n",
      "        [0.3875],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.3753],\n",
      "        [0.4668],\n",
      "        [0.3912],\n",
      "        [0.9999],\n",
      "        [0.3747],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.3575],\n",
      "        [0.9999],\n",
      "        [0.0209],\n",
      "        [0.3808],\n",
      "        [0.8223],\n",
      "        [0.0000],\n",
      "        [0.7820],\n",
      "        [0.9814],\n",
      "        [0.3728],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0288],\n",
      "        [0.5334],\n",
      "        [0.4454],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.4642],\n",
      "        [0.4580],\n",
      "        [0.9967],\n",
      "        [0.9996],\n",
      "        [0.2577],\n",
      "        [0.9997],\n",
      "        [0.7129],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [0.2610],\n",
      "        [0.9956],\n",
      "        [0.4611],\n",
      "        [1.0000]])\n",
      "######### Epoch: 39  ######### Train Loss: 0.00029678019927814603  ######### Relative L2 Test Norm: 13.420642852783203\n",
      "Output batch pred: tensor([[[0.4666],\n",
      "         [0.6729],\n",
      "         [1.0034],\n",
      "         [1.0077],\n",
      "         [1.0038],\n",
      "         [1.0078],\n",
      "         [0.5434],\n",
      "         [1.0054],\n",
      "         [1.0032],\n",
      "         [0.9246],\n",
      "         [0.9947],\n",
      "         [0.9963],\n",
      "         [0.9951],\n",
      "         [0.9593],\n",
      "         [0.4512],\n",
      "         [0.4714],\n",
      "         [0.5227],\n",
      "         [0.4558],\n",
      "         [0.9943],\n",
      "         [0.9917],\n",
      "         [0.9917],\n",
      "         [0.4509],\n",
      "         [0.3451],\n",
      "         [0.0478],\n",
      "         [0.4519],\n",
      "         [0.4899],\n",
      "         [0.9821],\n",
      "         [0.7746],\n",
      "         [0.4404],\n",
      "         [0.9742],\n",
      "         [0.9960],\n",
      "         [0.9998],\n",
      "         [0.3659],\n",
      "         [1.0047],\n",
      "         [0.2872],\n",
      "         [0.9170],\n",
      "         [1.0036],\n",
      "         [1.0021],\n",
      "         [0.3782],\n",
      "         [0.9938],\n",
      "         [0.9947],\n",
      "         [0.0679],\n",
      "         [0.5013],\n",
      "         [0.9943],\n",
      "         [0.4502],\n",
      "         [0.9987],\n",
      "         [1.0005],\n",
      "         [0.5236],\n",
      "         [0.5338],\n",
      "         [1.0011],\n",
      "         [1.0034],\n",
      "         [1.0000],\n",
      "         [0.9936],\n",
      "         [0.9911],\n",
      "         [0.4517],\n",
      "         [0.9861],\n",
      "         [0.4968],\n",
      "         [0.9882],\n",
      "         [0.2480],\n",
      "         [0.9881],\n",
      "         [1.0052],\n",
      "         [1.0085],\n",
      "         [1.0077],\n",
      "         [0.5486],\n",
      "         [0.0424],\n",
      "         [1.0017],\n",
      "         [0.9959],\n",
      "         [0.9158],\n",
      "         [0.9235],\n",
      "         [0.9790],\n",
      "         [0.9795],\n",
      "         [0.5186],\n",
      "         [0.9824],\n",
      "         [0.2555],\n",
      "         [0.2579],\n",
      "         [0.9970],\n",
      "         [1.0001],\n",
      "         [0.9997],\n",
      "         [0.3864],\n",
      "         [0.9934],\n",
      "         [0.5030],\n",
      "         [0.8125],\n",
      "         [0.9902],\n",
      "         [0.0459],\n",
      "         [0.0456],\n",
      "         [0.7526],\n",
      "         [1.0018],\n",
      "         [1.0043],\n",
      "         [1.0047],\n",
      "         [0.2750],\n",
      "         [1.0065],\n",
      "         [1.0005],\n",
      "         [0.7352],\n",
      "         [0.9577],\n",
      "         [0.9851],\n",
      "         [0.9826],\n",
      "         [0.8304],\n",
      "         [0.9814],\n",
      "         [0.9831],\n",
      "         [0.9861],\n",
      "         [0.2402],\n",
      "         [0.9934],\n",
      "         [0.0578],\n",
      "         [1.0011],\n",
      "         [1.0001],\n",
      "         [1.0047],\n",
      "         [0.9663],\n",
      "         [0.8708],\n",
      "         [1.0020],\n",
      "         [0.9979],\n",
      "         [0.8661],\n",
      "         [0.9806],\n",
      "         [0.9213],\n",
      "         [0.8637],\n",
      "         [0.0703],\n",
      "         [0.5524],\n",
      "         [0.9936],\n",
      "         [0.9960],\n",
      "         [0.9972],\n",
      "         [0.9990],\n",
      "         [0.2279],\n",
      "         [0.3891],\n",
      "         [0.3964],\n",
      "         [0.9949],\n",
      "         [0.9778],\n",
      "         [0.4602],\n",
      "         [0.2471],\n",
      "         [0.9836],\n",
      "         [0.3635],\n",
      "         [0.1788],\n",
      "         [0.2544],\n",
      "         [0.9936],\n",
      "         [0.6879],\n",
      "         [0.9988],\n",
      "         [0.9986],\n",
      "         [0.9955],\n",
      "         [0.9925],\n",
      "         [0.9855],\n",
      "         [0.6776],\n",
      "         [0.9723],\n",
      "         [0.9741],\n",
      "         [0.3453],\n",
      "         [0.9742],\n",
      "         [0.9774],\n",
      "         [0.0383],\n",
      "         [0.9847],\n",
      "         [0.9879],\n",
      "         [0.9901],\n",
      "         [0.9893],\n",
      "         [0.9892],\n",
      "         [0.0502],\n",
      "         [0.7606],\n",
      "         [0.5406],\n",
      "         [0.9795],\n",
      "         [0.9786],\n",
      "         [0.9831],\n",
      "         [0.9893],\n",
      "         [0.9593],\n",
      "         [0.3754],\n",
      "         [0.9994],\n",
      "         [0.6352],\n",
      "         [1.0032],\n",
      "         [1.0036],\n",
      "         [0.5291],\n",
      "         [0.9992],\n",
      "         [0.3947],\n",
      "         [0.9940],\n",
      "         [0.9956],\n",
      "         [0.9971],\n",
      "         [0.9996],\n",
      "         [0.9983],\n",
      "         [0.3853],\n",
      "         [1.0039],\n",
      "         [1.0043],\n",
      "         [1.0045],\n",
      "         [1.0034],\n",
      "         [0.9899],\n",
      "         [1.0015]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.4552],\n",
      "        [0.6327],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.4503],\n",
      "        [0.4668],\n",
      "        [0.5139],\n",
      "        [0.4527],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.3575],\n",
      "        [0.0247],\n",
      "        [0.4642],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.4480],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.9998],\n",
      "        [0.2735],\n",
      "        [0.8761],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.0335],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.5165],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.9164],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.0142],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.6920],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.8223],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.9814],\n",
      "        [0.9009],\n",
      "        [0.8379],\n",
      "        [0.0383],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.3840],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.4645],\n",
      "        [0.2547],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [0.1762],\n",
      "        [0.2610],\n",
      "        [0.9995],\n",
      "        [0.6555],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [0.9956],\n",
      "        [0.9999],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.0368],\n",
      "        [0.7391],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [0.9490],\n",
      "        [0.3747],\n",
      "        [0.9966],\n",
      "        [0.5945],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [1.0000]])\n",
      "######### Epoch: 40  ######### Train Loss: 0.00024544939515180886  ######### Relative L2 Test Norm: 14.484519958496094\n",
      "Output batch pred: tensor([[[0.2238],\n",
      "         [0.9723],\n",
      "         [0.5008],\n",
      "         [0.3562],\n",
      "         [0.9751],\n",
      "         [0.3397],\n",
      "         [0.3486],\n",
      "         [0.0436],\n",
      "         [0.5273],\n",
      "         [0.9757],\n",
      "         [0.9773],\n",
      "         [0.9771],\n",
      "         [0.9791],\n",
      "         [0.9499],\n",
      "         [0.9865],\n",
      "         [0.9866],\n",
      "         [0.5021],\n",
      "         [0.9833],\n",
      "         [0.2486],\n",
      "         [0.8416],\n",
      "         [0.9753],\n",
      "         [0.4362],\n",
      "         [0.9877],\n",
      "         [0.3852],\n",
      "         [0.9962],\n",
      "         [0.4691],\n",
      "         [1.0013],\n",
      "         [1.0009],\n",
      "         [0.9968],\n",
      "         [0.9937],\n",
      "         [0.9914],\n",
      "         [0.9835],\n",
      "         [0.3788],\n",
      "         [0.9848],\n",
      "         [0.9824],\n",
      "         [0.8432],\n",
      "         [0.9913],\n",
      "         [0.8680],\n",
      "         [0.9961],\n",
      "         [0.9257],\n",
      "         [0.3865],\n",
      "         [0.9946],\n",
      "         [0.9912],\n",
      "         [0.9913],\n",
      "         [0.9780],\n",
      "         [0.9915],\n",
      "         [0.3759],\n",
      "         [0.2642],\n",
      "         [0.9991],\n",
      "         [0.5199],\n",
      "         [0.9993],\n",
      "         [1.0004],\n",
      "         [0.4021],\n",
      "         [0.9900],\n",
      "         [0.6789],\n",
      "         [0.0438],\n",
      "         [0.9790],\n",
      "         [0.4952],\n",
      "         [0.7594],\n",
      "         [0.9832],\n",
      "         [0.9847],\n",
      "         [0.9856],\n",
      "         [0.9861],\n",
      "         [0.9858],\n",
      "         [0.9818],\n",
      "         [0.9799],\n",
      "         [0.2360],\n",
      "         [0.9706],\n",
      "         [0.0475],\n",
      "         [0.9133],\n",
      "         [0.2608],\n",
      "         [0.9810],\n",
      "         [0.6905],\n",
      "         [0.9497],\n",
      "         [0.4719],\n",
      "         [0.9882],\n",
      "         [0.9846],\n",
      "         [0.7136],\n",
      "         [0.9554],\n",
      "         [0.4864],\n",
      "         [0.9667],\n",
      "         [0.2196],\n",
      "         [0.9660],\n",
      "         [0.9747],\n",
      "         [0.9789],\n",
      "         [0.9858],\n",
      "         [0.4595],\n",
      "         [0.9951],\n",
      "         [0.9960],\n",
      "         [0.9921],\n",
      "         [0.9909],\n",
      "         [0.2146],\n",
      "         [0.4627],\n",
      "         [0.9812],\n",
      "         [0.9798],\n",
      "         [0.9819],\n",
      "         [0.9806],\n",
      "         [0.5067],\n",
      "         [0.9889],\n",
      "         [0.9909],\n",
      "         [0.9913],\n",
      "         [0.5087],\n",
      "         [0.9105],\n",
      "         [0.0658],\n",
      "         [0.7725],\n",
      "         [0.7321],\n",
      "         [0.9773],\n",
      "         [0.2490],\n",
      "         [0.9769],\n",
      "         [0.9776],\n",
      "         [0.9785],\n",
      "         [0.9786],\n",
      "         [0.3525],\n",
      "         [0.9812],\n",
      "         [0.9821],\n",
      "         [0.9846],\n",
      "         [0.9868],\n",
      "         [0.9884],\n",
      "         [0.9888],\n",
      "         [0.9933],\n",
      "         [0.9940],\n",
      "         [0.5238],\n",
      "         [0.9764],\n",
      "         [0.9121],\n",
      "         [0.9757],\n",
      "         [0.9727],\n",
      "         [0.9718],\n",
      "         [0.4274],\n",
      "         [0.9713],\n",
      "         [0.4328],\n",
      "         [0.9805],\n",
      "         [0.9867],\n",
      "         [0.9920],\n",
      "         [0.6255],\n",
      "         [0.9973],\n",
      "         [0.5303],\n",
      "         [0.0797],\n",
      "         [0.9917],\n",
      "         [0.3741],\n",
      "         [0.9839],\n",
      "         [0.9861],\n",
      "         [0.9877],\n",
      "         [0.0500],\n",
      "         [0.9926],\n",
      "         [0.9977],\n",
      "         [0.8290],\n",
      "         [0.6725],\n",
      "         [0.3660],\n",
      "         [0.9977],\n",
      "         [0.0759],\n",
      "         [0.9562],\n",
      "         [0.9871],\n",
      "         [0.9841],\n",
      "         [0.9871],\n",
      "         [0.9908],\n",
      "         [0.9910],\n",
      "         [0.1909],\n",
      "         [1.0000],\n",
      "         [0.2826],\n",
      "         [0.9642],\n",
      "         [0.4766],\n",
      "         [0.9947],\n",
      "         [0.5105],\n",
      "         [0.4478],\n",
      "         [0.9859],\n",
      "         [0.9883],\n",
      "         [0.0648],\n",
      "         [0.4493],\n",
      "         [0.9775],\n",
      "         [0.0520],\n",
      "         [0.5443],\n",
      "         [0.9886],\n",
      "         [0.9735],\n",
      "         [0.8882],\n",
      "         [0.8382],\n",
      "         [0.9691],\n",
      "         [0.9658],\n",
      "         [0.5216]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2518],\n",
      "        [0.9999],\n",
      "        [0.5151],\n",
      "        [0.3780],\n",
      "        [0.9995],\n",
      "        [0.3575],\n",
      "        [0.3728],\n",
      "        [0.0247],\n",
      "        [0.5334],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9490],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [0.8223],\n",
      "        [0.9956],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9999],\n",
      "        [0.6555],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9967],\n",
      "        [0.9994],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9164],\n",
      "        [0.2735],\n",
      "        [0.9997],\n",
      "        [0.6628],\n",
      "        [0.9420],\n",
      "        [0.4642],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.9724],\n",
      "        [0.5108],\n",
      "        [0.9996],\n",
      "        [0.2547],\n",
      "        [0.9962],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [0.8933],\n",
      "        [0.0288],\n",
      "        [0.7540],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9820],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.9996],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.7820],\n",
      "        [0.6327],\n",
      "        [0.3573],\n",
      "        [0.9997],\n",
      "        [0.0335],\n",
      "        [0.9515],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.9520],\n",
      "        [0.4645],\n",
      "        [0.9998],\n",
      "        [0.5054],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.4480],\n",
      "        [0.9814],\n",
      "        [0.0142],\n",
      "        [0.5245],\n",
      "        [0.9998],\n",
      "        [0.9819],\n",
      "        [0.8761],\n",
      "        [0.8296],\n",
      "        [0.9999],\n",
      "        [0.9959],\n",
      "        [0.5463]])\n",
      "######### Epoch: 41  ######### Train Loss: 0.0003363847208674997  ######### Relative L2 Test Norm: 15.2177734375\n",
      "Output batch pred: tensor([[[0.9749],\n",
      "         [0.3717],\n",
      "         [0.9642],\n",
      "         [0.7352],\n",
      "         [0.9828],\n",
      "         [0.2606],\n",
      "         [0.9843],\n",
      "         [0.9797],\n",
      "         [0.9819],\n",
      "         [0.9761],\n",
      "         [0.5059],\n",
      "         [0.9718],\n",
      "         [0.9719],\n",
      "         [0.9751],\n",
      "         [0.9782],\n",
      "         [0.9824],\n",
      "         [0.9859],\n",
      "         [0.4630],\n",
      "         [0.3713],\n",
      "         [0.9891],\n",
      "         [0.9871],\n",
      "         [0.9838],\n",
      "         [0.9788],\n",
      "         [0.2340],\n",
      "         [0.9709],\n",
      "         [0.9700],\n",
      "         [0.9565],\n",
      "         [0.9692],\n",
      "         [0.6704],\n",
      "         [0.9732],\n",
      "         [0.9755],\n",
      "         [0.9714],\n",
      "         [0.5004],\n",
      "         [0.4568],\n",
      "         [0.9855],\n",
      "         [0.9868],\n",
      "         [0.7305],\n",
      "         [0.9889],\n",
      "         [0.9882],\n",
      "         [0.8143],\n",
      "         [0.9825],\n",
      "         [0.5092],\n",
      "         [0.9755],\n",
      "         [0.9695],\n",
      "         [0.8962],\n",
      "         [0.9715],\n",
      "         [0.0512],\n",
      "         [0.5041],\n",
      "         [0.9800],\n",
      "         [0.9824],\n",
      "         [0.9865],\n",
      "         [0.8634],\n",
      "         [0.9888],\n",
      "         [0.9897],\n",
      "         [0.9910],\n",
      "         [0.9881],\n",
      "         [0.3729],\n",
      "         [0.9827],\n",
      "         [0.9802],\n",
      "         [0.0738],\n",
      "         [0.9851],\n",
      "         [0.9534],\n",
      "         [0.4525],\n",
      "         [0.9874],\n",
      "         [0.4701],\n",
      "         [0.9849],\n",
      "         [0.9802],\n",
      "         [0.9751],\n",
      "         [0.9696],\n",
      "         [0.9666],\n",
      "         [0.9642],\n",
      "         [0.8866],\n",
      "         [0.4778],\n",
      "         [0.9707],\n",
      "         [0.9771],\n",
      "         [0.0649],\n",
      "         [0.9859],\n",
      "         [0.9510],\n",
      "         [0.9845],\n",
      "         [0.9797],\n",
      "         [0.9712],\n",
      "         [0.0374],\n",
      "         [0.1931],\n",
      "         [0.6173],\n",
      "         [0.9581],\n",
      "         [0.4284],\n",
      "         [0.3449],\n",
      "         [0.4306],\n",
      "         [0.9776],\n",
      "         [0.5288],\n",
      "         [0.9477],\n",
      "         [0.9813],\n",
      "         [0.5429],\n",
      "         [0.9785],\n",
      "         [0.9775],\n",
      "         [0.9754],\n",
      "         [0.5965],\n",
      "         [0.9728],\n",
      "         [0.8261],\n",
      "         [0.8832],\n",
      "         [0.9758],\n",
      "         [0.4905],\n",
      "         [0.6607],\n",
      "         [0.3730],\n",
      "         [0.9780],\n",
      "         [0.9782],\n",
      "         [0.9767],\n",
      "         [0.3634],\n",
      "         [0.9823],\n",
      "         [0.9834],\n",
      "         [0.9887],\n",
      "         [0.9892],\n",
      "         [0.3858],\n",
      "         [0.9943],\n",
      "         [0.9945],\n",
      "         [0.9931],\n",
      "         [0.9919],\n",
      "         [0.9890],\n",
      "         [0.2559],\n",
      "         [0.0510],\n",
      "         [0.9886],\n",
      "         [0.9491],\n",
      "         [0.9888],\n",
      "         [0.9161],\n",
      "         [0.4992],\n",
      "         [0.9754],\n",
      "         [0.4637],\n",
      "         [0.2594],\n",
      "         [0.4473],\n",
      "         [0.5052],\n",
      "         [0.5567],\n",
      "         [0.7711],\n",
      "         [0.9905],\n",
      "         [0.9913],\n",
      "         [0.9906],\n",
      "         [0.7791],\n",
      "         [0.2360],\n",
      "         [0.2335],\n",
      "         [0.9734],\n",
      "         [0.9675],\n",
      "         [0.0549],\n",
      "         [0.9629],\n",
      "         [0.0327],\n",
      "         [0.4885],\n",
      "         [0.9682],\n",
      "         [0.2548],\n",
      "         [0.3449],\n",
      "         [0.9232],\n",
      "         [0.2547],\n",
      "         [0.9794],\n",
      "         [0.9781],\n",
      "         [0.9749],\n",
      "         [0.1652],\n",
      "         [0.9672],\n",
      "         [0.3291],\n",
      "         [0.4227],\n",
      "         [0.9561],\n",
      "         [0.3518],\n",
      "         [0.4994],\n",
      "         [0.9807],\n",
      "         [0.9781],\n",
      "         [0.9771],\n",
      "         [0.9726],\n",
      "         [0.9682],\n",
      "         [0.0207],\n",
      "         [0.8296],\n",
      "         [0.9642],\n",
      "         [0.9681],\n",
      "         [0.9719],\n",
      "         [0.8446],\n",
      "         [0.9864],\n",
      "         [0.4647],\n",
      "         [0.3936],\n",
      "         [0.9818],\n",
      "         [0.9944],\n",
      "         [0.9900],\n",
      "         [0.0690],\n",
      "         [0.9784]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.3912],\n",
      "        [0.9820],\n",
      "        [0.7129],\n",
      "        [0.9997],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.4645],\n",
      "        [0.3780],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.5038],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6920],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.9999],\n",
      "        [0.9962],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [0.0247],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.8933],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0383],\n",
      "        [0.9999],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.0142],\n",
      "        [0.2208],\n",
      "        [0.6327],\n",
      "        [0.9999],\n",
      "        [0.4611],\n",
      "        [0.3747],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [0.9490],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.6555],\n",
      "        [0.3930],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2610],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.5009],\n",
      "        [0.9819],\n",
      "        [0.4668],\n",
      "        [0.2646],\n",
      "        [0.4503],\n",
      "        [0.5030],\n",
      "        [0.5463],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.2518],\n",
      "        [0.2547],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.9996],\n",
      "        [0.0000],\n",
      "        [0.5139],\n",
      "        [0.9999],\n",
      "        [0.2729],\n",
      "        [0.3575],\n",
      "        [0.9164],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.9999],\n",
      "        [0.3573],\n",
      "        [0.4454],\n",
      "        [0.9724],\n",
      "        [0.3728],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [0.0209],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.3840],\n",
      "        [0.9814],\n",
      "        [0.9996],\n",
      "        [0.9995],\n",
      "        [0.0288],\n",
      "        [0.9998]])\n",
      "######### Epoch: 42  ######### Train Loss: 0.0004071698058396578  ######### Relative L2 Test Norm: 15.23586368560791\n",
      "Output batch pred: tensor([[[0.9783],\n",
      "         [0.9363],\n",
      "         [0.5961],\n",
      "         [0.9570],\n",
      "         [0.9719],\n",
      "         [0.9723],\n",
      "         [0.9717],\n",
      "         [0.9685],\n",
      "         [0.9727],\n",
      "         [0.2273],\n",
      "         [0.9722],\n",
      "         [0.8317],\n",
      "         [0.9683],\n",
      "         [0.3555],\n",
      "         [0.3507],\n",
      "         [0.9689],\n",
      "         [0.9761],\n",
      "         [0.9803],\n",
      "         [0.0392],\n",
      "         [0.9891],\n",
      "         [0.9913],\n",
      "         [0.9910],\n",
      "         [0.9874],\n",
      "         [0.5017],\n",
      "         [0.4884],\n",
      "         [0.3699],\n",
      "         [0.7406],\n",
      "         [0.2350],\n",
      "         [0.9622],\n",
      "         [0.9633],\n",
      "         [0.9678],\n",
      "         [0.8995],\n",
      "         [0.9763],\n",
      "         [0.9835],\n",
      "         [0.9868],\n",
      "         [0.9883],\n",
      "         [0.9880],\n",
      "         [0.9849],\n",
      "         [0.9834],\n",
      "         [0.9810],\n",
      "         [0.9785],\n",
      "         [0.9759],\n",
      "         [0.8299],\n",
      "         [0.9753],\n",
      "         [0.8497],\n",
      "         [0.9780],\n",
      "         [0.9811],\n",
      "         [0.9757],\n",
      "         [0.6721],\n",
      "         [0.9808],\n",
      "         [0.9770],\n",
      "         [0.9781],\n",
      "         [0.4356],\n",
      "         [0.9767],\n",
      "         [0.9765],\n",
      "         [0.9768],\n",
      "         [0.5218],\n",
      "         [0.9765],\n",
      "         [0.0586],\n",
      "         [0.9763],\n",
      "         [0.0517],\n",
      "         [0.9759],\n",
      "         [0.8412],\n",
      "         [0.9771],\n",
      "         [0.3637],\n",
      "         [0.0578],\n",
      "         [0.9775],\n",
      "         [0.0539],\n",
      "         [0.9411],\n",
      "         [0.9761],\n",
      "         [0.9127],\n",
      "         [0.2270],\n",
      "         [0.9648],\n",
      "         [0.2166],\n",
      "         [0.9656],\n",
      "         [0.9667],\n",
      "         [0.9683],\n",
      "         [0.9699],\n",
      "         [0.4407],\n",
      "         [0.9772],\n",
      "         [0.8024],\n",
      "         [0.9768],\n",
      "         [0.9759],\n",
      "         [0.3304],\n",
      "         [0.6677],\n",
      "         [0.9669],\n",
      "         [0.9483],\n",
      "         [0.9679],\n",
      "         [0.4797],\n",
      "         [0.4456],\n",
      "         [0.9749],\n",
      "         [0.9771],\n",
      "         [0.9802],\n",
      "         [0.5003],\n",
      "         [0.0521],\n",
      "         [0.9775],\n",
      "         [0.9742],\n",
      "         [0.9736],\n",
      "         [0.9710],\n",
      "         [0.9695],\n",
      "         [0.3491],\n",
      "         [0.4853],\n",
      "         [0.4422],\n",
      "         [0.9670],\n",
      "         [0.9833],\n",
      "         [0.4632],\n",
      "         [0.9887],\n",
      "         [0.9892],\n",
      "         [0.8999],\n",
      "         [0.2651],\n",
      "         [0.9880],\n",
      "         [0.9840],\n",
      "         [0.5094],\n",
      "         [0.2385],\n",
      "         [0.9841],\n",
      "         [0.7735],\n",
      "         [0.9840],\n",
      "         [0.9830],\n",
      "         [0.9826],\n",
      "         [0.9834],\n",
      "         [0.9832],\n",
      "         [0.6487],\n",
      "         [0.9069],\n",
      "         [0.5438],\n",
      "         [0.5151],\n",
      "         [0.9850],\n",
      "         [0.9850],\n",
      "         [0.3452],\n",
      "         [0.7327],\n",
      "         [0.9747],\n",
      "         [0.4309],\n",
      "         [0.3675],\n",
      "         [0.4967],\n",
      "         [0.1616],\n",
      "         [0.9758],\n",
      "         [0.9745],\n",
      "         [0.9450],\n",
      "         [0.0437],\n",
      "         [0.9703],\n",
      "         [0.9096],\n",
      "         [0.7139],\n",
      "         [0.9751],\n",
      "         [0.4496],\n",
      "         [0.0615],\n",
      "         [0.2519],\n",
      "         [0.9649],\n",
      "         [0.2520],\n",
      "         [0.9730],\n",
      "         [0.9772],\n",
      "         [0.2128],\n",
      "         [0.9846],\n",
      "         [0.9908],\n",
      "         [0.9921],\n",
      "         [0.9917],\n",
      "         [0.4489],\n",
      "         [0.4523],\n",
      "         [0.9809],\n",
      "         [0.3756],\n",
      "         [0.3570],\n",
      "         [0.9398],\n",
      "         [0.9771],\n",
      "         [0.0581],\n",
      "         [0.9799],\n",
      "         [0.9853],\n",
      "         [0.9872],\n",
      "         [0.9848],\n",
      "         [0.9738],\n",
      "         [0.9846],\n",
      "         [0.9800],\n",
      "         [0.5429],\n",
      "         [0.9754],\n",
      "         [0.5058],\n",
      "         [0.4388],\n",
      "         [0.4956],\n",
      "         [0.3632],\n",
      "         [0.9783],\n",
      "         [0.9772],\n",
      "         [0.9802]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.9420],\n",
      "        [0.5945],\n",
      "        [0.9814],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [0.9967],\n",
      "        [0.3840],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.0000],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.4988],\n",
      "        [0.3930],\n",
      "        [0.7391],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.6555],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5245],\n",
      "        [0.9997],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [0.8296],\n",
      "        [0.9994],\n",
      "        [0.3753],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.2577],\n",
      "        [0.9959],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.6628],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.4668],\n",
      "        [0.9966],\n",
      "        [0.9962],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.5054],\n",
      "        [0.4611],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8761],\n",
      "        [0.2646],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.8933],\n",
      "        [0.5334],\n",
      "        [0.5165],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.3912],\n",
      "        [0.5139],\n",
      "        [0.1762],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9515],\n",
      "        [0.0288],\n",
      "        [0.9804],\n",
      "        [0.9044],\n",
      "        [0.6920],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [0.0368],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.2208],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.3728],\n",
      "        [0.9490],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.4552],\n",
      "        [0.5080],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000]])\n",
      "######### Epoch: 43  ######### Train Loss: 0.00044097169302403927  ######### Relative L2 Test Norm: 15.395465850830078\n",
      "Output batch pred: tensor([[[0.9849],\n",
      "         [0.9762],\n",
      "         [0.8141],\n",
      "         [0.4646],\n",
      "         [0.3618],\n",
      "         [0.6444],\n",
      "         [0.9777],\n",
      "         [0.0463],\n",
      "         [0.9722],\n",
      "         [0.9714],\n",
      "         [0.9709],\n",
      "         [0.9720],\n",
      "         [0.9730],\n",
      "         [0.8983],\n",
      "         [0.9741],\n",
      "         [0.4972],\n",
      "         [0.9752],\n",
      "         [0.9763],\n",
      "         [0.2541],\n",
      "         [0.4363],\n",
      "         [0.9819],\n",
      "         [0.4551],\n",
      "         [0.9882],\n",
      "         [0.9901],\n",
      "         [0.4746],\n",
      "         [0.2553],\n",
      "         [0.9875],\n",
      "         [0.9880],\n",
      "         [0.9836],\n",
      "         [0.9791],\n",
      "         [0.9790],\n",
      "         [0.7525],\n",
      "         [0.2255],\n",
      "         [0.9756],\n",
      "         [0.4872],\n",
      "         [0.9822],\n",
      "         [0.4382],\n",
      "         [0.9845],\n",
      "         [0.4428],\n",
      "         [0.9837],\n",
      "         [0.4981],\n",
      "         [0.9813],\n",
      "         [0.9789],\n",
      "         [0.3683],\n",
      "         [0.9411],\n",
      "         [0.9803],\n",
      "         [0.1763],\n",
      "         [0.2145],\n",
      "         [0.9835],\n",
      "         [0.8532],\n",
      "         [0.9646],\n",
      "         [0.3373],\n",
      "         [0.0215],\n",
      "         [0.9692],\n",
      "         [0.9655],\n",
      "         [0.6597],\n",
      "         [0.8299],\n",
      "         [0.9680],\n",
      "         [0.8375],\n",
      "         [0.3616],\n",
      "         [0.9878],\n",
      "         [0.2614],\n",
      "         [0.9901],\n",
      "         [0.9921],\n",
      "         [0.7812],\n",
      "         [0.4595],\n",
      "         [0.9813],\n",
      "         [0.9739],\n",
      "         [0.0461],\n",
      "         [0.2219],\n",
      "         [0.2376],\n",
      "         [0.9676],\n",
      "         [0.9636],\n",
      "         [0.9670],\n",
      "         [0.0315],\n",
      "         [0.9717],\n",
      "         [0.8264],\n",
      "         [0.9758],\n",
      "         [0.9767],\n",
      "         [0.6645],\n",
      "         [0.9799],\n",
      "         [0.9806],\n",
      "         [0.9812],\n",
      "         [0.8922],\n",
      "         [0.9838],\n",
      "         [0.9823],\n",
      "         [0.9840],\n",
      "         [0.9826],\n",
      "         [0.0590],\n",
      "         [0.5457],\n",
      "         [0.0567],\n",
      "         [0.9884],\n",
      "         [0.9904],\n",
      "         [0.9582],\n",
      "         [0.9922],\n",
      "         [0.9928],\n",
      "         [0.5602],\n",
      "         [0.9877],\n",
      "         [0.9832],\n",
      "         [0.4440],\n",
      "         [0.0467],\n",
      "         [0.9770],\n",
      "         [0.9776],\n",
      "         [0.9797],\n",
      "         [0.9818],\n",
      "         [0.3701],\n",
      "         [0.9859],\n",
      "         [0.3826],\n",
      "         [0.9899],\n",
      "         [0.9841],\n",
      "         [0.9294],\n",
      "         [0.9500],\n",
      "         [0.2434],\n",
      "         [0.9802],\n",
      "         [0.9786],\n",
      "         [0.9776],\n",
      "         [0.9799],\n",
      "         [0.9813],\n",
      "         [0.9795],\n",
      "         [0.9817],\n",
      "         [0.5285],\n",
      "         [0.3393],\n",
      "         [0.7080],\n",
      "         [0.3676],\n",
      "         [0.9652],\n",
      "         [0.9668],\n",
      "         [0.9672],\n",
      "         [0.4783],\n",
      "         [0.3514],\n",
      "         [0.4405],\n",
      "         [0.9703],\n",
      "         [0.9861],\n",
      "         [0.9875],\n",
      "         [0.3848],\n",
      "         [0.9821],\n",
      "         [0.9809],\n",
      "         [0.9772],\n",
      "         [0.4406],\n",
      "         [0.9691],\n",
      "         [0.9579],\n",
      "         [0.4912],\n",
      "         [0.4998],\n",
      "         [0.9804],\n",
      "         [0.9828],\n",
      "         [0.9873],\n",
      "         [0.9889],\n",
      "         [0.5118],\n",
      "         [0.9826],\n",
      "         [0.0722],\n",
      "         [0.6044],\n",
      "         [0.9767],\n",
      "         [0.9726],\n",
      "         [0.9716],\n",
      "         [0.7301],\n",
      "         [0.2538],\n",
      "         [0.9813],\n",
      "         [0.9845],\n",
      "         [0.9861],\n",
      "         [0.9864],\n",
      "         [0.5017],\n",
      "         [0.9831],\n",
      "         [0.9814],\n",
      "         [0.9796],\n",
      "         [0.9427],\n",
      "         [0.9610],\n",
      "         [0.9807],\n",
      "         [0.9817],\n",
      "         [0.9832],\n",
      "         [0.9844],\n",
      "         [0.9852],\n",
      "         [0.5153],\n",
      "         [0.9797],\n",
      "         [0.9777],\n",
      "         [0.5052],\n",
      "         [0.9032],\n",
      "         [0.8987],\n",
      "         [0.0632],\n",
      "         [0.3620]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.9819],\n",
      "        [0.7820],\n",
      "        [0.4642],\n",
      "        [0.3753],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.9996],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2735],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.4668],\n",
      "        [0.2577],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.2518],\n",
      "        [0.9999],\n",
      "        [0.4988],\n",
      "        [0.9997],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.9994],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.9420],\n",
      "        [0.9999],\n",
      "        [0.1762],\n",
      "        [0.2208],\n",
      "        [0.9998],\n",
      "        [0.8379],\n",
      "        [0.9814],\n",
      "        [0.3575],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.7540],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.2547],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.5334],\n",
      "        [0.0209],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.9999],\n",
      "        [0.9956],\n",
      "        [0.9164],\n",
      "        [0.9490],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.3573],\n",
      "        [0.6920],\n",
      "        [0.3912],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5009],\n",
      "        [0.3747],\n",
      "        [0.4552],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.3930],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.9997],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.5080],\n",
      "        [0.5108],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.5054],\n",
      "        [0.9997],\n",
      "        [0.0368],\n",
      "        [0.5945],\n",
      "        [0.9999],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9520],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5139],\n",
      "        [0.9009],\n",
      "        [0.8933],\n",
      "        [0.0288],\n",
      "        [0.3728]])\n",
      "######### Epoch: 44  ######### Train Loss: 0.0003579701005946845  ######### Relative L2 Test Norm: 14.876906394958496\n",
      "Output batch pred: tensor([[[0.9812],\n",
      "         [0.4864],\n",
      "         [0.9787],\n",
      "         [0.9792],\n",
      "         [0.9450],\n",
      "         [0.9845],\n",
      "         [0.4598],\n",
      "         [0.3745],\n",
      "         [0.9924],\n",
      "         [0.9931],\n",
      "         [0.9915],\n",
      "         [0.0531],\n",
      "         [0.5015],\n",
      "         [0.9888],\n",
      "         [0.6503],\n",
      "         [0.2394],\n",
      "         [0.3363],\n",
      "         [0.3645],\n",
      "         [0.9781],\n",
      "         [0.9750],\n",
      "         [0.4416],\n",
      "         [0.5263],\n",
      "         [0.9753],\n",
      "         [0.7979],\n",
      "         [0.9784],\n",
      "         [0.5473],\n",
      "         [0.9850],\n",
      "         [0.9895],\n",
      "         [0.6854],\n",
      "         [0.9899],\n",
      "         [0.9779],\n",
      "         [0.2607],\n",
      "         [0.9919],\n",
      "         [0.9882],\n",
      "         [0.9815],\n",
      "         [0.9794],\n",
      "         [0.3460],\n",
      "         [0.2390],\n",
      "         [0.2098],\n",
      "         [0.9843],\n",
      "         [0.9878],\n",
      "         [0.9762],\n",
      "         [0.8602],\n",
      "         [0.9841],\n",
      "         [0.9793],\n",
      "         [0.9778],\n",
      "         [0.9769],\n",
      "         [0.9337],\n",
      "         [0.9747],\n",
      "         [0.9760],\n",
      "         [0.9811],\n",
      "         [0.9855],\n",
      "         [0.9143],\n",
      "         [0.8602],\n",
      "         [0.9983],\n",
      "         [0.9963],\n",
      "         [0.9960],\n",
      "         [0.2667],\n",
      "         [0.3676],\n",
      "         [0.7150],\n",
      "         [0.4412],\n",
      "         [0.9802],\n",
      "         [0.9811],\n",
      "         [0.0439],\n",
      "         [0.9904],\n",
      "         [0.9953],\n",
      "         [0.9970],\n",
      "         [0.9979],\n",
      "         [0.9972],\n",
      "         [0.9927],\n",
      "         [0.2567],\n",
      "         [0.1695],\n",
      "         [0.9734],\n",
      "         [0.9698],\n",
      "         [0.0389],\n",
      "         [0.9666],\n",
      "         [0.0470],\n",
      "         [0.9758],\n",
      "         [0.9831],\n",
      "         [0.8383],\n",
      "         [0.9871],\n",
      "         [0.0581],\n",
      "         [0.9902],\n",
      "         [0.9889],\n",
      "         [0.9525],\n",
      "         [0.5013],\n",
      "         [0.5093],\n",
      "         [0.9857],\n",
      "         [0.9873],\n",
      "         [0.9846],\n",
      "         [0.9893],\n",
      "         [0.7674],\n",
      "         [0.9843],\n",
      "         [0.9840],\n",
      "         [0.9808],\n",
      "         [0.9653],\n",
      "         [0.9714],\n",
      "         [0.5003],\n",
      "         [0.9731],\n",
      "         [0.3502],\n",
      "         [0.9468],\n",
      "         [0.7762],\n",
      "         [0.9887],\n",
      "         [0.9919],\n",
      "         [0.9341],\n",
      "         [0.9896],\n",
      "         [0.9181],\n",
      "         [0.5063],\n",
      "         [0.2464],\n",
      "         [0.9850],\n",
      "         [0.4427],\n",
      "         [0.8503],\n",
      "         [0.9868],\n",
      "         [0.9879],\n",
      "         [0.9881],\n",
      "         [0.9883],\n",
      "         [0.9862],\n",
      "         [0.3589],\n",
      "         [0.7347],\n",
      "         [0.9829],\n",
      "         [0.0590],\n",
      "         [0.5256],\n",
      "         [0.5103],\n",
      "         [0.4647],\n",
      "         [0.9923],\n",
      "         [0.9979],\n",
      "         [0.9890],\n",
      "         [1.0037],\n",
      "         [0.4640],\n",
      "         [0.5374],\n",
      "         [1.0000],\n",
      "         [0.3676],\n",
      "         [0.9885],\n",
      "         [0.4431],\n",
      "         [0.9773],\n",
      "         [0.9719],\n",
      "         [0.9672],\n",
      "         [0.3466],\n",
      "         [0.9670],\n",
      "         [0.2203],\n",
      "         [0.3543],\n",
      "         [0.9728],\n",
      "         [0.9794],\n",
      "         [0.9844],\n",
      "         [0.9898],\n",
      "         [0.9940],\n",
      "         [0.9973],\n",
      "         [0.0715],\n",
      "         [0.5339],\n",
      "         [0.2877],\n",
      "         [0.9831],\n",
      "         [0.6965],\n",
      "         [0.0610],\n",
      "         [0.4969],\n",
      "         [0.9779],\n",
      "         [0.9766],\n",
      "         [0.3514],\n",
      "         [0.5932],\n",
      "         [0.9761],\n",
      "         [0.9807],\n",
      "         [0.9855],\n",
      "         [0.9873],\n",
      "         [0.4433],\n",
      "         [0.9945],\n",
      "         [0.9964],\n",
      "         [0.9252],\n",
      "         [0.9963],\n",
      "         [0.9969],\n",
      "         [0.9941],\n",
      "         [0.9954],\n",
      "         [0.9086],\n",
      "         [0.9993],\n",
      "         [1.0005],\n",
      "         [0.0590],\n",
      "         [0.9956],\n",
      "         [0.4600],\n",
      "         [0.9920],\n",
      "         [0.4407]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.3840],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0000],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [0.6327],\n",
      "        [0.2547],\n",
      "        [0.3573],\n",
      "        [0.3875],\n",
      "        [0.9999],\n",
      "        [0.9962],\n",
      "        [0.4645],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.9999],\n",
      "        [0.5463],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.9956],\n",
      "        [0.9724],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.3575],\n",
      "        [0.2518],\n",
      "        [0.2208],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.8379],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.8933],\n",
      "        [0.8223],\n",
      "        [0.9994],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.3780],\n",
      "        [0.6920],\n",
      "        [0.4552],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0288],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.1762],\n",
      "        [0.9995],\n",
      "        [0.9997],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.9966],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.5009],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.9515],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [0.5054],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.7129],\n",
      "        [0.9997],\n",
      "        [0.0383],\n",
      "        [0.5245],\n",
      "        [0.5139],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.9995],\n",
      "        [0.4611],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0174],\n",
      "        [0.5108],\n",
      "        [0.2735],\n",
      "        [0.9814],\n",
      "        [0.6628],\n",
      "        [0.0142],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.3808],\n",
      "        [0.5945],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.9999],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.4503]])\n",
      "######### Epoch: 45  ######### Train Loss: 0.0003389309858903289  ######### Relative L2 Test Norm: 14.147846221923828\n",
      "Output batch pred: tensor([[[0.9859],\n",
      "         [0.4462],\n",
      "         [0.9824],\n",
      "         [0.9820],\n",
      "         [0.9809],\n",
      "         [0.9711],\n",
      "         [0.9858],\n",
      "         [0.9866],\n",
      "         [0.4473],\n",
      "         [0.3407],\n",
      "         [0.9910],\n",
      "         [0.9919],\n",
      "         [0.9925],\n",
      "         [0.7231],\n",
      "         [0.3829],\n",
      "         [0.9907],\n",
      "         [0.9953],\n",
      "         [0.4505],\n",
      "         [0.9990],\n",
      "         [1.0016],\n",
      "         [0.5193],\n",
      "         [0.0717],\n",
      "         [0.2657],\n",
      "         [1.0054],\n",
      "         [1.0032],\n",
      "         [0.9992],\n",
      "         [0.3424],\n",
      "         [0.9876],\n",
      "         [0.9825],\n",
      "         [0.9758],\n",
      "         [0.9774],\n",
      "         [0.9784],\n",
      "         [0.9801],\n",
      "         [0.9538],\n",
      "         [0.9987],\n",
      "         [0.5140],\n",
      "         [0.2630],\n",
      "         [1.0134],\n",
      "         [1.0138],\n",
      "         [0.4653],\n",
      "         [0.3851],\n",
      "         [0.9963],\n",
      "         [0.5128],\n",
      "         [0.0296],\n",
      "         [0.3507],\n",
      "         [0.9832],\n",
      "         [0.2461],\n",
      "         [0.4985],\n",
      "         [0.9978],\n",
      "         [0.8587],\n",
      "         [1.0055],\n",
      "         [0.7888],\n",
      "         [0.6303],\n",
      "         [0.3713],\n",
      "         [0.9932],\n",
      "         [0.9828],\n",
      "         [0.9838],\n",
      "         [0.6609],\n",
      "         [0.9842],\n",
      "         [0.9867],\n",
      "         [0.8108],\n",
      "         [0.5530],\n",
      "         [0.0661],\n",
      "         [0.3853],\n",
      "         [0.2627],\n",
      "         [0.4530],\n",
      "         [0.9959],\n",
      "         [0.4723],\n",
      "         [0.9932],\n",
      "         [0.9912],\n",
      "         [0.9556],\n",
      "         [0.9945],\n",
      "         [0.9994],\n",
      "         [0.9977],\n",
      "         [1.0032],\n",
      "         [1.0024],\n",
      "         [0.9999],\n",
      "         [0.2515],\n",
      "         [0.5348],\n",
      "         [0.4578],\n",
      "         [0.9100],\n",
      "         [0.2049],\n",
      "         [0.9862],\n",
      "         [0.9866],\n",
      "         [0.2579],\n",
      "         [0.5167],\n",
      "         [1.0031],\n",
      "         [0.9378],\n",
      "         [1.0094],\n",
      "         [1.0087],\n",
      "         [0.9772],\n",
      "         [0.5412],\n",
      "         [1.0050],\n",
      "         [1.0012],\n",
      "         [0.9970],\n",
      "         [0.5175],\n",
      "         [0.9105],\n",
      "         [0.9849],\n",
      "         [0.9714],\n",
      "         [0.9829],\n",
      "         [0.9823],\n",
      "         [0.9831],\n",
      "         [0.5420],\n",
      "         [0.8563],\n",
      "         [0.2617],\n",
      "         [0.0783],\n",
      "         [1.0113],\n",
      "         [1.0178],\n",
      "         [1.0185],\n",
      "         [1.0143],\n",
      "         [1.0132],\n",
      "         [1.0063],\n",
      "         [0.9964],\n",
      "         [0.9923],\n",
      "         [0.0361],\n",
      "         [0.9833],\n",
      "         [0.4939],\n",
      "         [0.3572],\n",
      "         [0.9894],\n",
      "         [0.9962],\n",
      "         [0.9974],\n",
      "         [1.0000],\n",
      "         [0.9835],\n",
      "         [0.9983],\n",
      "         [0.9946],\n",
      "         [0.4988],\n",
      "         [0.9810],\n",
      "         [0.9823],\n",
      "         [0.9667],\n",
      "         [0.2648],\n",
      "         [0.5148],\n",
      "         [0.9977],\n",
      "         [0.4729],\n",
      "         [1.0058],\n",
      "         [1.0069],\n",
      "         [0.7642],\n",
      "         [0.6665],\n",
      "         [0.0483],\n",
      "         [0.9824],\n",
      "         [0.8367],\n",
      "         [0.9688],\n",
      "         [0.9692],\n",
      "         [0.6637],\n",
      "         [0.8843],\n",
      "         [0.9840],\n",
      "         [0.9935],\n",
      "         [0.3876],\n",
      "         [1.0014],\n",
      "         [1.0023],\n",
      "         [0.9997],\n",
      "         [0.9934],\n",
      "         [0.9890],\n",
      "         [0.9843],\n",
      "         [0.0496],\n",
      "         [0.4323],\n",
      "         [0.9831],\n",
      "         [0.9852],\n",
      "         [0.3797],\n",
      "         [0.9948],\n",
      "         [0.9388],\n",
      "         [0.0451],\n",
      "         [0.1703],\n",
      "         [0.9937],\n",
      "         [0.9542],\n",
      "         [0.9724],\n",
      "         [0.9812],\n",
      "         [0.9823],\n",
      "         [0.4437],\n",
      "         [0.8544],\n",
      "         [0.9897],\n",
      "         [0.9938],\n",
      "         [0.9970],\n",
      "         [0.0628],\n",
      "         [0.3818],\n",
      "         [0.7917],\n",
      "         [0.9989],\n",
      "         [0.9959],\n",
      "         [0.9906]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9994],\n",
      "        [0.6920],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4503],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.0383],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.9995],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.2518],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [0.5151],\n",
      "        [0.0000],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.5009],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [0.9997],\n",
      "        [0.7391],\n",
      "        [0.5945],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.9997],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.7820],\n",
      "        [0.5463],\n",
      "        [0.0335],\n",
      "        [0.3840],\n",
      "        [0.2610],\n",
      "        [0.4454],\n",
      "        [0.9999],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9420],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.5245],\n",
      "        [0.4645],\n",
      "        [0.9009],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9515],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.5165],\n",
      "        [0.8933],\n",
      "        [0.9998],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.8223],\n",
      "        [0.2577],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [0.5054],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9814],\n",
      "        [0.2735],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.9959],\n",
      "        [0.9966],\n",
      "        [0.7129],\n",
      "        [0.6327],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0288],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9994],\n",
      "        [0.9164],\n",
      "        [0.0209],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.9820],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.8379],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.3780],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000]])\n",
      "######### Epoch: 46  ######### Train Loss: 0.00026826324756257236  ######### Relative L2 Test Norm: 13.791784286499023\n",
      "Output batch pred: tensor([[[0.9969],\n",
      "         [0.9968],\n",
      "         [0.9964],\n",
      "         [0.9954],\n",
      "         [0.9884],\n",
      "         [1.0022],\n",
      "         [1.0068],\n",
      "         [1.0077],\n",
      "         [1.0090],\n",
      "         [0.0340],\n",
      "         [0.8753],\n",
      "         [0.9146],\n",
      "         [0.9249],\n",
      "         [0.0616],\n",
      "         [0.8497],\n",
      "         [0.9963],\n",
      "         [0.3654],\n",
      "         [0.4418],\n",
      "         [0.9648],\n",
      "         [0.0566],\n",
      "         [0.3832],\n",
      "         [1.0034],\n",
      "         [0.1828],\n",
      "         [0.5221],\n",
      "         [1.0030],\n",
      "         [0.5117],\n",
      "         [0.4523],\n",
      "         [0.3814],\n",
      "         [0.3594],\n",
      "         [0.9922],\n",
      "         [0.4511],\n",
      "         [0.9903],\n",
      "         [0.9875],\n",
      "         [0.3618],\n",
      "         [0.4496],\n",
      "         [0.7273],\n",
      "         [0.9980],\n",
      "         [0.2521],\n",
      "         [1.0030],\n",
      "         [0.7629],\n",
      "         [1.0068],\n",
      "         [0.9721],\n",
      "         [1.0043],\n",
      "         [1.0017],\n",
      "         [0.9990],\n",
      "         [0.3434],\n",
      "         [0.9956],\n",
      "         [0.9947],\n",
      "         [0.9957],\n",
      "         [0.9958],\n",
      "         [1.0002],\n",
      "         [1.0028],\n",
      "         [1.0050],\n",
      "         [1.0068],\n",
      "         [0.8030],\n",
      "         [0.5743],\n",
      "         [0.9766],\n",
      "         [1.0128],\n",
      "         [1.0136],\n",
      "         [1.0136],\n",
      "         [0.8426],\n",
      "         [1.0154],\n",
      "         [1.0120],\n",
      "         [0.2279],\n",
      "         [1.0103],\n",
      "         [0.8796],\n",
      "         [1.0027],\n",
      "         [0.0450],\n",
      "         [0.8561],\n",
      "         [0.9940],\n",
      "         [0.9929],\n",
      "         [0.9902],\n",
      "         [0.4604],\n",
      "         [0.9273],\n",
      "         [1.0031],\n",
      "         [1.0068],\n",
      "         [1.0111],\n",
      "         [0.2601],\n",
      "         [0.2781],\n",
      "         [1.0106],\n",
      "         [1.0073],\n",
      "         [1.0032],\n",
      "         [0.9583],\n",
      "         [0.5071],\n",
      "         [0.4954],\n",
      "         [0.0613],\n",
      "         [0.9906],\n",
      "         [0.5098],\n",
      "         [0.0448],\n",
      "         [0.9957],\n",
      "         [0.3837],\n",
      "         [0.9970],\n",
      "         [0.6947],\n",
      "         [0.9787],\n",
      "         [0.9935],\n",
      "         [0.6134],\n",
      "         [0.9902],\n",
      "         [0.2491],\n",
      "         [0.9769],\n",
      "         [0.5266],\n",
      "         [0.9886],\n",
      "         [0.9902],\n",
      "         [0.9918],\n",
      "         [0.9930],\n",
      "         [0.9956],\n",
      "         [0.9949],\n",
      "         [1.0017],\n",
      "         [1.0034],\n",
      "         [1.0039],\n",
      "         [1.0074],\n",
      "         [1.0075],\n",
      "         [1.0067],\n",
      "         [0.7846],\n",
      "         [1.0007],\n",
      "         [0.9974],\n",
      "         [0.9962],\n",
      "         [0.3639],\n",
      "         [0.3468],\n",
      "         [0.9941],\n",
      "         [0.0491],\n",
      "         [0.9975],\n",
      "         [0.9997],\n",
      "         [0.9992],\n",
      "         [0.9436],\n",
      "         [1.0029],\n",
      "         [0.9996],\n",
      "         [1.0015],\n",
      "         [0.5065],\n",
      "         [0.2480],\n",
      "         [0.4646],\n",
      "         [0.9967],\n",
      "         [0.4603],\n",
      "         [1.0000],\n",
      "         [1.0009],\n",
      "         [0.2630],\n",
      "         [0.4549],\n",
      "         [1.0045],\n",
      "         [1.0055],\n",
      "         [1.0044],\n",
      "         [1.0042],\n",
      "         [1.0038],\n",
      "         [1.0045],\n",
      "         [0.6656],\n",
      "         [0.9988],\n",
      "         [1.0034],\n",
      "         [0.5278],\n",
      "         [0.0613],\n",
      "         [0.5027],\n",
      "         [0.2486],\n",
      "         [0.9940],\n",
      "         [0.2306],\n",
      "         [0.9903],\n",
      "         [0.9892],\n",
      "         [0.9913],\n",
      "         [0.9941],\n",
      "         [0.5112],\n",
      "         [0.0381],\n",
      "         [1.0063],\n",
      "         [0.5640],\n",
      "         [1.0100],\n",
      "         [1.0072],\n",
      "         [1.0055],\n",
      "         [0.9988],\n",
      "         [0.9974],\n",
      "         [0.4488],\n",
      "         [0.4338],\n",
      "         [0.5088],\n",
      "         [0.9909],\n",
      "         [0.9835],\n",
      "         [0.6842],\n",
      "         [1.0072],\n",
      "         [1.0125],\n",
      "         [1.0158],\n",
      "         [1.0188],\n",
      "         [0.4058],\n",
      "         [0.9439],\n",
      "         [0.3879],\n",
      "         [0.9912]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.9820],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.9967],\n",
      "        [0.0000],\n",
      "        [0.8296],\n",
      "        [0.8761],\n",
      "        [0.8933],\n",
      "        [0.0383],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.4454],\n",
      "        [0.9490],\n",
      "        [0.0288],\n",
      "        [0.3840],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [0.5080],\n",
      "        [0.9999],\n",
      "        [0.5030],\n",
      "        [0.4527],\n",
      "        [0.3912],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.4552],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9997],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.7540],\n",
      "        [0.5463],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9998],\n",
      "        [0.0247],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.5054],\n",
      "        [0.4988],\n",
      "        [0.0335],\n",
      "        [0.9999],\n",
      "        [0.5139],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [0.9724],\n",
      "        [0.9998],\n",
      "        [0.5945],\n",
      "        [0.9999],\n",
      "        [0.2686],\n",
      "        [0.9804],\n",
      "        [0.5245],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.3573],\n",
      "        [0.9998],\n",
      "        [0.0209],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9164],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.5038],\n",
      "        [0.2610],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.9956],\n",
      "        [0.9996],\n",
      "        [0.5151],\n",
      "        [0.0368],\n",
      "        [0.5009],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5108],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.9997],\n",
      "        [0.4580],\n",
      "        [0.4480],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3875],\n",
      "        [0.9044],\n",
      "        [0.3808],\n",
      "        [0.9814]])\n",
      "######### Epoch: 47  ######### Train Loss: 0.00025913366698659956  ######### Relative L2 Test Norm: 13.356518745422363\n",
      "Output batch pred: tensor([[[0.8664],\n",
      "         [0.5095],\n",
      "         [0.8173],\n",
      "         [0.4497],\n",
      "         [0.0358],\n",
      "         [0.9956],\n",
      "         [0.1599],\n",
      "         [0.9976],\n",
      "         [0.9866],\n",
      "         [0.9993],\n",
      "         [1.0006],\n",
      "         [0.5185],\n",
      "         [1.0036],\n",
      "         [1.0047],\n",
      "         [1.0044],\n",
      "         [0.3657],\n",
      "         [0.5061],\n",
      "         [0.9980],\n",
      "         [0.0581],\n",
      "         [0.9826],\n",
      "         [0.0619],\n",
      "         [0.9218],\n",
      "         [0.9384],\n",
      "         [1.0025],\n",
      "         [0.3530],\n",
      "         [0.0354],\n",
      "         [1.0118],\n",
      "         [0.3795],\n",
      "         [1.0105],\n",
      "         [0.5586],\n",
      "         [0.9262],\n",
      "         [0.5120],\n",
      "         [0.6922],\n",
      "         [0.4388],\n",
      "         [0.9954],\n",
      "         [0.9977],\n",
      "         [0.5050],\n",
      "         [1.0007],\n",
      "         [1.0050],\n",
      "         [1.0061],\n",
      "         [1.0056],\n",
      "         [0.4477],\n",
      "         [0.8690],\n",
      "         [1.0078],\n",
      "         [1.0065],\n",
      "         [1.0068],\n",
      "         [1.0075],\n",
      "         [1.0090],\n",
      "         [0.5235],\n",
      "         [0.0636],\n",
      "         [0.4658],\n",
      "         [1.0125],\n",
      "         [1.0107],\n",
      "         [1.0079],\n",
      "         [1.0050],\n",
      "         [1.0012],\n",
      "         [0.0433],\n",
      "         [0.2526],\n",
      "         [0.4619],\n",
      "         [1.0038],\n",
      "         [1.0047],\n",
      "         [0.7867],\n",
      "         [0.9711],\n",
      "         [1.0076],\n",
      "         [1.0074],\n",
      "         [1.0065],\n",
      "         [0.2380],\n",
      "         [1.0020],\n",
      "         [0.5542],\n",
      "         [1.0004],\n",
      "         [0.2597],\n",
      "         [1.0056],\n",
      "         [1.0106],\n",
      "         [1.0119],\n",
      "         [1.0171],\n",
      "         [1.0170],\n",
      "         [1.0183],\n",
      "         [1.0150],\n",
      "         [1.0113],\n",
      "         [0.8590],\n",
      "         [0.5251],\n",
      "         [0.9996],\n",
      "         [0.9992],\n",
      "         [0.0425],\n",
      "         [1.0083],\n",
      "         [1.0135],\n",
      "         [0.7077],\n",
      "         [1.0166],\n",
      "         [1.0216],\n",
      "         [1.0026],\n",
      "         [1.0174],\n",
      "         [1.0136],\n",
      "         [1.0084],\n",
      "         [0.6244],\n",
      "         [1.0030],\n",
      "         [1.0013],\n",
      "         [1.0007],\n",
      "         [0.2659],\n",
      "         [0.9143],\n",
      "         [1.0076],\n",
      "         [1.0080],\n",
      "         [1.0043],\n",
      "         [0.4693],\n",
      "         [1.0005],\n",
      "         [0.9983],\n",
      "         [0.0494],\n",
      "         [0.3674],\n",
      "         [0.4619],\n",
      "         [0.9695],\n",
      "         [1.0061],\n",
      "         [1.0137],\n",
      "         [1.0162],\n",
      "         [0.4898],\n",
      "         [1.0151],\n",
      "         [0.5163],\n",
      "         [1.0057],\n",
      "         [0.3751],\n",
      "         [0.9897],\n",
      "         [0.4388],\n",
      "         [0.9877],\n",
      "         [0.9907],\n",
      "         [0.2411],\n",
      "         [0.9963],\n",
      "         [1.0007],\n",
      "         [0.2460],\n",
      "         [0.7333],\n",
      "         [0.6632],\n",
      "         [0.9993],\n",
      "         [0.9252],\n",
      "         [0.2475],\n",
      "         [0.0526],\n",
      "         [0.9575],\n",
      "         [0.7795],\n",
      "         [0.9946],\n",
      "         [0.3769],\n",
      "         [1.0025],\n",
      "         [1.0028],\n",
      "         [1.0082],\n",
      "         [1.0110],\n",
      "         [1.0118],\n",
      "         [1.0121],\n",
      "         [1.0129],\n",
      "         [0.5347],\n",
      "         [0.3781],\n",
      "         [1.0112],\n",
      "         [1.0111],\n",
      "         [0.3657],\n",
      "         [1.0105],\n",
      "         [1.0111],\n",
      "         [0.3883],\n",
      "         [1.0072],\n",
      "         [1.0074],\n",
      "         [1.0060],\n",
      "         [0.7539],\n",
      "         [0.5384],\n",
      "         [1.0060],\n",
      "         [1.0063],\n",
      "         [0.9937],\n",
      "         [0.5123],\n",
      "         [1.0101],\n",
      "         [1.0133],\n",
      "         [1.0141],\n",
      "         [1.0140],\n",
      "         [1.0129],\n",
      "         [1.0130],\n",
      "         [1.0125],\n",
      "         [0.8782],\n",
      "         [0.4631],\n",
      "         [1.0103],\n",
      "         [1.0108],\n",
      "         [0.3943],\n",
      "         [1.0086],\n",
      "         [1.0059],\n",
      "         [0.2476],\n",
      "         [0.3759],\n",
      "         [0.9667],\n",
      "         [0.2136],\n",
      "         [0.9880]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.8379],\n",
      "        [0.5108],\n",
      "        [0.7820],\n",
      "        [0.4580],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [0.9995],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.9820],\n",
      "        [0.0335],\n",
      "        [0.9044],\n",
      "        [0.9164],\n",
      "        [0.9997],\n",
      "        [0.3573],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.9994],\n",
      "        [0.5334],\n",
      "        [0.8933],\n",
      "        [0.5080],\n",
      "        [0.6628],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [0.4454],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.0368],\n",
      "        [0.4503],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.0209],\n",
      "        [0.2686],\n",
      "        [0.4645],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.7391],\n",
      "        [0.9420],\n",
      "        [0.9962],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.0142],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.8761],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.3780],\n",
      "        [0.4611],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.9999],\n",
      "        [0.3840],\n",
      "        [0.9956],\n",
      "        [0.4527],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.6920],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.2646],\n",
      "        [0.0383],\n",
      "        [0.9515],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3575],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.7129],\n",
      "        [0.5245],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.9814],\n",
      "        [0.5009],\n",
      "        [0.9966],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.2518],\n",
      "        [0.3808],\n",
      "        [0.9520],\n",
      "        [0.2208],\n",
      "        [0.9804]])\n",
      "######### Epoch: 48  ######### Train Loss: 0.00026989905745722353  ######### Relative L2 Test Norm: 13.784088134765625\n",
      "Output batch pred: tensor([[[0.9952],\n",
      "         [1.0073],\n",
      "         [0.5199],\n",
      "         [1.0065],\n",
      "         [0.2654],\n",
      "         [1.0072],\n",
      "         [1.0074],\n",
      "         [0.3925],\n",
      "         [1.0049],\n",
      "         [0.0436],\n",
      "         [0.3727],\n",
      "         [1.0052],\n",
      "         [0.5242],\n",
      "         [1.0051],\n",
      "         [1.0043],\n",
      "         [0.3459],\n",
      "         [1.0047],\n",
      "         [0.3689],\n",
      "         [1.0080],\n",
      "         [0.1697],\n",
      "         [1.0106],\n",
      "         [1.0092],\n",
      "         [1.0095],\n",
      "         [1.0123],\n",
      "         [1.0121],\n",
      "         [1.0106],\n",
      "         [1.0116],\n",
      "         [1.0125],\n",
      "         [1.0111],\n",
      "         [0.9366],\n",
      "         [1.0146],\n",
      "         [0.3794],\n",
      "         [1.0010],\n",
      "         [0.5385],\n",
      "         [1.0147],\n",
      "         [1.0146],\n",
      "         [1.0125],\n",
      "         [0.9517],\n",
      "         [0.7978],\n",
      "         [0.3498],\n",
      "         [0.3774],\n",
      "         [0.5052],\n",
      "         [0.9998],\n",
      "         [1.0007],\n",
      "         [0.9973],\n",
      "         [0.5039],\n",
      "         [1.0020],\n",
      "         [0.3685],\n",
      "         [1.0052],\n",
      "         [1.0070],\n",
      "         [0.7558],\n",
      "         [0.3892],\n",
      "         [0.8305],\n",
      "         [1.0086],\n",
      "         [1.0087],\n",
      "         [1.0074],\n",
      "         [0.4500],\n",
      "         [0.5335],\n",
      "         [0.9066],\n",
      "         [0.9991],\n",
      "         [0.9983],\n",
      "         [0.9573],\n",
      "         [0.5086],\n",
      "         [1.0011],\n",
      "         [1.0043],\n",
      "         [1.0066],\n",
      "         [1.0093],\n",
      "         [1.0111],\n",
      "         [1.0013],\n",
      "         [0.5700],\n",
      "         [1.0130],\n",
      "         [0.2436],\n",
      "         [0.9764],\n",
      "         [0.9754],\n",
      "         [0.0529],\n",
      "         [1.0085],\n",
      "         [1.0076],\n",
      "         [0.2582],\n",
      "         [0.0449],\n",
      "         [1.0070],\n",
      "         [0.2539],\n",
      "         [0.6872],\n",
      "         [0.9321],\n",
      "         [0.8613],\n",
      "         [0.4428],\n",
      "         [0.2040],\n",
      "         [0.2409],\n",
      "         [0.9938],\n",
      "         [0.7165],\n",
      "         [0.9950],\n",
      "         [0.4544],\n",
      "         [0.5042],\n",
      "         [0.4618],\n",
      "         [1.0032],\n",
      "         [0.2411],\n",
      "         [1.0073],\n",
      "         [1.0093],\n",
      "         [0.6261],\n",
      "         [0.3826],\n",
      "         [1.0115],\n",
      "         [1.0098],\n",
      "         [1.0090],\n",
      "         [1.0032],\n",
      "         [0.5103],\n",
      "         [1.0052],\n",
      "         [0.0429],\n",
      "         [1.0019],\n",
      "         [0.6896],\n",
      "         [0.9985],\n",
      "         [0.9984],\n",
      "         [0.9973],\n",
      "         [0.9795],\n",
      "         [0.4554],\n",
      "         [0.8695],\n",
      "         [1.0037],\n",
      "         [0.4991],\n",
      "         [0.6633],\n",
      "         [1.0074],\n",
      "         [1.0090],\n",
      "         [1.0083],\n",
      "         [1.0081],\n",
      "         [1.0086],\n",
      "         [0.0392],\n",
      "         [0.9951],\n",
      "         [1.0047],\n",
      "         [1.0051],\n",
      "         [0.0239],\n",
      "         [1.0080],\n",
      "         [1.0096],\n",
      "         [1.0099],\n",
      "         [1.0089],\n",
      "         [1.0126],\n",
      "         [1.0123],\n",
      "         [0.2652],\n",
      "         [0.4618],\n",
      "         [1.0094],\n",
      "         [0.2527],\n",
      "         [1.0098],\n",
      "         [0.4655],\n",
      "         [0.0549],\n",
      "         [0.0629],\n",
      "         [1.0109],\n",
      "         [1.0118],\n",
      "         [0.4713],\n",
      "         [1.0135],\n",
      "         [0.9417],\n",
      "         [1.0139],\n",
      "         [0.4587],\n",
      "         [1.0139],\n",
      "         [1.0132],\n",
      "         [1.0118],\n",
      "         [0.8749],\n",
      "         [1.0077],\n",
      "         [1.0039],\n",
      "         [0.9682],\n",
      "         [0.9994],\n",
      "         [0.4359],\n",
      "         [0.0356],\n",
      "         [1.0016],\n",
      "         [1.0024],\n",
      "         [1.0043],\n",
      "         [1.0051],\n",
      "         [0.3732],\n",
      "         [1.0109],\n",
      "         [0.5624],\n",
      "         [1.0102],\n",
      "         [1.0103],\n",
      "         [0.5133],\n",
      "         [1.0090],\n",
      "         [1.0073],\n",
      "         [1.0048],\n",
      "         [1.0048],\n",
      "         [1.0054],\n",
      "         [1.0049],\n",
      "         [0.7820],\n",
      "         [1.0037],\n",
      "         [1.0033],\n",
      "         [0.8585]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9819],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [0.9999],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9966],\n",
      "        [0.0142],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.9997],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.9814],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.7540],\n",
      "        [0.3575],\n",
      "        [0.3875],\n",
      "        [0.5038],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.3912],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.5245],\n",
      "        [0.8761],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9520],\n",
      "        [0.9490],\n",
      "        [0.0335],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.6555],\n",
      "        [0.9044],\n",
      "        [0.8223],\n",
      "        [0.4503],\n",
      "        [0.2208],\n",
      "        [0.2610],\n",
      "        [0.9967],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.5080],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [0.5030],\n",
      "        [0.9998],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [0.4642],\n",
      "        [0.8379],\n",
      "        [0.9997],\n",
      "        [0.4988],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.9804],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.0247],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9515],\n",
      "        [0.9998],\n",
      "        [0.4454],\n",
      "        [0.0174],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.8139]])\n",
      "######### Epoch: 49  ######### Train Loss: 0.00025294910301454365  ######### Relative L2 Test Norm: 13.526103973388672\n",
      "Output batch pred: tensor([[[0.3577],\n",
      "         [1.0146],\n",
      "         [1.0146],\n",
      "         [1.0123],\n",
      "         [0.9728],\n",
      "         [0.4645],\n",
      "         [0.8663],\n",
      "         [0.9591],\n",
      "         [0.4928],\n",
      "         [0.9897],\n",
      "         [0.4829],\n",
      "         [0.9932],\n",
      "         [0.5088],\n",
      "         [0.8471],\n",
      "         [1.0023],\n",
      "         [0.0508],\n",
      "         [1.0066],\n",
      "         [1.0049],\n",
      "         [1.0051],\n",
      "         [0.2307],\n",
      "         [0.9969],\n",
      "         [0.9979],\n",
      "         [0.9954],\n",
      "         [0.9951],\n",
      "         [0.9752],\n",
      "         [0.0394],\n",
      "         [0.9961],\n",
      "         [0.3699],\n",
      "         [0.0408],\n",
      "         [0.3814],\n",
      "         [1.0092],\n",
      "         [0.9955],\n",
      "         [0.4584],\n",
      "         [1.0090],\n",
      "         [1.0077],\n",
      "         [1.0065],\n",
      "         [0.8259],\n",
      "         [1.0049],\n",
      "         [0.5165],\n",
      "         [1.0071],\n",
      "         [0.2448],\n",
      "         [1.0091],\n",
      "         [1.0096],\n",
      "         [1.0101],\n",
      "         [0.0471],\n",
      "         [0.7806],\n",
      "         [0.3769],\n",
      "         [1.0031],\n",
      "         [1.0014],\n",
      "         [1.0022],\n",
      "         [1.0041],\n",
      "         [0.9941],\n",
      "         [1.0103],\n",
      "         [0.8749],\n",
      "         [1.0159],\n",
      "         [0.5547],\n",
      "         [0.5653],\n",
      "         [1.0154],\n",
      "         [1.0116],\n",
      "         [0.3616],\n",
      "         [1.0032],\n",
      "         [0.4436],\n",
      "         [0.4988],\n",
      "         [0.9871],\n",
      "         [0.9963],\n",
      "         [1.0028],\n",
      "         [0.9715],\n",
      "         [0.3714],\n",
      "         [0.9334],\n",
      "         [1.0107],\n",
      "         [1.0086],\n",
      "         [0.5190],\n",
      "         [1.0013],\n",
      "         [0.9983],\n",
      "         [0.0327],\n",
      "         [0.9924],\n",
      "         [0.9780],\n",
      "         [0.6622],\n",
      "         [0.4427],\n",
      "         [0.9959],\n",
      "         [0.4948],\n",
      "         [1.0019],\n",
      "         [1.0034],\n",
      "         [0.8682],\n",
      "         [1.0058],\n",
      "         [0.0372],\n",
      "         [0.5144],\n",
      "         [1.0088],\n",
      "         [0.2653],\n",
      "         [1.0113],\n",
      "         [1.0119],\n",
      "         [1.0117],\n",
      "         [1.0109],\n",
      "         [1.0086],\n",
      "         [1.0071],\n",
      "         [1.0015],\n",
      "         [0.3346],\n",
      "         [0.4304],\n",
      "         [0.1527],\n",
      "         [0.9928],\n",
      "         [0.9977],\n",
      "         [0.9995],\n",
      "         [0.1990],\n",
      "         [0.4473],\n",
      "         [1.0109],\n",
      "         [1.0135],\n",
      "         [1.0111],\n",
      "         [1.0141],\n",
      "         [1.0141],\n",
      "         [1.0119],\n",
      "         [0.0609],\n",
      "         [0.3713],\n",
      "         [0.4667],\n",
      "         [0.6146],\n",
      "         [0.9981],\n",
      "         [0.3790],\n",
      "         [1.0010],\n",
      "         [0.4947],\n",
      "         [0.9411],\n",
      "         [0.2290],\n",
      "         [1.0017],\n",
      "         [1.0057],\n",
      "         [0.5623],\n",
      "         [1.0069],\n",
      "         [1.0090],\n",
      "         [1.0097],\n",
      "         [1.0060],\n",
      "         [0.9354],\n",
      "         [1.0067],\n",
      "         [1.0043],\n",
      "         [0.6927],\n",
      "         [1.0005],\n",
      "         [0.4268],\n",
      "         [0.9950],\n",
      "         [0.9954],\n",
      "         [0.9960],\n",
      "         [0.0249],\n",
      "         [0.5190],\n",
      "         [0.6606],\n",
      "         [0.2535],\n",
      "         [0.7365],\n",
      "         [1.0069],\n",
      "         [0.9358],\n",
      "         [1.0065],\n",
      "         [1.0039],\n",
      "         [1.0039],\n",
      "         [1.0032],\n",
      "         [0.2429],\n",
      "         [1.0050],\n",
      "         [0.3650],\n",
      "         [0.0396],\n",
      "         [1.0098],\n",
      "         [1.0088],\n",
      "         [1.0101],\n",
      "         [0.4573],\n",
      "         [1.0084],\n",
      "         [1.0057],\n",
      "         [1.0055],\n",
      "         [1.0041],\n",
      "         [1.0042],\n",
      "         [0.7961],\n",
      "         [0.9183],\n",
      "         [0.3787],\n",
      "         [0.9773],\n",
      "         [1.0171],\n",
      "         [1.0208],\n",
      "         [0.7728],\n",
      "         [1.0174],\n",
      "         [1.0146],\n",
      "         [1.0104],\n",
      "         [0.2553],\n",
      "         [1.0000],\n",
      "         [0.9998],\n",
      "         [0.2408],\n",
      "         [0.4530],\n",
      "         [1.0004],\n",
      "         [1.0067],\n",
      "         [1.0098]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.3573],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.4668],\n",
      "        [0.8379],\n",
      "        [0.9515],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9999],\n",
      "        [0.5165],\n",
      "        [0.8139],\n",
      "        [0.9998],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.0288],\n",
      "        [0.9999],\n",
      "        [0.3840],\n",
      "        [0.0209],\n",
      "        [0.3875],\n",
      "        [0.9997],\n",
      "        [0.9814],\n",
      "        [0.4552],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.9997],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.7391],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.5030],\n",
      "        [0.9819],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.3780],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.6555],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.9996],\n",
      "        [0.9995],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.3575],\n",
      "        [0.4480],\n",
      "        [0.1762],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.4503],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.3747],\n",
      "        [0.4642],\n",
      "        [0.5945],\n",
      "        [0.9966],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.9164],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [0.9998],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.5151],\n",
      "        [0.6327],\n",
      "        [0.2686],\n",
      "        [0.6920],\n",
      "        [0.9967],\n",
      "        [0.9044],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9994],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.8761],\n",
      "        [0.3808],\n",
      "        [0.9420],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [0.4611],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9996]])\n",
      "######### Epoch: 50  ######### Train Loss: 0.0002702622441574931  ######### Relative L2 Test Norm: 14.307427406311035\n",
      "Output batch pred: tensor([[[0.8721],\n",
      "         [1.0071],\n",
      "         [1.0086],\n",
      "         [1.0075],\n",
      "         [0.9361],\n",
      "         [0.3740],\n",
      "         [0.9918],\n",
      "         [1.0012],\n",
      "         [0.2447],\n",
      "         [0.5298],\n",
      "         [1.0011],\n",
      "         [0.9997],\n",
      "         [1.0007],\n",
      "         [0.9993],\n",
      "         [0.6441],\n",
      "         [0.2371],\n",
      "         [0.3590],\n",
      "         [0.9926],\n",
      "         [0.4414],\n",
      "         [0.5279],\n",
      "         [0.2273],\n",
      "         [0.5059],\n",
      "         [0.5124],\n",
      "         [0.5283],\n",
      "         [1.0162],\n",
      "         [0.0572],\n",
      "         [1.0222],\n",
      "         [0.6450],\n",
      "         [1.0174],\n",
      "         [1.0136],\n",
      "         [1.0094],\n",
      "         [1.0055],\n",
      "         [0.9979],\n",
      "         [0.9993],\n",
      "         [0.0139],\n",
      "         [0.9216],\n",
      "         [0.9978],\n",
      "         [0.4391],\n",
      "         [1.0029],\n",
      "         [0.0470],\n",
      "         [1.0073],\n",
      "         [1.0088],\n",
      "         [0.2421],\n",
      "         [0.2643],\n",
      "         [1.0104],\n",
      "         [1.0125],\n",
      "         [1.0107],\n",
      "         [1.0094],\n",
      "         [1.0068],\n",
      "         [0.7293],\n",
      "         [0.9637],\n",
      "         [0.9976],\n",
      "         [0.9938],\n",
      "         [0.9904],\n",
      "         [0.9911],\n",
      "         [0.4979],\n",
      "         [0.9910],\n",
      "         [0.3582],\n",
      "         [0.9527],\n",
      "         [0.9963],\n",
      "         [0.9985],\n",
      "         [0.0364],\n",
      "         [0.9998],\n",
      "         [0.9671],\n",
      "         [1.0005],\n",
      "         [1.0023],\n",
      "         [0.3603],\n",
      "         [1.0000],\n",
      "         [0.9992],\n",
      "         [0.9816],\n",
      "         [0.8986],\n",
      "         [0.5366],\n",
      "         [0.7542],\n",
      "         [0.4275],\n",
      "         [0.9813],\n",
      "         [0.9460],\n",
      "         [0.4306],\n",
      "         [0.2278],\n",
      "         [0.4474],\n",
      "         [0.9981],\n",
      "         [1.0028],\n",
      "         [0.3528],\n",
      "         [1.0110],\n",
      "         [0.3859],\n",
      "         [1.0135],\n",
      "         [0.2507],\n",
      "         [0.9978],\n",
      "         [1.0066],\n",
      "         [1.0044],\n",
      "         [1.0020],\n",
      "         [1.0004],\n",
      "         [0.9980],\n",
      "         [0.9993],\n",
      "         [0.0316],\n",
      "         [1.0015],\n",
      "         [1.0019],\n",
      "         [1.0020],\n",
      "         [0.5026],\n",
      "         [0.6973],\n",
      "         [0.2486],\n",
      "         [1.0043],\n",
      "         [0.0453],\n",
      "         [1.0069],\n",
      "         [1.0110],\n",
      "         [1.0128],\n",
      "         [1.0135],\n",
      "         [1.0141],\n",
      "         [1.0123],\n",
      "         [1.0091],\n",
      "         [1.0049],\n",
      "         [0.9997],\n",
      "         [0.9901],\n",
      "         [0.8377],\n",
      "         [0.9902],\n",
      "         [0.9700],\n",
      "         [0.9922],\n",
      "         [0.9940],\n",
      "         [0.9990],\n",
      "         [1.0024],\n",
      "         [1.0061],\n",
      "         [0.9300],\n",
      "         [1.0079],\n",
      "         [1.0084],\n",
      "         [0.9471],\n",
      "         [1.0054],\n",
      "         [0.3619],\n",
      "         [1.0038],\n",
      "         [1.0042],\n",
      "         [1.0047],\n",
      "         [1.0067],\n",
      "         [0.7955],\n",
      "         [1.0055],\n",
      "         [1.0039],\n",
      "         [0.4993],\n",
      "         [0.4963],\n",
      "         [0.9961],\n",
      "         [0.8494],\n",
      "         [0.4463],\n",
      "         [0.0271],\n",
      "         [0.9999],\n",
      "         [0.0284],\n",
      "         [0.5276],\n",
      "         [1.0157],\n",
      "         [1.0161],\n",
      "         [1.0205],\n",
      "         [1.0205],\n",
      "         [0.3928],\n",
      "         [0.4581],\n",
      "         [0.8766],\n",
      "         [0.8275],\n",
      "         [0.4513],\n",
      "         [1.0016],\n",
      "         [0.5143],\n",
      "         [0.3382],\n",
      "         [1.0039],\n",
      "         [1.0051],\n",
      "         [1.0051],\n",
      "         [1.0064],\n",
      "         [1.0072],\n",
      "         [0.3610],\n",
      "         [0.5009],\n",
      "         [1.0076],\n",
      "         [0.9988],\n",
      "         [0.4631],\n",
      "         [0.7651],\n",
      "         [1.0134],\n",
      "         [1.0125],\n",
      "         [0.1753],\n",
      "         [1.0111],\n",
      "         [1.0072],\n",
      "         [1.0004],\n",
      "         [0.3457],\n",
      "         [0.4214],\n",
      "         [0.9878],\n",
      "         [0.6540],\n",
      "         [0.9865],\n",
      "         [0.1879],\n",
      "         [0.0412]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.8379],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9044],\n",
      "        [0.3875],\n",
      "        [0.9820],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.5245],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.2735],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.5334],\n",
      "        [0.2577],\n",
      "        [0.5080],\n",
      "        [0.5054],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.9009],\n",
      "        [0.9999],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.2518],\n",
      "        [0.2729],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9420],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.3747],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [0.8761],\n",
      "        [0.5463],\n",
      "        [0.7391],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.4611],\n",
      "        [0.2646],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.9999],\n",
      "        [0.2547],\n",
      "        [0.9804],\n",
      "        [0.9995],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.6628],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9164],\n",
      "        [0.9999],\n",
      "        [0.3753],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.5030],\n",
      "        [0.5038],\n",
      "        [0.9994],\n",
      "        [0.8223],\n",
      "        [0.4645],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.5165],\n",
      "        [0.9997],\n",
      "        [0.9962],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.4454],\n",
      "        [0.8296],\n",
      "        [0.7820],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.3573],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.3780],\n",
      "        [0.4988],\n",
      "        [0.9999],\n",
      "        [0.9819],\n",
      "        [0.4552],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.0383]])\n",
      "######### Epoch: 51  ######### Train Loss: 0.00026372139109298587  ######### Relative L2 Test Norm: 14.751212120056152\n",
      "Output batch pred: tensor([[[0.9881],\n",
      "         [0.9741],\n",
      "         [0.9846],\n",
      "         [0.9856],\n",
      "         [0.3419],\n",
      "         [0.2218],\n",
      "         [0.9959],\n",
      "         [0.9993],\n",
      "         [0.9086],\n",
      "         [0.7912],\n",
      "         [0.8631],\n",
      "         [1.0037],\n",
      "         [1.0008],\n",
      "         [0.9980],\n",
      "         [0.4451],\n",
      "         [0.9908],\n",
      "         [0.5354],\n",
      "         [0.5263],\n",
      "         [0.7328],\n",
      "         [0.0181],\n",
      "         [0.9605],\n",
      "         [0.3388],\n",
      "         [1.0037],\n",
      "         [0.4561],\n",
      "         [0.0397],\n",
      "         [0.9275],\n",
      "         [1.0031],\n",
      "         [0.9905],\n",
      "         [0.5032],\n",
      "         [1.0042],\n",
      "         [0.5106],\n",
      "         [0.0594],\n",
      "         [0.3707],\n",
      "         [1.0082],\n",
      "         [1.0077],\n",
      "         [0.2629],\n",
      "         [0.0515],\n",
      "         [1.0037],\n",
      "         [1.0002],\n",
      "         [0.9967],\n",
      "         [0.9931],\n",
      "         [0.9168],\n",
      "         [0.9922],\n",
      "         [0.9920],\n",
      "         [0.9941],\n",
      "         [0.3604],\n",
      "         [1.0025],\n",
      "         [1.0048],\n",
      "         [1.0032],\n",
      "         [1.0065],\n",
      "         [1.0060],\n",
      "         [1.0051],\n",
      "         [0.0308],\n",
      "         [0.9835],\n",
      "         [1.0012],\n",
      "         [1.0005],\n",
      "         [0.6124],\n",
      "         [1.0001],\n",
      "         [0.9985],\n",
      "         [0.9970],\n",
      "         [0.9562],\n",
      "         [0.4907],\n",
      "         [0.9801],\n",
      "         [0.4411],\n",
      "         [0.9888],\n",
      "         [0.9872],\n",
      "         [0.9873],\n",
      "         [0.0235],\n",
      "         [0.9916],\n",
      "         [0.3592],\n",
      "         [0.9983],\n",
      "         [1.0010],\n",
      "         [0.5227],\n",
      "         [0.6664],\n",
      "         [1.0075],\n",
      "         [1.0077],\n",
      "         [0.9963],\n",
      "         [0.2485],\n",
      "         [1.0065],\n",
      "         [1.0039],\n",
      "         [1.0038],\n",
      "         [0.2467],\n",
      "         [1.0014],\n",
      "         [0.9982],\n",
      "         [0.4508],\n",
      "         [0.9991],\n",
      "         [0.9989],\n",
      "         [0.9986],\n",
      "         [0.0366],\n",
      "         [0.4509],\n",
      "         [0.3749],\n",
      "         [0.7041],\n",
      "         [1.0039],\n",
      "         [0.5127],\n",
      "         [0.5180],\n",
      "         [1.0102],\n",
      "         [1.0080],\n",
      "         [1.0070],\n",
      "         [1.0055],\n",
      "         [1.0041],\n",
      "         [1.0026],\n",
      "         [0.5124],\n",
      "         [0.9994],\n",
      "         [0.1619],\n",
      "         [0.9991],\n",
      "         [0.9999],\n",
      "         [0.9257],\n",
      "         [1.0004],\n",
      "         [0.9992],\n",
      "         [0.5154],\n",
      "         [0.9993],\n",
      "         [0.9646],\n",
      "         [0.9992],\n",
      "         [0.3549],\n",
      "         [1.0022],\n",
      "         [1.0032],\n",
      "         [1.0046],\n",
      "         [1.0045],\n",
      "         [0.3810],\n",
      "         [1.0037],\n",
      "         [1.0014],\n",
      "         [0.9995],\n",
      "         [0.9635],\n",
      "         [0.9972],\n",
      "         [0.5089],\n",
      "         [0.4366],\n",
      "         [0.9992],\n",
      "         [0.9989],\n",
      "         [0.3574],\n",
      "         [1.0009],\n",
      "         [0.8720],\n",
      "         [0.4370],\n",
      "         [0.9997],\n",
      "         [0.9999],\n",
      "         [0.9990],\n",
      "         [0.9968],\n",
      "         [0.3699],\n",
      "         [0.4333],\n",
      "         [1.0028],\n",
      "         [1.0041],\n",
      "         [1.0062],\n",
      "         [1.0089],\n",
      "         [1.0080],\n",
      "         [0.2102],\n",
      "         [0.2594],\n",
      "         [0.4649],\n",
      "         [0.2357],\n",
      "         [0.9990],\n",
      "         [0.9976],\n",
      "         [0.5276],\n",
      "         [0.9980],\n",
      "         [0.0321],\n",
      "         [1.0050],\n",
      "         [1.0069],\n",
      "         [0.6901],\n",
      "         [1.0097],\n",
      "         [1.0063],\n",
      "         [0.2353],\n",
      "         [0.9437],\n",
      "         [1.0015],\n",
      "         [0.5016],\n",
      "         [0.7176],\n",
      "         [0.8107],\n",
      "         [0.9920],\n",
      "         [0.4345],\n",
      "         [0.9969],\n",
      "         [0.9990],\n",
      "         [1.0011],\n",
      "         [1.0019],\n",
      "         [1.0027],\n",
      "         [0.0344],\n",
      "         [0.3451],\n",
      "         [0.9995],\n",
      "         [0.8487],\n",
      "         [0.8597],\n",
      "         [0.7655],\n",
      "         [0.9943],\n",
      "         [0.2284]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9999],\n",
      "        [0.9819],\n",
      "        [0.9967],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.8761],\n",
      "        [0.7540],\n",
      "        [0.8223],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.5334],\n",
      "        [0.7129],\n",
      "        [0.0000],\n",
      "        [0.9520],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.0288],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.0368],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.9724],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9420],\n",
      "        [0.5038],\n",
      "        [0.9804],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.5165],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9820],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0142],\n",
      "        [0.4527],\n",
      "        [0.3808],\n",
      "        [0.6628],\n",
      "        [0.9956],\n",
      "        [0.4988],\n",
      "        [0.5030],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.3747],\n",
      "        [0.9999],\n",
      "        [0.8379],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.3912],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.2729],\n",
      "        [0.4668],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [0.9999],\n",
      "        [0.9959],\n",
      "        [0.2518],\n",
      "        [0.9164],\n",
      "        [0.9996],\n",
      "        [0.5080],\n",
      "        [0.6920],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.3575],\n",
      "        [0.9962],\n",
      "        [0.8139],\n",
      "        [0.8296],\n",
      "        [0.7391],\n",
      "        [0.9997],\n",
      "        [0.2646]])\n",
      "######### Epoch: 52  ######### Train Loss: 0.00019649749447125942  ######### Relative L2 Test Norm: 14.08388614654541\n",
      "Output batch pred: tensor([[[0.9625],\n",
      "         [0.9963],\n",
      "         [0.9929],\n",
      "         [0.9895],\n",
      "         [0.9864],\n",
      "         [0.9821],\n",
      "         [0.9821],\n",
      "         [0.7581],\n",
      "         [0.9812],\n",
      "         [0.5124],\n",
      "         [0.9850],\n",
      "         [0.9120],\n",
      "         [0.2258],\n",
      "         [0.9933],\n",
      "         [0.2351],\n",
      "         [0.0374],\n",
      "         [1.0001],\n",
      "         [0.0343],\n",
      "         [0.9842],\n",
      "         [0.9920],\n",
      "         [0.9906],\n",
      "         [0.9891],\n",
      "         [0.7091],\n",
      "         [0.4383],\n",
      "         [0.7641],\n",
      "         [0.5027],\n",
      "         [0.9290],\n",
      "         [1.0073],\n",
      "         [0.5284],\n",
      "         [1.0124],\n",
      "         [0.5705],\n",
      "         [0.3798],\n",
      "         [0.3546],\n",
      "         [0.5288],\n",
      "         [0.6206],\n",
      "         [0.9985],\n",
      "         [0.5179],\n",
      "         [0.4570],\n",
      "         [1.0055],\n",
      "         [1.0086],\n",
      "         [1.0111],\n",
      "         [0.0179],\n",
      "         [1.0115],\n",
      "         [1.0092],\n",
      "         [1.0043],\n",
      "         [1.0004],\n",
      "         [0.9940],\n",
      "         [0.9920],\n",
      "         [0.6645],\n",
      "         [0.9907],\n",
      "         [0.4511],\n",
      "         [0.4519],\n",
      "         [0.9942],\n",
      "         [1.0128],\n",
      "         [1.0177],\n",
      "         [1.0194],\n",
      "         [1.0195],\n",
      "         [1.0169],\n",
      "         [1.0116],\n",
      "         [1.0038],\n",
      "         [0.9938],\n",
      "         [0.9805],\n",
      "         [0.2185],\n",
      "         [0.9709],\n",
      "         [0.9688],\n",
      "         [0.9692],\n",
      "         [0.8288],\n",
      "         [0.9792],\n",
      "         [0.4133],\n",
      "         [0.9909],\n",
      "         [0.4901],\n",
      "         [0.8694],\n",
      "         [0.3574],\n",
      "         [0.9420],\n",
      "         [1.0014],\n",
      "         [0.8589],\n",
      "         [0.9777],\n",
      "         [0.9947],\n",
      "         [0.9922],\n",
      "         [0.9884],\n",
      "         [0.9880],\n",
      "         [0.9855],\n",
      "         [0.4145],\n",
      "         [0.5079],\n",
      "         [0.0301],\n",
      "         [0.0453],\n",
      "         [0.3622],\n",
      "         [0.4815],\n",
      "         [0.4487],\n",
      "         [0.1539],\n",
      "         [0.9969],\n",
      "         [0.9065],\n",
      "         [1.0013],\n",
      "         [1.0038],\n",
      "         [1.0047],\n",
      "         [0.5076],\n",
      "         [0.3668],\n",
      "         [0.9623],\n",
      "         [0.2455],\n",
      "         [1.0004],\n",
      "         [0.4466],\n",
      "         [0.0489],\n",
      "         [0.9985],\n",
      "         [0.9971],\n",
      "         [0.9966],\n",
      "         [0.9960],\n",
      "         [0.9626],\n",
      "         [0.9966],\n",
      "         [0.4575],\n",
      "         [0.9981],\n",
      "         [0.9980],\n",
      "         [0.2380],\n",
      "         [0.9994],\n",
      "         [0.6969],\n",
      "         [1.0023],\n",
      "         [1.0030],\n",
      "         [1.0019],\n",
      "         [1.0026],\n",
      "         [1.0013],\n",
      "         [0.9992],\n",
      "         [0.9986],\n",
      "         [0.9952],\n",
      "         [0.9128],\n",
      "         [0.9914],\n",
      "         [0.2389],\n",
      "         [0.4833],\n",
      "         [0.2284],\n",
      "         [0.9857],\n",
      "         [0.9890],\n",
      "         [0.3655],\n",
      "         [0.4294],\n",
      "         [0.9963],\n",
      "         [0.9969],\n",
      "         [0.9982],\n",
      "         [0.9996],\n",
      "         [1.0019],\n",
      "         [0.9985],\n",
      "         [0.1959],\n",
      "         [0.9994],\n",
      "         [0.9864],\n",
      "         [0.9841],\n",
      "         [0.9970],\n",
      "         [0.9980],\n",
      "         [0.3537],\n",
      "         [0.3301],\n",
      "         [0.9964],\n",
      "         [0.9964],\n",
      "         [0.9956],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [0.9653],\n",
      "         [0.5170],\n",
      "         [0.0344],\n",
      "         [0.8574],\n",
      "         [1.0072],\n",
      "         [1.0091],\n",
      "         [0.5184],\n",
      "         [1.0101],\n",
      "         [0.6709],\n",
      "         [1.0081],\n",
      "         [0.8282],\n",
      "         [0.3761],\n",
      "         [1.0020],\n",
      "         [0.9995],\n",
      "         [0.3655],\n",
      "         [0.9955],\n",
      "         [0.2498],\n",
      "         [0.0311],\n",
      "         [0.9965],\n",
      "         [0.9986],\n",
      "         [0.7446],\n",
      "         [0.9973],\n",
      "         [1.0016],\n",
      "         [0.0315],\n",
      "         [1.0025],\n",
      "         [0.3632],\n",
      "         [1.0004],\n",
      "         [0.9985]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9490],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.2518],\n",
      "        [0.9998],\n",
      "        [0.2547],\n",
      "        [0.0247],\n",
      "        [0.9999],\n",
      "        [0.0383],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.6920],\n",
      "        [0.4611],\n",
      "        [0.7391],\n",
      "        [0.5080],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.9999],\n",
      "        [0.5463],\n",
      "        [0.3808],\n",
      "        [0.3575],\n",
      "        [0.5151],\n",
      "        [0.5945],\n",
      "        [0.9962],\n",
      "        [0.5108],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.4580],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9967],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [0.4503],\n",
      "        [0.9999],\n",
      "        [0.5009],\n",
      "        [0.8379],\n",
      "        [0.3728],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.4454],\n",
      "        [0.5245],\n",
      "        [0.0174],\n",
      "        [0.0368],\n",
      "        [0.3912],\n",
      "        [0.4988],\n",
      "        [0.4642],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5030],\n",
      "        [0.3747],\n",
      "        [0.9420],\n",
      "        [0.2577],\n",
      "        [0.9997],\n",
      "        [0.4527],\n",
      "        [0.0335],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9515],\n",
      "        [0.9997],\n",
      "        [0.4668],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.9997],\n",
      "        [0.2735],\n",
      "        [0.5038],\n",
      "        [0.2646],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.3930],\n",
      "        [0.4480],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9996],\n",
      "        [0.9804],\n",
      "        [0.9814],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.5165],\n",
      "        [0.0288],\n",
      "        [0.8139],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.9994],\n",
      "        [0.2729],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.9998],\n",
      "        [1.0000]])\n",
      "######### Epoch: 53  ######### Train Loss: 0.00025280131376348436  ######### Relative L2 Test Norm: 14.680950164794922\n",
      "Output batch pred: tensor([[[0.9943],\n",
      "         [0.9963],\n",
      "         [0.0229],\n",
      "         [0.9990],\n",
      "         [0.9975],\n",
      "         [0.9968],\n",
      "         [0.9946],\n",
      "         [0.4363],\n",
      "         [0.9889],\n",
      "         [0.8413],\n",
      "         [0.9860],\n",
      "         [0.0223],\n",
      "         [0.4424],\n",
      "         [0.9887],\n",
      "         [0.9885],\n",
      "         [0.2266],\n",
      "         [0.9900],\n",
      "         [0.3316],\n",
      "         [0.3573],\n",
      "         [0.9908],\n",
      "         [0.0451],\n",
      "         [0.0354],\n",
      "         [0.9928],\n",
      "         [0.4543],\n",
      "         [0.9960],\n",
      "         [0.9979],\n",
      "         [0.4379],\n",
      "         [0.9857],\n",
      "         [0.9959],\n",
      "         [0.9934],\n",
      "         [0.9931],\n",
      "         [0.9547],\n",
      "         [0.6390],\n",
      "         [0.9897],\n",
      "         [0.9892],\n",
      "         [0.9920],\n",
      "         [0.0298],\n",
      "         [0.9135],\n",
      "         [0.5473],\n",
      "         [0.9952],\n",
      "         [0.9199],\n",
      "         [0.2332],\n",
      "         [0.0423],\n",
      "         [0.9903],\n",
      "         [0.4866],\n",
      "         [0.8397],\n",
      "         [0.2321],\n",
      "         [0.9942],\n",
      "         [0.9980],\n",
      "         [0.7264],\n",
      "         [1.0021],\n",
      "         [1.0030],\n",
      "         [0.1950],\n",
      "         [0.6121],\n",
      "         [0.9994],\n",
      "         [0.9970],\n",
      "         [0.9955],\n",
      "         [0.9795],\n",
      "         [0.3463],\n",
      "         [0.9955],\n",
      "         [0.8666],\n",
      "         [0.9947],\n",
      "         [0.7777],\n",
      "         [1.0018],\n",
      "         [1.0042],\n",
      "         [1.0059],\n",
      "         [0.3638],\n",
      "         [0.5106],\n",
      "         [1.0039],\n",
      "         [1.0038],\n",
      "         [1.0024],\n",
      "         [1.0012],\n",
      "         [0.5020],\n",
      "         [0.9966],\n",
      "         [0.5133],\n",
      "         [0.5033],\n",
      "         [0.9893],\n",
      "         [0.9898],\n",
      "         [0.9896],\n",
      "         [0.9877],\n",
      "         [0.2282],\n",
      "         [0.9926],\n",
      "         [0.9930],\n",
      "         [0.9981],\n",
      "         [0.3740],\n",
      "         [1.0003],\n",
      "         [0.4524],\n",
      "         [0.9662],\n",
      "         [0.9990],\n",
      "         [0.9952],\n",
      "         [0.9928],\n",
      "         [0.9932],\n",
      "         [0.3721],\n",
      "         [0.3546],\n",
      "         [0.5003],\n",
      "         [0.9956],\n",
      "         [1.0003],\n",
      "         [1.0017],\n",
      "         [1.0003],\n",
      "         [0.9998],\n",
      "         [0.4928],\n",
      "         [0.9934],\n",
      "         [0.4414],\n",
      "         [0.9861],\n",
      "         [0.9835],\n",
      "         [0.9852],\n",
      "         [0.4296],\n",
      "         [0.3701],\n",
      "         [0.4417],\n",
      "         [0.3635],\n",
      "         [0.9804],\n",
      "         [0.0405],\n",
      "         [0.9990],\n",
      "         [0.2486],\n",
      "         [0.9959],\n",
      "         [0.9934],\n",
      "         [0.9913],\n",
      "         [0.6806],\n",
      "         [0.9781],\n",
      "         [0.9920],\n",
      "         [0.9937],\n",
      "         [0.4346],\n",
      "         [0.9963],\n",
      "         [0.9584],\n",
      "         [0.9998],\n",
      "         [0.2484],\n",
      "         [0.4593],\n",
      "         [0.9951],\n",
      "         [0.9963],\n",
      "         [0.5140],\n",
      "         [0.9974],\n",
      "         [0.9984],\n",
      "         [0.3669],\n",
      "         [0.8683],\n",
      "         [0.9907],\n",
      "         [1.0045],\n",
      "         [1.0042],\n",
      "         [0.9437],\n",
      "         [1.0025],\n",
      "         [0.9284],\n",
      "         [0.9990],\n",
      "         [0.9977],\n",
      "         [0.9967],\n",
      "         [0.2467],\n",
      "         [0.9011],\n",
      "         [0.9587],\n",
      "         [0.9940],\n",
      "         [0.9908],\n",
      "         [0.9905],\n",
      "         [0.5128],\n",
      "         [0.9861],\n",
      "         [0.7267],\n",
      "         [0.0084],\n",
      "         [0.9881],\n",
      "         [0.1532],\n",
      "         [0.5376],\n",
      "         [0.9975],\n",
      "         [1.0003],\n",
      "         [1.0032],\n",
      "         [0.5204],\n",
      "         [1.0012],\n",
      "         [1.0012],\n",
      "         [0.7845],\n",
      "         [0.9953],\n",
      "         [0.9930],\n",
      "         [0.8069],\n",
      "         [0.4926],\n",
      "         [0.9892],\n",
      "         [0.9876],\n",
      "         [0.0380],\n",
      "         [0.3248],\n",
      "         [0.9889],\n",
      "         [0.6603],\n",
      "         [0.9878],\n",
      "         [0.9871],\n",
      "         [0.9883],\n",
      "         [0.9891],\n",
      "         [0.2152]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.9996],\n",
      "        [0.0209],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.4642],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.9998],\n",
      "        [0.3575],\n",
      "        [0.3840],\n",
      "        [0.9997],\n",
      "        [0.0383],\n",
      "        [0.0247],\n",
      "        [0.9996],\n",
      "        [0.4645],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.6327],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.8933],\n",
      "        [0.5463],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [0.2577],\n",
      "        [0.0368],\n",
      "        [0.9994],\n",
      "        [0.5009],\n",
      "        [0.8139],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2208],\n",
      "        [0.5945],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [0.3728],\n",
      "        [0.9999],\n",
      "        [0.8379],\n",
      "        [0.9956],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.9997],\n",
      "        [0.3753],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.9999],\n",
      "        [0.5165],\n",
      "        [0.5108],\n",
      "        [0.9959],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.3875],\n",
      "        [0.9995],\n",
      "        [0.4552],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9967],\n",
      "        [0.9999],\n",
      "        [0.3930],\n",
      "        [0.3747],\n",
      "        [0.5038],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.3912],\n",
      "        [0.4527],\n",
      "        [0.3780],\n",
      "        [0.9724],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.4454],\n",
      "        [0.9997],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.4668],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.8296],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.2735],\n",
      "        [0.8761],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.7820],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0335],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2518]])\n",
      "######### Epoch: 54  ######### Train Loss: 0.0001874818408396095  ######### Relative L2 Test Norm: 14.6990327835083\n",
      "Output batch pred: tensor([[[0.2432],\n",
      "         [0.9975],\n",
      "         [0.9965],\n",
      "         [0.5144],\n",
      "         [0.6786],\n",
      "         [0.9616],\n",
      "         [0.9970],\n",
      "         [0.9965],\n",
      "         [0.0162],\n",
      "         [0.4563],\n",
      "         [0.9941],\n",
      "         [0.9941],\n",
      "         [0.9922],\n",
      "         [0.9934],\n",
      "         [0.5094],\n",
      "         [0.2235],\n",
      "         [0.9888],\n",
      "         [0.9885],\n",
      "         [0.9873],\n",
      "         [0.2395],\n",
      "         [0.0369],\n",
      "         [0.4499],\n",
      "         [0.9936],\n",
      "         [0.9941],\n",
      "         [0.9963],\n",
      "         [0.4403],\n",
      "         [0.4547],\n",
      "         [0.9962],\n",
      "         [0.9942],\n",
      "         [0.2226],\n",
      "         [0.9883],\n",
      "         [0.9877],\n",
      "         [0.9850],\n",
      "         [0.9865],\n",
      "         [0.4999],\n",
      "         [0.8036],\n",
      "         [0.4877],\n",
      "         [0.5433],\n",
      "         [0.9934],\n",
      "         [0.4388],\n",
      "         [0.7790],\n",
      "         [0.9727],\n",
      "         [0.9914],\n",
      "         [0.6782],\n",
      "         [0.5242],\n",
      "         [0.9458],\n",
      "         [0.9862],\n",
      "         [0.9866],\n",
      "         [0.9871],\n",
      "         [0.9904],\n",
      "         [0.3208],\n",
      "         [0.9794],\n",
      "         [0.9927],\n",
      "         [0.9946],\n",
      "         [0.9955],\n",
      "         [0.4971],\n",
      "         [0.1551],\n",
      "         [0.9971],\n",
      "         [0.9612],\n",
      "         [0.6535],\n",
      "         [0.3582],\n",
      "         [0.9967],\n",
      "         [0.0422],\n",
      "         [0.9948],\n",
      "         [0.0366],\n",
      "         [0.2411],\n",
      "         [0.0409],\n",
      "         [0.9900],\n",
      "         [0.9880],\n",
      "         [0.2263],\n",
      "         [0.2415],\n",
      "         [0.9912],\n",
      "         [0.9923],\n",
      "         [0.4986],\n",
      "         [0.9892],\n",
      "         [0.9900],\n",
      "         [0.9884],\n",
      "         [0.9887],\n",
      "         [0.9858],\n",
      "         [0.3430],\n",
      "         [0.9899],\n",
      "         [0.9912],\n",
      "         [0.9910],\n",
      "         [0.9942],\n",
      "         [0.7193],\n",
      "         [0.9957],\n",
      "         [0.9942],\n",
      "         [0.9935],\n",
      "         [0.0439],\n",
      "         [0.8937],\n",
      "         [0.0256],\n",
      "         [0.3476],\n",
      "         [0.9830],\n",
      "         [0.9834],\n",
      "         [0.9822],\n",
      "         [0.3558],\n",
      "         [0.9846],\n",
      "         [0.9876],\n",
      "         [0.2297],\n",
      "         [0.4891],\n",
      "         [0.8476],\n",
      "         [0.9924],\n",
      "         [0.9929],\n",
      "         [0.9585],\n",
      "         [0.9939],\n",
      "         [0.9925],\n",
      "         [0.9933],\n",
      "         [0.2012],\n",
      "         [0.0507],\n",
      "         [0.5047],\n",
      "         [0.7678],\n",
      "         [0.4459],\n",
      "         [0.3772],\n",
      "         [0.9829],\n",
      "         [0.9959],\n",
      "         [0.9962],\n",
      "         [0.9970],\n",
      "         [0.9989],\n",
      "         [0.6199],\n",
      "         [0.9418],\n",
      "         [1.0016],\n",
      "         [1.0009],\n",
      "         [0.4633],\n",
      "         [0.9962],\n",
      "         [0.9934],\n",
      "         [0.3638],\n",
      "         [0.9933],\n",
      "         [0.9957],\n",
      "         [0.4507],\n",
      "         [0.9989],\n",
      "         [0.3790],\n",
      "         [1.0029],\n",
      "         [1.0039],\n",
      "         [0.9318],\n",
      "         [1.0023],\n",
      "         [0.8718],\n",
      "         [0.8622],\n",
      "         [0.9942],\n",
      "         [0.9910],\n",
      "         [0.9908],\n",
      "         [0.9859],\n",
      "         [0.9919],\n",
      "         [0.3560],\n",
      "         [0.9949],\n",
      "         [0.5334],\n",
      "         [0.9987],\n",
      "         [0.9880],\n",
      "         [0.9985],\n",
      "         [0.9980],\n",
      "         [0.9963],\n",
      "         [0.9928],\n",
      "         [0.4881],\n",
      "         [0.9897],\n",
      "         [0.9892],\n",
      "         [0.3476],\n",
      "         [0.9906],\n",
      "         [0.9882],\n",
      "         [0.9908],\n",
      "         [0.9889],\n",
      "         [0.9182],\n",
      "         [0.9764],\n",
      "         [0.4295],\n",
      "         [0.8369],\n",
      "         [0.9887],\n",
      "         [0.0209],\n",
      "         [0.9883],\n",
      "         [0.9082],\n",
      "         [0.9900],\n",
      "         [0.9915],\n",
      "         [0.9930],\n",
      "         [0.4943],\n",
      "         [0.9944],\n",
      "         [0.9967],\n",
      "         [0.4339],\n",
      "         [0.9962],\n",
      "         [0.3399],\n",
      "         [0.9958],\n",
      "         [0.7435]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2610],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.5139],\n",
      "        [0.6555],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0000],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.9998],\n",
      "        [0.5151],\n",
      "        [0.2518],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [0.0335],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5165],\n",
      "        [0.7820],\n",
      "        [0.5009],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.7540],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.5334],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.1762],\n",
      "        [0.9998],\n",
      "        [0.9490],\n",
      "        [0.6327],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9997],\n",
      "        [0.0142],\n",
      "        [0.2646],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.2577],\n",
      "        [0.2735],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.8761],\n",
      "        [0.0209],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.5038],\n",
      "        [0.8223],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9999],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.0383],\n",
      "        [0.5080],\n",
      "        [0.7391],\n",
      "        [0.4552],\n",
      "        [0.3930],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.4668],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.9999],\n",
      "        [0.5245],\n",
      "        [0.9999],\n",
      "        [0.9820],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.9044],\n",
      "        [0.9814],\n",
      "        [0.4503],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.9997],\n",
      "        [0.8933],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [0.9994],\n",
      "        [0.7129]])\n",
      "######### Epoch: 55  ######### Train Loss: 0.00021382760314736515  ######### Relative L2 Test Norm: 14.763204574584961\n",
      "Output batch pred: tensor([[[0.9942],\n",
      "         [0.6525],\n",
      "         [0.9540],\n",
      "         [0.9943],\n",
      "         [0.9908],\n",
      "         [0.7610],\n",
      "         [0.6761],\n",
      "         [0.0350],\n",
      "         [0.9848],\n",
      "         [0.7977],\n",
      "         [0.9849],\n",
      "         [0.2392],\n",
      "         [0.9510],\n",
      "         [0.8499],\n",
      "         [0.4353],\n",
      "         [0.3562],\n",
      "         [0.9949],\n",
      "         [0.7878],\n",
      "         [0.9977],\n",
      "         [0.5062],\n",
      "         [0.9980],\n",
      "         [0.9986],\n",
      "         [0.9981],\n",
      "         [0.9967],\n",
      "         [0.9587],\n",
      "         [0.9905],\n",
      "         [0.9891],\n",
      "         [0.4858],\n",
      "         [0.9814],\n",
      "         [0.0286],\n",
      "         [0.9777],\n",
      "         [0.4080],\n",
      "         [0.3447],\n",
      "         [0.4223],\n",
      "         [0.9807],\n",
      "         [0.2276],\n",
      "         [0.9890],\n",
      "         [0.0378],\n",
      "         [0.0571],\n",
      "         [1.0000],\n",
      "         [0.5616],\n",
      "         [0.9998],\n",
      "         [0.7268],\n",
      "         [0.9961],\n",
      "         [0.9944],\n",
      "         [0.9917],\n",
      "         [0.0131],\n",
      "         [0.9857],\n",
      "         [0.9851],\n",
      "         [0.0310],\n",
      "         [0.9861],\n",
      "         [0.3292],\n",
      "         [0.9892],\n",
      "         [0.4452],\n",
      "         [0.5062],\n",
      "         [0.9904],\n",
      "         [0.9935],\n",
      "         [0.9817],\n",
      "         [0.9939],\n",
      "         [0.9320],\n",
      "         [0.3553],\n",
      "         [0.9188],\n",
      "         [0.9904],\n",
      "         [0.9901],\n",
      "         [0.2162],\n",
      "         [0.9914],\n",
      "         [0.9925],\n",
      "         [0.9937],\n",
      "         [0.9950],\n",
      "         [0.9963],\n",
      "         [0.0341],\n",
      "         [0.9954],\n",
      "         [0.9949],\n",
      "         [0.6773],\n",
      "         [0.2489],\n",
      "         [0.4416],\n",
      "         [0.9900],\n",
      "         [0.3486],\n",
      "         [0.9873],\n",
      "         [0.9895],\n",
      "         [0.8967],\n",
      "         [0.9740],\n",
      "         [0.9939],\n",
      "         [0.8484],\n",
      "         [0.1658],\n",
      "         [0.5474],\n",
      "         [0.9996],\n",
      "         [0.9987],\n",
      "         [0.2340],\n",
      "         [0.9917],\n",
      "         [0.9897],\n",
      "         [0.9874],\n",
      "         [0.9869],\n",
      "         [0.9863],\n",
      "         [0.9856],\n",
      "         [0.9886],\n",
      "         [0.4426],\n",
      "         [0.9182],\n",
      "         [0.9938],\n",
      "         [0.9945],\n",
      "         [0.9150],\n",
      "         [0.9908],\n",
      "         [0.3619],\n",
      "         [0.9916],\n",
      "         [0.9900],\n",
      "         [0.9890],\n",
      "         [0.3479],\n",
      "         [0.3312],\n",
      "         [0.0308],\n",
      "         [0.9534],\n",
      "         [0.9898],\n",
      "         [0.9856],\n",
      "         [0.4914],\n",
      "         [0.9892],\n",
      "         [0.2440],\n",
      "         [0.9864],\n",
      "         [0.5068],\n",
      "         [0.9896],\n",
      "         [0.9894],\n",
      "         [0.3576],\n",
      "         [0.9907],\n",
      "         [0.9908],\n",
      "         [0.9915],\n",
      "         [0.3733],\n",
      "         [0.2011],\n",
      "         [0.9926],\n",
      "         [0.9936],\n",
      "         [0.4572],\n",
      "         [0.0333],\n",
      "         [0.9958],\n",
      "         [0.9956],\n",
      "         [0.7487],\n",
      "         [0.9975],\n",
      "         [0.9965],\n",
      "         [0.9963],\n",
      "         [0.9949],\n",
      "         [0.9953],\n",
      "         [0.9812],\n",
      "         [0.9948],\n",
      "         [0.5030],\n",
      "         [0.8510],\n",
      "         [0.9939],\n",
      "         [0.3768],\n",
      "         [0.9925],\n",
      "         [0.2390],\n",
      "         [0.4979],\n",
      "         [0.9908],\n",
      "         [0.9894],\n",
      "         [0.5036],\n",
      "         [0.9868],\n",
      "         [0.9867],\n",
      "         [0.9875],\n",
      "         [0.9875],\n",
      "         [0.5213],\n",
      "         [0.9936],\n",
      "         [0.9842],\n",
      "         [0.8701],\n",
      "         [0.6205],\n",
      "         [0.9984],\n",
      "         [0.9994],\n",
      "         [0.4686],\n",
      "         [0.9977],\n",
      "         [0.4571],\n",
      "         [0.9915],\n",
      "         [0.2357],\n",
      "         [0.9905],\n",
      "         [0.9889],\n",
      "         [0.9880],\n",
      "         [0.5009],\n",
      "         [0.9924],\n",
      "         [0.4893],\n",
      "         [0.9943],\n",
      "         [0.4297],\n",
      "         [0.9950],\n",
      "         [0.9817],\n",
      "         [0.9945],\n",
      "         [0.9936],\n",
      "         [0.9941]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.6327],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.7391],\n",
      "        [0.6628],\n",
      "        [0.0368],\n",
      "        [0.9994],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.9515],\n",
      "        [0.8296],\n",
      "        [0.4503],\n",
      "        [0.3753],\n",
      "        [0.9999],\n",
      "        [0.7540],\n",
      "        [0.9998],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.9997],\n",
      "        [0.4480],\n",
      "        [0.3875],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.0383],\n",
      "        [0.9997],\n",
      "        [0.5463],\n",
      "        [0.9996],\n",
      "        [0.6920],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.3780],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.0288],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.2686],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.9724],\n",
      "        [0.9967],\n",
      "        [0.8139],\n",
      "        [0.1762],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.4580],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.3575],\n",
      "        [0.0247],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.9959],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.0209],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.9998],\n",
      "        [0.5080],\n",
      "        [0.8223],\n",
      "        [0.9999],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.5245],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [0.8379],\n",
      "        [0.5945],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000]])\n",
      "######### Epoch: 56  ######### Train Loss: 0.00022584943508263677  ######### Relative L2 Test Norm: 14.360286712646484\n",
      "Output batch pred: tensor([[[0.2599],\n",
      "         [0.9906],\n",
      "         [0.9914],\n",
      "         [0.3686],\n",
      "         [0.9895],\n",
      "         [0.9894],\n",
      "         [0.9910],\n",
      "         [0.9906],\n",
      "         [0.3384],\n",
      "         [0.5003],\n",
      "         [0.4381],\n",
      "         [0.3733],\n",
      "         [0.3479],\n",
      "         [0.9964],\n",
      "         [0.9983],\n",
      "         [0.9976],\n",
      "         [0.1988],\n",
      "         [0.5160],\n",
      "         [0.9944],\n",
      "         [0.9927],\n",
      "         [0.9908],\n",
      "         [0.9892],\n",
      "         [0.9514],\n",
      "         [0.9864],\n",
      "         [0.7575],\n",
      "         [0.9833],\n",
      "         [0.9860],\n",
      "         [0.9858],\n",
      "         [0.0302],\n",
      "         [0.9902],\n",
      "         [0.9920],\n",
      "         [0.9903],\n",
      "         [0.9942],\n",
      "         [0.0455],\n",
      "         [0.9941],\n",
      "         [0.9914],\n",
      "         [0.0577],\n",
      "         [0.0506],\n",
      "         [0.3506],\n",
      "         [0.9854],\n",
      "         [0.9840],\n",
      "         [0.4779],\n",
      "         [0.9833],\n",
      "         [0.9847],\n",
      "         [0.9454],\n",
      "         [0.9889],\n",
      "         [0.9919],\n",
      "         [0.9225],\n",
      "         [0.5057],\n",
      "         [0.4639],\n",
      "         [1.0006],\n",
      "         [0.9990],\n",
      "         [0.0216],\n",
      "         [0.9914],\n",
      "         [0.9912],\n",
      "         [0.0222],\n",
      "         [0.9740],\n",
      "         [0.9851],\n",
      "         [0.9839],\n",
      "         [0.5256],\n",
      "         [0.9869],\n",
      "         [0.7323],\n",
      "         [0.9905],\n",
      "         [0.9916],\n",
      "         [0.6835],\n",
      "         [0.9936],\n",
      "         [0.9955],\n",
      "         [0.8151],\n",
      "         [0.4400],\n",
      "         [0.2470],\n",
      "         [0.9985],\n",
      "         [0.2473],\n",
      "         [1.0003],\n",
      "         [0.7334],\n",
      "         [1.0006],\n",
      "         [0.9996],\n",
      "         [0.9987],\n",
      "         [0.9602],\n",
      "         [0.9911],\n",
      "         [0.8934],\n",
      "         [0.9102],\n",
      "         [0.8480],\n",
      "         [0.9787],\n",
      "         [0.9799],\n",
      "         [0.9808],\n",
      "         [0.4977],\n",
      "         [0.9868],\n",
      "         [0.9895],\n",
      "         [0.3606],\n",
      "         [0.0415],\n",
      "         [0.9980],\n",
      "         [0.4520],\n",
      "         [0.6159],\n",
      "         [0.9948],\n",
      "         [0.1592],\n",
      "         [0.9882],\n",
      "         [0.9851],\n",
      "         [0.9836],\n",
      "         [0.9812],\n",
      "         [0.8386],\n",
      "         [0.9837],\n",
      "         [0.5041],\n",
      "         [0.6444],\n",
      "         [0.7784],\n",
      "         [0.9941],\n",
      "         [0.9930],\n",
      "         [0.2427],\n",
      "         [0.3682],\n",
      "         [0.9896],\n",
      "         [0.4425],\n",
      "         [0.0445],\n",
      "         [0.9853],\n",
      "         [0.9833],\n",
      "         [0.4398],\n",
      "         [0.9561],\n",
      "         [0.9937],\n",
      "         [0.9987],\n",
      "         [0.9836],\n",
      "         [1.0042],\n",
      "         [0.6957],\n",
      "         [1.0069],\n",
      "         [0.3739],\n",
      "         [1.0008],\n",
      "         [0.9943],\n",
      "         [0.9936],\n",
      "         [0.5025],\n",
      "         [0.9895],\n",
      "         [0.8516],\n",
      "         [0.9759],\n",
      "         [0.8401],\n",
      "         [0.4562],\n",
      "         [0.9827],\n",
      "         [0.9959],\n",
      "         [0.0435],\n",
      "         [0.9981],\n",
      "         [0.2386],\n",
      "         [0.4576],\n",
      "         [0.9324],\n",
      "         [0.9921],\n",
      "         [0.9894],\n",
      "         [0.4358],\n",
      "         [0.9905],\n",
      "         [0.9898],\n",
      "         [0.4956],\n",
      "         [0.9919],\n",
      "         [0.9936],\n",
      "         [0.9141],\n",
      "         [0.9931],\n",
      "         [0.9899],\n",
      "         [0.9892],\n",
      "         [0.9849],\n",
      "         [0.9858],\n",
      "         [0.9841],\n",
      "         [0.9849],\n",
      "         [0.9873],\n",
      "         [0.9880],\n",
      "         [0.9923],\n",
      "         [0.9931],\n",
      "         [0.5319],\n",
      "         [0.9827],\n",
      "         [0.9967],\n",
      "         [0.2536],\n",
      "         [0.2560],\n",
      "         [0.5459],\n",
      "         [0.3527],\n",
      "         [0.3668],\n",
      "         [0.4931],\n",
      "         [0.9835],\n",
      "         [0.9838],\n",
      "         [0.9834],\n",
      "         [0.9877],\n",
      "         [0.9889],\n",
      "         [0.4494],\n",
      "         [0.4916],\n",
      "         [0.9939],\n",
      "         [0.9941],\n",
      "         [0.2441],\n",
      "         [0.3816]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2735],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.5038],\n",
      "        [0.4454],\n",
      "        [0.3840],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.0383],\n",
      "        [0.0335],\n",
      "        [0.3728],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9009],\n",
      "        [0.5054],\n",
      "        [0.4642],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9819],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.5334],\n",
      "        [0.9997],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.4480],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [0.6920],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.9044],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [0.4527],\n",
      "        [0.5945],\n",
      "        [0.9999],\n",
      "        [0.1762],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.6327],\n",
      "        [0.7540],\n",
      "        [0.9998],\n",
      "        [0.9966],\n",
      "        [0.2547],\n",
      "        [0.3808],\n",
      "        [0.9997],\n",
      "        [0.4552],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.4580],\n",
      "        [0.9515],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.9994],\n",
      "        [0.6555],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [0.8296],\n",
      "        [0.9804],\n",
      "        [0.8139],\n",
      "        [0.4645],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.4611],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.5030],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.2729],\n",
      "        [0.5463],\n",
      "        [0.3747],\n",
      "        [0.3930],\n",
      "        [0.5108],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.5009],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.3912]])\n",
      "######### Epoch: 57  ######### Train Loss: 0.00018021637515630573  ######### Relative L2 Test Norm: 14.288057327270508\n",
      "Output batch pred: tensor([[[0.9914],\n",
      "         [0.9916],\n",
      "         [0.0393],\n",
      "         [0.8489],\n",
      "         [0.9922],\n",
      "         [0.9914],\n",
      "         [0.9917],\n",
      "         [0.9918],\n",
      "         [0.9937],\n",
      "         [0.9940],\n",
      "         [0.3362],\n",
      "         [0.6878],\n",
      "         [0.3587],\n",
      "         [0.9934],\n",
      "         [0.4481],\n",
      "         [0.3570],\n",
      "         [0.9927],\n",
      "         [0.9917],\n",
      "         [0.4571],\n",
      "         [0.9925],\n",
      "         [0.6083],\n",
      "         [0.9915],\n",
      "         [0.3611],\n",
      "         [0.8582],\n",
      "         [0.5044],\n",
      "         [0.9942],\n",
      "         [0.0481],\n",
      "         [0.9951],\n",
      "         [0.9803],\n",
      "         [0.3701],\n",
      "         [0.1642],\n",
      "         [0.9914],\n",
      "         [0.9545],\n",
      "         [0.3647],\n",
      "         [0.2261],\n",
      "         [0.9912],\n",
      "         [0.9873],\n",
      "         [0.9915],\n",
      "         [0.9939],\n",
      "         [0.9927],\n",
      "         [0.9922],\n",
      "         [0.5486],\n",
      "         [0.8603],\n",
      "         [0.9701],\n",
      "         [0.9900],\n",
      "         [0.5026],\n",
      "         [0.8393],\n",
      "         [0.4317],\n",
      "         [0.9934],\n",
      "         [0.9959],\n",
      "         [0.5058],\n",
      "         [0.9988],\n",
      "         [0.9977],\n",
      "         [0.9985],\n",
      "         [0.9959],\n",
      "         [0.0272],\n",
      "         [0.7417],\n",
      "         [0.7649],\n",
      "         [0.9886],\n",
      "         [0.9872],\n",
      "         [0.9832],\n",
      "         [0.9867],\n",
      "         [0.9863],\n",
      "         [0.9883],\n",
      "         [0.2462],\n",
      "         [0.9896],\n",
      "         [0.2051],\n",
      "         [0.9943],\n",
      "         [0.4659],\n",
      "         [0.9973],\n",
      "         [0.4531],\n",
      "         [0.9991],\n",
      "         [0.5491],\n",
      "         [0.9967],\n",
      "         [0.7246],\n",
      "         [0.2443],\n",
      "         [0.9556],\n",
      "         [0.9889],\n",
      "         [0.2322],\n",
      "         [0.8915],\n",
      "         [0.9853],\n",
      "         [0.9074],\n",
      "         [0.9888],\n",
      "         [0.9910],\n",
      "         [0.3780],\n",
      "         [0.9960],\n",
      "         [0.9980],\n",
      "         [0.9979],\n",
      "         [0.6579],\n",
      "         [0.9965],\n",
      "         [0.9947],\n",
      "         [0.9913],\n",
      "         [0.0484],\n",
      "         [0.2506],\n",
      "         [0.9890],\n",
      "         [0.5071],\n",
      "         [0.9882],\n",
      "         [0.9892],\n",
      "         [0.9881],\n",
      "         [0.9891],\n",
      "         [0.9854],\n",
      "         [0.3561],\n",
      "         [0.9854],\n",
      "         [0.9831],\n",
      "         [0.5043],\n",
      "         [0.9834],\n",
      "         [0.9859],\n",
      "         [0.0483],\n",
      "         [0.9277],\n",
      "         [0.9923],\n",
      "         [0.8134],\n",
      "         [0.0440],\n",
      "         [0.6790],\n",
      "         [0.9954],\n",
      "         [0.0404],\n",
      "         [0.9940],\n",
      "         [0.9825],\n",
      "         [0.0564],\n",
      "         [0.5074],\n",
      "         [0.9944],\n",
      "         [0.9951],\n",
      "         [0.9949],\n",
      "         [0.9547],\n",
      "         [0.9827],\n",
      "         [0.9930],\n",
      "         [0.9936],\n",
      "         [0.9935],\n",
      "         [0.9583],\n",
      "         [0.5035],\n",
      "         [0.4569],\n",
      "         [0.9921],\n",
      "         [0.9952],\n",
      "         [0.9964],\n",
      "         [0.9254],\n",
      "         [0.9978],\n",
      "         [0.9964],\n",
      "         [0.4562],\n",
      "         [0.4423],\n",
      "         [0.9936],\n",
      "         [0.9922],\n",
      "         [0.3771],\n",
      "         [0.9900],\n",
      "         [0.9891],\n",
      "         [0.2335],\n",
      "         [0.9922],\n",
      "         [0.3431],\n",
      "         [0.9948],\n",
      "         [0.9936],\n",
      "         [0.9941],\n",
      "         [0.9919],\n",
      "         [0.9930],\n",
      "         [0.4449],\n",
      "         [0.5099],\n",
      "         [0.7764],\n",
      "         [0.9766],\n",
      "         [0.9889],\n",
      "         [0.9913],\n",
      "         [0.2446],\n",
      "         [0.9923],\n",
      "         [0.4947],\n",
      "         [0.9903],\n",
      "         [0.9160],\n",
      "         [0.9894],\n",
      "         [0.9884],\n",
      "         [0.9866],\n",
      "         [0.9856],\n",
      "         [0.2308],\n",
      "         [0.4832],\n",
      "         [0.3533],\n",
      "         [0.9907],\n",
      "         [0.4343],\n",
      "         [0.9918],\n",
      "         [0.9950],\n",
      "         [0.0225],\n",
      "         [0.9950],\n",
      "         [0.5292],\n",
      "         [0.9926],\n",
      "         [0.9917]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.9997],\n",
      "        [0.0288],\n",
      "        [0.8223],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.6628],\n",
      "        [0.3747],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.3728],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.8296],\n",
      "        [0.5030],\n",
      "        [0.9994],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [0.3840],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.3875],\n",
      "        [0.2547],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.5463],\n",
      "        [0.8379],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.8139],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.0174],\n",
      "        [0.7129],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.9998],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.2646],\n",
      "        [0.9490],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.8761],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.3912],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.0247],\n",
      "        [0.6555],\n",
      "        [0.9995],\n",
      "        [0.0142],\n",
      "        [0.9997],\n",
      "        [0.9819],\n",
      "        [0.0383],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9420],\n",
      "        [0.9820],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.5080],\n",
      "        [0.4642],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9044],\n",
      "        [0.9996],\n",
      "        [0.9996],\n",
      "        [0.4611],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9997],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.5165],\n",
      "        [0.7540],\n",
      "        [0.9804],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.4988],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.9994],\n",
      "        [1.0000]])\n",
      "######### Epoch: 58  ######### Train Loss: 0.0001751222589518875  ######### Relative L2 Test Norm: 14.267128944396973\n",
      "Output batch pred: tensor([[[0.4989],\n",
      "         [0.9922],\n",
      "         [0.9905],\n",
      "         [0.9915],\n",
      "         [0.9915],\n",
      "         [0.5071],\n",
      "         [0.2362],\n",
      "         [0.3741],\n",
      "         [0.9953],\n",
      "         [0.9835],\n",
      "         [0.3815],\n",
      "         [0.9026],\n",
      "         [0.4386],\n",
      "         [0.9951],\n",
      "         [0.9937],\n",
      "         [0.9937],\n",
      "         [0.2299],\n",
      "         [0.0333],\n",
      "         [0.9129],\n",
      "         [0.0510],\n",
      "         [0.9203],\n",
      "         [0.9943],\n",
      "         [0.0433],\n",
      "         [0.9627],\n",
      "         [0.9981],\n",
      "         [0.9972],\n",
      "         [0.9623],\n",
      "         [0.9903],\n",
      "         [0.9310],\n",
      "         [0.4926],\n",
      "         [0.4510],\n",
      "         [0.9892],\n",
      "         [0.9879],\n",
      "         [0.9889],\n",
      "         [0.0269],\n",
      "         [0.9922],\n",
      "         [0.9930],\n",
      "         [0.5083],\n",
      "         [0.2535],\n",
      "         [0.9955],\n",
      "         [0.9951],\n",
      "         [0.9935],\n",
      "         [0.9201],\n",
      "         [0.8492],\n",
      "         [0.9896],\n",
      "         [0.9885],\n",
      "         [0.9877],\n",
      "         [0.9518],\n",
      "         [0.3562],\n",
      "         [0.9900],\n",
      "         [0.3370],\n",
      "         [0.9922],\n",
      "         [0.9930],\n",
      "         [0.9906],\n",
      "         [0.9922],\n",
      "         [0.5065],\n",
      "         [0.9924],\n",
      "         [0.9921],\n",
      "         [0.9914],\n",
      "         [0.9718],\n",
      "         [0.9903],\n",
      "         [0.0311],\n",
      "         [0.9917],\n",
      "         [0.2390],\n",
      "         [0.9933],\n",
      "         [0.9924],\n",
      "         [0.4595],\n",
      "         [0.9952],\n",
      "         [0.9960],\n",
      "         [0.3697],\n",
      "         [0.5194],\n",
      "         [0.4690],\n",
      "         [0.9952],\n",
      "         [0.9841],\n",
      "         [0.9959],\n",
      "         [0.9960],\n",
      "         [0.9960],\n",
      "         [0.3791],\n",
      "         [0.4468],\n",
      "         [0.9956],\n",
      "         [0.9991],\n",
      "         [0.4645],\n",
      "         [1.0002],\n",
      "         [1.0005],\n",
      "         [0.8554],\n",
      "         [0.2492],\n",
      "         [0.9982],\n",
      "         [0.9839],\n",
      "         [0.9951],\n",
      "         [0.9530],\n",
      "         [0.9895],\n",
      "         [0.9911],\n",
      "         [0.9896],\n",
      "         [0.9911],\n",
      "         [0.4461],\n",
      "         [0.9918],\n",
      "         [0.8131],\n",
      "         [0.9933],\n",
      "         [0.3748],\n",
      "         [0.9943],\n",
      "         [0.9947],\n",
      "         [0.4673],\n",
      "         [0.9951],\n",
      "         [0.9950],\n",
      "         [0.9940],\n",
      "         [0.8623],\n",
      "         [0.9937],\n",
      "         [0.9952],\n",
      "         [0.9938],\n",
      "         [0.9932],\n",
      "         [0.9800],\n",
      "         [0.9924],\n",
      "         [0.9920],\n",
      "         [0.9908],\n",
      "         [0.6044],\n",
      "         [0.9889],\n",
      "         [0.9871],\n",
      "         [0.9868],\n",
      "         [0.9886],\n",
      "         [0.8573],\n",
      "         [0.9872],\n",
      "         [0.3607],\n",
      "         [0.7376],\n",
      "         [0.4409],\n",
      "         [0.0569],\n",
      "         [0.9943],\n",
      "         [0.9933],\n",
      "         [0.9955],\n",
      "         [0.9968],\n",
      "         [0.3493],\n",
      "         [0.9980],\n",
      "         [0.0383],\n",
      "         [0.9952],\n",
      "         [0.5001],\n",
      "         [0.9965],\n",
      "         [0.7218],\n",
      "         [0.9935],\n",
      "         [0.9928],\n",
      "         [0.9922],\n",
      "         [0.1609],\n",
      "         [0.9923],\n",
      "         [0.9938],\n",
      "         [0.3554],\n",
      "         [0.4406],\n",
      "         [0.9933],\n",
      "         [0.9912],\n",
      "         [0.9900],\n",
      "         [0.9899],\n",
      "         [0.5438],\n",
      "         [0.4939],\n",
      "         [0.6445],\n",
      "         [0.5243],\n",
      "         [0.0482],\n",
      "         [0.9924],\n",
      "         [0.7694],\n",
      "         [0.6787],\n",
      "         [0.9973],\n",
      "         [0.9970],\n",
      "         [0.5411],\n",
      "         [0.9925],\n",
      "         [0.3511],\n",
      "         [0.2466],\n",
      "         [0.9852],\n",
      "         [0.9836],\n",
      "         [0.4995],\n",
      "         [0.2395],\n",
      "         [0.9846],\n",
      "         [0.9873],\n",
      "         [0.9879],\n",
      "         [0.6835],\n",
      "         [0.7823],\n",
      "         [0.2488],\n",
      "         [0.9977],\n",
      "         [0.2129],\n",
      "         [0.9986],\n",
      "         [0.5229],\n",
      "         [0.9953],\n",
      "         [0.0544]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.5038],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.2610],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.3930],\n",
      "        [0.8761],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.0174],\n",
      "        [0.8933],\n",
      "        [0.0383],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9956],\n",
      "        [0.9164],\n",
      "        [0.5009],\n",
      "        [0.4645],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5054],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9044],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9962],\n",
      "        [0.9999],\n",
      "        [0.5080],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3747],\n",
      "        [0.5108],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.3875],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.2547],\n",
      "        [0.9999],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.8296],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9966],\n",
      "        [0.3808],\n",
      "        [0.7129],\n",
      "        [0.4503],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.9994],\n",
      "        [0.0209],\n",
      "        [0.9959],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.1762],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.5030],\n",
      "        [0.6327],\n",
      "        [0.5245],\n",
      "        [0.0288],\n",
      "        [0.9998],\n",
      "        [0.7391],\n",
      "        [0.6555],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.5334],\n",
      "        [0.9994],\n",
      "        [0.3728],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.2729],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.7540],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9997],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.0335]])\n",
      "######### Epoch: 59  ######### Train Loss: 0.0001619089744053781  ######### Relative L2 Test Norm: 14.114388465881348\n",
      "Output batch pred: tensor([[[0.4612],\n",
      "         [1.0007],\n",
      "         [1.0009],\n",
      "         [0.4703],\n",
      "         [0.8582],\n",
      "         [0.2534],\n",
      "         [0.9946],\n",
      "         [0.9910],\n",
      "         [0.5125],\n",
      "         [0.9903],\n",
      "         [0.4900],\n",
      "         [0.1629],\n",
      "         [0.6477],\n",
      "         [0.9793],\n",
      "         [0.9934],\n",
      "         [0.4612],\n",
      "         [0.9957],\n",
      "         [0.5156],\n",
      "         [0.9963],\n",
      "         [0.0554],\n",
      "         [0.9976],\n",
      "         [0.7487],\n",
      "         [0.4543],\n",
      "         [0.3799],\n",
      "         [0.9791],\n",
      "         [0.9972],\n",
      "         [0.3523],\n",
      "         [0.9979],\n",
      "         [0.4686],\n",
      "         [0.9961],\n",
      "         [0.9953],\n",
      "         [0.9948],\n",
      "         [0.3649],\n",
      "         [0.9938],\n",
      "         [0.9944],\n",
      "         [0.9947],\n",
      "         [0.4450],\n",
      "         [0.8670],\n",
      "         [0.9043],\n",
      "         [0.7892],\n",
      "         [0.0568],\n",
      "         [0.9984],\n",
      "         [0.5063],\n",
      "         [0.9621],\n",
      "         [0.9964],\n",
      "         [0.9946],\n",
      "         [0.2309],\n",
      "         [0.6713],\n",
      "         [0.9878],\n",
      "         [0.9881],\n",
      "         [0.3534],\n",
      "         [0.9854],\n",
      "         [0.9855],\n",
      "         [0.9860],\n",
      "         [0.9887],\n",
      "         [0.9895],\n",
      "         [0.3735],\n",
      "         [0.9930],\n",
      "         [0.8143],\n",
      "         [0.9838],\n",
      "         [0.9837],\n",
      "         [0.9979],\n",
      "         [0.9982],\n",
      "         [0.4616],\n",
      "         [0.9964],\n",
      "         [0.9971],\n",
      "         [0.2561],\n",
      "         [0.9951],\n",
      "         [0.9931],\n",
      "         [0.4429],\n",
      "         [0.9972],\n",
      "         [0.9955],\n",
      "         [0.5106],\n",
      "         [0.9991],\n",
      "         [0.4490],\n",
      "         [0.9977],\n",
      "         [0.5101],\n",
      "         [0.9944],\n",
      "         [0.5530],\n",
      "         [0.9916],\n",
      "         [0.9930],\n",
      "         [0.9787],\n",
      "         [0.6106],\n",
      "         [0.9937],\n",
      "         [0.0336],\n",
      "         [0.9985],\n",
      "         [0.3718],\n",
      "         [0.9999],\n",
      "         [0.3961],\n",
      "         [1.0011],\n",
      "         [1.0013],\n",
      "         [0.9654],\n",
      "         [0.9957],\n",
      "         [0.2488],\n",
      "         [0.9201],\n",
      "         [0.9902],\n",
      "         [0.0438],\n",
      "         [0.9874],\n",
      "         [0.9901],\n",
      "         [0.5175],\n",
      "         [0.9581],\n",
      "         [0.9939],\n",
      "         [0.9957],\n",
      "         [0.0386],\n",
      "         [0.9967],\n",
      "         [0.9955],\n",
      "         [0.9958],\n",
      "         [0.9940],\n",
      "         [0.6905],\n",
      "         [0.2419],\n",
      "         [0.5310],\n",
      "         [0.9911],\n",
      "         [0.9895],\n",
      "         [0.8543],\n",
      "         [0.9288],\n",
      "         [0.9907],\n",
      "         [0.9896],\n",
      "         [0.9912],\n",
      "         [0.0393],\n",
      "         [0.9912],\n",
      "         [0.9928],\n",
      "         [0.5040],\n",
      "         [0.7211],\n",
      "         [0.3466],\n",
      "         [0.9957],\n",
      "         [0.9970],\n",
      "         [0.9938],\n",
      "         [0.2524],\n",
      "         [0.9997],\n",
      "         [1.0010],\n",
      "         [1.0014],\n",
      "         [1.0014],\n",
      "         [0.2493],\n",
      "         [0.5553],\n",
      "         [0.9999],\n",
      "         [0.9983],\n",
      "         [0.9944],\n",
      "         [0.9213],\n",
      "         [0.9929],\n",
      "         [0.3516],\n",
      "         [0.9905],\n",
      "         [0.9887],\n",
      "         [0.8394],\n",
      "         [0.9920],\n",
      "         [0.9931],\n",
      "         [0.9930],\n",
      "         [0.2610],\n",
      "         [0.3811],\n",
      "         [0.0633],\n",
      "         [0.5210],\n",
      "         [0.9168],\n",
      "         [0.9932],\n",
      "         [0.9936],\n",
      "         [0.9936],\n",
      "         [0.0522],\n",
      "         [0.9934],\n",
      "         [0.9943],\n",
      "         [0.2097],\n",
      "         [0.9956],\n",
      "         [0.3670],\n",
      "         [0.9971],\n",
      "         [0.5117],\n",
      "         [0.9964],\n",
      "         [0.9935],\n",
      "         [0.9925],\n",
      "         [0.0249],\n",
      "         [0.9884],\n",
      "         [0.9859],\n",
      "         [0.9872],\n",
      "         [0.9856],\n",
      "         [0.9875],\n",
      "         [0.9868],\n",
      "         [0.9891],\n",
      "         [0.7656],\n",
      "         [0.4508],\n",
      "         [0.9558],\n",
      "         [0.9976],\n",
      "         [0.9995]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.4552],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [0.8223],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.1762],\n",
      "        [0.6327],\n",
      "        [0.9820],\n",
      "        [0.9998],\n",
      "        [0.4645],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [0.9996],\n",
      "        [0.0288],\n",
      "        [0.9999],\n",
      "        [0.7129],\n",
      "        [0.4527],\n",
      "        [0.3840],\n",
      "        [0.9724],\n",
      "        [0.9995],\n",
      "        [0.3575],\n",
      "        [0.9998],\n",
      "        [0.4668],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.8379],\n",
      "        [0.8761],\n",
      "        [0.7540],\n",
      "        [0.0368],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2518],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9819],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.2729],\n",
      "        [0.9999],\n",
      "        [0.9959],\n",
      "        [0.4454],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9814],\n",
      "        [0.5945],\n",
      "        [0.9999],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.9967],\n",
      "        [0.3930],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.2577],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.8296],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [0.5038],\n",
      "        [0.6920],\n",
      "        [0.3573],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.9956],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.2547],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.2735],\n",
      "        [0.3875],\n",
      "        [0.0383],\n",
      "        [0.5139],\n",
      "        [0.8933],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9999],\n",
      "        [0.3747],\n",
      "        [0.9997],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.4580],\n",
      "        [0.9420],\n",
      "        [0.9995],\n",
      "        [1.0000]])\n",
      "######### Epoch: 60  ######### Train Loss: 0.0001531953166704625  ######### Relative L2 Test Norm: 13.47490406036377\n",
      "Output batch pred: tensor([[[0.2613],\n",
      "         [0.0813],\n",
      "         [1.0024],\n",
      "         [0.2680],\n",
      "         [0.9972],\n",
      "         [0.5179],\n",
      "         [0.9904],\n",
      "         [0.2369],\n",
      "         [0.9907],\n",
      "         [0.9913],\n",
      "         [0.4989],\n",
      "         [0.4582],\n",
      "         [0.9982],\n",
      "         [1.0002],\n",
      "         [1.0010],\n",
      "         [0.6646],\n",
      "         [0.9986],\n",
      "         [0.7875],\n",
      "         [0.9928],\n",
      "         [0.8418],\n",
      "         [0.9904],\n",
      "         [0.9896],\n",
      "         [0.9877],\n",
      "         [0.9893],\n",
      "         [0.7648],\n",
      "         [0.5067],\n",
      "         [0.2515],\n",
      "         [0.5102],\n",
      "         [1.0002],\n",
      "         [1.0002],\n",
      "         [1.0028],\n",
      "         [1.0009],\n",
      "         [1.0022],\n",
      "         [0.7015],\n",
      "         [0.9984],\n",
      "         [0.2117],\n",
      "         [0.9969],\n",
      "         [0.9946],\n",
      "         [0.9536],\n",
      "         [0.4482],\n",
      "         [0.3448],\n",
      "         [0.9834],\n",
      "         [0.4522],\n",
      "         [0.3786],\n",
      "         [0.8678],\n",
      "         [0.9236],\n",
      "         [0.9968],\n",
      "         [0.9831],\n",
      "         [0.0557],\n",
      "         [0.9801],\n",
      "         [0.8127],\n",
      "         [0.9561],\n",
      "         [0.9918],\n",
      "         [0.9916],\n",
      "         [0.9931],\n",
      "         [0.9967],\n",
      "         [0.6867],\n",
      "         [1.0007],\n",
      "         [1.0023],\n",
      "         [1.0034],\n",
      "         [1.0040],\n",
      "         [1.0010],\n",
      "         [1.0013],\n",
      "         [0.9979],\n",
      "         [0.6134],\n",
      "         [0.9887],\n",
      "         [0.9906],\n",
      "         [0.3568],\n",
      "         [0.3550],\n",
      "         [0.4533],\n",
      "         [0.9857],\n",
      "         [0.4418],\n",
      "         [0.3863],\n",
      "         [0.9921],\n",
      "         [0.9948],\n",
      "         [0.4497],\n",
      "         [0.9967],\n",
      "         [0.3774],\n",
      "         [0.9970],\n",
      "         [0.9954],\n",
      "         [0.9967],\n",
      "         [0.9968],\n",
      "         [0.0515],\n",
      "         [0.9975],\n",
      "         [0.9981],\n",
      "         [0.0456],\n",
      "         [0.9989],\n",
      "         [0.9982],\n",
      "         [0.9977],\n",
      "         [0.9944],\n",
      "         [0.7248],\n",
      "         [0.9922],\n",
      "         [0.9923],\n",
      "         [0.9918],\n",
      "         [0.9898],\n",
      "         [0.9910],\n",
      "         [0.9216],\n",
      "         [0.9957],\n",
      "         [0.9977],\n",
      "         [0.5241],\n",
      "         [0.2514],\n",
      "         [1.0043],\n",
      "         [0.2725],\n",
      "         [1.0082],\n",
      "         [0.9892],\n",
      "         [0.0443],\n",
      "         [1.0036],\n",
      "         [1.0023],\n",
      "         [0.9387],\n",
      "         [0.9952],\n",
      "         [0.9922],\n",
      "         [0.4577],\n",
      "         [0.4566],\n",
      "         [0.9890],\n",
      "         [0.9760],\n",
      "         [0.9920],\n",
      "         [0.9940],\n",
      "         [0.9957],\n",
      "         [0.4504],\n",
      "         [0.5394],\n",
      "         [1.0000],\n",
      "         [0.5149],\n",
      "         [0.0580],\n",
      "         [0.3781],\n",
      "         [0.9966],\n",
      "         [0.9933],\n",
      "         [0.9927],\n",
      "         [0.9925],\n",
      "         [0.4995],\n",
      "         [0.9892],\n",
      "         [0.9934],\n",
      "         [0.9936],\n",
      "         [0.9949],\n",
      "         [0.9965],\n",
      "         [0.9975],\n",
      "         [0.9978],\n",
      "         [0.9953],\n",
      "         [0.3612],\n",
      "         [0.9933],\n",
      "         [0.9921],\n",
      "         [0.2325],\n",
      "         [0.9888],\n",
      "         [0.9879],\n",
      "         [0.9898],\n",
      "         [0.8463],\n",
      "         [0.0295],\n",
      "         [0.9911],\n",
      "         [0.5378],\n",
      "         [0.9942],\n",
      "         [0.2486],\n",
      "         [0.9941],\n",
      "         [0.3856],\n",
      "         [0.9018],\n",
      "         [0.9966],\n",
      "         [0.5233],\n",
      "         [0.9966],\n",
      "         [0.4687],\n",
      "         [0.9991],\n",
      "         [0.7489],\n",
      "         [0.3493],\n",
      "         [1.0010],\n",
      "         [1.0010],\n",
      "         [0.3657],\n",
      "         [0.8641],\n",
      "         [0.0262],\n",
      "         [0.9175],\n",
      "         [0.9605],\n",
      "         [0.5133],\n",
      "         [0.5490],\n",
      "         [0.9892],\n",
      "         [0.9884],\n",
      "         [0.9553],\n",
      "         [0.9903],\n",
      "         [0.9946],\n",
      "         [0.9973],\n",
      "         [0.5147],\n",
      "         [0.0757],\n",
      "         [0.1929]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2518],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.4988],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.6327],\n",
      "        [0.9999],\n",
      "        [0.7540],\n",
      "        [0.9967],\n",
      "        [0.8139],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7391],\n",
      "        [0.5080],\n",
      "        [0.2686],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.9994],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.4527],\n",
      "        [0.3573],\n",
      "        [0.9819],\n",
      "        [0.4552],\n",
      "        [0.3875],\n",
      "        [0.8379],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [0.0368],\n",
      "        [0.9804],\n",
      "        [0.7820],\n",
      "        [0.9520],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.3728],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [0.9997],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.5108],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [0.0174],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.4642],\n",
      "        [0.9999],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.0247],\n",
      "        [0.3808],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [0.9959],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [0.9995],\n",
      "        [0.3930],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9999],\n",
      "        [0.4668],\n",
      "        [0.9999],\n",
      "        [0.7129],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [0.8296],\n",
      "        [0.0000],\n",
      "        [0.8933],\n",
      "        [0.9515],\n",
      "        [0.5139],\n",
      "        [0.5463],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.0335],\n",
      "        [0.1762]])\n",
      "######### Epoch: 61  ######### Train Loss: 0.00017952972848434  ######### Relative L2 Test Norm: 13.536624908447266\n",
      "Output batch pred: tensor([[[0.9934],\n",
      "         [0.9938],\n",
      "         [0.9933],\n",
      "         [0.4582],\n",
      "         [0.9902],\n",
      "         [0.9930],\n",
      "         [0.9789],\n",
      "         [0.3794],\n",
      "         [0.9930],\n",
      "         [0.4369],\n",
      "         [0.9962],\n",
      "         [0.9178],\n",
      "         [0.6153],\n",
      "         [0.2619],\n",
      "         [1.0021],\n",
      "         [1.0002],\n",
      "         [0.4794],\n",
      "         [0.5696],\n",
      "         [0.5354],\n",
      "         [0.2644],\n",
      "         [1.0001],\n",
      "         [0.4675],\n",
      "         [0.2688],\n",
      "         [0.5164],\n",
      "         [0.9945],\n",
      "         [0.9923],\n",
      "         [0.1746],\n",
      "         [0.9937],\n",
      "         [0.0494],\n",
      "         [0.9957],\n",
      "         [0.9958],\n",
      "         [0.3758],\n",
      "         [0.9982],\n",
      "         [0.2629],\n",
      "         [1.0010],\n",
      "         [1.0022],\n",
      "         [1.0026],\n",
      "         [1.0015],\n",
      "         [1.0015],\n",
      "         [1.0011],\n",
      "         [1.0015],\n",
      "         [1.0006],\n",
      "         [0.7325],\n",
      "         [0.3724],\n",
      "         [0.7770],\n",
      "         [0.9242],\n",
      "         [0.9963],\n",
      "         [0.9942],\n",
      "         [0.9958],\n",
      "         [0.9841],\n",
      "         [0.8571],\n",
      "         [0.0492],\n",
      "         [0.9965],\n",
      "         [0.9973],\n",
      "         [0.0572],\n",
      "         [0.8226],\n",
      "         [0.8717],\n",
      "         [0.9979],\n",
      "         [0.9976],\n",
      "         [0.9930],\n",
      "         [0.8638],\n",
      "         [0.9967],\n",
      "         [0.9951],\n",
      "         [0.9951],\n",
      "         [0.9952],\n",
      "         [0.4588],\n",
      "         [0.9945],\n",
      "         [0.9949],\n",
      "         [0.9230],\n",
      "         [0.9941],\n",
      "         [0.9934],\n",
      "         [0.9917],\n",
      "         [0.2420],\n",
      "         [0.9920],\n",
      "         [0.9926],\n",
      "         [0.9921],\n",
      "         [0.9925],\n",
      "         [0.9929],\n",
      "         [0.9922],\n",
      "         [0.9024],\n",
      "         [0.9952],\n",
      "         [0.9979],\n",
      "         [0.9987],\n",
      "         [1.0002],\n",
      "         [1.0026],\n",
      "         [0.5162],\n",
      "         [1.0030],\n",
      "         [1.0026],\n",
      "         [1.0008],\n",
      "         [0.9977],\n",
      "         [0.9953],\n",
      "         [0.9948],\n",
      "         [0.9936],\n",
      "         [0.9905],\n",
      "         [0.4922],\n",
      "         [0.9928],\n",
      "         [0.9735],\n",
      "         [0.3420],\n",
      "         [0.9943],\n",
      "         [0.9967],\n",
      "         [0.5153],\n",
      "         [0.9967],\n",
      "         [0.9979],\n",
      "         [0.9843],\n",
      "         [0.9969],\n",
      "         [0.9625],\n",
      "         [0.3773],\n",
      "         [0.9989],\n",
      "         [0.9977],\n",
      "         [0.0760],\n",
      "         [0.4560],\n",
      "         [0.9968],\n",
      "         [0.4608],\n",
      "         [0.7507],\n",
      "         [0.2508],\n",
      "         [0.9982],\n",
      "         [0.5081],\n",
      "         [0.9957],\n",
      "         [0.3589],\n",
      "         [0.9926],\n",
      "         [0.9947],\n",
      "         [0.0515],\n",
      "         [0.5243],\n",
      "         [0.4532],\n",
      "         [0.9995],\n",
      "         [0.2476],\n",
      "         [1.0017],\n",
      "         [1.0028],\n",
      "         [0.9675],\n",
      "         [1.0018],\n",
      "         [0.8533],\n",
      "         [0.5386],\n",
      "         [1.0012],\n",
      "         [0.3697],\n",
      "         [0.9374],\n",
      "         [0.3795],\n",
      "         [0.3872],\n",
      "         [0.0587],\n",
      "         [0.9950],\n",
      "         [0.0408],\n",
      "         [0.5064],\n",
      "         [0.9956],\n",
      "         [0.9968],\n",
      "         [0.4616],\n",
      "         [0.2041],\n",
      "         [0.9941],\n",
      "         [0.9947],\n",
      "         [0.2485],\n",
      "         [0.9958],\n",
      "         [0.5419],\n",
      "         [0.9957],\n",
      "         [0.9962],\n",
      "         [0.6542],\n",
      "         [0.5041],\n",
      "         [0.9640],\n",
      "         [0.9976],\n",
      "         [0.9990],\n",
      "         [0.0310],\n",
      "         [0.9853],\n",
      "         [0.0570],\n",
      "         [0.3426],\n",
      "         [0.9909],\n",
      "         [0.9901],\n",
      "         [0.9894],\n",
      "         [0.9890],\n",
      "         [0.9896],\n",
      "         [0.9900],\n",
      "         [0.3660],\n",
      "         [0.6778],\n",
      "         [0.9979],\n",
      "         [0.9612],\n",
      "         [1.0036],\n",
      "         [1.0032],\n",
      "         [0.7951],\n",
      "         [0.5265],\n",
      "         [1.0007],\n",
      "         [0.4543],\n",
      "         [0.6909]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.5945],\n",
      "        [0.2729],\n",
      "        [0.9997],\n",
      "        [0.9962],\n",
      "        [0.4668],\n",
      "        [0.5463],\n",
      "        [0.5151],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [0.2735],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.9999],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.6920],\n",
      "        [0.3753],\n",
      "        [0.7391],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9820],\n",
      "        [0.8223],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.7820],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9966],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.3573],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5080],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.0368],\n",
      "        [0.4480],\n",
      "        [0.9959],\n",
      "        [0.4527],\n",
      "        [0.7129],\n",
      "        [0.2547],\n",
      "        [0.9999],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.5165],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.9164],\n",
      "        [0.3840],\n",
      "        [0.3912],\n",
      "        [0.0288],\n",
      "        [0.9967],\n",
      "        [0.0142],\n",
      "        [0.5030],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2646],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [0.6327],\n",
      "        [0.5038],\n",
      "        [0.9515],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.9819],\n",
      "        [0.0383],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.6555],\n",
      "        [0.9995],\n",
      "        [0.9420],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.5139],\n",
      "        [0.9997],\n",
      "        [0.4552],\n",
      "        [0.6628]])\n",
      "######### Epoch: 62  ######### Train Loss: 0.00018770151655189693  ######### Relative L2 Test Norm: 13.862584114074707\n",
      "Output batch pred: tensor([[[0.2748],\n",
      "         [1.0083],\n",
      "         [1.0080],\n",
      "         [0.9464],\n",
      "         [0.9342],\n",
      "         [0.8685],\n",
      "         [0.3813],\n",
      "         [0.5076],\n",
      "         [0.4501],\n",
      "         [0.9948],\n",
      "         [0.5127],\n",
      "         [0.5123],\n",
      "         [0.9977],\n",
      "         [1.0019],\n",
      "         [0.6700],\n",
      "         [0.1837],\n",
      "         [1.0049],\n",
      "         [0.5290],\n",
      "         [0.9834],\n",
      "         [0.9993],\n",
      "         [0.9979],\n",
      "         [0.9969],\n",
      "         [0.9940],\n",
      "         [0.7221],\n",
      "         [0.9953],\n",
      "         [0.6816],\n",
      "         [0.3822],\n",
      "         [0.9999],\n",
      "         [0.6998],\n",
      "         [0.5659],\n",
      "         [1.0023],\n",
      "         [1.0001],\n",
      "         [0.9956],\n",
      "         [0.3474],\n",
      "         [0.9944],\n",
      "         [0.9921],\n",
      "         [0.9918],\n",
      "         [0.9887],\n",
      "         [0.9894],\n",
      "         [0.8386],\n",
      "         [0.9898],\n",
      "         [0.9916],\n",
      "         [0.2491],\n",
      "         [0.8653],\n",
      "         [0.9967],\n",
      "         [0.2098],\n",
      "         [0.9983],\n",
      "         [0.2604],\n",
      "         [0.9982],\n",
      "         [0.9978],\n",
      "         [0.9946],\n",
      "         [0.9945],\n",
      "         [0.9564],\n",
      "         [0.9907],\n",
      "         [0.9907],\n",
      "         [0.0368],\n",
      "         [0.9921],\n",
      "         [0.9942],\n",
      "         [0.9975],\n",
      "         [0.0604],\n",
      "         [1.0020],\n",
      "         [1.0056],\n",
      "         [1.0048],\n",
      "         [0.0578],\n",
      "         [0.0596],\n",
      "         [1.0022],\n",
      "         [1.0039],\n",
      "         [0.4548],\n",
      "         [0.9996],\n",
      "         [0.8192],\n",
      "         [0.9989],\n",
      "         [0.6169],\n",
      "         [0.5060],\n",
      "         [1.0013],\n",
      "         [0.0676],\n",
      "         [0.3795],\n",
      "         [0.0580],\n",
      "         [1.0027],\n",
      "         [0.4688],\n",
      "         [0.7806],\n",
      "         [1.0016],\n",
      "         [0.9856],\n",
      "         [0.9960],\n",
      "         [0.2430],\n",
      "         [0.4596],\n",
      "         [0.9836],\n",
      "         [0.9959],\n",
      "         [0.4437],\n",
      "         [0.9959],\n",
      "         [0.3551],\n",
      "         [0.5507],\n",
      "         [0.3900],\n",
      "         [0.9975],\n",
      "         [0.2435],\n",
      "         [0.9941],\n",
      "         [0.9932],\n",
      "         [0.9925],\n",
      "         [0.9901],\n",
      "         [0.9910],\n",
      "         [0.9790],\n",
      "         [0.9920],\n",
      "         [0.8506],\n",
      "         [0.3646],\n",
      "         [0.2587],\n",
      "         [1.0001],\n",
      "         [0.0363],\n",
      "         [1.0026],\n",
      "         [1.0024],\n",
      "         [1.0027],\n",
      "         [0.3657],\n",
      "         [0.5365],\n",
      "         [0.9947],\n",
      "         [0.9937],\n",
      "         [0.9898],\n",
      "         [0.9905],\n",
      "         [0.9901],\n",
      "         [0.3628],\n",
      "         [0.5056],\n",
      "         [0.9946],\n",
      "         [0.9979],\n",
      "         [0.5276],\n",
      "         [1.0018],\n",
      "         [0.7975],\n",
      "         [1.0053],\n",
      "         [0.4720],\n",
      "         [1.0038],\n",
      "         [0.2433],\n",
      "         [0.4697],\n",
      "         [0.9970],\n",
      "         [0.9844],\n",
      "         [0.9245],\n",
      "         [0.9971],\n",
      "         [0.9063],\n",
      "         [0.9994],\n",
      "         [1.0014],\n",
      "         [0.4754],\n",
      "         [0.9626],\n",
      "         [0.0505],\n",
      "         [1.0024],\n",
      "         [0.9995],\n",
      "         [0.4605],\n",
      "         [0.9961],\n",
      "         [0.5218],\n",
      "         [0.3713],\n",
      "         [0.9966],\n",
      "         [0.3868],\n",
      "         [0.7477],\n",
      "         [0.0583],\n",
      "         [0.5259],\n",
      "         [0.9978],\n",
      "         [0.9958],\n",
      "         [0.9970],\n",
      "         [0.9955],\n",
      "         [0.9937],\n",
      "         [0.9924],\n",
      "         [0.5014],\n",
      "         [0.9901],\n",
      "         [0.9885],\n",
      "         [0.9548],\n",
      "         [0.9904],\n",
      "         [0.9901],\n",
      "         [0.9948],\n",
      "         [0.9964],\n",
      "         [0.9978],\n",
      "         [0.9974],\n",
      "         [0.2463],\n",
      "         [0.9994],\n",
      "         [0.9962],\n",
      "         [0.9962],\n",
      "         [0.9619],\n",
      "         [0.9944],\n",
      "         [0.9922],\n",
      "         [0.9154],\n",
      "         [0.9946],\n",
      "         [0.4471],\n",
      "         [0.9968],\n",
      "         [1.0009],\n",
      "         [1.0016]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2729],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.9044],\n",
      "        [0.8296],\n",
      "        [0.3840],\n",
      "        [0.5009],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.9724],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9956],\n",
      "        [0.3573],\n",
      "        [0.9995],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9994],\n",
      "        [0.2735],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.0288],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.5945],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [0.0335],\n",
      "        [0.3753],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.7391],\n",
      "        [0.9997],\n",
      "        [0.9814],\n",
      "        [0.9994],\n",
      "        [0.2610],\n",
      "        [0.4645],\n",
      "        [0.9819],\n",
      "        [0.9998],\n",
      "        [0.4454],\n",
      "        [0.9999],\n",
      "        [0.3575],\n",
      "        [0.5334],\n",
      "        [0.3912],\n",
      "        [0.9999],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.3747],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.5245],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.7540],\n",
      "        [0.9997],\n",
      "        [0.4611],\n",
      "        [0.9999],\n",
      "        [0.2518],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [0.8761],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.9420],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.3930],\n",
      "        [0.7129],\n",
      "        [0.0368],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.9999],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.9999],\n",
      "        [0.9515],\n",
      "        [0.9996],\n",
      "        [0.9996],\n",
      "        [0.8933],\n",
      "        [0.9999],\n",
      "        [0.4480],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9966]])\n",
      "######### Epoch: 63  ######### Train Loss: 0.00019713444635272026  ######### Relative L2 Test Norm: 13.123981475830078\n",
      "Output batch pred: tensor([[[0.9918],\n",
      "         [0.9924],\n",
      "         [0.9944],\n",
      "         [0.9942],\n",
      "         [0.5039],\n",
      "         [0.2719],\n",
      "         [0.3771],\n",
      "         [0.1878],\n",
      "         [0.8597],\n",
      "         [1.0005],\n",
      "         [0.0618],\n",
      "         [0.2171],\n",
      "         [1.0008],\n",
      "         [0.9991],\n",
      "         [0.9975],\n",
      "         [0.9996],\n",
      "         [0.9990],\n",
      "         [0.5123],\n",
      "         [0.9998],\n",
      "         [0.9999],\n",
      "         [0.9980],\n",
      "         [0.9992],\n",
      "         [0.9998],\n",
      "         [0.8703],\n",
      "         [0.9989],\n",
      "         [0.0418],\n",
      "         [0.9983],\n",
      "         [0.9966],\n",
      "         [0.9960],\n",
      "         [0.5135],\n",
      "         [0.5460],\n",
      "         [0.0583],\n",
      "         [0.6569],\n",
      "         [0.9936],\n",
      "         [0.7246],\n",
      "         [0.9973],\n",
      "         [0.9990],\n",
      "         [0.9670],\n",
      "         [1.0022],\n",
      "         [0.9920],\n",
      "         [0.5170],\n",
      "         [0.0356],\n",
      "         [1.0031],\n",
      "         [0.3586],\n",
      "         [0.9983],\n",
      "         [0.9627],\n",
      "         [0.9930],\n",
      "         [0.9926],\n",
      "         [0.9777],\n",
      "         [0.5089],\n",
      "         [0.9862],\n",
      "         [0.9878],\n",
      "         [0.9078],\n",
      "         [0.9891],\n",
      "         [0.9921],\n",
      "         [0.0612],\n",
      "         [0.5379],\n",
      "         [0.6199],\n",
      "         [0.9604],\n",
      "         [1.0019],\n",
      "         [1.0013],\n",
      "         [0.9995],\n",
      "         [0.9984],\n",
      "         [0.9982],\n",
      "         [0.9971],\n",
      "         [0.5046],\n",
      "         [0.9955],\n",
      "         [0.9932],\n",
      "         [0.9049],\n",
      "         [0.9975],\n",
      "         [1.0003],\n",
      "         [1.0019],\n",
      "         [0.9679],\n",
      "         [0.2501],\n",
      "         [0.9999],\n",
      "         [0.9984],\n",
      "         [0.9964],\n",
      "         [0.9955],\n",
      "         [0.5097],\n",
      "         [0.9793],\n",
      "         [0.4539],\n",
      "         [0.3791],\n",
      "         [0.9959],\n",
      "         [0.6863],\n",
      "         [0.3941],\n",
      "         [0.4653],\n",
      "         [0.9956],\n",
      "         [0.9398],\n",
      "         [1.0088],\n",
      "         [1.0081],\n",
      "         [0.8621],\n",
      "         [0.4765],\n",
      "         [0.8677],\n",
      "         [0.4468],\n",
      "         [0.4489],\n",
      "         [0.9948],\n",
      "         [0.2424],\n",
      "         [0.9940],\n",
      "         [0.2460],\n",
      "         [0.9944],\n",
      "         [0.0505],\n",
      "         [0.4453],\n",
      "         [0.4558],\n",
      "         [0.9941],\n",
      "         [0.9937],\n",
      "         [0.9927],\n",
      "         [0.9915],\n",
      "         [0.3593],\n",
      "         [0.3739],\n",
      "         [0.9956],\n",
      "         [0.9999],\n",
      "         [1.0018],\n",
      "         [1.0038],\n",
      "         [0.9451],\n",
      "         [0.7597],\n",
      "         [1.0063],\n",
      "         [1.0053],\n",
      "         [1.0031],\n",
      "         [0.9999],\n",
      "         [0.5186],\n",
      "         [0.9938],\n",
      "         [0.9914],\n",
      "         [0.9895],\n",
      "         [0.2364],\n",
      "         [0.3601],\n",
      "         [0.9882],\n",
      "         [0.9899],\n",
      "         [0.9193],\n",
      "         [0.3675],\n",
      "         [0.9968],\n",
      "         [0.9998],\n",
      "         [1.0000],\n",
      "         [0.5648],\n",
      "         [0.0603],\n",
      "         [0.7929],\n",
      "         [1.0021],\n",
      "         [0.0704],\n",
      "         [0.9998],\n",
      "         [0.2692],\n",
      "         [0.5146],\n",
      "         [1.0023],\n",
      "         [0.0402],\n",
      "         [1.0043],\n",
      "         [1.0039],\n",
      "         [1.0006],\n",
      "         [0.7819],\n",
      "         [0.4573],\n",
      "         [0.9976],\n",
      "         [0.9946],\n",
      "         [0.9926],\n",
      "         [0.9904],\n",
      "         [0.9869],\n",
      "         [0.3551],\n",
      "         [0.2362],\n",
      "         [0.9910],\n",
      "         [0.9945],\n",
      "         [0.9994],\n",
      "         [1.0018],\n",
      "         [0.4761],\n",
      "         [1.0066],\n",
      "         [0.2723],\n",
      "         [0.4831],\n",
      "         [0.7056],\n",
      "         [0.9841],\n",
      "         [0.5300],\n",
      "         [0.9990],\n",
      "         [0.3620],\n",
      "         [0.9968],\n",
      "         [0.8183],\n",
      "         [0.9969],\n",
      "         [0.9959],\n",
      "         [0.9979],\n",
      "         [0.9966],\n",
      "         [0.9953],\n",
      "         [0.3457],\n",
      "         [0.9943],\n",
      "         [0.9939],\n",
      "         [0.9911]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4988],\n",
      "        [0.2735],\n",
      "        [0.3747],\n",
      "        [0.1762],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.2208],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9997],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.5334],\n",
      "        [0.0383],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [0.5009],\n",
      "        [0.0000],\n",
      "        [0.9994],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.0368],\n",
      "        [0.5245],\n",
      "        [0.5945],\n",
      "        [0.9420],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.5030],\n",
      "        [0.9997],\n",
      "        [0.9956],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9520],\n",
      "        [0.2577],\n",
      "        [0.9995],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.5108],\n",
      "        [0.9804],\n",
      "        [0.4611],\n",
      "        [0.3912],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [0.3930],\n",
      "        [0.4527],\n",
      "        [0.9814],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.8139],\n",
      "        [0.4645],\n",
      "        [0.8296],\n",
      "        [0.4454],\n",
      "        [0.4503],\n",
      "        [0.9999],\n",
      "        [0.2518],\n",
      "        [0.9997],\n",
      "        [0.2547],\n",
      "        [0.9998],\n",
      "        [0.0174],\n",
      "        [0.4480],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.3753],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.0247],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.7391],\n",
      "        [0.4552],\n",
      "        [0.9996],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.4642],\n",
      "        [0.9999],\n",
      "        [0.2686],\n",
      "        [0.4668],\n",
      "        [0.6628],\n",
      "        [0.9724],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000]])\n",
      "######### Epoch: 64  ######### Train Loss: 0.00022666466247756034  ######### Relative L2 Test Norm: 13.509042739868164\n",
      "Output batch pred: tensor([[[0.9994],\n",
      "         [1.0033],\n",
      "         [1.0027],\n",
      "         [1.0008],\n",
      "         [0.3831],\n",
      "         [0.9966],\n",
      "         [0.5161],\n",
      "         [0.9904],\n",
      "         [0.9902],\n",
      "         [0.8566],\n",
      "         [0.9885],\n",
      "         [0.9883],\n",
      "         [0.9184],\n",
      "         [0.9942],\n",
      "         [0.2534],\n",
      "         [0.0469],\n",
      "         [0.7960],\n",
      "         [0.5248],\n",
      "         [0.9929],\n",
      "         [1.0056],\n",
      "         [1.0031],\n",
      "         [1.0023],\n",
      "         [1.0008],\n",
      "         [0.2076],\n",
      "         [0.5235],\n",
      "         [0.9964],\n",
      "         [0.9940],\n",
      "         [0.9963],\n",
      "         [0.3463],\n",
      "         [0.9181],\n",
      "         [0.9963],\n",
      "         [0.2663],\n",
      "         [0.9968],\n",
      "         [0.4572],\n",
      "         [0.9978],\n",
      "         [0.8161],\n",
      "         [0.2414],\n",
      "         [0.2445],\n",
      "         [0.9946],\n",
      "         [0.9927],\n",
      "         [0.9948],\n",
      "         [0.3623],\n",
      "         [0.9946],\n",
      "         [0.1637],\n",
      "         [0.9982],\n",
      "         [0.9990],\n",
      "         [1.0009],\n",
      "         [1.0013],\n",
      "         [1.0018],\n",
      "         [1.0015],\n",
      "         [0.9885],\n",
      "         [1.0001],\n",
      "         [0.9998],\n",
      "         [0.9989],\n",
      "         [0.9965],\n",
      "         [0.9958],\n",
      "         [0.0456],\n",
      "         [0.4434],\n",
      "         [0.9917],\n",
      "         [0.4570],\n",
      "         [0.9918],\n",
      "         [0.0278],\n",
      "         [0.8470],\n",
      "         [0.9898],\n",
      "         [0.9903],\n",
      "         [0.9902],\n",
      "         [0.9910],\n",
      "         [0.0504],\n",
      "         [0.9952],\n",
      "         [0.9970],\n",
      "         [0.5252],\n",
      "         [1.0010],\n",
      "         [1.0006],\n",
      "         [1.0029],\n",
      "         [0.0654],\n",
      "         [1.0023],\n",
      "         [0.9967],\n",
      "         [0.9978],\n",
      "         [0.9954],\n",
      "         [0.5505],\n",
      "         [0.9906],\n",
      "         [0.9915],\n",
      "         [0.9922],\n",
      "         [0.5022],\n",
      "         [0.4998],\n",
      "         [0.6962],\n",
      "         [1.0002],\n",
      "         [1.0046],\n",
      "         [1.0049],\n",
      "         [1.0074],\n",
      "         [0.7901],\n",
      "         [1.0087],\n",
      "         [1.0056],\n",
      "         [0.4560],\n",
      "         [0.5454],\n",
      "         [0.9674],\n",
      "         [0.4567],\n",
      "         [0.3835],\n",
      "         [0.9994],\n",
      "         [0.2583],\n",
      "         [0.9858],\n",
      "         [0.6173],\n",
      "         [0.9989],\n",
      "         [0.9863],\n",
      "         [0.3671],\n",
      "         [0.0413],\n",
      "         [0.3474],\n",
      "         [0.5080],\n",
      "         [0.9940],\n",
      "         [0.9918],\n",
      "         [0.9943],\n",
      "         [0.9945],\n",
      "         [0.4623],\n",
      "         [0.9980],\n",
      "         [0.9999],\n",
      "         [0.9676],\n",
      "         [0.2531],\n",
      "         [0.5136],\n",
      "         [0.9422],\n",
      "         [0.8545],\n",
      "         [1.0012],\n",
      "         [0.9055],\n",
      "         [0.9969],\n",
      "         [0.3776],\n",
      "         [0.9505],\n",
      "         [0.6711],\n",
      "         [0.9889],\n",
      "         [0.3499],\n",
      "         [0.7136],\n",
      "         [0.9898],\n",
      "         [0.9908],\n",
      "         [0.9189],\n",
      "         [0.9946],\n",
      "         [0.9965],\n",
      "         [0.9969],\n",
      "         [0.9995],\n",
      "         [1.0001],\n",
      "         [0.2614],\n",
      "         [0.9993],\n",
      "         [0.9650],\n",
      "         [0.5491],\n",
      "         [1.0007],\n",
      "         [0.3807],\n",
      "         [0.9990],\n",
      "         [1.0006],\n",
      "         [0.9993],\n",
      "         [0.9988],\n",
      "         [0.4651],\n",
      "         [0.9960],\n",
      "         [0.8597],\n",
      "         [0.9918],\n",
      "         [0.9896],\n",
      "         [0.9910],\n",
      "         [0.9900],\n",
      "         [0.9893],\n",
      "         [0.9915],\n",
      "         [0.9926],\n",
      "         [0.9977],\n",
      "         [0.9991],\n",
      "         [0.4617],\n",
      "         [0.4542],\n",
      "         [1.0034],\n",
      "         [0.0475],\n",
      "         [0.0697],\n",
      "         [0.6680],\n",
      "         [0.2540],\n",
      "         [0.3761],\n",
      "         [0.0666],\n",
      "         [0.9778],\n",
      "         [0.9947],\n",
      "         [0.9950],\n",
      "         [0.5031],\n",
      "         [0.4629],\n",
      "         [0.3690],\n",
      "         [0.9977],\n",
      "         [0.9985],\n",
      "         [0.7486],\n",
      "         [0.5211]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9956],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9997],\n",
      "        [0.5151],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [0.0209],\n",
      "        [0.7540],\n",
      "        [0.5080],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.2208],\n",
      "        [0.5165],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.9996],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.2547],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.9966],\n",
      "        [0.1762],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.4503],\n",
      "        [0.9997],\n",
      "        [0.4645],\n",
      "        [0.9998],\n",
      "        [0.0142],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5038],\n",
      "        [0.4988],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.5245],\n",
      "        [0.9520],\n",
      "        [0.4527],\n",
      "        [0.3875],\n",
      "        [0.9999],\n",
      "        [0.2686],\n",
      "        [0.9804],\n",
      "        [0.5945],\n",
      "        [0.9997],\n",
      "        [0.9819],\n",
      "        [0.3747],\n",
      "        [0.0174],\n",
      "        [0.3575],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.2577],\n",
      "        [0.5009],\n",
      "        [0.9164],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.9998],\n",
      "        [0.3930],\n",
      "        [0.9420],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.5334],\n",
      "        [0.9999],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.4642],\n",
      "        [0.9999],\n",
      "        [0.8296],\n",
      "        [0.9994],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.4580],\n",
      "        [0.4480],\n",
      "        [0.9962],\n",
      "        [0.0000],\n",
      "        [0.0288],\n",
      "        [0.6327],\n",
      "        [0.2518],\n",
      "        [0.3753],\n",
      "        [0.0383],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.4668],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7129],\n",
      "        [0.5108]])\n",
      "######### Epoch: 65  ######### Train Loss: 0.00018513313261792064  ######### Relative L2 Test Norm: 13.862407684326172\n",
      "Output batch pred: tensor([[[0.2538],\n",
      "         [0.9983],\n",
      "         [0.0565],\n",
      "         [0.2631],\n",
      "         [0.0445],\n",
      "         [0.9989],\n",
      "         [0.1789],\n",
      "         [0.0512],\n",
      "         [0.8663],\n",
      "         [0.9940],\n",
      "         [0.9925],\n",
      "         [0.9916],\n",
      "         [0.9885],\n",
      "         [0.9922],\n",
      "         [0.9926],\n",
      "         [0.5140],\n",
      "         [0.8626],\n",
      "         [0.9991],\n",
      "         [0.4545],\n",
      "         [1.0026],\n",
      "         [1.0043],\n",
      "         [1.0041],\n",
      "         [1.0021],\n",
      "         [0.7538],\n",
      "         [1.0002],\n",
      "         [0.9956],\n",
      "         [0.9155],\n",
      "         [0.4328],\n",
      "         [0.9903],\n",
      "         [0.9547],\n",
      "         [0.9908],\n",
      "         [0.6502],\n",
      "         [0.9817],\n",
      "         [0.2391],\n",
      "         [0.4490],\n",
      "         [1.0002],\n",
      "         [0.5175],\n",
      "         [0.2491],\n",
      "         [0.9996],\n",
      "         [1.0001],\n",
      "         [0.9973],\n",
      "         [0.6113],\n",
      "         [0.9930],\n",
      "         [0.9573],\n",
      "         [0.9900],\n",
      "         [0.9284],\n",
      "         [0.5252],\n",
      "         [0.0301],\n",
      "         [0.9940],\n",
      "         [0.9940],\n",
      "         [0.9945],\n",
      "         [0.5129],\n",
      "         [0.9957],\n",
      "         [0.9931],\n",
      "         [0.9929],\n",
      "         [0.9901],\n",
      "         [0.3621],\n",
      "         [0.1982],\n",
      "         [0.9878],\n",
      "         [0.3512],\n",
      "         [0.4962],\n",
      "         [0.9910],\n",
      "         [0.8135],\n",
      "         [0.4995],\n",
      "         [0.9977],\n",
      "         [0.9974],\n",
      "         [0.9861],\n",
      "         [0.9983],\n",
      "         [0.9995],\n",
      "         [0.9969],\n",
      "         [0.9968],\n",
      "         [1.0003],\n",
      "         [0.9601],\n",
      "         [1.0008],\n",
      "         [1.0007],\n",
      "         [0.5115],\n",
      "         [0.3903],\n",
      "         [0.9277],\n",
      "         [0.9987],\n",
      "         [0.9984],\n",
      "         [0.9966],\n",
      "         [0.3630],\n",
      "         [0.9947],\n",
      "         [0.4608],\n",
      "         [0.9941],\n",
      "         [0.9948],\n",
      "         [0.9958],\n",
      "         [0.9968],\n",
      "         [0.4654],\n",
      "         [0.2712],\n",
      "         [0.4816],\n",
      "         [1.0045],\n",
      "         [0.4810],\n",
      "         [1.0051],\n",
      "         [1.0038],\n",
      "         [0.4635],\n",
      "         [0.9792],\n",
      "         [0.9827],\n",
      "         [0.0576],\n",
      "         [0.3751],\n",
      "         [0.3791],\n",
      "         [0.9917],\n",
      "         [0.6748],\n",
      "         [0.7828],\n",
      "         [0.3656],\n",
      "         [0.5231],\n",
      "         [1.0000],\n",
      "         [1.0006],\n",
      "         [0.8539],\n",
      "         [0.9996],\n",
      "         [1.0002],\n",
      "         [0.9988],\n",
      "         [0.3460],\n",
      "         [0.9224],\n",
      "         [0.9914],\n",
      "         [0.9922],\n",
      "         [0.9917],\n",
      "         [0.4981],\n",
      "         [0.9921],\n",
      "         [0.9911],\n",
      "         [0.9931],\n",
      "         [0.9942],\n",
      "         [0.4393],\n",
      "         [0.9939],\n",
      "         [0.9935],\n",
      "         [0.9915],\n",
      "         [0.7171],\n",
      "         [0.9921],\n",
      "         [0.9924],\n",
      "         [0.9936],\n",
      "         [0.9948],\n",
      "         [0.5457],\n",
      "         [0.9985],\n",
      "         [0.2636],\n",
      "         [1.0032],\n",
      "         [1.0025],\n",
      "         [1.0052],\n",
      "         [0.7018],\n",
      "         [1.0017],\n",
      "         [0.4620],\n",
      "         [0.9974],\n",
      "         [0.9959],\n",
      "         [0.9952],\n",
      "         [0.9935],\n",
      "         [0.0424],\n",
      "         [0.9899],\n",
      "         [0.2522],\n",
      "         [0.3626],\n",
      "         [0.9957],\n",
      "         [0.9845],\n",
      "         [0.9978],\n",
      "         [0.5561],\n",
      "         [0.9987],\n",
      "         [0.0581],\n",
      "         [0.3702],\n",
      "         [0.9990],\n",
      "         [0.9982],\n",
      "         [0.9991],\n",
      "         [0.9991],\n",
      "         [1.0002],\n",
      "         [1.0003],\n",
      "         [0.9088],\n",
      "         [0.2448],\n",
      "         [0.3507],\n",
      "         [1.0033],\n",
      "         [1.0020],\n",
      "         [0.0531],\n",
      "         [0.9999],\n",
      "         [0.5102],\n",
      "         [0.9961],\n",
      "         [0.8507],\n",
      "         [0.9922],\n",
      "         [0.5116],\n",
      "         [0.7639],\n",
      "         [0.0384],\n",
      "         [0.9925],\n",
      "         [0.9586],\n",
      "         [0.9942]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2610],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.2646],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.0209],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.5139],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.8933],\n",
      "        [0.4454],\n",
      "        [0.9997],\n",
      "        [0.9490],\n",
      "        [0.9997],\n",
      "        [0.6327],\n",
      "        [0.9820],\n",
      "        [0.2518],\n",
      "        [0.4480],\n",
      "        [0.9998],\n",
      "        [0.5054],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9999],\n",
      "        [0.9164],\n",
      "        [0.5245],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.3840],\n",
      "        [0.2208],\n",
      "        [0.9994],\n",
      "        [0.3728],\n",
      "        [0.5030],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.9804],\n",
      "        [0.9996],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [0.9420],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.3912],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.2729],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.9724],\n",
      "        [0.9814],\n",
      "        [0.0335],\n",
      "        [0.3875],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.7540],\n",
      "        [0.3780],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.9999],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.0247],\n",
      "        [0.9962],\n",
      "        [0.2686],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.9996],\n",
      "        [0.0368],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.2547],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.7391],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.9966]])\n",
      "######### Epoch: 66  ######### Train Loss: 0.000161133793881163  ######### Relative L2 Test Norm: 13.867868423461914\n",
      "Output batch pred: tensor([[[0.9125],\n",
      "         [0.9926],\n",
      "         [0.9949],\n",
      "         [0.9961],\n",
      "         [0.9975],\n",
      "         [0.9989],\n",
      "         [1.0001],\n",
      "         [0.5170],\n",
      "         [0.9970],\n",
      "         [0.6134],\n",
      "         [0.0406],\n",
      "         [0.9952],\n",
      "         [0.9964],\n",
      "         [0.9961],\n",
      "         [0.9956],\n",
      "         [0.9985],\n",
      "         [0.2544],\n",
      "         [0.6591],\n",
      "         [0.4685],\n",
      "         [0.5206],\n",
      "         [0.7455],\n",
      "         [0.8147],\n",
      "         [0.9944],\n",
      "         [0.3431],\n",
      "         [0.5032],\n",
      "         [0.9927],\n",
      "         [0.4577],\n",
      "         [0.9933],\n",
      "         [0.0333],\n",
      "         [0.9949],\n",
      "         [0.9624],\n",
      "         [0.9970],\n",
      "         [0.9955],\n",
      "         [0.5205],\n",
      "         [0.9552],\n",
      "         [0.7707],\n",
      "         [0.5536],\n",
      "         [0.3414],\n",
      "         [0.9959],\n",
      "         [0.9958],\n",
      "         [0.9952],\n",
      "         [0.7212],\n",
      "         [0.9945],\n",
      "         [0.9581],\n",
      "         [0.3733],\n",
      "         [0.6740],\n",
      "         [0.9912],\n",
      "         [0.9892],\n",
      "         [0.5013],\n",
      "         [0.9918],\n",
      "         [0.9926],\n",
      "         [0.9948],\n",
      "         [0.9953],\n",
      "         [0.7874],\n",
      "         [0.3722],\n",
      "         [0.9994],\n",
      "         [0.0229],\n",
      "         [0.9999],\n",
      "         [0.9978],\n",
      "         [0.9981],\n",
      "         [0.9954],\n",
      "         [0.2326],\n",
      "         [0.9903],\n",
      "         [0.9910],\n",
      "         [0.9880],\n",
      "         [0.9904],\n",
      "         [0.9897],\n",
      "         [0.0558],\n",
      "         [0.0568],\n",
      "         [0.3655],\n",
      "         [0.9974],\n",
      "         [1.0010],\n",
      "         [1.0032],\n",
      "         [1.0028],\n",
      "         [0.4476],\n",
      "         [0.9314],\n",
      "         [1.0007],\n",
      "         [0.5215],\n",
      "         [0.9972],\n",
      "         [0.9944],\n",
      "         [0.9941],\n",
      "         [0.9929],\n",
      "         [0.9940],\n",
      "         [0.4464],\n",
      "         [0.5068],\n",
      "         [0.9979],\n",
      "         [0.9991],\n",
      "         [0.9996],\n",
      "         [0.9992],\n",
      "         [0.8689],\n",
      "         [0.9968],\n",
      "         [0.6882],\n",
      "         [0.5276],\n",
      "         [0.8980],\n",
      "         [0.1620],\n",
      "         [0.9915],\n",
      "         [0.4458],\n",
      "         [0.3646],\n",
      "         [0.9934],\n",
      "         [0.8579],\n",
      "         [0.3797],\n",
      "         [0.9959],\n",
      "         [0.9959],\n",
      "         [0.9937],\n",
      "         [0.9960],\n",
      "         [0.3629],\n",
      "         [0.4538],\n",
      "         [0.9958],\n",
      "         [0.9924],\n",
      "         [0.9972],\n",
      "         [0.0569],\n",
      "         [0.9972],\n",
      "         [0.9973],\n",
      "         [0.9247],\n",
      "         [0.9985],\n",
      "         [0.2535],\n",
      "         [0.3597],\n",
      "         [0.9952],\n",
      "         [0.9933],\n",
      "         [0.9946],\n",
      "         [0.5023],\n",
      "         [0.9935],\n",
      "         [0.9943],\n",
      "         [0.9972],\n",
      "         [0.9980],\n",
      "         [0.9997],\n",
      "         [1.0001],\n",
      "         [0.3836],\n",
      "         [0.9399],\n",
      "         [0.9878],\n",
      "         [0.0578],\n",
      "         [0.9990],\n",
      "         [0.4652],\n",
      "         [0.4685],\n",
      "         [0.2659],\n",
      "         [0.4526],\n",
      "         [0.0409],\n",
      "         [0.9964],\n",
      "         [0.5012],\n",
      "         [0.9944],\n",
      "         [0.4960],\n",
      "         [0.9809],\n",
      "         [0.9926],\n",
      "         [0.9936],\n",
      "         [0.9942],\n",
      "         [0.9946],\n",
      "         [0.3636],\n",
      "         [0.9962],\n",
      "         [0.9945],\n",
      "         [0.4420],\n",
      "         [0.9964],\n",
      "         [0.9949],\n",
      "         [0.2463],\n",
      "         [0.5388],\n",
      "         [0.8503],\n",
      "         [0.9574],\n",
      "         [0.9925],\n",
      "         [0.9924],\n",
      "         [0.9717],\n",
      "         [0.0262],\n",
      "         [0.2305],\n",
      "         [0.9917],\n",
      "         [0.9916],\n",
      "         [0.8430],\n",
      "         [0.9922],\n",
      "         [0.9928],\n",
      "         [0.9989],\n",
      "         [0.2367],\n",
      "         [1.0008],\n",
      "         [1.0021],\n",
      "         [0.2072],\n",
      "         [1.0023],\n",
      "         [1.0010],\n",
      "         [0.9871],\n",
      "         [0.9954],\n",
      "         [0.9812],\n",
      "         [0.9923],\n",
      "         [0.2352]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.8933],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.0247],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.2686],\n",
      "        [0.6327],\n",
      "        [0.4668],\n",
      "        [0.5139],\n",
      "        [0.7129],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [0.9999],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9420],\n",
      "        [0.7391],\n",
      "        [0.5463],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.3875],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.7540],\n",
      "        [0.3840],\n",
      "        [0.9997],\n",
      "        [0.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0368],\n",
      "        [0.0335],\n",
      "        [0.3728],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4454],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.5030],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.5245],\n",
      "        [0.8761],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.3808],\n",
      "        [0.9997],\n",
      "        [0.8296],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [0.3753],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9164],\n",
      "        [0.9814],\n",
      "        [0.0288],\n",
      "        [0.9966],\n",
      "        [0.4611],\n",
      "        [0.4645],\n",
      "        [0.2735],\n",
      "        [0.4527],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9998],\n",
      "        [0.4988],\n",
      "        [0.9820],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [0.5334],\n",
      "        [0.8223],\n",
      "        [0.9520],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.0209],\n",
      "        [0.2577],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.9962],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.2610]])\n",
      "######### Epoch: 67  ######### Train Loss: 0.00014649250078946352  ######### Relative L2 Test Norm: 14.329145431518555\n",
      "Output batch pred: tensor([[[0.9988],\n",
      "         [0.9998],\n",
      "         [1.0002],\n",
      "         [0.2443],\n",
      "         [0.9992],\n",
      "         [0.4516],\n",
      "         [0.9963],\n",
      "         [0.9976],\n",
      "         [0.9951],\n",
      "         [0.9952],\n",
      "         [0.8424],\n",
      "         [0.9192],\n",
      "         [0.0448],\n",
      "         [0.4574],\n",
      "         [0.8526],\n",
      "         [0.5423],\n",
      "         [0.9982],\n",
      "         [0.9971],\n",
      "         [0.9976],\n",
      "         [0.4414],\n",
      "         [0.1603],\n",
      "         [0.2288],\n",
      "         [0.9742],\n",
      "         [0.9934],\n",
      "         [0.9932],\n",
      "         [0.4494],\n",
      "         [0.6852],\n",
      "         [0.9933],\n",
      "         [0.5153],\n",
      "         [0.9965],\n",
      "         [0.5044],\n",
      "         [0.9969],\n",
      "         [0.6096],\n",
      "         [0.0269],\n",
      "         [0.4999],\n",
      "         [0.9297],\n",
      "         [0.9903],\n",
      "         [0.9913],\n",
      "         [0.8081],\n",
      "         [0.3564],\n",
      "         [0.2424],\n",
      "         [0.4982],\n",
      "         [0.9914],\n",
      "         [0.9932],\n",
      "         [0.9937],\n",
      "         [0.6732],\n",
      "         [0.9936],\n",
      "         [0.9930],\n",
      "         [0.9935],\n",
      "         [0.9922],\n",
      "         [0.9941],\n",
      "         [0.9949],\n",
      "         [0.9952],\n",
      "         [0.5082],\n",
      "         [0.9612],\n",
      "         [0.9963],\n",
      "         [0.9946],\n",
      "         [0.4385],\n",
      "         [0.9809],\n",
      "         [0.9917],\n",
      "         [0.9922],\n",
      "         [0.7380],\n",
      "         [0.7148],\n",
      "         [0.9910],\n",
      "         [0.9927],\n",
      "         [0.3350],\n",
      "         [0.9944],\n",
      "         [0.3795],\n",
      "         [0.4660],\n",
      "         [0.5599],\n",
      "         [1.0009],\n",
      "         [1.0014],\n",
      "         [0.3896],\n",
      "         [0.8666],\n",
      "         [0.2569],\n",
      "         [0.5230],\n",
      "         [0.9958],\n",
      "         [0.9951],\n",
      "         [0.9915],\n",
      "         [0.9566],\n",
      "         [0.9916],\n",
      "         [0.0404],\n",
      "         [0.9924],\n",
      "         [0.4459],\n",
      "         [0.5025],\n",
      "         [0.9965],\n",
      "         [0.9987],\n",
      "         [0.4508],\n",
      "         [0.9991],\n",
      "         [0.2449],\n",
      "         [0.9970],\n",
      "         [0.9957],\n",
      "         [0.9935],\n",
      "         [0.9901],\n",
      "         [0.9903],\n",
      "         [0.0192],\n",
      "         [0.9164],\n",
      "         [0.9900],\n",
      "         [0.8609],\n",
      "         [0.9927],\n",
      "         [0.9934],\n",
      "         [0.9941],\n",
      "         [0.9970],\n",
      "         [0.9954],\n",
      "         [0.5158],\n",
      "         [0.0512],\n",
      "         [0.9925],\n",
      "         [0.9932],\n",
      "         [0.0438],\n",
      "         [0.9924],\n",
      "         [0.9925],\n",
      "         [0.4581],\n",
      "         [0.9939],\n",
      "         [0.9947],\n",
      "         [0.9954],\n",
      "         [0.9958],\n",
      "         [0.9961],\n",
      "         [0.9838],\n",
      "         [0.9952],\n",
      "         [0.9955],\n",
      "         [0.9817],\n",
      "         [0.3551],\n",
      "         [0.9945],\n",
      "         [0.9968],\n",
      "         [0.9975],\n",
      "         [0.9943],\n",
      "         [0.9981],\n",
      "         [0.2553],\n",
      "         [0.9992],\n",
      "         [0.9961],\n",
      "         [0.9961],\n",
      "         [0.0497],\n",
      "         [0.3400],\n",
      "         [0.9937],\n",
      "         [0.9917],\n",
      "         [0.9913],\n",
      "         [0.9905],\n",
      "         [0.9136],\n",
      "         [0.1988],\n",
      "         [0.5105],\n",
      "         [0.9858],\n",
      "         [0.5346],\n",
      "         [0.4588],\n",
      "         [0.3820],\n",
      "         [1.0006],\n",
      "         [0.9980],\n",
      "         [0.9977],\n",
      "         [0.0360],\n",
      "         [0.3597],\n",
      "         [0.9924],\n",
      "         [0.3613],\n",
      "         [0.9899],\n",
      "         [0.9911],\n",
      "         [0.9899],\n",
      "         [0.7643],\n",
      "         [0.6497],\n",
      "         [0.9922],\n",
      "         [0.7834],\n",
      "         [0.9961],\n",
      "         [0.9025],\n",
      "         [0.2537],\n",
      "         [0.9949],\n",
      "         [0.9939],\n",
      "         [0.9952],\n",
      "         [0.9937],\n",
      "         [0.3569],\n",
      "         [0.2337],\n",
      "         [0.3638],\n",
      "         [0.9925],\n",
      "         [0.4959],\n",
      "         [0.9612],\n",
      "         [0.9551],\n",
      "         [0.9931],\n",
      "         [0.9972],\n",
      "         [0.9985],\n",
      "         [0.9985],\n",
      "         [0.0346],\n",
      "         [0.9988]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.9009],\n",
      "        [0.0368],\n",
      "        [0.4645],\n",
      "        [0.8223],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9999],\n",
      "        [0.4480],\n",
      "        [0.1762],\n",
      "        [0.2518],\n",
      "        [0.9724],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.6628],\n",
      "        [0.9997],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.0000],\n",
      "        [0.5030],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.3753],\n",
      "        [0.2646],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.9804],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [0.7129],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.9996],\n",
      "        [0.3930],\n",
      "        [0.4668],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.8296],\n",
      "        [0.2686],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.9520],\n",
      "        [0.9998],\n",
      "        [0.0247],\n",
      "        [0.9997],\n",
      "        [0.4527],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.9998],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0142],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [0.8379],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.5139],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.3728],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.8933],\n",
      "        [0.2208],\n",
      "        [0.5108],\n",
      "        [0.9819],\n",
      "        [0.5245],\n",
      "        [0.4580],\n",
      "        [0.3875],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.0209],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.7391],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.9997],\n",
      "        [0.8761],\n",
      "        [0.2735],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.2547],\n",
      "        [0.3808],\n",
      "        [0.9994],\n",
      "        [0.4988],\n",
      "        [0.9515],\n",
      "        [0.9420],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0174],\n",
      "        [1.0000]])\n",
      "######### Epoch: 68  ######### Train Loss: 0.00013096279872115701  ######### Relative L2 Test Norm: 14.260395050048828\n",
      "Output batch pred: tensor([[[0.9492],\n",
      "         [0.9905],\n",
      "         [0.9918],\n",
      "         [0.9941],\n",
      "         [0.4500],\n",
      "         [0.9957],\n",
      "         [0.9973],\n",
      "         [0.4609],\n",
      "         [0.6108],\n",
      "         [0.9954],\n",
      "         [0.5060],\n",
      "         [0.0458],\n",
      "         [0.7383],\n",
      "         [0.9912],\n",
      "         [0.9898],\n",
      "         [0.9552],\n",
      "         [0.9918],\n",
      "         [0.7155],\n",
      "         [0.3489],\n",
      "         [0.9940],\n",
      "         [0.9208],\n",
      "         [0.9957],\n",
      "         [0.9966],\n",
      "         [0.4573],\n",
      "         [0.9986],\n",
      "         [0.9849],\n",
      "         [0.5085],\n",
      "         [0.9973],\n",
      "         [0.9962],\n",
      "         [0.9946],\n",
      "         [0.0334],\n",
      "         [0.9907],\n",
      "         [0.9157],\n",
      "         [0.3673],\n",
      "         [0.9839],\n",
      "         [0.4373],\n",
      "         [0.2325],\n",
      "         [0.9900],\n",
      "         [0.9921],\n",
      "         [0.9954],\n",
      "         [0.9959],\n",
      "         [0.3657],\n",
      "         [0.9855],\n",
      "         [0.9984],\n",
      "         [0.9983],\n",
      "         [0.0315],\n",
      "         [0.9958],\n",
      "         [0.3732],\n",
      "         [0.9954],\n",
      "         [0.9954],\n",
      "         [0.9945],\n",
      "         [0.9949],\n",
      "         [0.2309],\n",
      "         [0.9942],\n",
      "         [0.8573],\n",
      "         [0.9929],\n",
      "         [0.9909],\n",
      "         [0.4870],\n",
      "         [0.9754],\n",
      "         [0.9866],\n",
      "         [0.4902],\n",
      "         [0.5054],\n",
      "         [0.9868],\n",
      "         [0.9903],\n",
      "         [0.9902],\n",
      "         [0.2483],\n",
      "         [0.9956],\n",
      "         [0.4437],\n",
      "         [0.4482],\n",
      "         [0.5466],\n",
      "         [0.9996],\n",
      "         [0.9993],\n",
      "         [0.5351],\n",
      "         [0.9960],\n",
      "         [0.9961],\n",
      "         [0.9951],\n",
      "         [0.3389],\n",
      "         [0.6514],\n",
      "         [0.8434],\n",
      "         [0.9947],\n",
      "         [0.9607],\n",
      "         [0.9937],\n",
      "         [0.9976],\n",
      "         [0.9972],\n",
      "         [0.9878],\n",
      "         [1.0004],\n",
      "         [1.0016],\n",
      "         [0.5191],\n",
      "         [0.0409],\n",
      "         [0.9980],\n",
      "         [0.9979],\n",
      "         [0.9758],\n",
      "         [0.9940],\n",
      "         [0.9924],\n",
      "         [0.5111],\n",
      "         [0.0467],\n",
      "         [0.3691],\n",
      "         [0.3567],\n",
      "         [0.9926],\n",
      "         [0.9921],\n",
      "         [0.2415],\n",
      "         [0.8502],\n",
      "         [0.9576],\n",
      "         [0.3331],\n",
      "         [0.9911],\n",
      "         [0.9894],\n",
      "         [0.9913],\n",
      "         [0.4913],\n",
      "         [0.5080],\n",
      "         [0.9933],\n",
      "         [0.9933],\n",
      "         [0.4600],\n",
      "         [0.9942],\n",
      "         [0.9966],\n",
      "         [0.9944],\n",
      "         [0.2317],\n",
      "         [0.9920],\n",
      "         [0.9920],\n",
      "         [0.9889],\n",
      "         [0.0295],\n",
      "         [0.9883],\n",
      "         [0.0284],\n",
      "         [0.6783],\n",
      "         [0.9906],\n",
      "         [0.9922],\n",
      "         [0.9308],\n",
      "         [0.9953],\n",
      "         [0.9963],\n",
      "         [0.8681],\n",
      "         [0.6819],\n",
      "         [0.3730],\n",
      "         [0.9989],\n",
      "         [1.0010],\n",
      "         [0.9994],\n",
      "         [0.9991],\n",
      "         [0.9984],\n",
      "         [0.9993],\n",
      "         [0.9967],\n",
      "         [0.9936],\n",
      "         [0.9024],\n",
      "         [0.9948],\n",
      "         [0.9965],\n",
      "         [0.9956],\n",
      "         [0.9961],\n",
      "         [0.2565],\n",
      "         [0.9982],\n",
      "         [0.7720],\n",
      "         [0.9984],\n",
      "         [0.3600],\n",
      "         [0.1609],\n",
      "         [0.2498],\n",
      "         [0.9916],\n",
      "         [0.3565],\n",
      "         [0.7783],\n",
      "         [0.9922],\n",
      "         [0.9912],\n",
      "         [0.5491],\n",
      "         [0.4577],\n",
      "         [0.8144],\n",
      "         [0.2042],\n",
      "         [0.9964],\n",
      "         [0.9972],\n",
      "         [0.9188],\n",
      "         [0.9973],\n",
      "         [0.9975],\n",
      "         [0.2390],\n",
      "         [0.9976],\n",
      "         [0.0266],\n",
      "         [0.0525],\n",
      "         [0.4458],\n",
      "         [0.5021],\n",
      "         [0.9969],\n",
      "         [0.9956],\n",
      "         [0.9947],\n",
      "         [0.9935],\n",
      "         [0.9922],\n",
      "         [0.4277],\n",
      "         [0.9905]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9420],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [0.5945],\n",
      "        [0.9998],\n",
      "        [0.5080],\n",
      "        [0.0335],\n",
      "        [0.7129],\n",
      "        [0.9996],\n",
      "        [0.9996],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.3728],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.3930],\n",
      "        [0.9956],\n",
      "        [0.4552],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.3808],\n",
      "        [0.9804],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.9999],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.9819],\n",
      "        [0.9999],\n",
      "        [0.5038],\n",
      "        [0.5165],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [0.4503],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3575],\n",
      "        [0.6327],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [0.0288],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [0.9724],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5151],\n",
      "        [0.0368],\n",
      "        [0.3875],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.8223],\n",
      "        [0.9520],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.4668],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0142],\n",
      "        [0.9997],\n",
      "        [0.0174],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.6555],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.7391],\n",
      "        [0.9999],\n",
      "        [0.3753],\n",
      "        [0.1762],\n",
      "        [0.2729],\n",
      "        [0.9962],\n",
      "        [0.3780],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5463],\n",
      "        [0.4645],\n",
      "        [0.7820],\n",
      "        [0.2208],\n",
      "        [0.9995],\n",
      "        [0.9995],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.9999],\n",
      "        [0.0000],\n",
      "        [0.0383],\n",
      "        [0.4527],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [1.0000]])\n",
      "######### Epoch: 69  ######### Train Loss: 0.0001526723353890702  ######### Relative L2 Test Norm: 14.44659423828125\n",
      "Output batch pred: tensor([[[0.3636],\n",
      "         [0.4532],\n",
      "         [0.9337],\n",
      "         [0.9971],\n",
      "         [0.9983],\n",
      "         [1.0001],\n",
      "         [0.9662],\n",
      "         [1.0018],\n",
      "         [1.0022],\n",
      "         [1.0025],\n",
      "         [1.0020],\n",
      "         [1.0033],\n",
      "         [1.0017],\n",
      "         [0.9992],\n",
      "         [0.0434],\n",
      "         [0.9978],\n",
      "         [0.9967],\n",
      "         [0.2547],\n",
      "         [0.9944],\n",
      "         [0.9952],\n",
      "         [0.9953],\n",
      "         [0.5059],\n",
      "         [0.9955],\n",
      "         [0.4486],\n",
      "         [0.4610],\n",
      "         [0.9937],\n",
      "         [0.9909],\n",
      "         [0.5481],\n",
      "         [0.1559],\n",
      "         [0.9930],\n",
      "         [0.2385],\n",
      "         [0.9945],\n",
      "         [0.9957],\n",
      "         [0.0292],\n",
      "         [0.4426],\n",
      "         [0.0514],\n",
      "         [0.9975],\n",
      "         [0.9965],\n",
      "         [0.9952],\n",
      "         [0.2500],\n",
      "         [0.3569],\n",
      "         [0.4395],\n",
      "         [0.1958],\n",
      "         [0.9908],\n",
      "         [0.9893],\n",
      "         [0.9901],\n",
      "         [0.0311],\n",
      "         [0.9930],\n",
      "         [0.9189],\n",
      "         [0.9941],\n",
      "         [0.9578],\n",
      "         [0.9938],\n",
      "         [0.9912],\n",
      "         [0.9189],\n",
      "         [0.9914],\n",
      "         [0.9094],\n",
      "         [0.4919],\n",
      "         [0.5983],\n",
      "         [0.8348],\n",
      "         [0.9868],\n",
      "         [0.9853],\n",
      "         [0.9850],\n",
      "         [0.9868],\n",
      "         [0.9839],\n",
      "         [0.9867],\n",
      "         [0.8437],\n",
      "         [0.9905],\n",
      "         [0.0276],\n",
      "         [0.9930],\n",
      "         [0.9955],\n",
      "         [0.9986],\n",
      "         [0.9997],\n",
      "         [1.0007],\n",
      "         [0.7486],\n",
      "         [0.6936],\n",
      "         [0.5184],\n",
      "         [0.0506],\n",
      "         [0.9980],\n",
      "         [0.9952],\n",
      "         [0.9956],\n",
      "         [0.9962],\n",
      "         [0.9948],\n",
      "         [0.9840],\n",
      "         [0.9961],\n",
      "         [0.6785],\n",
      "         [0.8175],\n",
      "         [0.9998],\n",
      "         [0.3454],\n",
      "         [0.9887],\n",
      "         [0.3841],\n",
      "         [0.4636],\n",
      "         [0.7895],\n",
      "         [1.0004],\n",
      "         [0.9963],\n",
      "         [0.9982],\n",
      "         [0.9988],\n",
      "         [0.9978],\n",
      "         [0.9959],\n",
      "         [0.3520],\n",
      "         [0.4548],\n",
      "         [0.9933],\n",
      "         [0.8531],\n",
      "         [0.9894],\n",
      "         [0.3637],\n",
      "         [0.4989],\n",
      "         [0.6395],\n",
      "         [0.5056],\n",
      "         [0.2307],\n",
      "         [0.2351],\n",
      "         [0.4937],\n",
      "         [0.0393],\n",
      "         [0.9899],\n",
      "         [0.2444],\n",
      "         [0.9942],\n",
      "         [0.9970],\n",
      "         [0.4537],\n",
      "         [0.9957],\n",
      "         [0.4394],\n",
      "         [0.5052],\n",
      "         [0.9910],\n",
      "         [0.4330],\n",
      "         [0.9917],\n",
      "         [0.9919],\n",
      "         [0.9794],\n",
      "         [0.5156],\n",
      "         [0.9954],\n",
      "         [0.3777],\n",
      "         [0.9962],\n",
      "         [0.9961],\n",
      "         [0.8656],\n",
      "         [0.9938],\n",
      "         [0.9921],\n",
      "         [0.9888],\n",
      "         [0.9885],\n",
      "         [0.8920],\n",
      "         [0.9851],\n",
      "         [0.0135],\n",
      "         [0.9888],\n",
      "         [0.9925],\n",
      "         [0.9947],\n",
      "         [0.9981],\n",
      "         [0.9662],\n",
      "         [1.0015],\n",
      "         [0.5050],\n",
      "         [0.7281],\n",
      "         [0.9985],\n",
      "         [0.3700],\n",
      "         [0.9936],\n",
      "         [0.5211],\n",
      "         [0.2225],\n",
      "         [0.3453],\n",
      "         [0.9834],\n",
      "         [0.9838],\n",
      "         [0.9867],\n",
      "         [0.9896],\n",
      "         [0.9906],\n",
      "         [0.9933],\n",
      "         [0.3608],\n",
      "         [0.5442],\n",
      "         [0.9999],\n",
      "         [0.9987],\n",
      "         [0.9997],\n",
      "         [0.9578],\n",
      "         [0.9971],\n",
      "         [0.9962],\n",
      "         [0.9926],\n",
      "         [0.3328],\n",
      "         [0.9918],\n",
      "         [0.4939],\n",
      "         [0.9908],\n",
      "         [0.9928],\n",
      "         [0.9729],\n",
      "         [0.7650],\n",
      "         [0.9794],\n",
      "         [0.9932],\n",
      "         [0.0229],\n",
      "         [0.9920],\n",
      "         [0.2524]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.3808],\n",
      "        [0.4611],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.4668],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.0142],\n",
      "        [0.4503],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.3753],\n",
      "        [0.4527],\n",
      "        [0.2208],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0335],\n",
      "        [0.9999],\n",
      "        [0.9009],\n",
      "        [0.9999],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.5038],\n",
      "        [0.5945],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.9997],\n",
      "        [0.0288],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.7129],\n",
      "        [0.6628],\n",
      "        [0.5139],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [0.9819],\n",
      "        [0.3930],\n",
      "        [0.4645],\n",
      "        [0.7540],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.3728],\n",
      "        [0.4642],\n",
      "        [0.9997],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.5108],\n",
      "        [0.6327],\n",
      "        [0.5165],\n",
      "        [0.2547],\n",
      "        [0.2577],\n",
      "        [0.5009],\n",
      "        [0.0209],\n",
      "        [0.9956],\n",
      "        [0.2610],\n",
      "        [0.9967],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.6920],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.2518],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9995],\n",
      "        [0.3780],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9966],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [0.7391],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.9998],\n",
      "        [0.2735]])\n",
      "######### Epoch: 70  ######### Train Loss: 0.00016246650193352252  ######### Relative L2 Test Norm: 14.366520881652832\n",
      "Output batch pred: tensor([[[0.5430],\n",
      "         [0.9987],\n",
      "         [0.9977],\n",
      "         [0.5298],\n",
      "         [0.9962],\n",
      "         [0.9943],\n",
      "         [0.9596],\n",
      "         [0.9943],\n",
      "         [0.9941],\n",
      "         [0.8408],\n",
      "         [0.3702],\n",
      "         [0.9922],\n",
      "         [0.9102],\n",
      "         [0.3336],\n",
      "         [0.3485],\n",
      "         [0.9920],\n",
      "         [0.2323],\n",
      "         [0.9918],\n",
      "         [0.9206],\n",
      "         [0.9962],\n",
      "         [0.9926],\n",
      "         [0.8669],\n",
      "         [0.0320],\n",
      "         [0.9971],\n",
      "         [0.9957],\n",
      "         [0.4980],\n",
      "         [0.0166],\n",
      "         [0.9923],\n",
      "         [0.4942],\n",
      "         [0.9912],\n",
      "         [0.9913],\n",
      "         [0.2404],\n",
      "         [0.3520],\n",
      "         [0.9933],\n",
      "         [0.4406],\n",
      "         [0.5110],\n",
      "         [0.5082],\n",
      "         [0.9942],\n",
      "         [0.4590],\n",
      "         [0.3632],\n",
      "         [0.9925],\n",
      "         [0.9565],\n",
      "         [0.9932],\n",
      "         [0.3667],\n",
      "         [0.9936],\n",
      "         [0.9959],\n",
      "         [0.4358],\n",
      "         [0.9968],\n",
      "         [0.9855],\n",
      "         [0.9997],\n",
      "         [0.9994],\n",
      "         [0.4978],\n",
      "         [0.9958],\n",
      "         [0.9814],\n",
      "         [0.9906],\n",
      "         [0.9884],\n",
      "         [0.9853],\n",
      "         [0.0228],\n",
      "         [0.5349],\n",
      "         [0.9867],\n",
      "         [0.9878],\n",
      "         [0.6433],\n",
      "         [0.9908],\n",
      "         [0.9927],\n",
      "         [0.9536],\n",
      "         [0.9948],\n",
      "         [0.4547],\n",
      "         [0.4601],\n",
      "         [0.3599],\n",
      "         [0.9981],\n",
      "         [0.9991],\n",
      "         [0.9662],\n",
      "         [1.0013],\n",
      "         [0.9893],\n",
      "         [0.2410],\n",
      "         [0.4498],\n",
      "         [0.3472],\n",
      "         [0.2591],\n",
      "         [0.9960],\n",
      "         [0.9955],\n",
      "         [0.9312],\n",
      "         [0.7637],\n",
      "         [0.9917],\n",
      "         [0.2435],\n",
      "         [0.9916],\n",
      "         [0.9925],\n",
      "         [0.5055],\n",
      "         [0.8550],\n",
      "         [0.9994],\n",
      "         [0.9986],\n",
      "         [1.0006],\n",
      "         [1.0009],\n",
      "         [0.9994],\n",
      "         [0.9981],\n",
      "         [0.9987],\n",
      "         [0.4503],\n",
      "         [0.8139],\n",
      "         [0.9953],\n",
      "         [0.9928],\n",
      "         [0.3603],\n",
      "         [0.0524],\n",
      "         [0.9908],\n",
      "         [0.0484],\n",
      "         [0.9894],\n",
      "         [0.2028],\n",
      "         [0.9905],\n",
      "         [0.3739],\n",
      "         [0.0316],\n",
      "         [0.9920],\n",
      "         [0.9924],\n",
      "         [0.9938],\n",
      "         [0.5073],\n",
      "         [0.2399],\n",
      "         [0.9997],\n",
      "         [0.9984],\n",
      "         [0.9959],\n",
      "         [0.9981],\n",
      "         [0.9028],\n",
      "         [0.9951],\n",
      "         [0.9903],\n",
      "         [0.9916],\n",
      "         [0.9882],\n",
      "         [0.9901],\n",
      "         [0.9896],\n",
      "         [0.9162],\n",
      "         [0.4327],\n",
      "         [0.3638],\n",
      "         [0.9780],\n",
      "         [0.0298],\n",
      "         [0.9891],\n",
      "         [0.0435],\n",
      "         [0.9891],\n",
      "         [0.9701],\n",
      "         [0.2327],\n",
      "         [0.9904],\n",
      "         [0.9893],\n",
      "         [0.7378],\n",
      "         [0.9933],\n",
      "         [0.9950],\n",
      "         [0.0276],\n",
      "         [0.9967],\n",
      "         [0.9991],\n",
      "         [1.0005],\n",
      "         [0.9998],\n",
      "         [1.0003],\n",
      "         [0.9999],\n",
      "         [0.6152],\n",
      "         [0.9986],\n",
      "         [0.9962],\n",
      "         [0.9968],\n",
      "         [0.1567],\n",
      "         [0.9950],\n",
      "         [0.9943],\n",
      "         [0.9936],\n",
      "         [0.9919],\n",
      "         [0.6845],\n",
      "         [0.5132],\n",
      "         [0.9938],\n",
      "         [0.9947],\n",
      "         [0.9940],\n",
      "         [0.4448],\n",
      "         [0.9951],\n",
      "         [0.9958],\n",
      "         [0.9956],\n",
      "         [0.5133],\n",
      "         [0.9931],\n",
      "         [0.9935],\n",
      "         [0.8554],\n",
      "         [0.9937],\n",
      "         [0.2312],\n",
      "         [0.7174],\n",
      "         [0.4972],\n",
      "         [0.9955],\n",
      "         [0.9984],\n",
      "         [0.6794],\n",
      "         [0.9980],\n",
      "         [0.7867],\n",
      "         [0.4628]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.5334],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [0.3912],\n",
      "        [0.9996],\n",
      "        [0.8933],\n",
      "        [0.3575],\n",
      "        [0.3728],\n",
      "        [0.9998],\n",
      "        [0.2610],\n",
      "        [0.9967],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [0.8379],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.3747],\n",
      "        [0.9997],\n",
      "        [0.4527],\n",
      "        [0.5139],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.9999],\n",
      "        [0.3875],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4454],\n",
      "        [0.9996],\n",
      "        [0.9814],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.4642],\n",
      "        [0.3753],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.2518],\n",
      "        [0.4503],\n",
      "        [0.3573],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5080],\n",
      "        [0.8223],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.3780],\n",
      "        [0.0368],\n",
      "        [0.9999],\n",
      "        [0.0288],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.2577],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9044],\n",
      "        [0.4480],\n",
      "        [0.3840],\n",
      "        [0.9804],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.5945],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.6628],\n",
      "        [0.5165],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [0.2547],\n",
      "        [0.6920],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.4645]])\n",
      "######### Epoch: 71  ######### Train Loss: 0.0001541155797895044  ######### Relative L2 Test Norm: 14.313594818115234\n",
      "Output batch pred: tensor([[[0.0438],\n",
      "         [0.5059],\n",
      "         [0.9959],\n",
      "         [0.9971],\n",
      "         [0.9950],\n",
      "         [0.9956],\n",
      "         [0.9936],\n",
      "         [0.2214],\n",
      "         [0.9911],\n",
      "         [0.9902],\n",
      "         [0.0437],\n",
      "         [0.9911],\n",
      "         [0.9943],\n",
      "         [0.3653],\n",
      "         [0.9981],\n",
      "         [0.5129],\n",
      "         [0.0480],\n",
      "         [1.0013],\n",
      "         [0.5027],\n",
      "         [0.0539],\n",
      "         [0.9993],\n",
      "         [0.9981],\n",
      "         [0.9955],\n",
      "         [0.8124],\n",
      "         [0.9931],\n",
      "         [0.3673],\n",
      "         [0.4304],\n",
      "         [0.9561],\n",
      "         [0.9915],\n",
      "         [0.9907],\n",
      "         [0.9915],\n",
      "         [0.4499],\n",
      "         [0.9955],\n",
      "         [0.9936],\n",
      "         [0.9992],\n",
      "         [1.0012],\n",
      "         [0.9992],\n",
      "         [0.9668],\n",
      "         [0.5487],\n",
      "         [1.0007],\n",
      "         [0.5565],\n",
      "         [0.9951],\n",
      "         [0.9934],\n",
      "         [0.8409],\n",
      "         [0.9918],\n",
      "         [0.6017],\n",
      "         [0.2278],\n",
      "         [0.3588],\n",
      "         [0.8980],\n",
      "         [0.4562],\n",
      "         [0.2017],\n",
      "         [0.9947],\n",
      "         [0.6779],\n",
      "         [0.9959],\n",
      "         [0.4428],\n",
      "         [0.2382],\n",
      "         [0.9925],\n",
      "         [0.9896],\n",
      "         [0.9899],\n",
      "         [0.8517],\n",
      "         [0.9888],\n",
      "         [0.9712],\n",
      "         [0.9914],\n",
      "         [0.9947],\n",
      "         [0.8510],\n",
      "         [0.9954],\n",
      "         [0.3404],\n",
      "         [0.5129],\n",
      "         [0.6919],\n",
      "         [0.9998],\n",
      "         [0.9993],\n",
      "         [0.0322],\n",
      "         [0.9959],\n",
      "         [0.9958],\n",
      "         [0.5097],\n",
      "         [0.9927],\n",
      "         [0.9895],\n",
      "         [0.3692],\n",
      "         [0.8569],\n",
      "         [0.0317],\n",
      "         [0.9769],\n",
      "         [0.9904],\n",
      "         [0.9189],\n",
      "         [0.9948],\n",
      "         [0.9956],\n",
      "         [0.9979],\n",
      "         [0.9988],\n",
      "         [0.9985],\n",
      "         [0.9987],\n",
      "         [0.4587],\n",
      "         [0.9971],\n",
      "         [0.5010],\n",
      "         [0.9536],\n",
      "         [0.9933],\n",
      "         [0.9956],\n",
      "         [0.9956],\n",
      "         [0.2417],\n",
      "         [0.9970],\n",
      "         [0.9961],\n",
      "         [0.4439],\n",
      "         [0.9951],\n",
      "         [0.2372],\n",
      "         [0.4343],\n",
      "         [0.5205],\n",
      "         [0.9894],\n",
      "         [0.3584],\n",
      "         [0.9871],\n",
      "         [0.4881],\n",
      "         [0.9901],\n",
      "         [0.2477],\n",
      "         [0.2508],\n",
      "         [0.9971],\n",
      "         [0.9995],\n",
      "         [1.0006],\n",
      "         [1.0013],\n",
      "         [1.0019],\n",
      "         [1.0013],\n",
      "         [1.0017],\n",
      "         [0.2476],\n",
      "         [0.9995],\n",
      "         [0.9977],\n",
      "         [0.9969],\n",
      "         [0.9834],\n",
      "         [0.7416],\n",
      "         [0.9833],\n",
      "         [0.9956],\n",
      "         [0.3575],\n",
      "         [0.9226],\n",
      "         [0.9953],\n",
      "         [0.9945],\n",
      "         [0.3545],\n",
      "         [0.5106],\n",
      "         [0.9896],\n",
      "         [0.0151],\n",
      "         [0.9873],\n",
      "         [0.9861],\n",
      "         [0.9526],\n",
      "         [0.3454],\n",
      "         [0.9912],\n",
      "         [0.4981],\n",
      "         [0.9823],\n",
      "         [0.9986],\n",
      "         [0.7903],\n",
      "         [0.1727],\n",
      "         [0.6636],\n",
      "         [1.0033],\n",
      "         [0.9405],\n",
      "         [1.0008],\n",
      "         [0.0452],\n",
      "         [0.9966],\n",
      "         [0.4557],\n",
      "         [0.9912],\n",
      "         [0.7117],\n",
      "         [0.9094],\n",
      "         [0.9897],\n",
      "         [0.9899],\n",
      "         [0.9911],\n",
      "         [0.3693],\n",
      "         [0.9933],\n",
      "         [0.9930],\n",
      "         [0.9958],\n",
      "         [0.9967],\n",
      "         [0.7712],\n",
      "         [0.9977],\n",
      "         [0.4513],\n",
      "         [0.4558],\n",
      "         [1.0012],\n",
      "         [0.9978],\n",
      "         [1.0010],\n",
      "         [0.3410],\n",
      "         [0.9977],\n",
      "         [0.9971],\n",
      "         [0.9950],\n",
      "         [0.9948],\n",
      "         [0.9928],\n",
      "         [0.5099],\n",
      "         [0.9927],\n",
      "         [0.0202]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.0288],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.0383],\n",
      "        [0.9966],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.5080],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [0.4988],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.4454],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.9490],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.2547],\n",
      "        [0.3808],\n",
      "        [0.8761],\n",
      "        [0.4642],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.9998],\n",
      "        [0.4527],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.8223],\n",
      "        [0.9967],\n",
      "        [0.3573],\n",
      "        [0.5108],\n",
      "        [0.6628],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.3930],\n",
      "        [0.8379],\n",
      "        [0.0247],\n",
      "        [0.9804],\n",
      "        [0.9997],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.9998],\n",
      "        [0.5038],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [0.4503],\n",
      "        [0.9999],\n",
      "        [0.2577],\n",
      "        [0.4480],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.7129],\n",
      "        [0.9819],\n",
      "        [0.9999],\n",
      "        [0.3753],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9515],\n",
      "        [0.3728],\n",
      "        [0.9997],\n",
      "        [0.5030],\n",
      "        [0.9814],\n",
      "        [0.9998],\n",
      "        [0.7540],\n",
      "        [0.1762],\n",
      "        [0.6327],\n",
      "        [0.9999],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.8933],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.0000]])\n",
      "######### Epoch: 72  ######### Train Loss: 0.00016136153135448694  ######### Relative L2 Test Norm: 14.572982788085938\n",
      "Output batch pred: tensor([[[0.9934],\n",
      "         [0.5121],\n",
      "         [0.0464],\n",
      "         [0.9913],\n",
      "         [0.9931],\n",
      "         [0.1601],\n",
      "         [0.9940],\n",
      "         [0.9944],\n",
      "         [0.9916],\n",
      "         [0.4351],\n",
      "         [0.9942],\n",
      "         [0.5490],\n",
      "         [0.9956],\n",
      "         [0.9967],\n",
      "         [0.8673],\n",
      "         [0.9972],\n",
      "         [0.9810],\n",
      "         [1.0016],\n",
      "         [0.3871],\n",
      "         [0.7785],\n",
      "         [0.8530],\n",
      "         [0.9398],\n",
      "         [1.0004],\n",
      "         [0.9978],\n",
      "         [0.9971],\n",
      "         [0.9945],\n",
      "         [0.9954],\n",
      "         [0.9936],\n",
      "         [0.0301],\n",
      "         [0.0357],\n",
      "         [0.9927],\n",
      "         [0.9938],\n",
      "         [0.9952],\n",
      "         [0.9941],\n",
      "         [0.5402],\n",
      "         [0.3572],\n",
      "         [0.9844],\n",
      "         [0.2030],\n",
      "         [0.5130],\n",
      "         [0.9983],\n",
      "         [0.9977],\n",
      "         [0.6901],\n",
      "         [0.9986],\n",
      "         [0.7430],\n",
      "         [0.3667],\n",
      "         [0.9844],\n",
      "         [0.9608],\n",
      "         [0.9955],\n",
      "         [0.0434],\n",
      "         [0.9988],\n",
      "         [0.7873],\n",
      "         [0.2453],\n",
      "         [0.3811],\n",
      "         [1.0007],\n",
      "         [0.7269],\n",
      "         [0.9966],\n",
      "         [0.9039],\n",
      "         [0.9617],\n",
      "         [0.4450],\n",
      "         [0.9920],\n",
      "         [0.4960],\n",
      "         [0.9470],\n",
      "         [0.9874],\n",
      "         [0.9902],\n",
      "         [0.9913],\n",
      "         [0.9914],\n",
      "         [0.3342],\n",
      "         [0.9944],\n",
      "         [0.9958],\n",
      "         [0.3597],\n",
      "         [0.0429],\n",
      "         [0.9972],\n",
      "         [0.8539],\n",
      "         [0.2386],\n",
      "         [0.9975],\n",
      "         [0.9852],\n",
      "         [0.9189],\n",
      "         [0.9979],\n",
      "         [0.9622],\n",
      "         [0.3621],\n",
      "         [0.2494],\n",
      "         [0.4371],\n",
      "         [0.9939],\n",
      "         [0.4909],\n",
      "         [0.8095],\n",
      "         [0.4982],\n",
      "         [0.9938],\n",
      "         [0.2452],\n",
      "         [0.9968],\n",
      "         [0.9990],\n",
      "         [1.0000],\n",
      "         [1.0003],\n",
      "         [0.0181],\n",
      "         [0.9993],\n",
      "         [0.9977],\n",
      "         [0.9990],\n",
      "         [0.9981],\n",
      "         [0.9997],\n",
      "         [0.9992],\n",
      "         [1.0022],\n",
      "         [0.5118],\n",
      "         [0.3462],\n",
      "         [0.9322],\n",
      "         [1.0013],\n",
      "         [1.0017],\n",
      "         [0.9996],\n",
      "         [0.4523],\n",
      "         [0.5079],\n",
      "         [0.9902],\n",
      "         [0.9884],\n",
      "         [0.4846],\n",
      "         [0.9869],\n",
      "         [0.2398],\n",
      "         [0.9895],\n",
      "         [0.4528],\n",
      "         [0.8552],\n",
      "         [0.2332],\n",
      "         [0.9956],\n",
      "         [0.4508],\n",
      "         [0.9971],\n",
      "         [0.3651],\n",
      "         [0.9999],\n",
      "         [0.3651],\n",
      "         [0.0366],\n",
      "         [0.9999],\n",
      "         [0.9992],\n",
      "         [0.5203],\n",
      "         [0.9966],\n",
      "         [0.6120],\n",
      "         [0.9970],\n",
      "         [0.4371],\n",
      "         [0.9952],\n",
      "         [0.9929],\n",
      "         [0.4564],\n",
      "         [0.4547],\n",
      "         [0.9922],\n",
      "         [0.9917],\n",
      "         [0.9910],\n",
      "         [0.2401],\n",
      "         [0.9924],\n",
      "         [0.0284],\n",
      "         [0.9912],\n",
      "         [0.9920],\n",
      "         [0.9930],\n",
      "         [0.9952],\n",
      "         [0.5311],\n",
      "         [0.4464],\n",
      "         [0.9959],\n",
      "         [0.9965],\n",
      "         [0.9973],\n",
      "         [0.9966],\n",
      "         [0.9210],\n",
      "         [0.9949],\n",
      "         [0.9936],\n",
      "         [0.9926],\n",
      "         [0.0485],\n",
      "         [0.4981],\n",
      "         [0.2320],\n",
      "         [0.9928],\n",
      "         [0.9947],\n",
      "         [0.9950],\n",
      "         [0.6790],\n",
      "         [0.9967],\n",
      "         [0.9945],\n",
      "         [0.6547],\n",
      "         [0.9962],\n",
      "         [0.9954],\n",
      "         [0.9945],\n",
      "         [0.3758],\n",
      "         [0.9968],\n",
      "         [0.9937],\n",
      "         [0.9973],\n",
      "         [0.9843],\n",
      "         [0.9984],\n",
      "         [0.9982],\n",
      "         [0.9964],\n",
      "         [0.9955],\n",
      "         [0.9959]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.5165],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9962],\n",
      "        [0.4480],\n",
      "        [0.9998],\n",
      "        [0.5463],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9967],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.7391],\n",
      "        [0.8139],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0142],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.3728],\n",
      "        [0.9819],\n",
      "        [0.2208],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.3840],\n",
      "        [0.9820],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.2577],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.9956],\n",
      "        [0.8761],\n",
      "        [0.9515],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9420],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.8933],\n",
      "        [0.9999],\n",
      "        [0.9490],\n",
      "        [0.3808],\n",
      "        [0.2735],\n",
      "        [0.4503],\n",
      "        [0.9997],\n",
      "        [0.4988],\n",
      "        [0.7820],\n",
      "        [0.5030],\n",
      "        [0.9996],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5054],\n",
      "        [0.3573],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.8296],\n",
      "        [0.2547],\n",
      "        [0.9995],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.9996],\n",
      "        [0.4454],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [0.4642],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.9999],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.5038],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9997],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9995],\n",
      "        [0.9997]])\n",
      "######### Epoch: 73  ######### Train Loss: 0.0001622670388314873  ######### Relative L2 Test Norm: 14.259900093078613\n",
      "Output batch pred: tensor([[[0.9939],\n",
      "         [0.9807],\n",
      "         [0.9967],\n",
      "         [0.9959],\n",
      "         [0.9974],\n",
      "         [0.9979],\n",
      "         [0.9973],\n",
      "         [0.9949],\n",
      "         [0.9971],\n",
      "         [0.9955],\n",
      "         [0.9954],\n",
      "         [0.9952],\n",
      "         [0.9904],\n",
      "         [0.9938],\n",
      "         [0.5051],\n",
      "         [0.9916],\n",
      "         [0.9895],\n",
      "         [0.9905],\n",
      "         [0.9904],\n",
      "         [0.9278],\n",
      "         [0.8534],\n",
      "         [0.3660],\n",
      "         [0.9927],\n",
      "         [0.9925],\n",
      "         [0.7713],\n",
      "         [0.9963],\n",
      "         [0.9980],\n",
      "         [0.9978],\n",
      "         [0.4545],\n",
      "         [0.9990],\n",
      "         [0.9988],\n",
      "         [0.9994],\n",
      "         [0.9995],\n",
      "         [0.9992],\n",
      "         [0.5222],\n",
      "         [0.4635],\n",
      "         [0.9961],\n",
      "         [0.9959],\n",
      "         [0.3753],\n",
      "         [0.7820],\n",
      "         [0.9917],\n",
      "         [0.9581],\n",
      "         [0.9939],\n",
      "         [0.3413],\n",
      "         [0.9968],\n",
      "         [0.7461],\n",
      "         [0.9988],\n",
      "         [0.9999],\n",
      "         [1.0021],\n",
      "         [1.0003],\n",
      "         [1.0018],\n",
      "         [0.2036],\n",
      "         [0.9999],\n",
      "         [0.9984],\n",
      "         [0.5148],\n",
      "         [0.6531],\n",
      "         [0.9930],\n",
      "         [0.9953],\n",
      "         [0.9951],\n",
      "         [0.2342],\n",
      "         [0.9937],\n",
      "         [0.9827],\n",
      "         [0.9930],\n",
      "         [0.4368],\n",
      "         [0.9936],\n",
      "         [0.9921],\n",
      "         [0.0169],\n",
      "         [0.6860],\n",
      "         [0.9966],\n",
      "         [0.9258],\n",
      "         [0.9891],\n",
      "         [0.6878],\n",
      "         [0.0334],\n",
      "         [1.0027],\n",
      "         [1.0057],\n",
      "         [1.0025],\n",
      "         [0.3636],\n",
      "         [1.0004],\n",
      "         [0.9971],\n",
      "         [0.4555],\n",
      "         [0.9925],\n",
      "         [0.3723],\n",
      "         [0.9927],\n",
      "         [0.9956],\n",
      "         [0.9972],\n",
      "         [0.9982],\n",
      "         [0.0440],\n",
      "         [0.5014],\n",
      "         [0.9997],\n",
      "         [0.4578],\n",
      "         [0.0560],\n",
      "         [0.8559],\n",
      "         [1.0010],\n",
      "         [0.3818],\n",
      "         [0.5067],\n",
      "         [0.3689],\n",
      "         [1.0016],\n",
      "         [0.5451],\n",
      "         [0.9657],\n",
      "         [1.0001],\n",
      "         [0.5031],\n",
      "         [0.9989],\n",
      "         [0.9978],\n",
      "         [0.9555],\n",
      "         [0.9971],\n",
      "         [0.9961],\n",
      "         [0.4383],\n",
      "         [0.5523],\n",
      "         [0.4992],\n",
      "         [0.3618],\n",
      "         [0.3660],\n",
      "         [1.0032],\n",
      "         [0.0395],\n",
      "         [1.0003],\n",
      "         [0.2373],\n",
      "         [0.9986],\n",
      "         [0.9986],\n",
      "         [0.2479],\n",
      "         [0.5140],\n",
      "         [0.9954],\n",
      "         [0.3359],\n",
      "         [0.5039],\n",
      "         [0.9956],\n",
      "         [0.9958],\n",
      "         [0.4611],\n",
      "         [0.9957],\n",
      "         [0.4383],\n",
      "         [0.0466],\n",
      "         [0.8469],\n",
      "         [0.2498],\n",
      "         [0.9984],\n",
      "         [0.8674],\n",
      "         [0.3612],\n",
      "         [0.9967],\n",
      "         [0.4450],\n",
      "         [0.2450],\n",
      "         [0.9633],\n",
      "         [0.9857],\n",
      "         [0.4561],\n",
      "         [0.2467],\n",
      "         [0.9988],\n",
      "         [0.7269],\n",
      "         [1.0008],\n",
      "         [1.0011],\n",
      "         [0.9988],\n",
      "         [0.9990],\n",
      "         [0.9967],\n",
      "         [0.1619],\n",
      "         [0.9925],\n",
      "         [0.2291],\n",
      "         [0.6031],\n",
      "         [0.9899],\n",
      "         [0.9104],\n",
      "         [0.5233],\n",
      "         [0.9923],\n",
      "         [0.8990],\n",
      "         [0.9940],\n",
      "         [0.9939],\n",
      "         [0.9943],\n",
      "         [0.9961],\n",
      "         [0.9246],\n",
      "         [0.9958],\n",
      "         [0.9970],\n",
      "         [0.2558],\n",
      "         [0.9979],\n",
      "         [0.9777],\n",
      "         [0.8171],\n",
      "         [0.9974],\n",
      "         [0.9966],\n",
      "         [0.5008],\n",
      "         [0.9924],\n",
      "         [0.9924],\n",
      "         [0.0398],\n",
      "         [0.0315],\n",
      "         [0.9885],\n",
      "         [0.9873],\n",
      "         [0.0417],\n",
      "         [0.9893]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9164],\n",
      "        [0.8296],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.7540],\n",
      "        [0.9997],\n",
      "        [0.9520],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5139],\n",
      "        [0.6327],\n",
      "        [0.9962],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.9996],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.0000],\n",
      "        [0.6628],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [0.9804],\n",
      "        [0.6555],\n",
      "        [0.0142],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0209],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.0383],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.5038],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [0.5463],\n",
      "        [0.4988],\n",
      "        [0.3728],\n",
      "        [0.3747],\n",
      "        [0.9997],\n",
      "        [0.0174],\n",
      "        [0.9966],\n",
      "        [0.2547],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.5080],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.0288],\n",
      "        [0.8139],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.2646],\n",
      "        [0.9515],\n",
      "        [0.9820],\n",
      "        [0.4580],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.5945],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.9996],\n",
      "        [0.9044],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0368],\n",
      "        [0.0247],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000]])\n",
      "######### Epoch: 74  ######### Train Loss: 0.00014415931946132332  ######### Relative L2 Test Norm: 14.049111366271973\n",
      "Output batch pred: tensor([[[1.0006],\n",
      "         [1.0015],\n",
      "         [0.3485],\n",
      "         [1.0018],\n",
      "         [0.5096],\n",
      "         [1.0012],\n",
      "         [0.9999],\n",
      "         [0.9992],\n",
      "         [0.9982],\n",
      "         [0.9977],\n",
      "         [0.9958],\n",
      "         [0.9970],\n",
      "         [0.9163],\n",
      "         [0.9962],\n",
      "         [0.9970],\n",
      "         [0.4989],\n",
      "         [0.0348],\n",
      "         [0.9952],\n",
      "         [0.8529],\n",
      "         [0.9977],\n",
      "         [0.9983],\n",
      "         [0.2532],\n",
      "         [0.9971],\n",
      "         [1.0007],\n",
      "         [0.8243],\n",
      "         [1.0039],\n",
      "         [1.0049],\n",
      "         [1.0047],\n",
      "         [1.0035],\n",
      "         [1.0035],\n",
      "         [0.9877],\n",
      "         [0.5000],\n",
      "         [0.4499],\n",
      "         [0.9967],\n",
      "         [0.5151],\n",
      "         [0.2415],\n",
      "         [0.9973],\n",
      "         [0.0423],\n",
      "         [0.5142],\n",
      "         [0.9277],\n",
      "         [1.0007],\n",
      "         [0.9979],\n",
      "         [0.5190],\n",
      "         [0.9972],\n",
      "         [0.9950],\n",
      "         [0.4957],\n",
      "         [0.0442],\n",
      "         [0.1584],\n",
      "         [0.9811],\n",
      "         [0.9954],\n",
      "         [0.3814],\n",
      "         [0.9980],\n",
      "         [1.0020],\n",
      "         [0.9613],\n",
      "         [0.2474],\n",
      "         [0.9999],\n",
      "         [0.9976],\n",
      "         [0.4528],\n",
      "         [0.9914],\n",
      "         [0.3276],\n",
      "         [0.4899],\n",
      "         [0.4368],\n",
      "         [0.9872],\n",
      "         [0.9747],\n",
      "         [0.3515],\n",
      "         [0.6826],\n",
      "         [0.9938],\n",
      "         [0.0414],\n",
      "         [0.9972],\n",
      "         [0.9985],\n",
      "         [0.7238],\n",
      "         [0.4615],\n",
      "         [0.9986],\n",
      "         [0.4488],\n",
      "         [0.9980],\n",
      "         [0.9991],\n",
      "         [0.9994],\n",
      "         [0.3746],\n",
      "         [0.9977],\n",
      "         [0.9983],\n",
      "         [0.9613],\n",
      "         [0.9962],\n",
      "         [0.3735],\n",
      "         [0.9964],\n",
      "         [0.9955],\n",
      "         [0.9980],\n",
      "         [0.8612],\n",
      "         [0.5447],\n",
      "         [0.7883],\n",
      "         [0.7756],\n",
      "         [0.0454],\n",
      "         [1.0002],\n",
      "         [0.9983],\n",
      "         [0.9638],\n",
      "         [0.9963],\n",
      "         [0.9956],\n",
      "         [0.9951],\n",
      "         [0.9963],\n",
      "         [0.9972],\n",
      "         [0.2398],\n",
      "         [0.9963],\n",
      "         [0.6554],\n",
      "         [0.9989],\n",
      "         [0.3707],\n",
      "         [0.4422],\n",
      "         [0.5222],\n",
      "         [0.8492],\n",
      "         [1.0000],\n",
      "         [0.9985],\n",
      "         [0.9980],\n",
      "         [0.4584],\n",
      "         [0.9990],\n",
      "         [0.3633],\n",
      "         [0.9979],\n",
      "         [0.9987],\n",
      "         [0.3683],\n",
      "         [0.4477],\n",
      "         [0.9969],\n",
      "         [0.3740],\n",
      "         [0.9842],\n",
      "         [0.9954],\n",
      "         [0.9963],\n",
      "         [0.5518],\n",
      "         [0.2467],\n",
      "         [0.9965],\n",
      "         [0.2297],\n",
      "         [0.9941],\n",
      "         [0.9958],\n",
      "         [0.9982],\n",
      "         [0.7472],\n",
      "         [0.6180],\n",
      "         [0.5214],\n",
      "         [1.0026],\n",
      "         [0.2136],\n",
      "         [1.0043],\n",
      "         [1.0042],\n",
      "         [1.0040],\n",
      "         [0.2599],\n",
      "         [0.9966],\n",
      "         [0.9989],\n",
      "         [0.9971],\n",
      "         [0.9945],\n",
      "         [0.9956],\n",
      "         [0.0425],\n",
      "         [0.0277],\n",
      "         [0.9974],\n",
      "         [0.9993],\n",
      "         [0.9990],\n",
      "         [1.0012],\n",
      "         [1.0014],\n",
      "         [0.9276],\n",
      "         [1.0002],\n",
      "         [0.9976],\n",
      "         [0.9962],\n",
      "         [0.0336],\n",
      "         [0.9336],\n",
      "         [0.8654],\n",
      "         [0.9967],\n",
      "         [0.9973],\n",
      "         [0.9053],\n",
      "         [0.9979],\n",
      "         [0.9999],\n",
      "         [0.4678],\n",
      "         [1.0003],\n",
      "         [0.9992],\n",
      "         [0.9623],\n",
      "         [0.9942],\n",
      "         [0.2351],\n",
      "         [0.4329],\n",
      "         [0.3498],\n",
      "         [0.6667],\n",
      "         [0.5201],\n",
      "         [0.9883],\n",
      "         [0.0434],\n",
      "         [0.9904],\n",
      "         [0.9756],\n",
      "         [0.9975],\n",
      "         [0.9991]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9994],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.4988],\n",
      "        [0.4552],\n",
      "        [0.9998],\n",
      "        [0.5139],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.5080],\n",
      "        [0.9044],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5030],\n",
      "        [0.0368],\n",
      "        [0.1762],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9967],\n",
      "        [0.9998],\n",
      "        [0.9420],\n",
      "        [0.2646],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.4642],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [0.5054],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.3747],\n",
      "        [0.6628],\n",
      "        [0.9994],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.4645],\n",
      "        [0.9998],\n",
      "        [0.4527],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9490],\n",
      "        [0.9999],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.5334],\n",
      "        [0.7540],\n",
      "        [0.7391],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2610],\n",
      "        [0.9994],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.4454],\n",
      "        [0.5165],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.4503],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5463],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.5945],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.2735],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9995],\n",
      "        [0.0247],\n",
      "        [0.9164],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9997],\n",
      "        [0.2577],\n",
      "        [0.4480],\n",
      "        [0.3728],\n",
      "        [0.6555],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.9962],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [1.0000]])\n",
      "######### Epoch: 75  ######### Train Loss: 0.00015630027337465435  ######### Relative L2 Test Norm: 13.92790412902832\n",
      "Output batch pred: tensor([[[0.9906],\n",
      "         [0.9953],\n",
      "         [0.9969],\n",
      "         [0.9989],\n",
      "         [1.0019],\n",
      "         [0.9701],\n",
      "         [1.0033],\n",
      "         [1.0011],\n",
      "         [0.8473],\n",
      "         [0.7397],\n",
      "         [0.9921],\n",
      "         [0.0212],\n",
      "         [0.4327],\n",
      "         [0.4427],\n",
      "         [0.9937],\n",
      "         [0.0414],\n",
      "         [0.3429],\n",
      "         [0.9996],\n",
      "         [1.0001],\n",
      "         [0.2395],\n",
      "         [0.9988],\n",
      "         [0.9953],\n",
      "         [0.8997],\n",
      "         [0.9924],\n",
      "         [0.6499],\n",
      "         [0.5136],\n",
      "         [0.9920],\n",
      "         [0.9954],\n",
      "         [0.9993],\n",
      "         [1.0008],\n",
      "         [0.9660],\n",
      "         [0.4635],\n",
      "         [1.0016],\n",
      "         [1.0012],\n",
      "         [1.0016],\n",
      "         [1.0021],\n",
      "         [0.2464],\n",
      "         [1.0043],\n",
      "         [1.0046],\n",
      "         [1.0049],\n",
      "         [1.0033],\n",
      "         [1.0010],\n",
      "         [0.9969],\n",
      "         [0.9937],\n",
      "         [0.9927],\n",
      "         [0.0324],\n",
      "         [0.9907],\n",
      "         [0.9919],\n",
      "         [0.9903],\n",
      "         [0.5568],\n",
      "         [0.4527],\n",
      "         [1.0043],\n",
      "         [0.3763],\n",
      "         [0.3519],\n",
      "         [0.2096],\n",
      "         [0.9595],\n",
      "         [0.9977],\n",
      "         [0.8129],\n",
      "         [0.9933],\n",
      "         [0.2350],\n",
      "         [0.4372],\n",
      "         [0.9837],\n",
      "         [0.9998],\n",
      "         [0.5139],\n",
      "         [1.0027],\n",
      "         [1.0046],\n",
      "         [1.0033],\n",
      "         [0.2538],\n",
      "         [0.9972],\n",
      "         [0.0436],\n",
      "         [0.9924],\n",
      "         [0.1630],\n",
      "         [0.2479],\n",
      "         [0.5296],\n",
      "         [0.5081],\n",
      "         [1.0003],\n",
      "         [1.0041],\n",
      "         [0.9692],\n",
      "         [0.4534],\n",
      "         [1.0018],\n",
      "         [0.9274],\n",
      "         [0.9968],\n",
      "         [0.9947],\n",
      "         [0.9927],\n",
      "         [0.2500],\n",
      "         [0.9945],\n",
      "         [0.6892],\n",
      "         [0.9965],\n",
      "         [0.9974],\n",
      "         [0.9992],\n",
      "         [0.9985],\n",
      "         [0.9968],\n",
      "         [0.9952],\n",
      "         [0.3627],\n",
      "         [0.4974],\n",
      "         [0.2334],\n",
      "         [0.3798],\n",
      "         [0.4990],\n",
      "         [0.9964],\n",
      "         [0.9998],\n",
      "         [1.0014],\n",
      "         [1.0020],\n",
      "         [0.9988],\n",
      "         [0.0399],\n",
      "         [0.9971],\n",
      "         [0.9356],\n",
      "         [0.9968],\n",
      "         [0.9974],\n",
      "         [0.9866],\n",
      "         [0.5249],\n",
      "         [1.0003],\n",
      "         [0.9904],\n",
      "         [1.0021],\n",
      "         [0.9277],\n",
      "         [0.9803],\n",
      "         [0.9963],\n",
      "         [0.6053],\n",
      "         [0.2443],\n",
      "         [0.4547],\n",
      "         [0.9916],\n",
      "         [0.9956],\n",
      "         [0.9964],\n",
      "         [1.0008],\n",
      "         [0.8683],\n",
      "         [1.0031],\n",
      "         [1.0038],\n",
      "         [0.5218],\n",
      "         [0.3810],\n",
      "         [1.0008],\n",
      "         [0.9990],\n",
      "         [0.0518],\n",
      "         [0.3778],\n",
      "         [0.9977],\n",
      "         [0.5201],\n",
      "         [1.0010],\n",
      "         [0.9876],\n",
      "         [1.0010],\n",
      "         [0.0329],\n",
      "         [0.4652],\n",
      "         [0.4596],\n",
      "         [0.5434],\n",
      "         [0.7836],\n",
      "         [0.9949],\n",
      "         [0.9959],\n",
      "         [0.5142],\n",
      "         [0.4600],\n",
      "         [1.0004],\n",
      "         [0.6859],\n",
      "         [1.0021],\n",
      "         [1.0013],\n",
      "         [0.9188],\n",
      "         [0.3571],\n",
      "         [0.9938],\n",
      "         [0.9941],\n",
      "         [0.8605],\n",
      "         [0.9927],\n",
      "         [0.0503],\n",
      "         [0.7236],\n",
      "         [0.3780],\n",
      "         [1.0006],\n",
      "         [0.7782],\n",
      "         [1.0020],\n",
      "         [1.0007],\n",
      "         [0.5033],\n",
      "         [0.9967],\n",
      "         [0.3619],\n",
      "         [0.9957],\n",
      "         [0.3604],\n",
      "         [0.9970],\n",
      "         [0.9991],\n",
      "         [1.0007],\n",
      "         [1.0016],\n",
      "         [0.9992],\n",
      "         [0.8556],\n",
      "         [0.9973],\n",
      "         [0.9933],\n",
      "         [0.9911],\n",
      "         [0.0415]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9515],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.8139],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [0.0000],\n",
      "        [0.4480],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.8761],\n",
      "        [0.9999],\n",
      "        [0.6327],\n",
      "        [0.5139],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9956],\n",
      "        [0.5463],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.3573],\n",
      "        [0.2208],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.4454],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9999],\n",
      "        [0.0209],\n",
      "        [0.9997],\n",
      "        [0.1762],\n",
      "        [0.2686],\n",
      "        [0.5245],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9490],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [0.9044],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.5030],\n",
      "        [0.2518],\n",
      "        [0.3930],\n",
      "        [0.4988],\n",
      "        [0.9995],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.0247],\n",
      "        [0.9967],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9819],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.2729],\n",
      "        [0.4668],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5108],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [0.9994],\n",
      "        [0.0142],\n",
      "        [0.4642],\n",
      "        [0.4611],\n",
      "        [0.5334],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.3747],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9996],\n",
      "        [0.0335],\n",
      "        [0.6920],\n",
      "        [0.3840],\n",
      "        [0.9999],\n",
      "        [0.7391],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.5009],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.0368]])\n",
      "######### Epoch: 76  ######### Train Loss: 0.0001466726534999907  ######### Relative L2 Test Norm: 13.789701461791992\n",
      "Output batch pred: tensor([[[0.3701],\n",
      "         [0.9998],\n",
      "         [1.0016],\n",
      "         [1.0012],\n",
      "         [1.0006],\n",
      "         [1.0012],\n",
      "         [0.9279],\n",
      "         [0.9988],\n",
      "         [0.4632],\n",
      "         [0.9979],\n",
      "         [0.9964],\n",
      "         [0.9971],\n",
      "         [0.2610],\n",
      "         [0.9952],\n",
      "         [0.4442],\n",
      "         [0.9946],\n",
      "         [0.4976],\n",
      "         [0.0493],\n",
      "         [0.9954],\n",
      "         [0.9949],\n",
      "         [0.8634],\n",
      "         [0.9952],\n",
      "         [0.9609],\n",
      "         [0.5101],\n",
      "         [0.9987],\n",
      "         [1.0013],\n",
      "         [1.0028],\n",
      "         [1.0041],\n",
      "         [1.0028],\n",
      "         [1.0017],\n",
      "         [0.3748],\n",
      "         [0.9962],\n",
      "         [0.9759],\n",
      "         [0.9951],\n",
      "         [0.9937],\n",
      "         [0.0483],\n",
      "         [0.9987],\n",
      "         [0.2583],\n",
      "         [0.9900],\n",
      "         [0.1762],\n",
      "         [0.9686],\n",
      "         [0.6631],\n",
      "         [0.8506],\n",
      "         [0.0440],\n",
      "         [0.9824],\n",
      "         [0.9929],\n",
      "         [0.9117],\n",
      "         [0.9297],\n",
      "         [0.9928],\n",
      "         [0.5109],\n",
      "         [0.9961],\n",
      "         [0.9982],\n",
      "         [1.0013],\n",
      "         [0.4678],\n",
      "         [1.0011],\n",
      "         [0.9988],\n",
      "         [0.3461],\n",
      "         [0.9944],\n",
      "         [0.9943],\n",
      "         [0.9943],\n",
      "         [0.9926],\n",
      "         [0.2006],\n",
      "         [0.9199],\n",
      "         [0.9900],\n",
      "         [0.0351],\n",
      "         [0.5423],\n",
      "         [0.9969],\n",
      "         [0.9036],\n",
      "         [0.9986],\n",
      "         [0.9985],\n",
      "         [1.0003],\n",
      "         [0.4638],\n",
      "         [0.4496],\n",
      "         [1.0009],\n",
      "         [1.0010],\n",
      "         [1.0017],\n",
      "         [1.0002],\n",
      "         [0.9961],\n",
      "         [0.9966],\n",
      "         [0.0347],\n",
      "         [0.9939],\n",
      "         [0.9931],\n",
      "         [0.9800],\n",
      "         [0.9950],\n",
      "         [0.9960],\n",
      "         [0.9991],\n",
      "         [0.9992],\n",
      "         [0.3879],\n",
      "         [0.7282],\n",
      "         [1.0003],\n",
      "         [0.9633],\n",
      "         [0.9958],\n",
      "         [0.4452],\n",
      "         [0.2384],\n",
      "         [0.6761],\n",
      "         [0.9954],\n",
      "         [0.3624],\n",
      "         [0.9992],\n",
      "         [0.9982],\n",
      "         [0.8668],\n",
      "         [1.0014],\n",
      "         [0.5109],\n",
      "         [0.9982],\n",
      "         [0.5213],\n",
      "         [0.0283],\n",
      "         [0.0436],\n",
      "         [0.9925],\n",
      "         [0.9926],\n",
      "         [0.9928],\n",
      "         [0.8120],\n",
      "         [0.6880],\n",
      "         [0.9967],\n",
      "         [0.9868],\n",
      "         [1.0017],\n",
      "         [1.0033],\n",
      "         [1.0039],\n",
      "         [0.4520],\n",
      "         [1.0025],\n",
      "         [0.2616],\n",
      "         [0.9589],\n",
      "         [0.5192],\n",
      "         [0.9972],\n",
      "         [0.9950],\n",
      "         [0.9952],\n",
      "         [0.9956],\n",
      "         [0.9942],\n",
      "         [0.9959],\n",
      "         [0.3426],\n",
      "         [0.7838],\n",
      "         [0.9985],\n",
      "         [0.9965],\n",
      "         [0.3765],\n",
      "         [0.6186],\n",
      "         [0.5382],\n",
      "         [1.0011],\n",
      "         [0.5566],\n",
      "         [0.9989],\n",
      "         [0.5074],\n",
      "         [0.8530],\n",
      "         [0.9968],\n",
      "         [0.5182],\n",
      "         [0.4515],\n",
      "         [0.9979],\n",
      "         [0.9993],\n",
      "         [1.0022],\n",
      "         [1.0021],\n",
      "         [0.3662],\n",
      "         [1.0016],\n",
      "         [0.9987],\n",
      "         [0.7425],\n",
      "         [0.2322],\n",
      "         [0.9927],\n",
      "         [0.4573],\n",
      "         [0.0557],\n",
      "         [0.4551],\n",
      "         [0.3646],\n",
      "         [0.9986],\n",
      "         [1.0008],\n",
      "         [0.2441],\n",
      "         [1.0038],\n",
      "         [0.5081],\n",
      "         [1.0023],\n",
      "         [0.2444],\n",
      "         [0.9985],\n",
      "         [0.5044],\n",
      "         [0.7695],\n",
      "         [0.3798],\n",
      "         [0.2495],\n",
      "         [0.9978],\n",
      "         [0.9989],\n",
      "         [0.3762],\n",
      "         [0.9996],\n",
      "         [0.9988],\n",
      "         [0.9977],\n",
      "         [0.9966],\n",
      "         [0.9970],\n",
      "         [0.9966],\n",
      "         [0.0355]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.3780],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.9966],\n",
      "        [0.4988],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.8379],\n",
      "        [0.9999],\n",
      "        [0.9490],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.9996],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.9819],\n",
      "        [0.1762],\n",
      "        [0.9515],\n",
      "        [0.6327],\n",
      "        [0.8139],\n",
      "        [0.0288],\n",
      "        [0.9820],\n",
      "        [0.9999],\n",
      "        [0.8933],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [0.9994],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9044],\n",
      "        [0.9956],\n",
      "        [0.0142],\n",
      "        [0.5334],\n",
      "        [0.9998],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.3930],\n",
      "        [0.6920],\n",
      "        [0.9998],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.2577],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [0.5030],\n",
      "        [0.9967],\n",
      "        [0.5151],\n",
      "        [0.0000],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.6628],\n",
      "        [0.9995],\n",
      "        [0.9804],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.9420],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.7540],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [0.3808],\n",
      "        [0.5945],\n",
      "        [0.5245],\n",
      "        [0.9997],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.8223],\n",
      "        [0.9998],\n",
      "        [0.5165],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.7129],\n",
      "        [0.2518],\n",
      "        [0.9998],\n",
      "        [0.4668],\n",
      "        [0.0383],\n",
      "        [0.4611],\n",
      "        [0.3747],\n",
      "        [0.9994],\n",
      "        [0.9994],\n",
      "        [0.2547],\n",
      "        [0.9997],\n",
      "        [0.5009],\n",
      "        [0.9997],\n",
      "        [0.2610],\n",
      "        [0.9999],\n",
      "        [0.5038],\n",
      "        [0.7391],\n",
      "        [0.3912],\n",
      "        [0.2646],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0174]])\n",
      "######### Epoch: 77  ######### Train Loss: 0.0001312634558416903  ######### Relative L2 Test Norm: 13.723151206970215\n",
      "Output batch pred: tensor([[[0.5300],\n",
      "         [0.9990],\n",
      "         [0.2601],\n",
      "         [0.0448],\n",
      "         [0.9258],\n",
      "         [1.0006],\n",
      "         [0.9991],\n",
      "         [0.2455],\n",
      "         [0.8487],\n",
      "         [0.0499],\n",
      "         [0.9991],\n",
      "         [0.9997],\n",
      "         [1.0006],\n",
      "         [0.8586],\n",
      "         [0.6838],\n",
      "         [0.9996],\n",
      "         [0.9595],\n",
      "         [0.9985],\n",
      "         [0.9981],\n",
      "         [0.0239],\n",
      "         [0.3597],\n",
      "         [0.0516],\n",
      "         [0.9966],\n",
      "         [0.9956],\n",
      "         [0.9978],\n",
      "         [0.9981],\n",
      "         [0.3609],\n",
      "         [0.4411],\n",
      "         [0.9988],\n",
      "         [0.9973],\n",
      "         [0.9963],\n",
      "         [0.0460],\n",
      "         [0.9969],\n",
      "         [0.9986],\n",
      "         [0.0409],\n",
      "         [0.2597],\n",
      "         [1.0027],\n",
      "         [1.0014],\n",
      "         [0.4712],\n",
      "         [0.8733],\n",
      "         [1.0016],\n",
      "         [0.9994],\n",
      "         [0.4541],\n",
      "         [0.5066],\n",
      "         [0.5015],\n",
      "         [0.4428],\n",
      "         [0.4471],\n",
      "         [0.4567],\n",
      "         [0.9886],\n",
      "         [0.5198],\n",
      "         [0.5018],\n",
      "         [0.9952],\n",
      "         [0.9976],\n",
      "         [0.9989],\n",
      "         [0.9974],\n",
      "         [0.9971],\n",
      "         [0.9181],\n",
      "         [0.9853],\n",
      "         [0.9971],\n",
      "         [0.9959],\n",
      "         [0.7858],\n",
      "         [0.9983],\n",
      "         [0.9990],\n",
      "         [0.8638],\n",
      "         [1.0001],\n",
      "         [0.9992],\n",
      "         [0.3700],\n",
      "         [0.9987],\n",
      "         [0.9995],\n",
      "         [0.9645],\n",
      "         [0.9991],\n",
      "         [0.6586],\n",
      "         [0.9979],\n",
      "         [0.9971],\n",
      "         [0.1703],\n",
      "         [0.6134],\n",
      "         [0.9965],\n",
      "         [0.9961],\n",
      "         [0.9966],\n",
      "         [0.9971],\n",
      "         [0.9976],\n",
      "         [0.2595],\n",
      "         [0.9999],\n",
      "         [0.3799],\n",
      "         [0.7804],\n",
      "         [1.0026],\n",
      "         [1.0004],\n",
      "         [0.9998],\n",
      "         [0.9620],\n",
      "         [0.9955],\n",
      "         [0.9304],\n",
      "         [0.7373],\n",
      "         [0.9901],\n",
      "         [0.2357],\n",
      "         [0.3801],\n",
      "         [0.5179],\n",
      "         [0.9982],\n",
      "         [0.4526],\n",
      "         [1.0006],\n",
      "         [1.0000],\n",
      "         [0.3507],\n",
      "         [0.9988],\n",
      "         [0.3473],\n",
      "         [0.2065],\n",
      "         [0.5050],\n",
      "         [0.9925],\n",
      "         [0.9912],\n",
      "         [0.9923],\n",
      "         [0.6904],\n",
      "         [0.9966],\n",
      "         [0.9839],\n",
      "         [0.9991],\n",
      "         [0.9977],\n",
      "         [0.5462],\n",
      "         [0.3849],\n",
      "         [0.5213],\n",
      "         [0.9834],\n",
      "         [0.9956],\n",
      "         [0.9941],\n",
      "         [0.9956],\n",
      "         [0.9969],\n",
      "         [0.9036],\n",
      "         [0.2400],\n",
      "         [0.9987],\n",
      "         [0.9987],\n",
      "         [0.3693],\n",
      "         [0.9995],\n",
      "         [0.9978],\n",
      "         [0.9969],\n",
      "         [0.9994],\n",
      "         [0.9641],\n",
      "         [0.3852],\n",
      "         [0.9989],\n",
      "         [0.9990],\n",
      "         [1.0004],\n",
      "         [0.9983],\n",
      "         [0.8170],\n",
      "         [0.9960],\n",
      "         [0.9958],\n",
      "         [0.7171],\n",
      "         [0.2386],\n",
      "         [0.9953],\n",
      "         [0.9940],\n",
      "         [0.2477],\n",
      "         [0.9977],\n",
      "         [0.9985],\n",
      "         [0.4703],\n",
      "         [1.0015],\n",
      "         [1.0007],\n",
      "         [0.9984],\n",
      "         [0.9985],\n",
      "         [0.4986],\n",
      "         [0.9937],\n",
      "         [0.9940],\n",
      "         [0.9733],\n",
      "         [0.9942],\n",
      "         [0.5497],\n",
      "         [0.4397],\n",
      "         [0.0531],\n",
      "         [0.9976],\n",
      "         [0.9851],\n",
      "         [0.9980],\n",
      "         [0.3636],\n",
      "         [0.9951],\n",
      "         [0.0352],\n",
      "         [0.9997],\n",
      "         [0.0423],\n",
      "         [0.9281],\n",
      "         [1.0009],\n",
      "         [0.4517],\n",
      "         [0.9980],\n",
      "         [0.9976],\n",
      "         [0.5043],\n",
      "         [0.9959],\n",
      "         [0.4996],\n",
      "         [0.9930],\n",
      "         [0.9939],\n",
      "         [0.9947]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.5245],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [0.0209],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.8139],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [0.6555],\n",
      "        [0.9967],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.3753],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0174],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.5108],\n",
      "        [0.5080],\n",
      "        [0.4552],\n",
      "        [0.4580],\n",
      "        [0.4645],\n",
      "        [0.9959],\n",
      "        [0.5151],\n",
      "        [0.4988],\n",
      "        [0.9962],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.9819],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.9995],\n",
      "        [0.9996],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [0.5945],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.7129],\n",
      "        [0.9999],\n",
      "        [0.2518],\n",
      "        [0.3912],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.2208],\n",
      "        [0.5054],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [0.9999],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [0.3930],\n",
      "        [0.5165],\n",
      "        [0.9820],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.3875],\n",
      "        [0.9996],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9994],\n",
      "        [0.9966],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [0.9998],\n",
      "        [0.5463],\n",
      "        [0.4480],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.9956],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.5030],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997]])\n",
      "######### Epoch: 78  ######### Train Loss: 0.00013975561887491494  ######### Relative L2 Test Norm: 13.751348495483398\n",
      "Output batch pred: tensor([[[0.9955],\n",
      "         [0.9938],\n",
      "         [0.0249],\n",
      "         [0.9941],\n",
      "         [0.9944],\n",
      "         [0.9953],\n",
      "         [0.9979],\n",
      "         [0.9980],\n",
      "         [0.9375],\n",
      "         [0.8493],\n",
      "         [0.9943],\n",
      "         [0.9973],\n",
      "         [0.2473],\n",
      "         [0.9133],\n",
      "         [0.9915],\n",
      "         [0.4384],\n",
      "         [0.6026],\n",
      "         [0.5009],\n",
      "         [0.8576],\n",
      "         [0.4567],\n",
      "         [0.4989],\n",
      "         [0.0493],\n",
      "         [0.9929],\n",
      "         [0.5040],\n",
      "         [0.9971],\n",
      "         [0.9981],\n",
      "         [0.5194],\n",
      "         [0.4587],\n",
      "         [0.9986],\n",
      "         [1.0018],\n",
      "         [0.2483],\n",
      "         [1.0022],\n",
      "         [1.0023],\n",
      "         [1.0004],\n",
      "         [0.9666],\n",
      "         [1.0005],\n",
      "         [0.9985],\n",
      "         [0.7848],\n",
      "         [0.9972],\n",
      "         [0.3712],\n",
      "         [0.9953],\n",
      "         [0.3622],\n",
      "         [0.3431],\n",
      "         [0.2527],\n",
      "         [0.9936],\n",
      "         [0.3683],\n",
      "         [0.9954],\n",
      "         [0.9956],\n",
      "         [0.9948],\n",
      "         [0.9966],\n",
      "         [0.9574],\n",
      "         [0.9987],\n",
      "         [0.5104],\n",
      "         [0.9978],\n",
      "         [0.9981],\n",
      "         [0.4442],\n",
      "         [0.9983],\n",
      "         [0.9988],\n",
      "         [0.7738],\n",
      "         [0.9843],\n",
      "         [0.9858],\n",
      "         [0.9969],\n",
      "         [0.4638],\n",
      "         [0.2591],\n",
      "         [0.9978],\n",
      "         [0.4496],\n",
      "         [0.9966],\n",
      "         [0.6535],\n",
      "         [0.9948],\n",
      "         [0.6873],\n",
      "         [0.5198],\n",
      "         [0.9208],\n",
      "         [0.0475],\n",
      "         [0.9958],\n",
      "         [0.9973],\n",
      "         [0.4480],\n",
      "         [1.0002],\n",
      "         [0.4625],\n",
      "         [1.0025],\n",
      "         [0.7327],\n",
      "         [1.0030],\n",
      "         [1.0009],\n",
      "         [0.9094],\n",
      "         [1.0010],\n",
      "         [0.9991],\n",
      "         [0.9974],\n",
      "         [0.9960],\n",
      "         [0.9965],\n",
      "         [0.9952],\n",
      "         [0.9952],\n",
      "         [0.9966],\n",
      "         [0.5305],\n",
      "         [0.2377],\n",
      "         [0.0579],\n",
      "         [0.9961],\n",
      "         [0.0501],\n",
      "         [0.0459],\n",
      "         [0.9858],\n",
      "         [0.0557],\n",
      "         [0.9646],\n",
      "         [0.5107],\n",
      "         [0.9803],\n",
      "         [0.9875],\n",
      "         [0.9989],\n",
      "         [0.4613],\n",
      "         [0.7458],\n",
      "         [0.9969],\n",
      "         [0.9967],\n",
      "         [0.8589],\n",
      "         [0.2576],\n",
      "         [0.9962],\n",
      "         [0.5544],\n",
      "         [0.9966],\n",
      "         [0.9968],\n",
      "         [0.6796],\n",
      "         [0.9966],\n",
      "         [0.9948],\n",
      "         [0.9939],\n",
      "         [0.9944],\n",
      "         [0.3793],\n",
      "         [0.3565],\n",
      "         [0.9931],\n",
      "         [0.8116],\n",
      "         [0.9946],\n",
      "         [0.9932],\n",
      "         [0.9955],\n",
      "         [0.2088],\n",
      "         [0.9996],\n",
      "         [1.0010],\n",
      "         [1.0003],\n",
      "         [0.5531],\n",
      "         [1.0015],\n",
      "         [1.0008],\n",
      "         [0.5049],\n",
      "         [0.9983],\n",
      "         [0.9950],\n",
      "         [0.9957],\n",
      "         [0.3747],\n",
      "         [0.9937],\n",
      "         [0.9920],\n",
      "         [0.9934],\n",
      "         [0.9946],\n",
      "         [0.3737],\n",
      "         [0.9970],\n",
      "         [0.9986],\n",
      "         [0.9982],\n",
      "         [0.9998],\n",
      "         [0.3707],\n",
      "         [0.0469],\n",
      "         [0.9955],\n",
      "         [0.9970],\n",
      "         [0.9960],\n",
      "         [0.9941],\n",
      "         [0.3422],\n",
      "         [0.4594],\n",
      "         [0.8530],\n",
      "         [0.9958],\n",
      "         [0.9961],\n",
      "         [1.0004],\n",
      "         [1.0014],\n",
      "         [1.0007],\n",
      "         [0.9999],\n",
      "         [0.1677],\n",
      "         [0.5171],\n",
      "         [0.9203],\n",
      "         [0.2363],\n",
      "         [0.2413],\n",
      "         [0.9864],\n",
      "         [0.9885],\n",
      "         [0.5116],\n",
      "         [0.3583],\n",
      "         [0.9579],\n",
      "         [0.9953],\n",
      "         [0.0540],\n",
      "         [0.9990],\n",
      "         [0.9992],\n",
      "         [0.9978],\n",
      "         [0.9979]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.9999],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.8139],\n",
      "        [0.9956],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [0.8933],\n",
      "        [0.9999],\n",
      "        [0.4503],\n",
      "        [0.5945],\n",
      "        [0.5080],\n",
      "        [0.8379],\n",
      "        [0.4668],\n",
      "        [0.5038],\n",
      "        [0.0335],\n",
      "        [0.9997],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.4552],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.9998],\n",
      "        [0.3747],\n",
      "        [0.3573],\n",
      "        [0.2686],\n",
      "        [0.9998],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9420],\n",
      "        [0.9999],\n",
      "        [0.5054],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.9814],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.2729],\n",
      "        [0.9999],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [0.5165],\n",
      "        [0.9044],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.9999],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.2518],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.0142],\n",
      "        [0.9804],\n",
      "        [0.0288],\n",
      "        [0.9490],\n",
      "        [0.5009],\n",
      "        [0.9724],\n",
      "        [0.9819],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [0.7129],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.8296],\n",
      "        [0.2735],\n",
      "        [0.9997],\n",
      "        [0.5463],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.3728],\n",
      "        [0.9997],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.4645],\n",
      "        [0.8223],\n",
      "        [0.9998],\n",
      "        [0.9962],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [0.5139],\n",
      "        [0.9009],\n",
      "        [0.2547],\n",
      "        [0.2610],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.5151],\n",
      "        [0.3753],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9997]])\n",
      "######### Epoch: 79  ######### Train Loss: 0.00015172187704592943  ######### Relative L2 Test Norm: 13.983358383178711\n",
      "Output batch pred: tensor([[[0.9981],\n",
      "         [0.5056],\n",
      "         [0.9991],\n",
      "         [0.8579],\n",
      "         [0.9643],\n",
      "         [0.9996],\n",
      "         [0.9994],\n",
      "         [0.9993],\n",
      "         [0.9977],\n",
      "         [0.9976],\n",
      "         [0.9977],\n",
      "         [0.9378],\n",
      "         [0.5105],\n",
      "         [0.9992],\n",
      "         [0.8691],\n",
      "         [0.9978],\n",
      "         [0.0439],\n",
      "         [0.7714],\n",
      "         [0.9954],\n",
      "         [0.9947],\n",
      "         [0.2436],\n",
      "         [0.9944],\n",
      "         [0.9941],\n",
      "         [0.9966],\n",
      "         [0.9851],\n",
      "         [0.5200],\n",
      "         [1.0002],\n",
      "         [1.0020],\n",
      "         [1.0004],\n",
      "         [1.0008],\n",
      "         [0.9981],\n",
      "         [0.3461],\n",
      "         [0.3624],\n",
      "         [0.9819],\n",
      "         [0.5167],\n",
      "         [0.3727],\n",
      "         [0.3825],\n",
      "         [0.9953],\n",
      "         [0.4695],\n",
      "         [0.9960],\n",
      "         [0.9792],\n",
      "         [0.9988],\n",
      "         [0.9964],\n",
      "         [0.9955],\n",
      "         [0.2082],\n",
      "         [0.9935],\n",
      "         [0.5416],\n",
      "         [0.9934],\n",
      "         [0.9923],\n",
      "         [0.9923],\n",
      "         [0.9959],\n",
      "         [0.9974],\n",
      "         [0.9948],\n",
      "         [0.9993],\n",
      "         [1.0013],\n",
      "         [1.0012],\n",
      "         [0.3809],\n",
      "         [0.0542],\n",
      "         [0.9960],\n",
      "         [0.9937],\n",
      "         [0.6740],\n",
      "         [0.1648],\n",
      "         [0.9862],\n",
      "         [0.9887],\n",
      "         [0.9889],\n",
      "         [0.9905],\n",
      "         [0.4962],\n",
      "         [0.9918],\n",
      "         [0.6527],\n",
      "         [0.9962],\n",
      "         [0.6150],\n",
      "         [0.4460],\n",
      "         [0.9985],\n",
      "         [0.9983],\n",
      "         [0.2448],\n",
      "         [0.5254],\n",
      "         [0.9973],\n",
      "         [0.9968],\n",
      "         [0.9952],\n",
      "         [0.9947],\n",
      "         [0.9941],\n",
      "         [0.9131],\n",
      "         [0.9916],\n",
      "         [0.9911],\n",
      "         [0.9887],\n",
      "         [0.9919],\n",
      "         [0.0482],\n",
      "         [0.9907],\n",
      "         [0.9568],\n",
      "         [0.6834],\n",
      "         [0.8983],\n",
      "         [0.0188],\n",
      "         [0.9955],\n",
      "         [0.5138],\n",
      "         [0.5085],\n",
      "         [0.9995],\n",
      "         [0.9997],\n",
      "         [0.9979],\n",
      "         [0.4468],\n",
      "         [0.8595],\n",
      "         [0.9813],\n",
      "         [0.3549],\n",
      "         [0.8063],\n",
      "         [0.9891],\n",
      "         [0.5047],\n",
      "         [0.9891],\n",
      "         [0.9892],\n",
      "         [0.7776],\n",
      "         [0.9947],\n",
      "         [0.9957],\n",
      "         [0.0348],\n",
      "         [0.9988],\n",
      "         [1.0005],\n",
      "         [0.9991],\n",
      "         [0.9991],\n",
      "         [0.9247],\n",
      "         [0.2458],\n",
      "         [0.9927],\n",
      "         [0.9939],\n",
      "         [0.5526],\n",
      "         [0.9921],\n",
      "         [0.9920],\n",
      "         [0.9933],\n",
      "         [0.9942],\n",
      "         [0.9959],\n",
      "         [0.3424],\n",
      "         [0.9206],\n",
      "         [0.9958],\n",
      "         [0.4508],\n",
      "         [0.7178],\n",
      "         [0.0507],\n",
      "         [0.3647],\n",
      "         [0.9954],\n",
      "         [0.9954],\n",
      "         [0.4583],\n",
      "         [0.2573],\n",
      "         [0.9996],\n",
      "         [0.9639],\n",
      "         [0.4491],\n",
      "         [1.0002],\n",
      "         [0.9991],\n",
      "         [0.9976],\n",
      "         [0.0462],\n",
      "         [0.9974],\n",
      "         [0.3734],\n",
      "         [0.9956],\n",
      "         [0.9959],\n",
      "         [0.5035],\n",
      "         [0.9947],\n",
      "         [0.3797],\n",
      "         [0.9953],\n",
      "         [0.9943],\n",
      "         [0.9532],\n",
      "         [0.0413],\n",
      "         [0.9948],\n",
      "         [0.4629],\n",
      "         [0.2433],\n",
      "         [0.9834],\n",
      "         [0.4667],\n",
      "         [0.9987],\n",
      "         [0.9982],\n",
      "         [0.9975],\n",
      "         [0.9969],\n",
      "         [0.9972],\n",
      "         [0.4476],\n",
      "         [0.2397],\n",
      "         [0.4533],\n",
      "         [0.9978],\n",
      "         [0.5340],\n",
      "         [0.9970],\n",
      "         [0.2581],\n",
      "         [0.7438],\n",
      "         [0.0436],\n",
      "         [0.2599],\n",
      "         [0.3645],\n",
      "         [0.8448],\n",
      "         [0.9957],\n",
      "         [0.9968]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [0.9520],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9164],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.9994],\n",
      "        [0.0288],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.3747],\n",
      "        [0.9819],\n",
      "        [0.5151],\n",
      "        [0.3840],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.9998],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [0.2208],\n",
      "        [0.9996],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [0.3875],\n",
      "        [0.0368],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.1762],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9997],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.5165],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.6628],\n",
      "        [0.8761],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.5038],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [0.8296],\n",
      "        [0.9820],\n",
      "        [0.3728],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.7540],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.6920],\n",
      "        [0.0335],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.4611],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0209],\n",
      "        [0.9999],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.0247],\n",
      "        [0.9999],\n",
      "        [0.4642],\n",
      "        [0.2577],\n",
      "        [0.9814],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.4503],\n",
      "        [0.2518],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.7129],\n",
      "        [0.0174],\n",
      "        [0.2729],\n",
      "        [0.3753],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [1.0000]])\n",
      "######### Epoch: 80  ######### Train Loss: 0.00012463734310586005  ######### Relative L2 Test Norm: 14.007055282592773\n",
      "Output batch pred: tensor([[[0.8075],\n",
      "         [0.9908],\n",
      "         [0.9921],\n",
      "         [0.9305],\n",
      "         [0.8638],\n",
      "         [0.9835],\n",
      "         [0.9969],\n",
      "         [0.9980],\n",
      "         [0.9987],\n",
      "         [0.9974],\n",
      "         [0.0476],\n",
      "         [0.9627],\n",
      "         [0.9846],\n",
      "         [0.9963],\n",
      "         [0.9965],\n",
      "         [0.3615],\n",
      "         [0.9933],\n",
      "         [0.3663],\n",
      "         [0.9924],\n",
      "         [0.9923],\n",
      "         [0.9925],\n",
      "         [0.9944],\n",
      "         [0.9948],\n",
      "         [0.0305],\n",
      "         [0.9966],\n",
      "         [0.9847],\n",
      "         [0.9968],\n",
      "         [0.0442],\n",
      "         [0.9962],\n",
      "         [0.9962],\n",
      "         [0.9962],\n",
      "         [0.9956],\n",
      "         [0.3553],\n",
      "         [0.9935],\n",
      "         [0.6738],\n",
      "         [0.7799],\n",
      "         [0.9923],\n",
      "         [0.6878],\n",
      "         [0.9951],\n",
      "         [0.9943],\n",
      "         [0.7447],\n",
      "         [0.7713],\n",
      "         [0.8463],\n",
      "         [0.9971],\n",
      "         [0.2423],\n",
      "         [0.9153],\n",
      "         [0.9952],\n",
      "         [0.8509],\n",
      "         [0.5510],\n",
      "         [0.9949],\n",
      "         [0.2532],\n",
      "         [0.9949],\n",
      "         [0.9965],\n",
      "         [0.4567],\n",
      "         [0.9951],\n",
      "         [0.4576],\n",
      "         [0.3810],\n",
      "         [0.4941],\n",
      "         [0.4358],\n",
      "         [0.9881],\n",
      "         [0.9879],\n",
      "         [0.9871],\n",
      "         [0.8941],\n",
      "         [0.9900],\n",
      "         [0.9167],\n",
      "         [0.9915],\n",
      "         [0.9932],\n",
      "         [0.9958],\n",
      "         [0.9613],\n",
      "         [0.9974],\n",
      "         [0.2406],\n",
      "         [0.9960],\n",
      "         [0.2502],\n",
      "         [0.5222],\n",
      "         [0.3814],\n",
      "         [0.4685],\n",
      "         [0.4556],\n",
      "         [0.0605],\n",
      "         [0.0442],\n",
      "         [0.9969],\n",
      "         [0.9967],\n",
      "         [0.9959],\n",
      "         [0.3795],\n",
      "         [0.9916],\n",
      "         [0.1658],\n",
      "         [0.9920],\n",
      "         [0.5116],\n",
      "         [0.3593],\n",
      "         [0.2552],\n",
      "         [0.8541],\n",
      "         [0.9927],\n",
      "         [0.9933],\n",
      "         [0.9947],\n",
      "         [0.9939],\n",
      "         [0.4388],\n",
      "         [0.9941],\n",
      "         [0.9243],\n",
      "         [0.9968],\n",
      "         [0.9966],\n",
      "         [0.9961],\n",
      "         [0.9952],\n",
      "         [0.5050],\n",
      "         [0.9939],\n",
      "         [0.5161],\n",
      "         [0.9936],\n",
      "         [0.3399],\n",
      "         [0.9957],\n",
      "         [0.9959],\n",
      "         [0.9964],\n",
      "         [0.9985],\n",
      "         [1.0007],\n",
      "         [1.0006],\n",
      "         [0.0571],\n",
      "         [0.9991],\n",
      "         [0.9979],\n",
      "         [0.9937],\n",
      "         [0.9942],\n",
      "         [0.9907],\n",
      "         [0.2022],\n",
      "         [0.9881],\n",
      "         [0.9894],\n",
      "         [0.4418],\n",
      "         [0.6493],\n",
      "         [0.9746],\n",
      "         [0.9964],\n",
      "         [0.9833],\n",
      "         [0.0479],\n",
      "         [0.4688],\n",
      "         [0.5124],\n",
      "         [1.0003],\n",
      "         [0.9989],\n",
      "         [0.9988],\n",
      "         [0.9997],\n",
      "         [0.9995],\n",
      "         [0.9996],\n",
      "         [1.0001],\n",
      "         [0.5186],\n",
      "         [0.9996],\n",
      "         [0.9964],\n",
      "         [1.0009],\n",
      "         [0.2625],\n",
      "         [0.9975],\n",
      "         [0.9979],\n",
      "         [0.9957],\n",
      "         [0.0313],\n",
      "         [0.4448],\n",
      "         [0.0415],\n",
      "         [0.9928],\n",
      "         [0.3696],\n",
      "         [0.5395],\n",
      "         [0.9922],\n",
      "         [0.9528],\n",
      "         [0.9937],\n",
      "         [0.9953],\n",
      "         [0.9963],\n",
      "         [0.9965],\n",
      "         [0.3697],\n",
      "         [0.5370],\n",
      "         [0.9957],\n",
      "         [0.9951],\n",
      "         [0.6158],\n",
      "         [0.9967],\n",
      "         [0.9926],\n",
      "         [0.7214],\n",
      "         [0.5056],\n",
      "         [0.9957],\n",
      "         [0.5036],\n",
      "         [0.9945],\n",
      "         [0.2651],\n",
      "         [0.4669],\n",
      "         [0.2451],\n",
      "         [0.3519],\n",
      "         [0.9950],\n",
      "         [0.9594],\n",
      "         [0.5119],\n",
      "         [0.9920],\n",
      "         [0.9900],\n",
      "         [0.9907]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.7820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.8379],\n",
      "        [0.9819],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.0335],\n",
      "        [0.9490],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3747],\n",
      "        [0.9996],\n",
      "        [0.3808],\n",
      "        [0.9994],\n",
      "        [0.9995],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.9994],\n",
      "        [0.0288],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.7129],\n",
      "        [0.7391],\n",
      "        [0.8139],\n",
      "        [0.9997],\n",
      "        [0.2577],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.4580],\n",
      "        [0.9999],\n",
      "        [0.4611],\n",
      "        [0.3930],\n",
      "        [0.4988],\n",
      "        [0.4480],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.5151],\n",
      "        [0.3875],\n",
      "        [0.4668],\n",
      "        [0.4552],\n",
      "        [0.0368],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.9997],\n",
      "        [0.5139],\n",
      "        [0.3753],\n",
      "        [0.2735],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.9962],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.2208],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.6327],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.0247],\n",
      "        [0.4642],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9999],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0000],\n",
      "        [0.4503],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.5334],\n",
      "        [0.9997],\n",
      "        [0.9420],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.3780],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.6920],\n",
      "        [0.5030],\n",
      "        [0.9997],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.4645],\n",
      "        [0.2518],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000]])\n",
      "######### Epoch: 81  ######### Train Loss: 0.00012792026973329484  ######### Relative L2 Test Norm: 13.979138374328613\n",
      "Output batch pred: tensor([[[0.8497],\n",
      "         [0.0300],\n",
      "         [0.9933],\n",
      "         [0.9925],\n",
      "         [0.5025],\n",
      "         [0.7637],\n",
      "         [0.9917],\n",
      "         [0.9935],\n",
      "         [0.5388],\n",
      "         [0.5181],\n",
      "         [0.9961],\n",
      "         [0.4453],\n",
      "         [0.9971],\n",
      "         [0.9971],\n",
      "         [0.9958],\n",
      "         [0.9952],\n",
      "         [0.9940],\n",
      "         [0.9944],\n",
      "         [0.7794],\n",
      "         [0.9918],\n",
      "         [0.7157],\n",
      "         [0.9782],\n",
      "         [0.9579],\n",
      "         [0.0582],\n",
      "         [0.9944],\n",
      "         [0.5139],\n",
      "         [0.1713],\n",
      "         [0.9957],\n",
      "         [0.9957],\n",
      "         [0.5163],\n",
      "         [0.9331],\n",
      "         [0.9936],\n",
      "         [0.9946],\n",
      "         [0.2358],\n",
      "         [0.9936],\n",
      "         [0.9921],\n",
      "         [0.4441],\n",
      "         [0.9190],\n",
      "         [0.9801],\n",
      "         [0.9910],\n",
      "         [0.8418],\n",
      "         [0.4552],\n",
      "         [0.9936],\n",
      "         [0.9211],\n",
      "         [0.9962],\n",
      "         [0.9978],\n",
      "         [0.3756],\n",
      "         [0.4670],\n",
      "         [0.9999],\n",
      "         [0.3528],\n",
      "         [0.9983],\n",
      "         [0.2662],\n",
      "         [0.0541],\n",
      "         [0.8597],\n",
      "         [0.9965],\n",
      "         [0.9833],\n",
      "         [0.0545],\n",
      "         [0.9596],\n",
      "         [0.5013],\n",
      "         [0.4499],\n",
      "         [0.9939],\n",
      "         [0.9920],\n",
      "         [0.2447],\n",
      "         [0.9918],\n",
      "         [0.9902],\n",
      "         [0.9907],\n",
      "         [0.3550],\n",
      "         [0.8997],\n",
      "         [0.9946],\n",
      "         [0.9973],\n",
      "         [0.9964],\n",
      "         [0.9994],\n",
      "         [0.9997],\n",
      "         [0.9992],\n",
      "         [0.9994],\n",
      "         [0.9986],\n",
      "         [0.9973],\n",
      "         [0.3726],\n",
      "         [0.0402],\n",
      "         [0.2452],\n",
      "         [0.9948],\n",
      "         [0.9953],\n",
      "         [0.7443],\n",
      "         [0.9964],\n",
      "         [0.9834],\n",
      "         [0.9952],\n",
      "         [0.0411],\n",
      "         [0.9920],\n",
      "         [0.5029],\n",
      "         [0.2352],\n",
      "         [0.9914],\n",
      "         [0.9905],\n",
      "         [0.6827],\n",
      "         [0.4933],\n",
      "         [0.9911],\n",
      "         [0.9919],\n",
      "         [0.9914],\n",
      "         [0.9918],\n",
      "         [0.9937],\n",
      "         [0.9931],\n",
      "         [0.8124],\n",
      "         [0.9898],\n",
      "         [0.9576],\n",
      "         [0.3821],\n",
      "         [0.9736],\n",
      "         [0.3655],\n",
      "         [0.9920],\n",
      "         [0.3796],\n",
      "         [0.9946],\n",
      "         [0.9952],\n",
      "         [0.3435],\n",
      "         [0.9979],\n",
      "         [0.9981],\n",
      "         [0.9989],\n",
      "         [0.3690],\n",
      "         [0.9575],\n",
      "         [0.9974],\n",
      "         [0.4449],\n",
      "         [0.3659],\n",
      "         [0.9132],\n",
      "         [0.9900],\n",
      "         [0.9871],\n",
      "         [0.9874],\n",
      "         [0.9861],\n",
      "         [0.2381],\n",
      "         [0.9884],\n",
      "         [0.0368],\n",
      "         [0.9927],\n",
      "         [0.9920],\n",
      "         [0.2491],\n",
      "         [0.9987],\n",
      "         [0.9979],\n",
      "         [0.0594],\n",
      "         [0.5113],\n",
      "         [0.9968],\n",
      "         [0.9945],\n",
      "         [0.9939],\n",
      "         [0.5280],\n",
      "         [0.8594],\n",
      "         [0.9922],\n",
      "         [0.9907],\n",
      "         [0.9924],\n",
      "         [0.2094],\n",
      "         [0.9956],\n",
      "         [0.9966],\n",
      "         [0.4552],\n",
      "         [0.9957],\n",
      "         [0.6767],\n",
      "         [0.6511],\n",
      "         [0.9902],\n",
      "         [0.9902],\n",
      "         [0.9893],\n",
      "         [0.6040],\n",
      "         [0.4995],\n",
      "         [0.9898],\n",
      "         [0.9911],\n",
      "         [0.9916],\n",
      "         [0.9927],\n",
      "         [0.9940],\n",
      "         [0.9936],\n",
      "         [0.9949],\n",
      "         [0.9950],\n",
      "         [0.9973],\n",
      "         [0.4508],\n",
      "         [0.2624],\n",
      "         [0.9971],\n",
      "         [0.3831],\n",
      "         [0.9954],\n",
      "         [0.4676],\n",
      "         [0.0424],\n",
      "         [0.9954],\n",
      "         [0.5567],\n",
      "         [0.9948],\n",
      "         [0.9962],\n",
      "         [0.4644],\n",
      "         [0.9941],\n",
      "         [0.5193],\n",
      "         [0.9944]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.8223],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5080],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5334],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.9999],\n",
      "        [0.6920],\n",
      "        [0.9814],\n",
      "        [0.9515],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5139],\n",
      "        [0.9164],\n",
      "        [0.9996],\n",
      "        [0.9997],\n",
      "        [0.2547],\n",
      "        [0.9997],\n",
      "        [0.9995],\n",
      "        [0.4503],\n",
      "        [0.9044],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.4611],\n",
      "        [0.9999],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [0.0247],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [0.0335],\n",
      "        [0.9520],\n",
      "        [0.5009],\n",
      "        [0.4552],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.3728],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.0142],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.9999],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9956],\n",
      "        [0.9490],\n",
      "        [0.3930],\n",
      "        [0.9724],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.9420],\n",
      "        [0.9996],\n",
      "        [0.4454],\n",
      "        [0.3747],\n",
      "        [0.8933],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0368],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [0.8379],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.5945],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.3875],\n",
      "        [0.9962],\n",
      "        [0.4645],\n",
      "        [0.0174],\n",
      "        [0.9966],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [1.0000]])\n",
      "######### Epoch: 82  ######### Train Loss: 0.00013083324301987886  ######### Relative L2 Test Norm: 14.243597030639648\n",
      "Output batch pred: tensor([[[0.2487],\n",
      "         [0.9952],\n",
      "         [0.9941],\n",
      "         [0.9937],\n",
      "         [0.9578],\n",
      "         [0.9929],\n",
      "         [0.2597],\n",
      "         [0.9959],\n",
      "         [0.9956],\n",
      "         [0.9970],\n",
      "         [0.6946],\n",
      "         [0.9846],\n",
      "         [0.9990],\n",
      "         [0.9986],\n",
      "         [0.0478],\n",
      "         [0.4511],\n",
      "         [0.9954],\n",
      "         [0.9948],\n",
      "         [0.4661],\n",
      "         [0.9937],\n",
      "         [0.9948],\n",
      "         [0.9588],\n",
      "         [0.9948],\n",
      "         [0.9941],\n",
      "         [0.9947],\n",
      "         [0.9914],\n",
      "         [0.9929],\n",
      "         [0.2437],\n",
      "         [0.7694],\n",
      "         [0.9933],\n",
      "         [0.5313],\n",
      "         [0.9913],\n",
      "         [0.9915],\n",
      "         [0.9906],\n",
      "         [0.8540],\n",
      "         [0.9914],\n",
      "         [0.9916],\n",
      "         [0.9929],\n",
      "         [0.5522],\n",
      "         [0.9943],\n",
      "         [0.9939],\n",
      "         [0.3842],\n",
      "         [0.3780],\n",
      "         [0.9947],\n",
      "         [0.9929],\n",
      "         [0.9930],\n",
      "         [0.9899],\n",
      "         [0.9903],\n",
      "         [0.9864],\n",
      "         [0.8932],\n",
      "         [0.9890],\n",
      "         [0.9903],\n",
      "         [0.9911],\n",
      "         [0.9928],\n",
      "         [0.1663],\n",
      "         [0.9951],\n",
      "         [0.4416],\n",
      "         [0.9965],\n",
      "         [0.6135],\n",
      "         [0.9963],\n",
      "         [0.9221],\n",
      "         [0.9926],\n",
      "         [0.9936],\n",
      "         [0.7388],\n",
      "         [0.9915],\n",
      "         [0.0499],\n",
      "         [0.3563],\n",
      "         [0.9883],\n",
      "         [0.9902],\n",
      "         [0.5368],\n",
      "         [0.9906],\n",
      "         [0.2062],\n",
      "         [0.6750],\n",
      "         [0.3448],\n",
      "         [0.0263],\n",
      "         [0.9970],\n",
      "         [0.9979],\n",
      "         [0.9985],\n",
      "         [0.3471],\n",
      "         [0.9950],\n",
      "         [0.9913],\n",
      "         [0.9916],\n",
      "         [0.8470],\n",
      "         [0.9901],\n",
      "         [0.4356],\n",
      "         [0.9773],\n",
      "         [0.9894],\n",
      "         [0.9920],\n",
      "         [0.5122],\n",
      "         [0.9917],\n",
      "         [0.9930],\n",
      "         [0.9931],\n",
      "         [0.9933],\n",
      "         [0.4539],\n",
      "         [0.9924],\n",
      "         [0.9931],\n",
      "         [0.5007],\n",
      "         [0.5076],\n",
      "         [0.9928],\n",
      "         [0.9946],\n",
      "         [0.9953],\n",
      "         [0.5086],\n",
      "         [0.4593],\n",
      "         [0.0408],\n",
      "         [0.9979],\n",
      "         [0.9955],\n",
      "         [0.6561],\n",
      "         [0.9941],\n",
      "         [0.3783],\n",
      "         [0.9297],\n",
      "         [0.9501],\n",
      "         [0.5127],\n",
      "         [0.9927],\n",
      "         [0.9915],\n",
      "         [0.2380],\n",
      "         [0.5006],\n",
      "         [0.4989],\n",
      "         [0.8621],\n",
      "         [0.2543],\n",
      "         [0.4440],\n",
      "         [0.3657],\n",
      "         [0.9951],\n",
      "         [0.4515],\n",
      "         [0.9969],\n",
      "         [0.9984],\n",
      "         [0.3675],\n",
      "         [0.9970],\n",
      "         [0.9990],\n",
      "         [0.9807],\n",
      "         [0.7265],\n",
      "         [0.2580],\n",
      "         [0.9971],\n",
      "         [0.9956],\n",
      "         [0.8425],\n",
      "         [0.9892],\n",
      "         [0.9935],\n",
      "         [0.3554],\n",
      "         [0.4559],\n",
      "         [0.9935],\n",
      "         [0.9941],\n",
      "         [0.9954],\n",
      "         [0.9948],\n",
      "         [0.0345],\n",
      "         [0.9953],\n",
      "         [0.0548],\n",
      "         [0.9945],\n",
      "         [0.9944],\n",
      "         [0.9926],\n",
      "         [0.7784],\n",
      "         [0.3679],\n",
      "         [0.9163],\n",
      "         [0.5015],\n",
      "         [0.9775],\n",
      "         [0.9781],\n",
      "         [0.9901],\n",
      "         [0.0374],\n",
      "         [0.9884],\n",
      "         [0.9913],\n",
      "         [0.9896],\n",
      "         [0.3666],\n",
      "         [0.9947],\n",
      "         [0.9949],\n",
      "         [0.9970],\n",
      "         [0.2505],\n",
      "         [0.8168],\n",
      "         [0.9962],\n",
      "         [0.9951],\n",
      "         [0.9944],\n",
      "         [0.9586],\n",
      "         [0.9933],\n",
      "         [0.9126],\n",
      "         [0.4596],\n",
      "         [0.0563],\n",
      "         [0.2407],\n",
      "         [0.5013],\n",
      "         [0.0478],\n",
      "         [0.9960],\n",
      "         [0.5238]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2610],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.9995],\n",
      "        [0.2729],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.0288],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [0.9490],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.7391],\n",
      "        [0.9999],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.3930],\n",
      "        [0.3875],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.3728],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [0.9995],\n",
      "        [0.2208],\n",
      "        [0.6555],\n",
      "        [0.3575],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.9994],\n",
      "        [0.9962],\n",
      "        [0.9996],\n",
      "        [0.8223],\n",
      "        [0.9999],\n",
      "        [0.4480],\n",
      "        [0.9820],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5038],\n",
      "        [0.4580],\n",
      "        [0.0174],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9164],\n",
      "        [0.9420],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.5030],\n",
      "        [0.5009],\n",
      "        [0.8379],\n",
      "        [0.2686],\n",
      "        [0.4503],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.6920],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.8139],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.4642],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.7540],\n",
      "        [0.3840],\n",
      "        [0.9009],\n",
      "        [0.5080],\n",
      "        [0.9804],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.9515],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [0.4645],\n",
      "        [0.0335],\n",
      "        [0.2518],\n",
      "        [0.4988],\n",
      "        [0.0209],\n",
      "        [0.9997],\n",
      "        [0.5165]])\n",
      "######### Epoch: 83  ######### Train Loss: 0.00013348253560252488  ######### Relative L2 Test Norm: 14.187708854675293\n",
      "Output batch pred: tensor([[[0.5565],\n",
      "         [0.9970],\n",
      "         [0.9963],\n",
      "         [0.9946],\n",
      "         [0.9922],\n",
      "         [0.9907],\n",
      "         [0.9897],\n",
      "         [0.9893],\n",
      "         [0.9889],\n",
      "         [0.2471],\n",
      "         [0.9930],\n",
      "         [0.4430],\n",
      "         [0.7204],\n",
      "         [0.5065],\n",
      "         [0.9558],\n",
      "         [0.3774],\n",
      "         [0.9963],\n",
      "         [0.5169],\n",
      "         [0.8113],\n",
      "         [0.9928],\n",
      "         [0.9914],\n",
      "         [0.2383],\n",
      "         [0.8547],\n",
      "         [0.5111],\n",
      "         [0.0536],\n",
      "         [0.9954],\n",
      "         [0.2536],\n",
      "         [0.9960],\n",
      "         [0.0455],\n",
      "         [0.5187],\n",
      "         [0.9895],\n",
      "         [0.9923],\n",
      "         [0.9931],\n",
      "         [0.5121],\n",
      "         [0.9924],\n",
      "         [0.1700],\n",
      "         [0.7679],\n",
      "         [0.6538],\n",
      "         [0.9960],\n",
      "         [0.0588],\n",
      "         [0.9329],\n",
      "         [0.0276],\n",
      "         [0.9938],\n",
      "         [0.9928],\n",
      "         [0.9908],\n",
      "         [0.9921],\n",
      "         [0.4425],\n",
      "         [0.9897],\n",
      "         [0.9914],\n",
      "         [0.9931],\n",
      "         [0.9919],\n",
      "         [0.9913],\n",
      "         [0.9919],\n",
      "         [0.3745],\n",
      "         [0.9940],\n",
      "         [0.9809],\n",
      "         [0.9931],\n",
      "         [0.9962],\n",
      "         [0.0384],\n",
      "         [0.9982],\n",
      "         [0.3635],\n",
      "         [0.9980],\n",
      "         [0.9972],\n",
      "         [0.9832],\n",
      "         [0.9931],\n",
      "         [0.9933],\n",
      "         [0.0497],\n",
      "         [0.9893],\n",
      "         [0.3400],\n",
      "         [0.4463],\n",
      "         [0.3798],\n",
      "         [0.9586],\n",
      "         [0.9954],\n",
      "         [0.9963],\n",
      "         [0.9967],\n",
      "         [0.9952],\n",
      "         [0.9943],\n",
      "         [0.0261],\n",
      "         [0.9139],\n",
      "         [0.9934],\n",
      "         [0.9948],\n",
      "         [0.9943],\n",
      "         [0.9956],\n",
      "         [0.7461],\n",
      "         [0.9841],\n",
      "         [0.2626],\n",
      "         [0.9995],\n",
      "         [0.9983],\n",
      "         [0.4651],\n",
      "         [0.9947],\n",
      "         [0.2081],\n",
      "         [0.9910],\n",
      "         [0.4391],\n",
      "         [0.9803],\n",
      "         [0.9725],\n",
      "         [0.0356],\n",
      "         [0.3657],\n",
      "         [0.9917],\n",
      "         [0.9928],\n",
      "         [0.9921],\n",
      "         [0.5378],\n",
      "         [0.9898],\n",
      "         [0.9927],\n",
      "         [0.9927],\n",
      "         [0.9924],\n",
      "         [0.9934],\n",
      "         [0.4617],\n",
      "         [0.9903],\n",
      "         [0.9574],\n",
      "         [0.9920],\n",
      "         [0.9898],\n",
      "         [0.0429],\n",
      "         [0.9907],\n",
      "         [0.9907],\n",
      "         [0.9920],\n",
      "         [0.8975],\n",
      "         [0.5075],\n",
      "         [0.4630],\n",
      "         [0.5048],\n",
      "         [0.9971],\n",
      "         [0.5375],\n",
      "         [0.9963],\n",
      "         [0.9933],\n",
      "         [0.6756],\n",
      "         [0.6839],\n",
      "         [0.9878],\n",
      "         [0.9890],\n",
      "         [0.3541],\n",
      "         [0.7746],\n",
      "         [0.2409],\n",
      "         [0.9927],\n",
      "         [0.9945],\n",
      "         [0.2590],\n",
      "         [0.8518],\n",
      "         [0.3723],\n",
      "         [0.4554],\n",
      "         [0.8411],\n",
      "         [0.9179],\n",
      "         [0.4476],\n",
      "         [0.9913],\n",
      "         [0.5004],\n",
      "         [0.9941],\n",
      "         [0.9973],\n",
      "         [0.9978],\n",
      "         [0.2429],\n",
      "         [1.0015],\n",
      "         [1.0015],\n",
      "         [1.0005],\n",
      "         [0.9974],\n",
      "         [0.4402],\n",
      "         [0.9938],\n",
      "         [0.9929],\n",
      "         [0.9916],\n",
      "         [0.9903],\n",
      "         [0.3581],\n",
      "         [0.9929],\n",
      "         [0.9934],\n",
      "         [0.3440],\n",
      "         [0.9964],\n",
      "         [0.5011],\n",
      "         [0.3671],\n",
      "         [0.9957],\n",
      "         [0.9942],\n",
      "         [0.9204],\n",
      "         [0.9925],\n",
      "         [0.5065],\n",
      "         [0.9929],\n",
      "         [0.9929],\n",
      "         [0.6113],\n",
      "         [0.9581],\n",
      "         [0.9947],\n",
      "         [0.9946],\n",
      "         [0.9945],\n",
      "         [0.9938],\n",
      "         [0.9950],\n",
      "         [0.2380],\n",
      "         [0.8644],\n",
      "         [0.9956]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.5463],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.9997],\n",
      "        [0.4503],\n",
      "        [0.6920],\n",
      "        [0.5038],\n",
      "        [0.9420],\n",
      "        [0.3875],\n",
      "        [0.9999],\n",
      "        [0.5151],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.2577],\n",
      "        [0.8296],\n",
      "        [0.5108],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.5165],\n",
      "        [0.9956],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.7391],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [0.0368],\n",
      "        [0.9164],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9820],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.0383],\n",
      "        [0.9966],\n",
      "        [0.3575],\n",
      "        [0.4552],\n",
      "        [0.3930],\n",
      "        [0.9520],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.0142],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.9814],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.9959],\n",
      "        [0.4480],\n",
      "        [0.9819],\n",
      "        [0.9724],\n",
      "        [0.0174],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.9962],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0288],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.5080],\n",
      "        [0.4642],\n",
      "        [0.5009],\n",
      "        [0.9997],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.7540],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.8223],\n",
      "        [0.3840],\n",
      "        [0.4611],\n",
      "        [0.8139],\n",
      "        [0.9044],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9996],\n",
      "        [0.3753],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.8379],\n",
      "        [0.9999]])\n",
      "######### Epoch: 84  ######### Train Loss: 0.00013180781388655305  ######### Relative L2 Test Norm: 13.980937004089355\n",
      "Output batch pred: tensor([[[0.2389],\n",
      "         [0.9910],\n",
      "         [0.2416],\n",
      "         [0.9909],\n",
      "         [0.9924],\n",
      "         [0.4455],\n",
      "         [0.9922],\n",
      "         [0.8989],\n",
      "         [0.9944],\n",
      "         [0.9944],\n",
      "         [0.7401],\n",
      "         [0.5005],\n",
      "         [0.9938],\n",
      "         [0.3588],\n",
      "         [0.8384],\n",
      "         [0.9914],\n",
      "         [0.9900],\n",
      "         [0.9901],\n",
      "         [0.9778],\n",
      "         [0.3543],\n",
      "         [0.5256],\n",
      "         [0.2483],\n",
      "         [0.7835],\n",
      "         [0.9970],\n",
      "         [0.9998],\n",
      "         [1.0000],\n",
      "         [1.0014],\n",
      "         [1.0015],\n",
      "         [0.9990],\n",
      "         [0.9265],\n",
      "         [0.3813],\n",
      "         [0.2562],\n",
      "         [0.9953],\n",
      "         [0.2521],\n",
      "         [0.9935],\n",
      "         [0.6478],\n",
      "         [0.9941],\n",
      "         [0.9936],\n",
      "         [0.9958],\n",
      "         [0.0331],\n",
      "         [0.9977],\n",
      "         [0.9982],\n",
      "         [0.0375],\n",
      "         [0.4631],\n",
      "         [0.8605],\n",
      "         [0.9965],\n",
      "         [0.9220],\n",
      "         [0.9970],\n",
      "         [0.9948],\n",
      "         [0.9968],\n",
      "         [0.0366],\n",
      "         [0.6764],\n",
      "         [0.9960],\n",
      "         [0.9973],\n",
      "         [0.9547],\n",
      "         [0.3739],\n",
      "         [0.5386],\n",
      "         [0.0482],\n",
      "         [0.9936],\n",
      "         [0.2341],\n",
      "         [0.9741],\n",
      "         [0.5139],\n",
      "         [0.5143],\n",
      "         [0.9578],\n",
      "         [0.9911],\n",
      "         [0.9930],\n",
      "         [0.9929],\n",
      "         [0.9936],\n",
      "         [0.9929],\n",
      "         [0.3608],\n",
      "         [0.9930],\n",
      "         [0.7168],\n",
      "         [0.9928],\n",
      "         [0.5502],\n",
      "         [0.2377],\n",
      "         [0.9926],\n",
      "         [0.9946],\n",
      "         [0.0482],\n",
      "         [0.3458],\n",
      "         [0.3717],\n",
      "         [0.9946],\n",
      "         [0.5020],\n",
      "         [0.8659],\n",
      "         [0.9964],\n",
      "         [0.4495],\n",
      "         [0.6143],\n",
      "         [0.5068],\n",
      "         [0.9917],\n",
      "         [0.9791],\n",
      "         [0.8123],\n",
      "         [0.0259],\n",
      "         [0.8494],\n",
      "         [0.9926],\n",
      "         [0.9933],\n",
      "         [0.9893],\n",
      "         [0.9937],\n",
      "         [0.9950],\n",
      "         [0.9973],\n",
      "         [0.3488],\n",
      "         [0.4592],\n",
      "         [0.9980],\n",
      "         [0.9863],\n",
      "         [0.4463],\n",
      "         [0.9378],\n",
      "         [0.9968],\n",
      "         [0.9976],\n",
      "         [0.9965],\n",
      "         [0.9953],\n",
      "         [0.3585],\n",
      "         [0.9927],\n",
      "         [0.9932],\n",
      "         [0.9919],\n",
      "         [0.9917],\n",
      "         [0.9924],\n",
      "         [0.9922],\n",
      "         [0.4391],\n",
      "         [0.9822],\n",
      "         [0.9941],\n",
      "         [0.9946],\n",
      "         [0.9618],\n",
      "         [0.9955],\n",
      "         [0.9975],\n",
      "         [0.5117],\n",
      "         [0.9966],\n",
      "         [0.0508],\n",
      "         [0.9942],\n",
      "         [0.9930],\n",
      "         [0.9894],\n",
      "         [0.9900],\n",
      "         [0.9884],\n",
      "         [0.9871],\n",
      "         [0.9869],\n",
      "         [0.9880],\n",
      "         [0.9885],\n",
      "         [0.9876],\n",
      "         [0.9908],\n",
      "         [0.7632],\n",
      "         [0.9918],\n",
      "         [0.9931],\n",
      "         [0.4629],\n",
      "         [0.9961],\n",
      "         [0.9601],\n",
      "         [0.9949],\n",
      "         [0.9948],\n",
      "         [0.4505],\n",
      "         [0.1707],\n",
      "         [0.9920],\n",
      "         [0.5107],\n",
      "         [0.9916],\n",
      "         [0.4960],\n",
      "         [0.9875],\n",
      "         [0.9909],\n",
      "         [0.9882],\n",
      "         [0.9918],\n",
      "         [0.9924],\n",
      "         [0.6845],\n",
      "         [0.0448],\n",
      "         [0.9946],\n",
      "         [0.9949],\n",
      "         [0.9959],\n",
      "         [0.3720],\n",
      "         [0.9965],\n",
      "         [0.9949],\n",
      "         [0.9161],\n",
      "         [0.4588],\n",
      "         [0.5081],\n",
      "         [0.9964],\n",
      "         [0.4635],\n",
      "         [0.9956],\n",
      "         [0.2095],\n",
      "         [0.9965],\n",
      "         [0.5175],\n",
      "         [0.9943],\n",
      "         [0.2435],\n",
      "         [0.9919],\n",
      "         [0.9935],\n",
      "         [0.3778],\n",
      "         [0.0449]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2610],\n",
      "        [0.9998],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.3747],\n",
      "        [0.5245],\n",
      "        [0.2686],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9966],\n",
      "        [0.9044],\n",
      "        [0.3912],\n",
      "        [0.2735],\n",
      "        [0.9999],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.0209],\n",
      "        [0.4642],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.6555],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.3875],\n",
      "        [0.5334],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.9724],\n",
      "        [0.5165],\n",
      "        [0.5151],\n",
      "        [0.9490],\n",
      "        [0.9962],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.9998],\n",
      "        [0.6920],\n",
      "        [0.9998],\n",
      "        [0.5463],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.3573],\n",
      "        [0.3808],\n",
      "        [0.9997],\n",
      "        [0.4988],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.5945],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.7820],\n",
      "        [0.0000],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.4580],\n",
      "        [0.9999],\n",
      "        [0.9804],\n",
      "        [0.4454],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9515],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.1762],\n",
      "        [0.9999],\n",
      "        [0.5108],\n",
      "        [0.9997],\n",
      "        [0.5009],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.6628],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.8933],\n",
      "        [0.4611],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.9996],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.3930],\n",
      "        [0.0288]])\n",
      "######### Epoch: 85  ######### Train Loss: 0.00013558099453803152  ######### Relative L2 Test Norm: 13.952348709106445\n",
      "Output batch pred: tensor([[[0.2360],\n",
      "         [0.9931],\n",
      "         [0.9919],\n",
      "         [0.4328],\n",
      "         [0.5207],\n",
      "         [0.1574],\n",
      "         [0.4935],\n",
      "         [0.9919],\n",
      "         [0.9929],\n",
      "         [0.9922],\n",
      "         [0.5157],\n",
      "         [0.6508],\n",
      "         [0.3783],\n",
      "         [0.9904],\n",
      "         [0.9925],\n",
      "         [0.9903],\n",
      "         [0.5087],\n",
      "         [0.9196],\n",
      "         [0.5138],\n",
      "         [0.9948],\n",
      "         [0.9953],\n",
      "         [0.9947],\n",
      "         [0.9854],\n",
      "         [0.9958],\n",
      "         [0.2090],\n",
      "         [0.4479],\n",
      "         [0.9958],\n",
      "         [0.9960],\n",
      "         [0.2507],\n",
      "         [0.5529],\n",
      "         [0.9964],\n",
      "         [0.9973],\n",
      "         [0.9978],\n",
      "         [0.4673],\n",
      "         [0.9637],\n",
      "         [0.5052],\n",
      "         [0.9973],\n",
      "         [0.9964],\n",
      "         [0.9940],\n",
      "         [0.9943],\n",
      "         [0.2444],\n",
      "         [0.9927],\n",
      "         [0.9942],\n",
      "         [0.8580],\n",
      "         [0.9971],\n",
      "         [0.5018],\n",
      "         [0.9993],\n",
      "         [0.9994],\n",
      "         [0.0554],\n",
      "         [0.9968],\n",
      "         [0.4647],\n",
      "         [0.3648],\n",
      "         [0.9950],\n",
      "         [0.0314],\n",
      "         [0.9932],\n",
      "         [0.9934],\n",
      "         [0.9920],\n",
      "         [0.9513],\n",
      "         [0.2352],\n",
      "         [0.9883],\n",
      "         [0.9928],\n",
      "         [0.9795],\n",
      "         [0.8597],\n",
      "         [0.2546],\n",
      "         [0.9923],\n",
      "         [0.6722],\n",
      "         [0.9928],\n",
      "         [0.6084],\n",
      "         [0.9960],\n",
      "         [0.4577],\n",
      "         [0.5060],\n",
      "         [0.2414],\n",
      "         [0.5442],\n",
      "         [0.4412],\n",
      "         [0.9963],\n",
      "         [0.9942],\n",
      "         [0.3428],\n",
      "         [0.9945],\n",
      "         [0.7808],\n",
      "         [0.9954],\n",
      "         [0.9949],\n",
      "         [0.0478],\n",
      "         [0.9962],\n",
      "         [0.9982],\n",
      "         [0.9972],\n",
      "         [0.4648],\n",
      "         [0.9988],\n",
      "         [0.9189],\n",
      "         [0.9986],\n",
      "         [0.9977],\n",
      "         [0.9963],\n",
      "         [0.3656],\n",
      "         [0.9959],\n",
      "         [0.9976],\n",
      "         [0.0533],\n",
      "         [0.9965],\n",
      "         [0.7221],\n",
      "         [0.9960],\n",
      "         [0.9948],\n",
      "         [0.9940],\n",
      "         [0.3405],\n",
      "         [0.9914],\n",
      "         [0.2396],\n",
      "         [0.9305],\n",
      "         [0.2509],\n",
      "         [0.9932],\n",
      "         [0.9945],\n",
      "         [0.0269],\n",
      "         [0.9952],\n",
      "         [0.9945],\n",
      "         [0.9947],\n",
      "         [0.9960],\n",
      "         [0.9955],\n",
      "         [0.7427],\n",
      "         [0.9957],\n",
      "         [0.0284],\n",
      "         [0.9936],\n",
      "         [0.9940],\n",
      "         [0.4436],\n",
      "         [0.3797],\n",
      "         [0.9909],\n",
      "         [0.9917],\n",
      "         [0.9916],\n",
      "         [0.9912],\n",
      "         [0.8483],\n",
      "         [0.5048],\n",
      "         [0.6881],\n",
      "         [0.3705],\n",
      "         [0.9992],\n",
      "         [1.0005],\n",
      "         [0.0524],\n",
      "         [0.5164],\n",
      "         [1.0010],\n",
      "         [0.8519],\n",
      "         [0.9640],\n",
      "         [0.9968],\n",
      "         [0.7717],\n",
      "         [0.9953],\n",
      "         [0.9931],\n",
      "         [0.9900],\n",
      "         [0.0376],\n",
      "         [0.9906],\n",
      "         [0.9923],\n",
      "         [0.9910],\n",
      "         [0.3579],\n",
      "         [0.9935],\n",
      "         [0.9943],\n",
      "         [0.4498],\n",
      "         [0.3764],\n",
      "         [0.9973],\n",
      "         [0.0405],\n",
      "         [0.9982],\n",
      "         [0.4560],\n",
      "         [0.5210],\n",
      "         [0.9967],\n",
      "         [0.9957],\n",
      "         [0.9936],\n",
      "         [0.9940],\n",
      "         [0.9578],\n",
      "         [0.8974],\n",
      "         [0.9778],\n",
      "         [0.9731],\n",
      "         [0.9798],\n",
      "         [0.3562],\n",
      "         [0.9936],\n",
      "         [0.9931],\n",
      "         [0.9910],\n",
      "         [0.9912],\n",
      "         [0.9173],\n",
      "         [0.3647],\n",
      "         [0.9926],\n",
      "         [0.9942],\n",
      "         [0.9942],\n",
      "         [0.9971],\n",
      "         [0.9978],\n",
      "         [0.8177],\n",
      "         [0.9989],\n",
      "         [0.9958]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.2518],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.5245],\n",
      "        [0.1762],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [0.5151],\n",
      "        [0.6327],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9967],\n",
      "        [0.5108],\n",
      "        [0.9044],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.2686],\n",
      "        [0.5463],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.4645],\n",
      "        [0.9490],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.2646],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [0.2577],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.8379],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [0.9999],\n",
      "        [0.5945],\n",
      "        [0.9999],\n",
      "        [0.4611],\n",
      "        [0.5038],\n",
      "        [0.2547],\n",
      "        [0.5334],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.4642],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.9962],\n",
      "        [0.9994],\n",
      "        [0.0383],\n",
      "        [0.9996],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [0.9164],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.7129],\n",
      "        [0.9999],\n",
      "        [0.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4503],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [0.5080],\n",
      "        [0.6628],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.5054],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [0.9520],\n",
      "        [0.9999],\n",
      "        [0.7391],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.0247],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.3728],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.3875],\n",
      "        [0.9998],\n",
      "        [0.0209],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9515],\n",
      "        [0.8761],\n",
      "        [0.9814],\n",
      "        [0.9724],\n",
      "        [0.9804],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [0.9966]])\n",
      "######### Epoch: 86  ######### Train Loss: 0.00013827113434672356  ######### Relative L2 Test Norm: 14.12490177154541\n",
      "Output batch pred: tensor([[[0.9577],\n",
      "         [0.9922],\n",
      "         [0.2539],\n",
      "         [0.9930],\n",
      "         [0.9937],\n",
      "         [0.6844],\n",
      "         [0.9932],\n",
      "         [0.0455],\n",
      "         [0.8138],\n",
      "         [0.9836],\n",
      "         [0.2072],\n",
      "         [0.9970],\n",
      "         [0.9973],\n",
      "         [0.9969],\n",
      "         [0.9016],\n",
      "         [0.9935],\n",
      "         [0.9962],\n",
      "         [0.9966],\n",
      "         [0.9969],\n",
      "         [0.9958],\n",
      "         [0.5416],\n",
      "         [0.9972],\n",
      "         [0.9974],\n",
      "         [0.9964],\n",
      "         [0.9984],\n",
      "         [0.9974],\n",
      "         [0.0488],\n",
      "         [0.9999],\n",
      "         [1.0016],\n",
      "         [1.0024],\n",
      "         [1.0018],\n",
      "         [1.0025],\n",
      "         [0.0412],\n",
      "         [0.0365],\n",
      "         [0.9976],\n",
      "         [0.4479],\n",
      "         [0.9956],\n",
      "         [0.9930],\n",
      "         [0.5148],\n",
      "         [0.9922],\n",
      "         [0.3728],\n",
      "         [0.9907],\n",
      "         [0.9913],\n",
      "         [0.4545],\n",
      "         [0.5258],\n",
      "         [0.2371],\n",
      "         [0.9920],\n",
      "         [0.7381],\n",
      "         [0.9945],\n",
      "         [0.9940],\n",
      "         [0.3381],\n",
      "         [0.9905],\n",
      "         [0.9544],\n",
      "         [0.3647],\n",
      "         [0.0472],\n",
      "         [0.2319],\n",
      "         [0.6711],\n",
      "         [0.8539],\n",
      "         [0.9574],\n",
      "         [0.9933],\n",
      "         [0.9904],\n",
      "         [0.4493],\n",
      "         [0.9920],\n",
      "         [0.9934],\n",
      "         [0.9926],\n",
      "         [0.3782],\n",
      "         [0.9950],\n",
      "         [0.9975],\n",
      "         [0.9971],\n",
      "         [0.9991],\n",
      "         [0.3657],\n",
      "         [0.9175],\n",
      "         [0.2543],\n",
      "         [0.0342],\n",
      "         [0.2552],\n",
      "         [0.9944],\n",
      "         [0.3423],\n",
      "         [0.5029],\n",
      "         [0.8470],\n",
      "         [0.9984],\n",
      "         [0.9991],\n",
      "         [0.9993],\n",
      "         [0.9985],\n",
      "         [0.2498],\n",
      "         [0.9993],\n",
      "         [0.9967],\n",
      "         [0.9964],\n",
      "         [0.9941],\n",
      "         [0.9950],\n",
      "         [0.1622],\n",
      "         [0.2382],\n",
      "         [0.4542],\n",
      "         [0.5037],\n",
      "         [0.9976],\n",
      "         [0.6149],\n",
      "         [0.5238],\n",
      "         [0.9986],\n",
      "         [0.9987],\n",
      "         [0.9986],\n",
      "         [0.0493],\n",
      "         [0.9976],\n",
      "         [0.9962],\n",
      "         [0.4394],\n",
      "         [0.9931],\n",
      "         [0.9933],\n",
      "         [0.9938],\n",
      "         [0.5064],\n",
      "         [0.9924],\n",
      "         [0.9924],\n",
      "         [0.9908],\n",
      "         [0.9929],\n",
      "         [0.9926],\n",
      "         [0.7807],\n",
      "         [0.9962],\n",
      "         [0.8546],\n",
      "         [0.9984],\n",
      "         [0.9889],\n",
      "         [1.0000],\n",
      "         [1.0016],\n",
      "         [1.0023],\n",
      "         [0.9998],\n",
      "         [0.3717],\n",
      "         [0.9239],\n",
      "         [0.9969],\n",
      "         [0.5046],\n",
      "         [0.9943],\n",
      "         [0.9937],\n",
      "         [0.9941],\n",
      "         [0.5500],\n",
      "         [0.9817],\n",
      "         [0.9961],\n",
      "         [0.0201],\n",
      "         [0.9981],\n",
      "         [0.9978],\n",
      "         [0.3722],\n",
      "         [0.9973],\n",
      "         [0.9571],\n",
      "         [0.9977],\n",
      "         [0.7685],\n",
      "         [0.5070],\n",
      "         [0.9936],\n",
      "         [0.4422],\n",
      "         [0.6450],\n",
      "         [0.4422],\n",
      "         [0.4892],\n",
      "         [0.3676],\n",
      "         [0.9899],\n",
      "         [0.3561],\n",
      "         [0.4587],\n",
      "         [0.9942],\n",
      "         [0.7206],\n",
      "         [0.9970],\n",
      "         [0.9986],\n",
      "         [0.2486],\n",
      "         [0.9978],\n",
      "         [0.9789],\n",
      "         [0.5028],\n",
      "         [0.9972],\n",
      "         [0.9965],\n",
      "         [0.9958],\n",
      "         [0.9955],\n",
      "         [0.4604],\n",
      "         [0.9940],\n",
      "         [0.4400],\n",
      "         [0.9953],\n",
      "         [0.0402],\n",
      "         [0.9928],\n",
      "         [0.3625],\n",
      "         [0.9834],\n",
      "         [0.9963],\n",
      "         [0.9975],\n",
      "         [0.9247],\n",
      "         [0.9962],\n",
      "         [0.9946],\n",
      "         [0.9351],\n",
      "         [0.5173],\n",
      "         [0.9949],\n",
      "         [0.8635]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9520],\n",
      "        [0.9996],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.6628],\n",
      "        [0.9999],\n",
      "        [0.0288],\n",
      "        [0.7820],\n",
      "        [0.9820],\n",
      "        [0.2208],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8761],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.0247],\n",
      "        [0.0174],\n",
      "        [0.9959],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.5165],\n",
      "        [0.9998],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4645],\n",
      "        [0.5245],\n",
      "        [0.2547],\n",
      "        [0.9962],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [0.9998],\n",
      "        [0.9490],\n",
      "        [0.3840],\n",
      "        [0.0335],\n",
      "        [0.2518],\n",
      "        [0.6555],\n",
      "        [0.8296],\n",
      "        [0.9515],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.9996],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.3930],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.8933],\n",
      "        [0.2686],\n",
      "        [0.0142],\n",
      "        [0.2729],\n",
      "        [0.9994],\n",
      "        [0.3575],\n",
      "        [0.5030],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.2577],\n",
      "        [0.4611],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.0368],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.4480],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.7540],\n",
      "        [0.9999],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.3780],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5463],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.9999],\n",
      "        [0.9420],\n",
      "        [0.9998],\n",
      "        [0.7391],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.6327],\n",
      "        [0.4552],\n",
      "        [0.4988],\n",
      "        [0.3875],\n",
      "        [0.9997],\n",
      "        [0.3753],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.9997],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.9956],\n",
      "        [0.3728],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9044],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.8379]])\n",
      "######### Epoch: 87  ######### Train Loss: 0.00012774838251061738  ######### Relative L2 Test Norm: 13.81210994720459\n",
      "Output batch pred: tensor([[[0.9938],\n",
      "         [0.0529],\n",
      "         [0.9972],\n",
      "         [0.4526],\n",
      "         [0.2613],\n",
      "         [0.8181],\n",
      "         [0.8557],\n",
      "         [0.0338],\n",
      "         [0.9963],\n",
      "         [0.4588],\n",
      "         [0.9933],\n",
      "         [0.9922],\n",
      "         [0.9928],\n",
      "         [0.3564],\n",
      "         [0.6485],\n",
      "         [0.9936],\n",
      "         [0.9921],\n",
      "         [0.9173],\n",
      "         [0.9917],\n",
      "         [0.4909],\n",
      "         [0.2019],\n",
      "         [0.9922],\n",
      "         [0.9921],\n",
      "         [0.3584],\n",
      "         [0.4476],\n",
      "         [0.9837],\n",
      "         [0.0448],\n",
      "         [0.8621],\n",
      "         [0.5249],\n",
      "         [1.0011],\n",
      "         [0.9867],\n",
      "         [0.9982],\n",
      "         [0.7761],\n",
      "         [0.9991],\n",
      "         [0.5079],\n",
      "         [0.9983],\n",
      "         [0.9980],\n",
      "         [0.9856],\n",
      "         [0.9973],\n",
      "         [0.9969],\n",
      "         [0.9964],\n",
      "         [0.9994],\n",
      "         [0.4511],\n",
      "         [0.9983],\n",
      "         [0.3790],\n",
      "         [0.8693],\n",
      "         [1.0000],\n",
      "         [0.7884],\n",
      "         [1.0006],\n",
      "         [0.9994],\n",
      "         [0.1681],\n",
      "         [0.9981],\n",
      "         [0.3493],\n",
      "         [0.9994],\n",
      "         [0.6153],\n",
      "         [0.5089],\n",
      "         [0.9967],\n",
      "         [0.9952],\n",
      "         [0.3812],\n",
      "         [0.9939],\n",
      "         [0.9941],\n",
      "         [0.3775],\n",
      "         [0.9960],\n",
      "         [0.4978],\n",
      "         [0.5131],\n",
      "         [0.9966],\n",
      "         [0.9954],\n",
      "         [0.9949],\n",
      "         [0.6883],\n",
      "         [0.9970],\n",
      "         [0.9957],\n",
      "         [0.9981],\n",
      "         [0.3751],\n",
      "         [0.9989],\n",
      "         [0.9967],\n",
      "         [0.9977],\n",
      "         [0.9982],\n",
      "         [0.2417],\n",
      "         [0.9961],\n",
      "         [0.9755],\n",
      "         [0.9933],\n",
      "         [0.9917],\n",
      "         [0.9956],\n",
      "         [0.9966],\n",
      "         [0.9967],\n",
      "         [0.9627],\n",
      "         [0.9260],\n",
      "         [0.9584],\n",
      "         [0.2574],\n",
      "         [0.9971],\n",
      "         [0.3614],\n",
      "         [0.7191],\n",
      "         [0.8411],\n",
      "         [0.5056],\n",
      "         [0.9914],\n",
      "         [0.9904],\n",
      "         [0.7350],\n",
      "         [0.0335],\n",
      "         [0.0474],\n",
      "         [0.9932],\n",
      "         [0.9941],\n",
      "         [0.3417],\n",
      "         [0.9950],\n",
      "         [0.9956],\n",
      "         [0.4422],\n",
      "         [0.3663],\n",
      "         [0.9959],\n",
      "         [0.2399],\n",
      "         [0.9963],\n",
      "         [0.9956],\n",
      "         [0.0247],\n",
      "         [0.5039],\n",
      "         [0.9950],\n",
      "         [0.9936],\n",
      "         [0.9948],\n",
      "         [0.9897],\n",
      "         [0.9929],\n",
      "         [0.9959],\n",
      "         [0.5319],\n",
      "         [0.9980],\n",
      "         [1.0001],\n",
      "         [0.4448],\n",
      "         [0.4488],\n",
      "         [0.4711],\n",
      "         [0.4685],\n",
      "         [1.0002],\n",
      "         [1.0008],\n",
      "         [0.0375],\n",
      "         [0.9999],\n",
      "         [0.9988],\n",
      "         [1.0005],\n",
      "         [1.0014],\n",
      "         [1.0021],\n",
      "         [0.9231],\n",
      "         [1.0026],\n",
      "         [0.2628],\n",
      "         [0.2440],\n",
      "         [0.9960],\n",
      "         [0.9967],\n",
      "         [0.9952],\n",
      "         [0.0474],\n",
      "         [0.5467],\n",
      "         [0.9568],\n",
      "         [0.9930],\n",
      "         [0.9938],\n",
      "         [0.9952],\n",
      "         [0.9976],\n",
      "         [0.9966],\n",
      "         [0.9975],\n",
      "         [0.9970],\n",
      "         [0.2487],\n",
      "         [0.9953],\n",
      "         [0.8999],\n",
      "         [0.5384],\n",
      "         [0.5143],\n",
      "         [0.9937],\n",
      "         [0.9826],\n",
      "         [0.9608],\n",
      "         [0.9973],\n",
      "         [0.9972],\n",
      "         [0.9971],\n",
      "         [0.4535],\n",
      "         [0.0368],\n",
      "         [0.9955],\n",
      "         [0.3592],\n",
      "         [0.9961],\n",
      "         [0.9966],\n",
      "         [0.9971],\n",
      "         [0.9962],\n",
      "         [0.6797],\n",
      "         [0.2346],\n",
      "         [0.9972],\n",
      "         [0.9963],\n",
      "         [0.9964],\n",
      "         [0.9952],\n",
      "         [0.5018],\n",
      "         [0.9296],\n",
      "         [0.9924]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.2735],\n",
      "        [0.7820],\n",
      "        [0.8223],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.4580],\n",
      "        [0.9819],\n",
      "        [0.0288],\n",
      "        [0.8296],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.9996],\n",
      "        [0.9967],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.4527],\n",
      "        [0.9996],\n",
      "        [0.3875],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.6628],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.3840],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.9999],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9490],\n",
      "        [0.9044],\n",
      "        [0.9420],\n",
      "        [0.2686],\n",
      "        [0.9997],\n",
      "        [0.3728],\n",
      "        [0.6920],\n",
      "        [0.8139],\n",
      "        [0.5108],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.0174],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.3573],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [0.2577],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9956],\n",
      "        [0.9966],\n",
      "        [0.9996],\n",
      "        [0.5245],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.4454],\n",
      "        [0.4480],\n",
      "        [0.4668],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.5463],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.5334],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.9804],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.0247],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.6555],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9164],\n",
      "        [1.0000]])\n",
      "######### Epoch: 88  ######### Train Loss: 0.00012937696010340005  ######### Relative L2 Test Norm: 13.933767318725586\n",
      "Output batch pred: tensor([[[0.9643],\n",
      "         [0.3451],\n",
      "         [0.9982],\n",
      "         [0.9015],\n",
      "         [0.9950],\n",
      "         [0.7779],\n",
      "         [0.9922],\n",
      "         [0.9907],\n",
      "         [0.9912],\n",
      "         [0.9891],\n",
      "         [0.9913],\n",
      "         [0.9910],\n",
      "         [0.4466],\n",
      "         [0.9921],\n",
      "         [0.9928],\n",
      "         [0.3543],\n",
      "         [0.8552],\n",
      "         [0.9831],\n",
      "         [0.9967],\n",
      "         [0.9974],\n",
      "         [0.2594],\n",
      "         [0.9222],\n",
      "         [0.3689],\n",
      "         [0.4998],\n",
      "         [0.4513],\n",
      "         [0.4531],\n",
      "         [0.9899],\n",
      "         [0.9935],\n",
      "         [0.9955],\n",
      "         [0.9952],\n",
      "         [0.2398],\n",
      "         [0.0309],\n",
      "         [0.9997],\n",
      "         [1.0000],\n",
      "         [0.8683],\n",
      "         [0.9956],\n",
      "         [0.0431],\n",
      "         [0.9935],\n",
      "         [0.9924],\n",
      "         [0.6057],\n",
      "         [0.9909],\n",
      "         [0.6693],\n",
      "         [0.9909],\n",
      "         [0.9172],\n",
      "         [0.9927],\n",
      "         [0.9942],\n",
      "         [0.3831],\n",
      "         [0.5195],\n",
      "         [0.5206],\n",
      "         [0.4663],\n",
      "         [0.4643],\n",
      "         [0.3756],\n",
      "         [0.2527],\n",
      "         [0.3632],\n",
      "         [0.7470],\n",
      "         [0.5093],\n",
      "         [1.0002],\n",
      "         [1.0016],\n",
      "         [1.0031],\n",
      "         [0.5438],\n",
      "         [1.0022],\n",
      "         [1.0020],\n",
      "         [1.0028],\n",
      "         [1.0018],\n",
      "         [1.0006],\n",
      "         [0.9994],\n",
      "         [0.9983],\n",
      "         [0.9999],\n",
      "         [0.9989],\n",
      "         [0.9875],\n",
      "         [0.5189],\n",
      "         [0.3459],\n",
      "         [1.0006],\n",
      "         [1.0018],\n",
      "         [0.5156],\n",
      "         [1.0038],\n",
      "         [1.0041],\n",
      "         [1.0065],\n",
      "         [0.4569],\n",
      "         [1.0075],\n",
      "         [1.0073],\n",
      "         [1.0058],\n",
      "         [0.0549],\n",
      "         [1.0029],\n",
      "         [1.0008],\n",
      "         [0.9962],\n",
      "         [0.9946],\n",
      "         [0.9925],\n",
      "         [0.9907],\n",
      "         [0.9868],\n",
      "         [0.2387],\n",
      "         [0.8443],\n",
      "         [0.9921],\n",
      "         [0.0397],\n",
      "         [0.9970],\n",
      "         [0.9954],\n",
      "         [0.9974],\n",
      "         [0.9978],\n",
      "         [0.9969],\n",
      "         [0.9933],\n",
      "         [0.9578],\n",
      "         [0.4523],\n",
      "         [0.9914],\n",
      "         [0.9085],\n",
      "         [0.6784],\n",
      "         [0.9917],\n",
      "         [0.5444],\n",
      "         [0.9904],\n",
      "         [0.9931],\n",
      "         [0.9932],\n",
      "         [0.9951],\n",
      "         [0.8118],\n",
      "         [0.0251],\n",
      "         [0.3738],\n",
      "         [0.4427],\n",
      "         [0.5404],\n",
      "         [0.0373],\n",
      "         [0.9540],\n",
      "         [0.9951],\n",
      "         [0.5037],\n",
      "         [0.3594],\n",
      "         [0.9929],\n",
      "         [0.2407],\n",
      "         [0.9926],\n",
      "         [0.9952],\n",
      "         [0.9601],\n",
      "         [0.4491],\n",
      "         [0.4435],\n",
      "         [1.0015],\n",
      "         [0.0545],\n",
      "         [0.0519],\n",
      "         [1.0019],\n",
      "         [0.2146],\n",
      "         [0.9999],\n",
      "         [0.0566],\n",
      "         [0.5129],\n",
      "         [0.5003],\n",
      "         [0.2387],\n",
      "         [0.3686],\n",
      "         [0.2371],\n",
      "         [0.9939],\n",
      "         [0.7720],\n",
      "         [0.9983],\n",
      "         [0.9990],\n",
      "         [0.6587],\n",
      "         [0.8489],\n",
      "         [0.9989],\n",
      "         [0.7242],\n",
      "         [0.9994],\n",
      "         [0.9994],\n",
      "         [1.0000],\n",
      "         [1.0002],\n",
      "         [0.9994],\n",
      "         [0.1666],\n",
      "         [1.0014],\n",
      "         [0.9998],\n",
      "         [1.0010],\n",
      "         [0.2571],\n",
      "         [1.0007],\n",
      "         [1.0005],\n",
      "         [0.9988],\n",
      "         [0.9995],\n",
      "         [0.9990],\n",
      "         [0.9981],\n",
      "         [0.9867],\n",
      "         [0.9977],\n",
      "         [0.9359],\n",
      "         [0.9822],\n",
      "         [0.9951],\n",
      "         [0.9963],\n",
      "         [0.9958],\n",
      "         [0.9962],\n",
      "         [0.5003],\n",
      "         [0.9968],\n",
      "         [0.9792],\n",
      "         [0.9992],\n",
      "         [0.3826],\n",
      "         [1.0015]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9490],\n",
      "        [0.3573],\n",
      "        [0.9997],\n",
      "        [0.8761],\n",
      "        [0.9996],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.8296],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2735],\n",
      "        [0.9009],\n",
      "        [0.3780],\n",
      "        [0.4988],\n",
      "        [0.4552],\n",
      "        [0.4580],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.3930],\n",
      "        [0.5151],\n",
      "        [0.5165],\n",
      "        [0.4668],\n",
      "        [0.4642],\n",
      "        [0.3840],\n",
      "        [0.2646],\n",
      "        [0.3728],\n",
      "        [0.7129],\n",
      "        [0.5030],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9820],\n",
      "        [0.5139],\n",
      "        [0.3575],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.4480],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.0368],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [0.2686],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.9515],\n",
      "        [0.4645],\n",
      "        [0.9999],\n",
      "        [0.8933],\n",
      "        [0.6628],\n",
      "        [0.9998],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.7820],\n",
      "        [0.0000],\n",
      "        [0.3875],\n",
      "        [0.4503],\n",
      "        [0.5334],\n",
      "        [0.0174],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.3753],\n",
      "        [0.9998],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.4527],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.5108],\n",
      "        [0.5009],\n",
      "        [0.2547],\n",
      "        [0.3808],\n",
      "        [0.2518],\n",
      "        [0.9962],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.6327],\n",
      "        [0.8139],\n",
      "        [0.9998],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9997],\n",
      "        [0.2729],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.9998],\n",
      "        [0.9164],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.9997],\n",
      "        [0.3912],\n",
      "        [0.9997]])\n",
      "######### Epoch: 89  ######### Train Loss: 0.0001342736795777455  ######### Relative L2 Test Norm: 13.833005905151367\n",
      "Output batch pred: tensor([[[0.6069],\n",
      "         [0.0417],\n",
      "         [0.0403],\n",
      "         [0.0454],\n",
      "         [0.9947],\n",
      "         [0.9946],\n",
      "         [0.4941],\n",
      "         [0.9964],\n",
      "         [0.9972],\n",
      "         [0.9993],\n",
      "         [0.9989],\n",
      "         [0.9986],\n",
      "         [0.9973],\n",
      "         [0.9975],\n",
      "         [0.9953],\n",
      "         [0.9182],\n",
      "         [0.9916],\n",
      "         [0.9888],\n",
      "         [0.8432],\n",
      "         [0.9905],\n",
      "         [0.9920],\n",
      "         [0.5236],\n",
      "         [0.9959],\n",
      "         [0.9973],\n",
      "         [0.8608],\n",
      "         [0.9988],\n",
      "         [0.0278],\n",
      "         [0.9983],\n",
      "         [0.9967],\n",
      "         [0.9958],\n",
      "         [0.9958],\n",
      "         [0.9958],\n",
      "         [0.3610],\n",
      "         [1.0002],\n",
      "         [0.2386],\n",
      "         [1.0027],\n",
      "         [0.2539],\n",
      "         [0.9979],\n",
      "         [1.0011],\n",
      "         [0.9987],\n",
      "         [0.9951],\n",
      "         [0.3626],\n",
      "         [0.5336],\n",
      "         [0.9904],\n",
      "         [0.9912],\n",
      "         [0.9498],\n",
      "         [0.9940],\n",
      "         [0.9964],\n",
      "         [0.9954],\n",
      "         [0.5156],\n",
      "         [0.6946],\n",
      "         [0.3719],\n",
      "         [1.0017],\n",
      "         [0.4586],\n",
      "         [0.5128],\n",
      "         [0.9977],\n",
      "         [0.4454],\n",
      "         [0.7452],\n",
      "         [0.9988],\n",
      "         [0.9998],\n",
      "         [1.0007],\n",
      "         [1.0014],\n",
      "         [0.2504],\n",
      "         [0.9664],\n",
      "         [1.0010],\n",
      "         [0.0448],\n",
      "         [0.9661],\n",
      "         [1.0011],\n",
      "         [0.9649],\n",
      "         [0.3444],\n",
      "         [0.9965],\n",
      "         [0.9941],\n",
      "         [0.9922],\n",
      "         [0.9910],\n",
      "         [0.9894],\n",
      "         [0.9892],\n",
      "         [0.9901],\n",
      "         [0.3737],\n",
      "         [0.8599],\n",
      "         [0.5143],\n",
      "         [0.9977],\n",
      "         [1.0021],\n",
      "         [0.9245],\n",
      "         [1.0038],\n",
      "         [1.0033],\n",
      "         [0.3526],\n",
      "         [0.9997],\n",
      "         [0.4508],\n",
      "         [0.9912],\n",
      "         [0.9913],\n",
      "         [0.9888],\n",
      "         [0.9877],\n",
      "         [0.9877],\n",
      "         [0.2263],\n",
      "         [0.7117],\n",
      "         [0.9803],\n",
      "         [0.9954],\n",
      "         [0.5063],\n",
      "         [0.2427],\n",
      "         [0.9997],\n",
      "         [1.0012],\n",
      "         [1.0001],\n",
      "         [0.9993],\n",
      "         [1.0006],\n",
      "         [1.0010],\n",
      "         [1.0005],\n",
      "         [0.6837],\n",
      "         [1.0041],\n",
      "         [0.0596],\n",
      "         [0.4495],\n",
      "         [0.5112],\n",
      "         [0.2672],\n",
      "         [1.0024],\n",
      "         [0.8513],\n",
      "         [0.5587],\n",
      "         [0.2539],\n",
      "         [0.4492],\n",
      "         [0.9997],\n",
      "         [0.9976],\n",
      "         [0.6562],\n",
      "         [0.9998],\n",
      "         [0.9800],\n",
      "         [0.3809],\n",
      "         [0.9875],\n",
      "         [0.9986],\n",
      "         [1.0004],\n",
      "         [0.3756],\n",
      "         [0.5237],\n",
      "         [1.0006],\n",
      "         [0.8205],\n",
      "         [0.3693],\n",
      "         [0.4699],\n",
      "         [1.0018],\n",
      "         [0.7866],\n",
      "         [0.9974],\n",
      "         [0.0507],\n",
      "         [0.8992],\n",
      "         [0.5117],\n",
      "         [0.9923],\n",
      "         [0.9918],\n",
      "         [0.9162],\n",
      "         [0.9941],\n",
      "         [0.5013],\n",
      "         [0.5004],\n",
      "         [0.9963],\n",
      "         [0.9817],\n",
      "         [0.9938],\n",
      "         [0.9959],\n",
      "         [0.7671],\n",
      "         [0.9957],\n",
      "         [0.9929],\n",
      "         [0.9836],\n",
      "         [0.9963],\n",
      "         [0.3752],\n",
      "         [0.4627],\n",
      "         [1.0011],\n",
      "         [1.0016],\n",
      "         [1.0020],\n",
      "         [1.0019],\n",
      "         [0.4473],\n",
      "         [0.2078],\n",
      "         [0.9994],\n",
      "         [0.9967],\n",
      "         [0.0392],\n",
      "         [0.9336],\n",
      "         [0.2521],\n",
      "         [0.9961],\n",
      "         [0.0259],\n",
      "         [0.1611],\n",
      "         [0.9975],\n",
      "         [0.9983],\n",
      "         [0.9997],\n",
      "         [1.0007],\n",
      "         [1.0007],\n",
      "         [0.9998],\n",
      "         [0.4589],\n",
      "         [0.4627],\n",
      "         [0.3648]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.5945],\n",
      "        [0.0174],\n",
      "        [0.0209],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.4988],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.5245],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.5334],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9959],\n",
      "        [0.5108],\n",
      "        [0.6628],\n",
      "        [0.3780],\n",
      "        [0.9997],\n",
      "        [0.4580],\n",
      "        [0.5080],\n",
      "        [0.9997],\n",
      "        [0.4503],\n",
      "        [0.7129],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.2610],\n",
      "        [0.9520],\n",
      "        [0.9998],\n",
      "        [0.0247],\n",
      "        [0.9490],\n",
      "        [0.9999],\n",
      "        [0.9515],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.8379],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3573],\n",
      "        [0.9994],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.6920],\n",
      "        [0.9804],\n",
      "        [0.9994],\n",
      "        [0.5038],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.4454],\n",
      "        [0.5009],\n",
      "        [0.2735],\n",
      "        [0.9999],\n",
      "        [0.8139],\n",
      "        [0.5463],\n",
      "        [0.2686],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.3912],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.3753],\n",
      "        [0.4668],\n",
      "        [0.9998],\n",
      "        [0.7540],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.8761],\n",
      "        [0.5151],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.5030],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.9820],\n",
      "        [0.9999],\n",
      "        [0.3875],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.9164],\n",
      "        [0.2729],\n",
      "        [0.9998],\n",
      "        [0.0142],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.4642],\n",
      "        [0.3747]])\n",
      "######### Epoch: 90  ######### Train Loss: 0.00013301888247951865  ######### Relative L2 Test Norm: 13.808769226074219\n",
      "Output batch pred: tensor([[[0.9967],\n",
      "         [0.9977],\n",
      "         [0.9235],\n",
      "         [0.9991],\n",
      "         [0.4647],\n",
      "         [0.9967],\n",
      "         [0.9995],\n",
      "         [0.2468],\n",
      "         [0.9982],\n",
      "         [0.9989],\n",
      "         [0.9990],\n",
      "         [0.9937],\n",
      "         [0.6888],\n",
      "         [0.7424],\n",
      "         [0.9975],\n",
      "         [0.3578],\n",
      "         [0.9964],\n",
      "         [0.9953],\n",
      "         [0.9955],\n",
      "         [0.5045],\n",
      "         [0.9974],\n",
      "         [0.9357],\n",
      "         [0.9979],\n",
      "         [0.9993],\n",
      "         [1.0004],\n",
      "         [0.0480],\n",
      "         [1.0004],\n",
      "         [0.9245],\n",
      "         [0.3439],\n",
      "         [0.4623],\n",
      "         [0.5096],\n",
      "         [0.3633],\n",
      "         [0.9987],\n",
      "         [1.0001],\n",
      "         [0.9994],\n",
      "         [0.3652],\n",
      "         [0.5348],\n",
      "         [0.0525],\n",
      "         [0.3841],\n",
      "         [0.5232],\n",
      "         [1.0017],\n",
      "         [0.4639],\n",
      "         [0.4461],\n",
      "         [0.9976],\n",
      "         [0.3415],\n",
      "         [0.9976],\n",
      "         [0.9968],\n",
      "         [0.9950],\n",
      "         [0.9955],\n",
      "         [0.9934],\n",
      "         [0.9938],\n",
      "         [0.4471],\n",
      "         [0.9951],\n",
      "         [0.0345],\n",
      "         [0.9962],\n",
      "         [0.9950],\n",
      "         [0.3729],\n",
      "         [0.6750],\n",
      "         [0.9977],\n",
      "         [0.5399],\n",
      "         [0.5011],\n",
      "         [0.9964],\n",
      "         [0.4552],\n",
      "         [0.2573],\n",
      "         [0.9947],\n",
      "         [0.6089],\n",
      "         [0.5033],\n",
      "         [0.9934],\n",
      "         [0.3690],\n",
      "         [0.9852],\n",
      "         [0.4412],\n",
      "         [0.9981],\n",
      "         [0.9995],\n",
      "         [0.3734],\n",
      "         [0.9982],\n",
      "         [0.9996],\n",
      "         [0.9853],\n",
      "         [0.9983],\n",
      "         [0.9971],\n",
      "         [0.9763],\n",
      "         [0.9949],\n",
      "         [0.8496],\n",
      "         [0.0314],\n",
      "         [0.4935],\n",
      "         [0.9961],\n",
      "         [0.0210],\n",
      "         [0.5209],\n",
      "         [0.9987],\n",
      "         [0.9997],\n",
      "         [0.9996],\n",
      "         [0.4584],\n",
      "         [0.5247],\n",
      "         [1.0014],\n",
      "         [0.2413],\n",
      "         [1.0036],\n",
      "         [1.0025],\n",
      "         [1.0025],\n",
      "         [1.0025],\n",
      "         [0.1680],\n",
      "         [0.9638],\n",
      "         [0.9984],\n",
      "         [0.2047],\n",
      "         [0.2350],\n",
      "         [0.5489],\n",
      "         [0.9954],\n",
      "         [0.9951],\n",
      "         [0.5049],\n",
      "         [0.9943],\n",
      "         [0.9944],\n",
      "         [0.9946],\n",
      "         [0.9951],\n",
      "         [0.9951],\n",
      "         [0.9955],\n",
      "         [0.7825],\n",
      "         [0.9952],\n",
      "         [0.0364],\n",
      "         [0.9966],\n",
      "         [0.6546],\n",
      "         [0.9976],\n",
      "         [0.9944],\n",
      "         [0.9019],\n",
      "         [0.9936],\n",
      "         [0.0397],\n",
      "         [0.9956],\n",
      "         [0.9953],\n",
      "         [0.2495],\n",
      "         [0.9947],\n",
      "         [0.9928],\n",
      "         [0.8624],\n",
      "         [0.9960],\n",
      "         [0.9969],\n",
      "         [0.9972],\n",
      "         [0.9976],\n",
      "         [0.2549],\n",
      "         [0.9965],\n",
      "         [0.9959],\n",
      "         [0.9936],\n",
      "         [0.9965],\n",
      "         [0.4990],\n",
      "         [0.9948],\n",
      "         [0.8593],\n",
      "         [0.9619],\n",
      "         [0.9990],\n",
      "         [0.9999],\n",
      "         [1.0013],\n",
      "         [0.3732],\n",
      "         [1.0005],\n",
      "         [0.7762],\n",
      "         [0.0501],\n",
      "         [0.9185],\n",
      "         [0.9973],\n",
      "         [0.9953],\n",
      "         [0.9942],\n",
      "         [0.2421],\n",
      "         [0.0419],\n",
      "         [0.9953],\n",
      "         [0.9546],\n",
      "         [0.9972],\n",
      "         [0.2405],\n",
      "         [0.8519],\n",
      "         [1.0026],\n",
      "         [1.0049],\n",
      "         [0.9920],\n",
      "         [0.4604],\n",
      "         [1.0050],\n",
      "         [0.9926],\n",
      "         [0.3900],\n",
      "         [1.0009],\n",
      "         [0.9998],\n",
      "         [0.9983],\n",
      "         [0.9953],\n",
      "         [0.4386],\n",
      "         [0.9940],\n",
      "         [0.8094],\n",
      "         [0.9933],\n",
      "         [0.9922],\n",
      "         [0.9579],\n",
      "         [0.7157]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9996],\n",
      "        [0.9998],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2610],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9997],\n",
      "        [0.9956],\n",
      "        [0.6628],\n",
      "        [0.7129],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [0.9997],\n",
      "        [0.9164],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.3573],\n",
      "        [0.4642],\n",
      "        [0.5080],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.5245],\n",
      "        [0.0335],\n",
      "        [0.3912],\n",
      "        [0.5151],\n",
      "        [0.9999],\n",
      "        [0.4645],\n",
      "        [0.4503],\n",
      "        [0.9967],\n",
      "        [0.3575],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.3875],\n",
      "        [0.6555],\n",
      "        [0.9999],\n",
      "        [0.5334],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.2729],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [0.9819],\n",
      "        [0.4454],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.0209],\n",
      "        [0.4988],\n",
      "        [0.9994],\n",
      "        [0.0000],\n",
      "        [0.5165],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9966],\n",
      "        [0.4552],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [0.2518],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.2208],\n",
      "        [0.2547],\n",
      "        [0.5463],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.8761],\n",
      "        [0.9959],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8379],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [0.9998],\n",
      "        [0.8296],\n",
      "        [0.9520],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.9999],\n",
      "        [0.7391],\n",
      "        [0.0288],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [0.2646],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.8139],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9814],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.6920]])\n",
      "######### Epoch: 91  ######### Train Loss: 0.0001234450173797086  ######### Relative L2 Test Norm: 13.863251686096191\n",
      "Output batch pred: tensor([[[0.6859],\n",
      "         [0.9205],\n",
      "         [0.9971],\n",
      "         [0.9975],\n",
      "         [0.0424],\n",
      "         [0.9980],\n",
      "         [1.0009],\n",
      "         [0.4614],\n",
      "         [0.9826],\n",
      "         [1.0028],\n",
      "         [0.7905],\n",
      "         [1.0013],\n",
      "         [1.0018],\n",
      "         [1.0008],\n",
      "         [0.2055],\n",
      "         [0.0381],\n",
      "         [0.2510],\n",
      "         [0.5108],\n",
      "         [0.0137],\n",
      "         [0.9922],\n",
      "         [0.9937],\n",
      "         [0.5066],\n",
      "         [0.9931],\n",
      "         [0.9958],\n",
      "         [0.9982],\n",
      "         [0.8491],\n",
      "         [0.9898],\n",
      "         [0.4667],\n",
      "         [0.3680],\n",
      "         [1.0009],\n",
      "         [0.5006],\n",
      "         [0.9970],\n",
      "         [0.2497],\n",
      "         [0.4570],\n",
      "         [0.4490],\n",
      "         [0.9962],\n",
      "         [0.9973],\n",
      "         [0.4441],\n",
      "         [0.9986],\n",
      "         [0.9988],\n",
      "         [0.9971],\n",
      "         [0.9832],\n",
      "         [0.9974],\n",
      "         [0.9831],\n",
      "         [0.5388],\n",
      "         [0.9962],\n",
      "         [0.9954],\n",
      "         [0.9966],\n",
      "         [0.3601],\n",
      "         [0.9995],\n",
      "         [0.3757],\n",
      "         [0.7720],\n",
      "         [0.9997],\n",
      "         [0.8156],\n",
      "         [0.0332],\n",
      "         [0.9932],\n",
      "         [0.2292],\n",
      "         [0.4316],\n",
      "         [0.9928],\n",
      "         [0.9928],\n",
      "         [0.9955],\n",
      "         [0.4413],\n",
      "         [1.0003],\n",
      "         [0.3729],\n",
      "         [1.0021],\n",
      "         [1.0023],\n",
      "         [1.0025],\n",
      "         [0.0527],\n",
      "         [0.9982],\n",
      "         [0.4936],\n",
      "         [0.4987],\n",
      "         [0.9922],\n",
      "         [0.9928],\n",
      "         [0.9920],\n",
      "         [0.0383],\n",
      "         [0.6090],\n",
      "         [0.5535],\n",
      "         [0.9975],\n",
      "         [0.4679],\n",
      "         [0.0357],\n",
      "         [1.0004],\n",
      "         [1.0002],\n",
      "         [0.9985],\n",
      "         [0.9974],\n",
      "         [0.9982],\n",
      "         [0.9554],\n",
      "         [0.3768],\n",
      "         [0.9585],\n",
      "         [0.9949],\n",
      "         [0.1636],\n",
      "         [0.2453],\n",
      "         [0.9923],\n",
      "         [0.0498],\n",
      "         [0.9936],\n",
      "         [0.9955],\n",
      "         [0.9247],\n",
      "         [1.0006],\n",
      "         [1.0011],\n",
      "         [1.0034],\n",
      "         [1.0027],\n",
      "         [1.0031],\n",
      "         [0.9660],\n",
      "         [0.9984],\n",
      "         [0.9961],\n",
      "         [0.2419],\n",
      "         [0.9919],\n",
      "         [0.9892],\n",
      "         [0.9899],\n",
      "         [0.9925],\n",
      "         [0.6485],\n",
      "         [0.9960],\n",
      "         [0.9962],\n",
      "         [0.5363],\n",
      "         [1.0024],\n",
      "         [1.0028],\n",
      "         [1.0022],\n",
      "         [0.9980],\n",
      "         [0.8604],\n",
      "         [0.9951],\n",
      "         [0.0364],\n",
      "         [0.3762],\n",
      "         [0.9916],\n",
      "         [0.9936],\n",
      "         [0.8491],\n",
      "         [0.9925],\n",
      "         [0.9158],\n",
      "         [0.3718],\n",
      "         [0.2433],\n",
      "         [0.9997],\n",
      "         [1.0001],\n",
      "         [0.5077],\n",
      "         [0.2416],\n",
      "         [1.0001],\n",
      "         [0.7469],\n",
      "         [0.9993],\n",
      "         [1.0008],\n",
      "         [0.9973],\n",
      "         [1.0008],\n",
      "         [0.9872],\n",
      "         [0.9990],\n",
      "         [0.3461],\n",
      "         [0.9992],\n",
      "         [0.3688],\n",
      "         [0.5220],\n",
      "         [0.8674],\n",
      "         [0.9988],\n",
      "         [0.9993],\n",
      "         [0.6810],\n",
      "         [0.9995],\n",
      "         [0.9637],\n",
      "         [0.9990],\n",
      "         [0.9978],\n",
      "         [0.7232],\n",
      "         [0.3450],\n",
      "         [0.9981],\n",
      "         [0.9985],\n",
      "         [0.5160],\n",
      "         [0.9943],\n",
      "         [0.9973],\n",
      "         [0.5081],\n",
      "         [0.3585],\n",
      "         [0.9947],\n",
      "         [0.9960],\n",
      "         [0.2540],\n",
      "         [0.9961],\n",
      "         [0.4480],\n",
      "         [0.9923],\n",
      "         [0.9979],\n",
      "         [0.9992],\n",
      "         [0.5058],\n",
      "         [0.4495],\n",
      "         [1.0005],\n",
      "         [0.9380],\n",
      "         [0.9997],\n",
      "         [0.9992],\n",
      "         [0.9984],\n",
      "         [0.9019],\n",
      "         [0.9950]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.6628],\n",
      "        [0.9009],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.0335],\n",
      "        [0.9967],\n",
      "        [0.9997],\n",
      "        [0.4611],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.0247],\n",
      "        [0.2735],\n",
      "        [0.5151],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.9819],\n",
      "        [0.4645],\n",
      "        [0.3753],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [0.9996],\n",
      "        [0.2686],\n",
      "        [0.4642],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.5334],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.3747],\n",
      "        [0.9999],\n",
      "        [0.3875],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [0.7820],\n",
      "        [0.0174],\n",
      "        [0.9966],\n",
      "        [0.2518],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.5945],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9420],\n",
      "        [0.3912],\n",
      "        [0.9520],\n",
      "        [0.9998],\n",
      "        [0.1762],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.2610],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.6327],\n",
      "        [0.9994],\n",
      "        [0.9959],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.3840],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5030],\n",
      "        [0.2547],\n",
      "        [0.9999],\n",
      "        [0.7129],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.5165],\n",
      "        [0.8379],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.9999],\n",
      "        [0.9490],\n",
      "        [0.9995],\n",
      "        [0.9999],\n",
      "        [0.6920],\n",
      "        [0.3575],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.5139],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.4527],\n",
      "        [0.9997],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.8761],\n",
      "        [0.9998]])\n",
      "######### Epoch: 92  ######### Train Loss: 0.00013214413775131106  ######### Relative L2 Test Norm: 14.151371955871582\n",
      "Output batch pred: tensor([[[0.9960],\n",
      "         [0.2386],\n",
      "         [0.9811],\n",
      "         [0.9958],\n",
      "         [0.9962],\n",
      "         [0.9971],\n",
      "         [0.0349],\n",
      "         [0.4484],\n",
      "         [0.9978],\n",
      "         [0.6764],\n",
      "         [0.9978],\n",
      "         [0.9978],\n",
      "         [0.4365],\n",
      "         [0.3618],\n",
      "         [0.9960],\n",
      "         [0.4382],\n",
      "         [0.0432],\n",
      "         [0.9921],\n",
      "         [0.9740],\n",
      "         [0.0368],\n",
      "         [0.5488],\n",
      "         [0.0385],\n",
      "         [0.9948],\n",
      "         [0.9957],\n",
      "         [0.7821],\n",
      "         [0.9969],\n",
      "         [0.9972],\n",
      "         [0.9964],\n",
      "         [0.9981],\n",
      "         [0.9987],\n",
      "         [0.9623],\n",
      "         [0.3639],\n",
      "         [0.4995],\n",
      "         [0.2505],\n",
      "         [0.0352],\n",
      "         [0.9998],\n",
      "         [0.9994],\n",
      "         [0.9979],\n",
      "         [0.2013],\n",
      "         [0.9974],\n",
      "         [0.9968],\n",
      "         [0.2299],\n",
      "         [0.5080],\n",
      "         [0.4570],\n",
      "         [0.9912],\n",
      "         [0.9935],\n",
      "         [0.3749],\n",
      "         [0.7375],\n",
      "         [0.5130],\n",
      "         [0.7160],\n",
      "         [0.9935],\n",
      "         [0.9941],\n",
      "         [0.9963],\n",
      "         [0.2531],\n",
      "         [0.9973],\n",
      "         [0.9975],\n",
      "         [0.7688],\n",
      "         [0.0497],\n",
      "         [0.9945],\n",
      "         [0.9953],\n",
      "         [0.4955],\n",
      "         [0.3547],\n",
      "         [0.4556],\n",
      "         [0.9960],\n",
      "         [0.9958],\n",
      "         [0.3718],\n",
      "         [0.9655],\n",
      "         [1.0025],\n",
      "         [1.0023],\n",
      "         [0.9431],\n",
      "         [1.0014],\n",
      "         [1.0019],\n",
      "         [0.9994],\n",
      "         [0.9968],\n",
      "         [0.3396],\n",
      "         [0.9933],\n",
      "         [0.9918],\n",
      "         [0.9933],\n",
      "         [0.9919],\n",
      "         [0.9961],\n",
      "         [0.9944],\n",
      "         [0.9043],\n",
      "         [0.0500],\n",
      "         [1.0013],\n",
      "         [0.8631],\n",
      "         [1.0000],\n",
      "         [0.9983],\n",
      "         [0.9976],\n",
      "         [0.5415],\n",
      "         [0.3665],\n",
      "         [0.3404],\n",
      "         [0.2414],\n",
      "         [0.9963],\n",
      "         [0.9958],\n",
      "         [0.8448],\n",
      "         [0.9962],\n",
      "         [0.9970],\n",
      "         [0.9960],\n",
      "         [0.4460],\n",
      "         [0.9953],\n",
      "         [0.9843],\n",
      "         [0.9965],\n",
      "         [0.9962],\n",
      "         [0.9144],\n",
      "         [0.9958],\n",
      "         [0.9944],\n",
      "         [0.4512],\n",
      "         [0.0192],\n",
      "         [0.9927],\n",
      "         [0.9916],\n",
      "         [0.5227],\n",
      "         [0.4341],\n",
      "         [0.9952],\n",
      "         [0.6875],\n",
      "         [0.9978],\n",
      "         [0.9946],\n",
      "         [0.5148],\n",
      "         [0.8585],\n",
      "         [0.9995],\n",
      "         [0.9985],\n",
      "         [0.2594],\n",
      "         [0.6542],\n",
      "         [0.9939],\n",
      "         [0.9951],\n",
      "         [0.9947],\n",
      "         [0.9947],\n",
      "         [0.4502],\n",
      "         [0.2505],\n",
      "         [0.9951],\n",
      "         [0.9954],\n",
      "         [0.9244],\n",
      "         [0.9986],\n",
      "         [0.0499],\n",
      "         [0.9972],\n",
      "         [0.9238],\n",
      "         [0.9975],\n",
      "         [0.9962],\n",
      "         [0.8645],\n",
      "         [0.4618],\n",
      "         [0.9563],\n",
      "         [0.1657],\n",
      "         [0.9983],\n",
      "         [0.9870],\n",
      "         [0.9984],\n",
      "         [0.9996],\n",
      "         [0.5222],\n",
      "         [0.9633],\n",
      "         [0.9979],\n",
      "         [0.5027],\n",
      "         [0.5044],\n",
      "         [0.9962],\n",
      "         [0.9979],\n",
      "         [0.9966],\n",
      "         [0.9988],\n",
      "         [0.9987],\n",
      "         [0.2360],\n",
      "         [0.9999],\n",
      "         [0.9868],\n",
      "         [1.0001],\n",
      "         [1.0011],\n",
      "         [1.0009],\n",
      "         [1.0019],\n",
      "         [0.8205],\n",
      "         [1.0013],\n",
      "         [1.0023],\n",
      "         [0.6165],\n",
      "         [0.5086],\n",
      "         [1.0026],\n",
      "         [1.0005],\n",
      "         [0.3645],\n",
      "         [0.3776],\n",
      "         [0.5182],\n",
      "         [0.9986],\n",
      "         [1.0002],\n",
      "         [1.0002],\n",
      "         [0.3833],\n",
      "         [0.9961],\n",
      "         [0.9986]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[1.0000],\n",
      "        [0.2577],\n",
      "        [0.9814],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.4552],\n",
      "        [0.9994],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4454],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.4503],\n",
      "        [0.0288],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [0.0209],\n",
      "        [0.5463],\n",
      "        [0.0247],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9490],\n",
      "        [0.3747],\n",
      "        [0.4988],\n",
      "        [0.2646],\n",
      "        [0.0142],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.2208],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.2518],\n",
      "        [0.5108],\n",
      "        [0.4642],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [0.7129],\n",
      "        [0.5151],\n",
      "        [0.6920],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.0335],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.5009],\n",
      "        [0.3728],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.3840],\n",
      "        [0.9520],\n",
      "        [0.9995],\n",
      "        [0.9998],\n",
      "        [0.9164],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.5334],\n",
      "        [0.3808],\n",
      "        [0.3573],\n",
      "        [0.2610],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9997],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.9999],\n",
      "        [0.9956],\n",
      "        [0.5080],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.6327],\n",
      "        [0.9966],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.8379],\n",
      "        [0.4668],\n",
      "        [0.9420],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.9515],\n",
      "        [0.9997],\n",
      "        [0.5030],\n",
      "        [0.5054],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.9999],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.5945],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.3875],\n",
      "        [0.5139],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [1.0000],\n",
      "        [0.9998]])\n",
      "######### Epoch: 93  ######### Train Loss: 0.00013594070333056152  ######### Relative L2 Test Norm: 14.035595893859863\n",
      "Output batch pred: tensor([[[0.9965],\n",
      "         [0.6545],\n",
      "         [0.4596],\n",
      "         [1.0021],\n",
      "         [0.9911],\n",
      "         [0.0319],\n",
      "         [1.0048],\n",
      "         [1.0045],\n",
      "         [0.5489],\n",
      "         [0.5235],\n",
      "         [1.0000],\n",
      "         [0.9995],\n",
      "         [0.9854],\n",
      "         [0.9978],\n",
      "         [0.9964],\n",
      "         [0.2513],\n",
      "         [0.8137],\n",
      "         [0.4446],\n",
      "         [0.9988],\n",
      "         [0.9643],\n",
      "         [0.9984],\n",
      "         [0.7239],\n",
      "         [0.9192],\n",
      "         [0.0410],\n",
      "         [0.9936],\n",
      "         [0.9954],\n",
      "         [0.9939],\n",
      "         [0.8981],\n",
      "         [0.9943],\n",
      "         [0.3688],\n",
      "         [0.3562],\n",
      "         [0.9939],\n",
      "         [0.9794],\n",
      "         [0.0342],\n",
      "         [0.9590],\n",
      "         [0.9964],\n",
      "         [0.7817],\n",
      "         [0.9963],\n",
      "         [0.9961],\n",
      "         [0.9962],\n",
      "         [0.9960],\n",
      "         [0.8418],\n",
      "         [0.3573],\n",
      "         [0.9946],\n",
      "         [0.9955],\n",
      "         [0.9943],\n",
      "         [0.5280],\n",
      "         [0.4612],\n",
      "         [0.2444],\n",
      "         [0.5516],\n",
      "         [0.5022],\n",
      "         [0.9968],\n",
      "         [0.3418],\n",
      "         [0.9963],\n",
      "         [0.9979],\n",
      "         [0.9619],\n",
      "         [0.3722],\n",
      "         [0.9993],\n",
      "         [0.4627],\n",
      "         [0.3831],\n",
      "         [0.4989],\n",
      "         [0.9980],\n",
      "         [0.0489],\n",
      "         [0.9959],\n",
      "         [0.6101],\n",
      "         [0.9963],\n",
      "         [0.5116],\n",
      "         [0.5008],\n",
      "         [0.9962],\n",
      "         [0.2369],\n",
      "         [0.6814],\n",
      "         [1.0004],\n",
      "         [0.7748],\n",
      "         [1.0009],\n",
      "         [0.4549],\n",
      "         [0.8577],\n",
      "         [1.0001],\n",
      "         [0.9995],\n",
      "         [0.9241],\n",
      "         [0.1623],\n",
      "         [0.9960],\n",
      "         [0.9960],\n",
      "         [0.9948],\n",
      "         [0.9942],\n",
      "         [0.3620],\n",
      "         [0.9922],\n",
      "         [0.4349],\n",
      "         [0.9940],\n",
      "         [0.3593],\n",
      "         [0.9960],\n",
      "         [0.9961],\n",
      "         [0.9219],\n",
      "         [0.9982],\n",
      "         [0.9975],\n",
      "         [0.9969],\n",
      "         [0.9970],\n",
      "         [0.9974],\n",
      "         [0.4615],\n",
      "         [0.9974],\n",
      "         [0.5051],\n",
      "         [0.9972],\n",
      "         [0.9969],\n",
      "         [0.9971],\n",
      "         [0.9992],\n",
      "         [0.9997],\n",
      "         [0.9978],\n",
      "         [0.9994],\n",
      "         [0.5065],\n",
      "         [0.9981],\n",
      "         [0.9938],\n",
      "         [0.9943],\n",
      "         [0.9933],\n",
      "         [0.2428],\n",
      "         [0.9906],\n",
      "         [0.9930],\n",
      "         [0.9928],\n",
      "         [0.4417],\n",
      "         [0.3598],\n",
      "         [0.0255],\n",
      "         [0.9985],\n",
      "         [0.5229],\n",
      "         [1.0010],\n",
      "         [1.0018],\n",
      "         [0.5177],\n",
      "         [0.2141],\n",
      "         [1.0018],\n",
      "         [0.9992],\n",
      "         [0.0552],\n",
      "         [0.0466],\n",
      "         [0.9362],\n",
      "         [0.9979],\n",
      "         [0.9975],\n",
      "         [0.3440],\n",
      "         [0.9940],\n",
      "         [0.9955],\n",
      "         [0.0444],\n",
      "         [0.9964],\n",
      "         [0.8634],\n",
      "         [0.9959],\n",
      "         [0.9950],\n",
      "         [0.9940],\n",
      "         [0.4457],\n",
      "         [0.9928],\n",
      "         [0.9912],\n",
      "         [0.9917],\n",
      "         [0.4305],\n",
      "         [0.9921],\n",
      "         [0.9910],\n",
      "         [0.9930],\n",
      "         [0.9752],\n",
      "         [0.2539],\n",
      "         [0.9947],\n",
      "         [0.7413],\n",
      "         [0.6872],\n",
      "         [0.9925],\n",
      "         [0.9942],\n",
      "         [0.2469],\n",
      "         [0.9922],\n",
      "         [0.9930],\n",
      "         [0.9930],\n",
      "         [0.9932],\n",
      "         [0.9933],\n",
      "         [0.9957],\n",
      "         [0.2404],\n",
      "         [0.9857],\n",
      "         [0.0397],\n",
      "         [1.0002],\n",
      "         [1.0006],\n",
      "         [0.9974],\n",
      "         [0.5212],\n",
      "         [0.9983],\n",
      "         [0.9969],\n",
      "         [0.8567],\n",
      "         [0.3751],\n",
      "         [0.9520],\n",
      "         [0.9932],\n",
      "         [0.2346],\n",
      "         [0.9951]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9994],\n",
      "        [0.6327],\n",
      "        [0.4611],\n",
      "        [0.9998],\n",
      "        [0.9819],\n",
      "        [0.0142],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [0.5151],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.2729],\n",
      "        [0.7820],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9997],\n",
      "        [0.6920],\n",
      "        [0.8933],\n",
      "        [0.0247],\n",
      "        [0.9956],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.8761],\n",
      "        [0.9999],\n",
      "        [0.3875],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [0.0174],\n",
      "        [0.9520],\n",
      "        [0.9998],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.4668],\n",
      "        [0.2610],\n",
      "        [0.5463],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9490],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [0.4642],\n",
      "        [0.3930],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [0.0335],\n",
      "        [0.9999],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.2518],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.9997],\n",
      "        [0.4552],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.1762],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.9999],\n",
      "        [0.5038],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.4503],\n",
      "        [0.3728],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.2208],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.0288],\n",
      "        [0.9164],\n",
      "        [0.9997],\n",
      "        [0.9996],\n",
      "        [0.3575],\n",
      "        [0.9962],\n",
      "        [0.9999],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [0.4580],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.4454],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [0.9724],\n",
      "        [0.2735],\n",
      "        [0.9999],\n",
      "        [0.7129],\n",
      "        [0.6628],\n",
      "        [0.9959],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.2577],\n",
      "        [0.9820],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.3912],\n",
      "        [0.9420],\n",
      "        [0.9996],\n",
      "        [0.2547],\n",
      "        [0.9997]])\n",
      "######### Epoch: 94  ######### Train Loss: 0.0001416653540218249  ######### Relative L2 Test Norm: 14.343123435974121\n",
      "Output batch pred: tensor([[[0.9180],\n",
      "         [0.9935],\n",
      "         [0.9916],\n",
      "         [0.5325],\n",
      "         [0.9804],\n",
      "         [0.9910],\n",
      "         [0.6067],\n",
      "         [0.9940],\n",
      "         [0.0501],\n",
      "         [0.9974],\n",
      "         [0.3777],\n",
      "         [0.9594],\n",
      "         [0.0410],\n",
      "         [0.5006],\n",
      "         [0.9926],\n",
      "         [0.4921],\n",
      "         [0.9939],\n",
      "         [0.9942],\n",
      "         [0.9960],\n",
      "         [0.9858],\n",
      "         [0.9956],\n",
      "         [0.2627],\n",
      "         [0.5117],\n",
      "         [1.0010],\n",
      "         [0.9994],\n",
      "         [0.5202],\n",
      "         [0.7679],\n",
      "         [0.9941],\n",
      "         [0.4517],\n",
      "         [0.4392],\n",
      "         [0.9575],\n",
      "         [0.9927],\n",
      "         [0.9950],\n",
      "         [0.9945],\n",
      "         [0.9959],\n",
      "         [0.9939],\n",
      "         [0.9950],\n",
      "         [0.9943],\n",
      "         [0.8415],\n",
      "         [0.9524],\n",
      "         [0.9952],\n",
      "         [0.4622],\n",
      "         [0.4990],\n",
      "         [0.9958],\n",
      "         [0.4584],\n",
      "         [0.3712],\n",
      "         [1.0005],\n",
      "         [0.9997],\n",
      "         [0.9987],\n",
      "         [0.9971],\n",
      "         [0.9024],\n",
      "         [0.9962],\n",
      "         [0.9961],\n",
      "         [0.9981],\n",
      "         [1.0006],\n",
      "         [0.9673],\n",
      "         [1.0018],\n",
      "         [1.0017],\n",
      "         [1.0021],\n",
      "         [0.9816],\n",
      "         [0.9970],\n",
      "         [0.9966],\n",
      "         [0.9934],\n",
      "         [0.9922],\n",
      "         [0.9894],\n",
      "         [0.2291],\n",
      "         [0.9911],\n",
      "         [0.9922],\n",
      "         [0.4464],\n",
      "         [0.5519],\n",
      "         [0.9943],\n",
      "         [0.9944],\n",
      "         [0.0408],\n",
      "         [0.8590],\n",
      "         [0.9965],\n",
      "         [0.9972],\n",
      "         [0.9976],\n",
      "         [0.9976],\n",
      "         [0.5199],\n",
      "         [0.5181],\n",
      "         [0.5347],\n",
      "         [0.9972],\n",
      "         [0.2577],\n",
      "         [0.9830],\n",
      "         [0.9951],\n",
      "         [0.9919],\n",
      "         [0.9184],\n",
      "         [0.9914],\n",
      "         [0.1631],\n",
      "         [0.9927],\n",
      "         [0.9942],\n",
      "         [0.9955],\n",
      "         [0.5097],\n",
      "         [0.9981],\n",
      "         [0.9982],\n",
      "         [0.3649],\n",
      "         [0.9957],\n",
      "         [0.9959],\n",
      "         [0.3577],\n",
      "         [0.9941],\n",
      "         [0.9940],\n",
      "         [0.2453],\n",
      "         [0.8616],\n",
      "         [0.9804],\n",
      "         [0.9938],\n",
      "         [0.4489],\n",
      "         [0.3456],\n",
      "         [0.9994],\n",
      "         [1.0000],\n",
      "         [0.9990],\n",
      "         [1.0004],\n",
      "         [0.8205],\n",
      "         [1.0014],\n",
      "         [1.0014],\n",
      "         [0.0259],\n",
      "         [0.9991],\n",
      "         [0.2576],\n",
      "         [0.9953],\n",
      "         [0.3387],\n",
      "         [0.9898],\n",
      "         [0.7739],\n",
      "         [0.9880],\n",
      "         [0.9915],\n",
      "         [0.9919],\n",
      "         [0.6722],\n",
      "         [0.9342],\n",
      "         [0.9991],\n",
      "         [0.4643],\n",
      "         [1.0007],\n",
      "         [0.4453],\n",
      "         [0.6539],\n",
      "         [0.9968],\n",
      "         [0.9956],\n",
      "         [0.9939],\n",
      "         [0.8458],\n",
      "         [0.0394],\n",
      "         [0.9926],\n",
      "         [0.9941],\n",
      "         [0.7187],\n",
      "         [0.2445],\n",
      "         [0.6930],\n",
      "         [1.0003],\n",
      "         [1.0034],\n",
      "         [1.0030],\n",
      "         [1.0028],\n",
      "         [1.0000],\n",
      "         [1.0017],\n",
      "         [1.0014],\n",
      "         [0.9999],\n",
      "         [0.2030],\n",
      "         [0.0505],\n",
      "         [0.4977],\n",
      "         [0.9937],\n",
      "         [0.5040],\n",
      "         [0.0304],\n",
      "         [0.9904],\n",
      "         [0.2232],\n",
      "         [0.9892],\n",
      "         [0.9922],\n",
      "         [0.9953],\n",
      "         [0.9976],\n",
      "         [0.3712],\n",
      "         [0.3718],\n",
      "         [0.4448],\n",
      "         [1.0013],\n",
      "         [0.4670],\n",
      "         [0.7441],\n",
      "         [0.0464],\n",
      "         [0.0337],\n",
      "         [0.9931],\n",
      "         [0.9939],\n",
      "         [0.9945],\n",
      "         [0.9126],\n",
      "         [0.3752],\n",
      "         [0.3758],\n",
      "         [0.2371],\n",
      "         [0.3617],\n",
      "         [0.9968]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9009],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.5334],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [0.3875],\n",
      "        [0.9490],\n",
      "        [0.0288],\n",
      "        [0.5054],\n",
      "        [0.9999],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9804],\n",
      "        [0.9956],\n",
      "        [0.2729],\n",
      "        [0.5038],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.7391],\n",
      "        [1.0000],\n",
      "        [0.4611],\n",
      "        [0.4503],\n",
      "        [0.9520],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.8139],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.4988],\n",
      "        [0.9962],\n",
      "        [0.4580],\n",
      "        [0.3780],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9999],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.5463],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.0209],\n",
      "        [0.8296],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.5151],\n",
      "        [0.5139],\n",
      "        [0.5245],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9044],\n",
      "        [0.9999],\n",
      "        [0.1762],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3728],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.2646],\n",
      "        [0.8379],\n",
      "        [0.9814],\n",
      "        [0.9967],\n",
      "        [0.4527],\n",
      "        [0.3573],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9999],\n",
      "        [0.9995],\n",
      "        [0.7820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.9966],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.9164],\n",
      "        [0.9996],\n",
      "        [0.4645],\n",
      "        [0.9999],\n",
      "        [0.4480],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.2610],\n",
      "        [0.6628],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9959],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.2208],\n",
      "        [0.0368],\n",
      "        [0.5030],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [0.0174],\n",
      "        [0.9996],\n",
      "        [0.2518],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3840],\n",
      "        [0.3808],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [0.7129],\n",
      "        [0.0247],\n",
      "        [0.0142],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.8933],\n",
      "        [0.3930],\n",
      "        [0.3912],\n",
      "        [0.2547],\n",
      "        [0.3753],\n",
      "        [1.0000]])\n",
      "######### Epoch: 95  ######### Train Loss: 0.00012877261906396598  ######### Relative L2 Test Norm: 14.055331230163574\n",
      "Output batch pred: tensor([[[0.4503],\n",
      "         [0.9944],\n",
      "         [0.3655],\n",
      "         [0.9921],\n",
      "         [0.4580],\n",
      "         [0.3694],\n",
      "         [0.4451],\n",
      "         [0.9950],\n",
      "         [0.9955],\n",
      "         [0.6525],\n",
      "         [0.0496],\n",
      "         [0.9966],\n",
      "         [0.9955],\n",
      "         [0.9936],\n",
      "         [0.1664],\n",
      "         [0.9593],\n",
      "         [0.9965],\n",
      "         [0.8562],\n",
      "         [0.3717],\n",
      "         [0.5145],\n",
      "         [0.9965],\n",
      "         [0.9608],\n",
      "         [0.4414],\n",
      "         [0.9967],\n",
      "         [0.9967],\n",
      "         [0.9340],\n",
      "         [0.9926],\n",
      "         [0.7415],\n",
      "         [0.9762],\n",
      "         [0.0245],\n",
      "         [0.9954],\n",
      "         [0.9935],\n",
      "         [0.9961],\n",
      "         [0.9974],\n",
      "         [0.9989],\n",
      "         [1.0002],\n",
      "         [0.9999],\n",
      "         [0.9988],\n",
      "         [0.2602],\n",
      "         [0.9990],\n",
      "         [0.3665],\n",
      "         [0.6097],\n",
      "         [0.0365],\n",
      "         [0.9935],\n",
      "         [0.3380],\n",
      "         [0.5003],\n",
      "         [0.9777],\n",
      "         [0.4915],\n",
      "         [0.9858],\n",
      "         [0.9915],\n",
      "         [0.9907],\n",
      "         [0.9910],\n",
      "         [0.2393],\n",
      "         [0.2502],\n",
      "         [0.9938],\n",
      "         [0.4935],\n",
      "         [0.9931],\n",
      "         [0.9952],\n",
      "         [0.9924],\n",
      "         [0.9950],\n",
      "         [0.3590],\n",
      "         [0.9962],\n",
      "         [0.9963],\n",
      "         [0.3784],\n",
      "         [0.9959],\n",
      "         [0.9006],\n",
      "         [0.5186],\n",
      "         [0.2458],\n",
      "         [0.9980],\n",
      "         [0.9995],\n",
      "         [1.0007],\n",
      "         [1.0023],\n",
      "         [0.4597],\n",
      "         [1.0043],\n",
      "         [1.0040],\n",
      "         [1.0047],\n",
      "         [0.5630],\n",
      "         [0.4492],\n",
      "         [0.8495],\n",
      "         [0.9982],\n",
      "         [0.9963],\n",
      "         [0.4603],\n",
      "         [0.7655],\n",
      "         [0.9934],\n",
      "         [0.7781],\n",
      "         [0.9920],\n",
      "         [0.6848],\n",
      "         [0.9936],\n",
      "         [0.5114],\n",
      "         [0.9936],\n",
      "         [0.9914],\n",
      "         [0.8080],\n",
      "         [0.0341],\n",
      "         [0.9925],\n",
      "         [0.9928],\n",
      "         [0.9936],\n",
      "         [0.5372],\n",
      "         [0.0466],\n",
      "         [0.9973],\n",
      "         [0.9979],\n",
      "         [0.9976],\n",
      "         [0.9221],\n",
      "         [0.9225],\n",
      "         [0.9949],\n",
      "         [0.2351],\n",
      "         [0.9923],\n",
      "         [0.9936],\n",
      "         [0.9939],\n",
      "         [0.9939],\n",
      "         [0.9929],\n",
      "         [0.9935],\n",
      "         [0.9965],\n",
      "         [0.9975],\n",
      "         [0.9976],\n",
      "         [0.9957],\n",
      "         [0.2080],\n",
      "         [0.9962],\n",
      "         [0.9940],\n",
      "         [0.0399],\n",
      "         [0.9919],\n",
      "         [0.5003],\n",
      "         [0.9813],\n",
      "         [0.2435],\n",
      "         [0.9962],\n",
      "         [0.7218],\n",
      "         [0.4403],\n",
      "         [0.4631],\n",
      "         [0.9972],\n",
      "         [0.9982],\n",
      "         [0.9970],\n",
      "         [0.2596],\n",
      "         [0.5310],\n",
      "         [0.9959],\n",
      "         [0.9950],\n",
      "         [0.9131],\n",
      "         [0.0421],\n",
      "         [0.8494],\n",
      "         [0.0472],\n",
      "         [0.3577],\n",
      "         [0.9943],\n",
      "         [0.9943],\n",
      "         [0.8615],\n",
      "         [0.9932],\n",
      "         [0.9961],\n",
      "         [0.9949],\n",
      "         [0.6758],\n",
      "         [0.5051],\n",
      "         [0.9606],\n",
      "         [0.9961],\n",
      "         [0.9962],\n",
      "         [0.9971],\n",
      "         [0.9962],\n",
      "         [0.9968],\n",
      "         [0.4532],\n",
      "         [0.3772],\n",
      "         [0.9546],\n",
      "         [0.5080],\n",
      "         [0.9967],\n",
      "         [0.9972],\n",
      "         [0.9988],\n",
      "         [0.9993],\n",
      "         [0.9984],\n",
      "         [0.9998],\n",
      "         [0.9993],\n",
      "         [0.9980],\n",
      "         [0.9987],\n",
      "         [0.3463],\n",
      "         [0.3618],\n",
      "         [0.9956],\n",
      "         [0.9830],\n",
      "         [0.2373],\n",
      "         [0.9976],\n",
      "         [0.9962],\n",
      "         [0.9977],\n",
      "         [0.9849],\n",
      "         [0.5018],\n",
      "         [0.9964],\n",
      "         [0.0253]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.4580],\n",
      "        [0.9997],\n",
      "        [0.3808],\n",
      "        [0.9966],\n",
      "        [0.4642],\n",
      "        [0.3840],\n",
      "        [0.4527],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6327],\n",
      "        [0.0335],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [0.1762],\n",
      "        [0.9520],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.3875],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.9515],\n",
      "        [0.4503],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9164],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.9724],\n",
      "        [0.0142],\n",
      "        [0.9994],\n",
      "        [0.9959],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.2729],\n",
      "        [0.9998],\n",
      "        [0.3780],\n",
      "        [0.5945],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.3575],\n",
      "        [0.5080],\n",
      "        [0.9820],\n",
      "        [0.5009],\n",
      "        [0.9956],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3753],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.5165],\n",
      "        [0.2610],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [0.9997],\n",
      "        [0.5463],\n",
      "        [0.4480],\n",
      "        [0.8139],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.4668],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [0.6628],\n",
      "        [0.9998],\n",
      "        [0.5139],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.5334],\n",
      "        [0.0368],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.9044],\n",
      "        [0.9996],\n",
      "        [0.2518],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.2208],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.9804],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [0.6920],\n",
      "        [0.4454],\n",
      "        [0.4645],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.2735],\n",
      "        [0.5245],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.8933],\n",
      "        [0.0288],\n",
      "        [0.8223],\n",
      "        [0.0383],\n",
      "        [0.3747],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.8379],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.6555],\n",
      "        [0.5054],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.4611],\n",
      "        [0.3930],\n",
      "        [0.9420],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.3573],\n",
      "        [0.3728],\n",
      "        [0.9967],\n",
      "        [0.9814],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9819],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.0000]])\n",
      "######### Epoch: 96  ######### Train Loss: 0.00011899243691004813  ######### Relative L2 Test Norm: 14.172813415527344\n",
      "Output batch pred: tensor([[[0.6726],\n",
      "         [0.9976],\n",
      "         [0.9982],\n",
      "         [1.0008],\n",
      "         [0.9994],\n",
      "         [0.5487],\n",
      "         [0.2421],\n",
      "         [0.0412],\n",
      "         [0.9621],\n",
      "         [0.9960],\n",
      "         [0.9932],\n",
      "         [0.9940],\n",
      "         [0.9928],\n",
      "         [0.9934],\n",
      "         [0.9907],\n",
      "         [0.9936],\n",
      "         [0.9814],\n",
      "         [0.9955],\n",
      "         [0.9935],\n",
      "         [0.9928],\n",
      "         [0.4570],\n",
      "         [0.0486],\n",
      "         [0.9946],\n",
      "         [0.9946],\n",
      "         [0.3784],\n",
      "         [0.9950],\n",
      "         [0.9960],\n",
      "         [0.4497],\n",
      "         [0.4618],\n",
      "         [0.4477],\n",
      "         [0.3760],\n",
      "         [0.9961],\n",
      "         [0.9957],\n",
      "         [0.9948],\n",
      "         [0.9957],\n",
      "         [0.9942],\n",
      "         [0.7437],\n",
      "         [0.9977],\n",
      "         [0.9229],\n",
      "         [0.9862],\n",
      "         [0.9983],\n",
      "         [0.9955],\n",
      "         [0.9960],\n",
      "         [0.9927],\n",
      "         [0.0455],\n",
      "         [0.3594],\n",
      "         [0.9907],\n",
      "         [0.9901],\n",
      "         [0.5024],\n",
      "         [0.9926],\n",
      "         [0.9951],\n",
      "         [0.9960],\n",
      "         [0.9992],\n",
      "         [0.9969],\n",
      "         [0.4476],\n",
      "         [0.9984],\n",
      "         [0.9988],\n",
      "         [0.9928],\n",
      "         [0.6107],\n",
      "         [0.2561],\n",
      "         [0.9949],\n",
      "         [0.9941],\n",
      "         [0.9954],\n",
      "         [0.9962],\n",
      "         [0.9963],\n",
      "         [0.9983],\n",
      "         [0.8178],\n",
      "         [0.5101],\n",
      "         [0.9988],\n",
      "         [0.9965],\n",
      "         [0.9966],\n",
      "         [0.9965],\n",
      "         [0.8624],\n",
      "         [0.0242],\n",
      "         [0.5010],\n",
      "         [0.9804],\n",
      "         [0.2395],\n",
      "         [0.0384],\n",
      "         [0.9151],\n",
      "         [0.9929],\n",
      "         [0.9947],\n",
      "         [0.8505],\n",
      "         [0.6850],\n",
      "         [0.3389],\n",
      "         [0.9921],\n",
      "         [0.5112],\n",
      "         [0.9711],\n",
      "         [0.3659],\n",
      "         [0.9923],\n",
      "         [0.9919],\n",
      "         [0.1642],\n",
      "         [0.9957],\n",
      "         [0.5004],\n",
      "         [0.9985],\n",
      "         [0.9985],\n",
      "         [1.0001],\n",
      "         [0.9972],\n",
      "         [0.9975],\n",
      "         [0.3666],\n",
      "         [0.4474],\n",
      "         [0.3815],\n",
      "         [0.9972],\n",
      "         [0.4960],\n",
      "         [0.9936],\n",
      "         [0.9924],\n",
      "         [0.9933],\n",
      "         [0.9921],\n",
      "         [0.9559],\n",
      "         [0.3584],\n",
      "         [0.4366],\n",
      "         [0.9944],\n",
      "         [0.9933],\n",
      "         [0.9936],\n",
      "         [0.9937],\n",
      "         [0.9937],\n",
      "         [0.9946],\n",
      "         [0.5135],\n",
      "         [0.8550],\n",
      "         [0.2059],\n",
      "         [0.3434],\n",
      "         [0.9550],\n",
      "         [0.2573],\n",
      "         [1.0002],\n",
      "         [0.8498],\n",
      "         [1.0029],\n",
      "         [1.0028],\n",
      "         [0.5174],\n",
      "         [1.0014],\n",
      "         [0.5105],\n",
      "         [1.0009],\n",
      "         [0.9977],\n",
      "         [0.0332],\n",
      "         [0.7190],\n",
      "         [0.9943],\n",
      "         [0.9925],\n",
      "         [0.6461],\n",
      "         [0.9917],\n",
      "         [0.9797],\n",
      "         [0.9942],\n",
      "         [0.9951],\n",
      "         [0.9944],\n",
      "         [0.9969],\n",
      "         [0.5531],\n",
      "         [0.9987],\n",
      "         [0.5205],\n",
      "         [0.2427],\n",
      "         [0.9968],\n",
      "         [0.0369],\n",
      "         [0.2521],\n",
      "         [0.2460],\n",
      "         [0.9955],\n",
      "         [0.9947],\n",
      "         [0.0374],\n",
      "         [0.9963],\n",
      "         [0.9217],\n",
      "         [0.9970],\n",
      "         [0.9975],\n",
      "         [0.9992],\n",
      "         [0.9627],\n",
      "         [0.4582],\n",
      "         [0.7850],\n",
      "         [0.0540],\n",
      "         [0.9976],\n",
      "         [0.7679],\n",
      "         [0.9957],\n",
      "         [0.2390],\n",
      "         [0.9943],\n",
      "         [0.9941],\n",
      "         [0.9934],\n",
      "         [0.8969],\n",
      "         [0.4520],\n",
      "         [0.9908],\n",
      "         [0.3587],\n",
      "         [0.3550],\n",
      "         [0.4557],\n",
      "         [0.5223],\n",
      "         [0.9267],\n",
      "         [0.9917]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.6555],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5334],\n",
      "        [0.2518],\n",
      "        [0.0209],\n",
      "        [0.9515],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9959],\n",
      "        [0.9995],\n",
      "        [0.9804],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.4645],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.3930],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.4552],\n",
      "        [0.4642],\n",
      "        [0.4527],\n",
      "        [0.3875],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9967],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.9009],\n",
      "        [0.9819],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.0335],\n",
      "        [0.3808],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5108],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.9956],\n",
      "        [0.5945],\n",
      "        [0.2735],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.5054],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.8379],\n",
      "        [0.0000],\n",
      "        [0.5038],\n",
      "        [0.9814],\n",
      "        [0.2577],\n",
      "        [0.0247],\n",
      "        [0.8933],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8223],\n",
      "        [0.6628],\n",
      "        [0.3573],\n",
      "        [0.9999],\n",
      "        [0.5151],\n",
      "        [0.9724],\n",
      "        [0.3840],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.1762],\n",
      "        [1.0000],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [0.4503],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.4988],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9994],\n",
      "        [0.9490],\n",
      "        [0.3780],\n",
      "        [0.4480],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5139],\n",
      "        [0.8296],\n",
      "        [0.2208],\n",
      "        [0.3575],\n",
      "        [0.9420],\n",
      "        [0.2729],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.5080],\n",
      "        [0.9997],\n",
      "        [0.5030],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.6327],\n",
      "        [1.0000],\n",
      "        [0.9820],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.5463],\n",
      "        [0.9998],\n",
      "        [0.5165],\n",
      "        [0.2547],\n",
      "        [1.0000],\n",
      "        [0.0142],\n",
      "        [0.2686],\n",
      "        [0.2646],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.9999],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9520],\n",
      "        [0.4580],\n",
      "        [0.7540],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [0.2610],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.8761],\n",
      "        [0.4611],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.3728],\n",
      "        [0.4668],\n",
      "        [0.5245],\n",
      "        [0.9164],\n",
      "        [0.9997]])\n",
      "######### Epoch: 97  ######### Train Loss: 0.00012888947094324976  ######### Relative L2 Test Norm: 14.20162582397461\n",
      "Output batch pred: tensor([[[0.3670],\n",
      "         [0.9978],\n",
      "         [0.9968],\n",
      "         [0.9968],\n",
      "         [0.9934],\n",
      "         [0.9941],\n",
      "         [0.6520],\n",
      "         [0.9952],\n",
      "         [0.9944],\n",
      "         [0.0436],\n",
      "         [0.4995],\n",
      "         [0.3723],\n",
      "         [0.9886],\n",
      "         [0.9883],\n",
      "         [0.9869],\n",
      "         [0.7999],\n",
      "         [0.2227],\n",
      "         [0.9831],\n",
      "         [0.9857],\n",
      "         [0.9855],\n",
      "         [0.3529],\n",
      "         [0.9877],\n",
      "         [0.9904],\n",
      "         [0.0412],\n",
      "         [0.3801],\n",
      "         [0.9914],\n",
      "         [0.9936],\n",
      "         [0.9953],\n",
      "         [0.5424],\n",
      "         [0.9974],\n",
      "         [0.9570],\n",
      "         [1.0000],\n",
      "         [1.0013],\n",
      "         [0.3513],\n",
      "         [0.5401],\n",
      "         [1.0031],\n",
      "         [0.9996],\n",
      "         [0.9397],\n",
      "         [0.9988],\n",
      "         [0.9962],\n",
      "         [0.9958],\n",
      "         [0.9935],\n",
      "         [0.9924],\n",
      "         [0.9927],\n",
      "         [0.4323],\n",
      "         [0.0414],\n",
      "         [0.9938],\n",
      "         [0.3374],\n",
      "         [0.9203],\n",
      "         [0.9960],\n",
      "         [0.9967],\n",
      "         [0.9016],\n",
      "         [0.9949],\n",
      "         [0.6107],\n",
      "         [0.9959],\n",
      "         [0.9944],\n",
      "         [0.2412],\n",
      "         [0.2473],\n",
      "         [0.5137],\n",
      "         [0.4982],\n",
      "         [0.9914],\n",
      "         [0.9922],\n",
      "         [0.9918],\n",
      "         [0.9924],\n",
      "         [0.0373],\n",
      "         [0.9179],\n",
      "         [0.2021],\n",
      "         [0.9961],\n",
      "         [0.9973],\n",
      "         [0.9975],\n",
      "         [0.9966],\n",
      "         [0.9985],\n",
      "         [0.9979],\n",
      "         [0.9968],\n",
      "         [0.9973],\n",
      "         [0.3678],\n",
      "         [0.7678],\n",
      "         [0.9951],\n",
      "         [0.9975],\n",
      "         [0.4433],\n",
      "         [0.9983],\n",
      "         [0.9969],\n",
      "         [0.9970],\n",
      "         [0.9623],\n",
      "         [0.9978],\n",
      "         [0.9773],\n",
      "         [0.5005],\n",
      "         [0.9849],\n",
      "         [0.9947],\n",
      "         [0.9987],\n",
      "         [0.9986],\n",
      "         [0.2407],\n",
      "         [0.0248],\n",
      "         [0.3631],\n",
      "         [0.9870],\n",
      "         [0.7244],\n",
      "         [0.1665],\n",
      "         [0.4430],\n",
      "         [0.9958],\n",
      "         [0.5510],\n",
      "         [0.9919],\n",
      "         [0.9914],\n",
      "         [0.0339],\n",
      "         [0.9555],\n",
      "         [0.8469],\n",
      "         [0.9932],\n",
      "         [0.0434],\n",
      "         [0.5151],\n",
      "         [0.4949],\n",
      "         [0.9938],\n",
      "         [0.0538],\n",
      "         [0.0413],\n",
      "         [0.5108],\n",
      "         [0.3714],\n",
      "         [0.4488],\n",
      "         [0.9943],\n",
      "         [0.9129],\n",
      "         [0.9889],\n",
      "         [0.9939],\n",
      "         [0.9939],\n",
      "         [0.2545],\n",
      "         [0.6735],\n",
      "         [0.9927],\n",
      "         [0.9930],\n",
      "         [0.7802],\n",
      "         [0.9961],\n",
      "         [0.9961],\n",
      "         [0.9974],\n",
      "         [0.9982],\n",
      "         [0.9972],\n",
      "         [0.9959],\n",
      "         [0.9962],\n",
      "         [0.9952],\n",
      "         [0.3687],\n",
      "         [0.7389],\n",
      "         [0.9941],\n",
      "         [0.5058],\n",
      "         [0.9822],\n",
      "         [0.4626],\n",
      "         [0.9984],\n",
      "         [1.0004],\n",
      "         [1.0021],\n",
      "         [0.8668],\n",
      "         [0.4718],\n",
      "         [1.0026],\n",
      "         [1.0007],\n",
      "         [0.9985],\n",
      "         [0.4559],\n",
      "         [1.0002],\n",
      "         [0.9840],\n",
      "         [0.9976],\n",
      "         [0.9982],\n",
      "         [0.9973],\n",
      "         [0.4641],\n",
      "         [0.4572],\n",
      "         [0.5023],\n",
      "         [0.9913],\n",
      "         [0.2563],\n",
      "         [0.9565],\n",
      "         [0.9919],\n",
      "         [0.3593],\n",
      "         [0.9949],\n",
      "         [0.9942],\n",
      "         [0.5128],\n",
      "         [0.9994],\n",
      "         [1.0003],\n",
      "         [0.8688],\n",
      "         [0.6952],\n",
      "         [0.4550],\n",
      "         [0.2522],\n",
      "         [0.2576],\n",
      "         [0.9981],\n",
      "         [0.9956],\n",
      "         [0.8448],\n",
      "         [0.9968],\n",
      "         [0.9961],\n",
      "         [0.9960],\n",
      "         [0.9964]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.3780],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9966],\n",
      "        [0.6327],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0335],\n",
      "        [0.5054],\n",
      "        [0.3912],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7820],\n",
      "        [0.2518],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.3753],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0209],\n",
      "        [0.3930],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5334],\n",
      "        [1.0000],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.3575],\n",
      "        [0.5245],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.9164],\n",
      "        [0.9994],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.4454],\n",
      "        [0.0368],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [0.9044],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.9998],\n",
      "        [0.5945],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2577],\n",
      "        [0.2646],\n",
      "        [0.5165],\n",
      "        [0.5038],\n",
      "        [0.9996],\n",
      "        [0.9998],\n",
      "        [0.9995],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.9009],\n",
      "        [0.2208],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.3808],\n",
      "        [0.7391],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.4503],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9515],\n",
      "        [0.9998],\n",
      "        [0.9724],\n",
      "        [0.5009],\n",
      "        [0.9819],\n",
      "        [0.9959],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.0000],\n",
      "        [0.3728],\n",
      "        [0.9820],\n",
      "        [0.6920],\n",
      "        [0.1762],\n",
      "        [0.4480],\n",
      "        [0.9997],\n",
      "        [0.5463],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.0142],\n",
      "        [0.9520],\n",
      "        [0.8223],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [0.5151],\n",
      "        [0.4988],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [0.0247],\n",
      "        [0.5139],\n",
      "        [0.3875],\n",
      "        [0.4580],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.9956],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.2729],\n",
      "        [0.6555],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [0.9997],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3840],\n",
      "        [0.7129],\n",
      "        [1.0000],\n",
      "        [0.5080],\n",
      "        [0.9804],\n",
      "        [0.4642],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.4645],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9962],\n",
      "        [0.4552],\n",
      "        [1.0000],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.4668],\n",
      "        [0.4611],\n",
      "        [0.5030],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.9490],\n",
      "        [1.0000],\n",
      "        [0.3747],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.5108],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.8379],\n",
      "        [0.6628],\n",
      "        [0.4527],\n",
      "        [0.2610],\n",
      "        [0.2686],\n",
      "        [1.0000],\n",
      "        [0.9967],\n",
      "        [0.8139],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998]])\n",
      "######### Epoch: 98  ######### Train Loss: 0.00013706267054658383  ######### Relative L2 Test Norm: 14.120138168334961\n",
      "Output batch pred: tensor([[[0.9908],\n",
      "         [0.9921],\n",
      "         [0.9926],\n",
      "         [0.9774],\n",
      "         [0.9940],\n",
      "         [0.0355],\n",
      "         [0.9944],\n",
      "         [0.9941],\n",
      "         [0.9941],\n",
      "         [0.3449],\n",
      "         [0.8611],\n",
      "         [0.8118],\n",
      "         [0.4997],\n",
      "         [0.9944],\n",
      "         [0.9962],\n",
      "         [0.9600],\n",
      "         [0.9964],\n",
      "         [0.9968],\n",
      "         [0.9966],\n",
      "         [0.6545],\n",
      "         [0.3659],\n",
      "         [0.9822],\n",
      "         [0.5178],\n",
      "         [0.9963],\n",
      "         [0.9974],\n",
      "         [0.9977],\n",
      "         [0.8490],\n",
      "         [0.9586],\n",
      "         [0.9989],\n",
      "         [0.9976],\n",
      "         [0.9035],\n",
      "         [0.4587],\n",
      "         [0.8509],\n",
      "         [0.9897],\n",
      "         [0.9895],\n",
      "         [0.9888],\n",
      "         [0.2389],\n",
      "         [0.9912],\n",
      "         [0.9932],\n",
      "         [0.4458],\n",
      "         [0.9950],\n",
      "         [0.9956],\n",
      "         [0.0406],\n",
      "         [0.9949],\n",
      "         [0.3792],\n",
      "         [0.9298],\n",
      "         [0.9788],\n",
      "         [0.6712],\n",
      "         [0.7638],\n",
      "         [0.9911],\n",
      "         [0.9939],\n",
      "         [0.9959],\n",
      "         [0.1684],\n",
      "         [0.9986],\n",
      "         [0.9981],\n",
      "         [0.9195],\n",
      "         [0.9801],\n",
      "         [0.9981],\n",
      "         [0.9971],\n",
      "         [0.9955],\n",
      "         [0.9943],\n",
      "         [0.5239],\n",
      "         [0.9547],\n",
      "         [0.9895],\n",
      "         [0.9899],\n",
      "         [0.9913],\n",
      "         [0.9898],\n",
      "         [0.4361],\n",
      "         [0.2455],\n",
      "         [0.2400],\n",
      "         [0.9917],\n",
      "         [0.9942],\n",
      "         [0.9951],\n",
      "         [0.9971],\n",
      "         [0.9963],\n",
      "         [0.3807],\n",
      "         [0.9980],\n",
      "         [0.9978],\n",
      "         [0.2623],\n",
      "         [0.9947],\n",
      "         [0.9961],\n",
      "         [0.9959],\n",
      "         [0.7416],\n",
      "         [0.0486],\n",
      "         [0.9984],\n",
      "         [0.0527],\n",
      "         [0.9991],\n",
      "         [0.9997],\n",
      "         [1.0014],\n",
      "         [0.5233],\n",
      "         [0.3766],\n",
      "         [0.9979],\n",
      "         [0.9959],\n",
      "         [0.9939],\n",
      "         [0.4432],\n",
      "         [0.0353],\n",
      "         [0.9946],\n",
      "         [0.9953],\n",
      "         [0.5022],\n",
      "         [0.4385],\n",
      "         [0.5058],\n",
      "         [0.9965],\n",
      "         [0.9978],\n",
      "         [0.2381],\n",
      "         [0.3585],\n",
      "         [0.9827],\n",
      "         [0.9936],\n",
      "         [0.9938],\n",
      "         [0.9930],\n",
      "         [0.7760],\n",
      "         [0.9934],\n",
      "         [0.9949],\n",
      "         [0.0464],\n",
      "         [0.5374],\n",
      "         [0.0355],\n",
      "         [0.9969],\n",
      "         [0.3774],\n",
      "         [0.9970],\n",
      "         [0.9217],\n",
      "         [0.5171],\n",
      "         [0.9963],\n",
      "         [0.9965],\n",
      "         [0.4468],\n",
      "         [0.9959],\n",
      "         [0.4530],\n",
      "         [0.9960],\n",
      "         [0.2529],\n",
      "         [0.9939],\n",
      "         [0.2352],\n",
      "         [0.9935],\n",
      "         [0.5488],\n",
      "         [0.9578],\n",
      "         [0.9943],\n",
      "         [0.4601],\n",
      "         [0.5055],\n",
      "         [0.9950],\n",
      "         [0.9945],\n",
      "         [0.6868],\n",
      "         [0.9939],\n",
      "         [0.9974],\n",
      "         [0.0458],\n",
      "         [0.9977],\n",
      "         [0.5122],\n",
      "         [0.3695],\n",
      "         [0.9972],\n",
      "         [0.9981],\n",
      "         [0.3676],\n",
      "         [0.3649],\n",
      "         [0.9968],\n",
      "         [0.9971],\n",
      "         [0.9936],\n",
      "         [0.9954],\n",
      "         [0.4974],\n",
      "         [0.7201],\n",
      "         [0.9970],\n",
      "         [0.9977],\n",
      "         [0.9978],\n",
      "         [0.9989],\n",
      "         [0.6148],\n",
      "         [0.2094],\n",
      "         [0.2601],\n",
      "         [0.0232],\n",
      "         [0.9996],\n",
      "         [0.9995],\n",
      "         [0.9957],\n",
      "         [0.9979],\n",
      "         [0.9982],\n",
      "         [0.5038],\n",
      "         [0.4620],\n",
      "         [0.9221],\n",
      "         [0.9973],\n",
      "         [0.3459],\n",
      "         [0.9950],\n",
      "         [0.8570],\n",
      "         [0.9941],\n",
      "         [0.4585],\n",
      "         [0.9875],\n",
      "         [0.9916]]], grad_fn=<ViewBackward0>)\n",
      "Output batch: tensor([[0.9998],\n",
      "        [1.0000],\n",
      "        [0.9996],\n",
      "        [0.9814],\n",
      "        [1.0000],\n",
      "        [0.0174],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.3575],\n",
      "        [0.8379],\n",
      "        [0.7820],\n",
      "        [0.5009],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9520],\n",
      "        [0.9998],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.6327],\n",
      "        [0.3753],\n",
      "        [0.9804],\n",
      "        [0.5139],\n",
      "        [1.0000],\n",
      "        [0.9997],\n",
      "        [0.9998],\n",
      "        [0.8139],\n",
      "        [0.9420],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.8761],\n",
      "        [0.4611],\n",
      "        [0.8223],\n",
      "        [0.9959],\n",
      "        [0.9966],\n",
      "        [0.9997],\n",
      "        [0.2610],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.4552],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.0247],\n",
      "        [1.0000],\n",
      "        [0.3930],\n",
      "        [0.9164],\n",
      "        [0.9820],\n",
      "        [0.6555],\n",
      "        [0.7391],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.1762],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.8933],\n",
      "        [0.9724],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.5245],\n",
      "        [0.9490],\n",
      "        [0.9967],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.4480],\n",
      "        [0.2646],\n",
      "        [0.2577],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.9999],\n",
      "        [0.9998],\n",
      "        [0.3875],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2735],\n",
      "        [0.9998],\n",
      "        [0.9996],\n",
      "        [1.0000],\n",
      "        [0.7129],\n",
      "        [0.0335],\n",
      "        [0.9998],\n",
      "        [0.0383],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.5165],\n",
      "        [0.3840],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9998],\n",
      "        [0.4503],\n",
      "        [0.0142],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [0.5038],\n",
      "        [0.4454],\n",
      "        [0.5054],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.2547],\n",
      "        [0.3728],\n",
      "        [0.9819],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.7540],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0368],\n",
      "        [0.5334],\n",
      "        [0.0209],\n",
      "        [1.0000],\n",
      "        [0.3912],\n",
      "        [1.0000],\n",
      "        [0.9044],\n",
      "        [0.5151],\n",
      "        [0.9998],\n",
      "        [0.9998],\n",
      "        [0.4527],\n",
      "        [0.9998],\n",
      "        [0.4580],\n",
      "        [0.9998],\n",
      "        [0.2686],\n",
      "        [0.9995],\n",
      "        [0.2518],\n",
      "        [0.9999],\n",
      "        [0.5463],\n",
      "        [0.9515],\n",
      "        [1.0000],\n",
      "        [0.4668],\n",
      "        [0.5080],\n",
      "        [0.9994],\n",
      "        [0.9999],\n",
      "        [0.6628],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0288],\n",
      "        [0.9997],\n",
      "        [0.5108],\n",
      "        [0.3808],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.3780],\n",
      "        [0.3747],\n",
      "        [0.9997],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [0.4988],\n",
      "        [0.6920],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9994],\n",
      "        [1.0000],\n",
      "        [0.5945],\n",
      "        [0.2208],\n",
      "        [0.2729],\n",
      "        [0.0000],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [0.9962],\n",
      "        [1.0000],\n",
      "        [0.9999],\n",
      "        [0.5030],\n",
      "        [0.4645],\n",
      "        [0.9009],\n",
      "        [1.0000],\n",
      "        [0.3573],\n",
      "        [1.0000],\n",
      "        [0.8296],\n",
      "        [0.9998],\n",
      "        [0.4642],\n",
      "        [0.9956],\n",
      "        [1.0000]])\n",
      "######### Epoch: 99  ######### Train Loss: 0.00011785849346779287  ######### Relative L2 Test Norm: 14.072036743164062\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "optimizer = Adam(fno.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "l = torch.nn.MSELoss()\n",
    "freq_print = 1\n",
    "for epoch in range(epochs):\n",
    "    train_mse = 0.0\n",
    "    for step, (input_batch, output_batch) in enumerate(training_set_tf0):\n",
    "        optimizer.zero_grad()\n",
    "        # print(input_batch.shape)\n",
    "        # print(fno(input_batch).shape)\n",
    "        output_pred_batch = fno(input_batch)\n",
    "        print(\"Output batch pred: {}\".format(output_pred_batch))\n",
    "        print(\"Output batch: {}\".format(output_batch))\n",
    "        loss_f = l(output_pred_batch, output_batch)\n",
    "        loss_f.backward()\n",
    "        optimizer.step()\n",
    "        train_mse += loss_f.item()\n",
    "    train_mse /= len(training_set_tf0)\n",
    "    # print(train_mse)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # print(\"=========\")\n",
    "        # print(\"Testing Set\")\n",
    "        fno.eval()\n",
    "        test_relative_l2 = 0.0\n",
    "        for step, (input_batch, output_batch) in enumerate(testing_set_tf0):\n",
    "            output_pred_batch = fno(input_batch)\n",
    "            loss_f = (torch.mean((output_pred_batch - output_batch) ** 2) / torch.mean(output_batch ** 2)) ** 0.5 * 100\n",
    "            test_relative_l2 += loss_f.item()\n",
    "        test_relative_l2 /= len(testing_set_tf0)\n",
    "\n",
    "    if epoch % freq_print == 0: print(\"######### Epoch:\", epoch, \" ######### Train Loss:\", train_mse, \" ######### Relative L2 Test Norm:\", test_relative_l2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_data = 4\n",
    "input_function_train_n = input_train\n",
    "output_function_train_tf = Tf0_train\n",
    "\n",
    "\n",
    "output_function_train_pred_n = fno(input_function_train_n)\n",
    "# print(output_function_test_pred_n.shape)\n",
    "output_function_train_pred_n = output_function_train_pred_n.detach()[0,:,0]\n",
    "print(output_function_train_pred_n.shape)\n",
    "print(input_function_train_n[:,0].shape)\n",
    "# print(input_function_test_n[0,:,1])\n",
    "plt.figure(dpi=250)\n",
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.scatter(input_function_train_n[:,0], output_function_train_pred_n, label=\"Approximate Solution\", s=2, c=\"red\")\n",
    "plt.plot(input_function_train_n, output_function_train_tf, label=\"True Solution\", c=\"C0\", lw=2)\n",
    "p = 2\n",
    "err = (torch.mean(abs(output_function_train_tf.detach().reshape(-1, ) - output_function_train_pred_n.detach().reshape(-1, )) ** p) / torch.mean(abs(output_function_train_tf.detach()) ** p)) ** (1 / p) * 100\n",
    "print(\"Relative L2 error: \", err.item())\n",
    "plt.legend()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer with 1D Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(fno.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "l = torch.nn.MSELoss()\n",
    "freq_print = 1\n",
    "for epoch in range(epochs):\n",
    "    train_mse = 0.0\n",
    "    for step, (input_batch, output_batch) in enumerate(training_set_tf0):\n",
    "        optimizer.zero_grad()\n",
    "        # print(input_batch.shape)\n",
    "        # print(fno(input_batch).shape)\n",
    "        output_pred_batch = fno(input_batch).squeeze(2) # gives you the prediction of T_s or T_f\n",
    "        print(output_pred_batch)\n",
    "        print(output_batch)\n",
    "        loss_f = l(output_pred_batch, output_batch)\n",
    "        loss_f.backward()\n",
    "        optimizer.step()\n",
    "        train_mse += loss_f.item()\n",
    "    train_mse /= len(training_set_tf0)\n",
    "    # print(train_mse)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # print(\"=========\")\n",
    "        # print(\"Testing Set\")\n",
    "        fno.eval()\n",
    "        test_relative_l2 = 0.0\n",
    "        for step, (input_batch, output_batch) in enumerate(testing_set_tf0):\n",
    "            output_pred_batch = fno(input_batch).squeeze(2)\n",
    "            loss_f = (torch.mean((output_pred_batch - output_batch) ** 2) / torch.mean(output_batch ** 2)) ** 0.5 * 100\n",
    "            test_relative_l2 += loss_f.item()\n",
    "        test_relative_l2 /= len(testing_set_tf0)\n",
    "\n",
    "    if epoch % freq_print == 0: print(\"######### Epoch:\", epoch, \" ######### Train Loss:\", train_mse, \" ######### Relative L2 Test Norm:\", test_relative_l2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_data = 4\n",
    "input_function_train_n = input_data_train\n",
    "output_function_train_tf = Tf0_train\n",
    "\n",
    "plt.plot(input_function_train_n, output_function_train_tf, label=\"True Solution\", c=\"C0\", lw=2)\n",
    "output_function_train_pred_n = fno(input_function_train_n)\n",
    "# print(output_function_test_pred_n.shape)\n",
    "output_function_train_pred_n = output_function_train_pred_n.detach()[0,:,0]\n",
    "print(output_function_train_pred_n.shape)\n",
    "print(input_function_train_n[:,0].shape)\n",
    "# print(input_function_test_n[0,:,1])\n",
    "plt.figure(dpi=250)\n",
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.scatter(input_function_train_n[:,0], output_function_train_pred_n, label=\"Approximate Solution\", s=8, c=\"C0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_function_test_n = input_data_test\n",
    "output_function_test_tf = Tf0_test\n",
    "\n",
    "plt.plot(input_function_test_n, output_function_test_tf, label=\"True Solution\", c=\"C0\", lw=2)\n",
    "output_function_test_pred_n = fno(input_function_test_n)\n",
    "# print(output_function_test_pred_n.shape)\n",
    "output_function_test_pred_n = output_function_test_pred_n.detach()[0,:,0]\n",
    "print(output_function_test_pred_n.shape)\n",
    "print(input_function_test_n[:,0].shape)\n",
    "# print(input_function_test_n[0,:,1])\n",
    "plt.figure(dpi=250)\n",
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.scatter(input_function_test_n[:,0], output_function_test_pred_n, label=\"Approximate Solution\", s=8, c=\"C0\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNO 2D Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "#  2d fourier layer\n",
    "################################################################\n",
    "class SpectralConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
    "        super(SpectralConv2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1  # Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = modes2\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul2d(self, input, weights):\n",
    "        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
    "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        # Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfft2(x)\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-2), x.size(-1) // 2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
    "\n",
    "        # Return to physical space\n",
    "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class FNO2d(nn.Module):\n",
    "    def __init__(self, fno_architecture, device=None, padding_frac=1 / 4):\n",
    "        super(FNO2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "\n",
    "        input: the solution of the coefficient function and locations (a(x, y), x, y)\n",
    "        input shape: (batchsize, x=s, y=s, c=3)\n",
    "        output: the solution \n",
    "        output shape: (batchsize, x=s, y=s, c=1)\n",
    "        \"\"\"\n",
    "        self.modes1 = fno_architecture[\"modes\"]\n",
    "        self.modes2 = fno_architecture[\"modes\"]\n",
    "        self.width = fno_architecture[\"width\"]\n",
    "        self.n_layers = fno_architecture[\"n_layers\"]\n",
    "        self.retrain_fno = fno_architecture[\"retrain_fno\"]\n",
    "\n",
    "        torch.manual_seed(self.retrain_fno)\n",
    "        # self.padding = 9 # pad the domain if input is non-periodic\n",
    "        self.padding_frac = padding_frac\n",
    "        self.fc0 = nn.Linear(3, self.width)  # input channel is 3: (a(x, y), x, y)\n",
    "        \n",
    "        self.conv_list = nn.ModuleList(\n",
    "            [nn.Conv2d(self.width, self.width, 1) for _ in range(self.n_layers)])\n",
    "        self.spectral_list = nn.ModuleList(\n",
    "            [SpectralConv2d(self.width, self.width, self.modes1, self.modes2) for _ in range(self.n_layers)])\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc0(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        x1_padding = int(round(x.shape[-1] * self.padding_frac))\n",
    "        x2_padding = int(round(x.shape[-2] * self.padding_frac))\n",
    "        x = F.pad(x, [0, x1_padding, 0, x2_padding])\n",
    "\n",
    "        for k, (s, c) in enumerate(zip(self.spectral_list, self.conv_list)):\n",
    "\n",
    "            x1 = s(x)\n",
    "            x2 = c(x)\n",
    "            x = x1 + x2\n",
    "            if k != self.n_layers - 1:\n",
    "                x = F.gelu(x)\n",
    "        x = x[..., :-x1_padding, :-x2_padding]\n",
    "\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
